{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae\n",
    "#plt.switch_backend('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: \n",
      "b'2014040101'\n",
      " shape:(4392,) \n",
      " in_flow:\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 4. 1. 1. 0. 0.]\n",
      " [0. 0. 2. 5. 0. 2. 2. 0.]\n",
      " [0. 0. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 3. 1. 4. 2. 0. 0.]\n",
      " [0. 3. 3. 6. 3. 0. 0. 0.]\n",
      " [0. 2. 6. 5. 5. 0. 0. 0.]\n",
      " [0. 6. 3. 8. 1. 0. 0. 0.]\n",
      " [0. 2. 0. 2. 0. 0. 0. 0.]\n",
      " [3. 4. 5. 0. 1. 0. 1. 0.]\n",
      " [0. 2. 2. 1. 0. 0. 2. 1.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 3. 1. 0.]\n",
      " [0. 0. 0. 1. 2. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1.]] \n",
      " out_flow: \n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 3. 2. 1. 0. 0.]\n",
      " [0. 0. 0. 3. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 2. 1. 0. 0. 0.]\n",
      " [0. 4. 2. 1. 2. 0. 0. 0.]\n",
      " [0. 1. 5. 5. 3. 0. 0. 0.]\n",
      " [0. 2. 5. 3. 4. 0. 0. 0.]\n",
      " [0. 2. 4. 7. 0. 0. 0. 0.]\n",
      " [1. 1. 2. 9. 1. 0. 0. 0.]\n",
      " [1. 1. 2. 2. 1. 0. 2. 0.]\n",
      " [1. 2. 2. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 2. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 2. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "(4392, 2, 16, 8)\n"
     ]
    }
   ],
   "source": [
    "f_data = h5py.File(\"./BikeNYC/NYC14_M16x8_T60_NewEnd.h5\")\n",
    "BikeNYC_date = f_data['date']\n",
    "BikeNYC_data = f_data['data']\n",
    "print(f'date: \\n{BikeNYC_date[0]}\\n shape:{BikeNYC_date.shape} \\n in_flow:\\n{BikeNYC_data[0][0]} \\n out_flow: \\n{BikeNYC_data[0][1]}')\n",
    "print(BikeNYC_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3074, 16, 8) (439, 16, 8) (879, 16, 8)\n",
      "(3067, 7, 16, 8)\n",
      "(432, 7, 16, 8)\n",
      "(872, 7, 16, 8)\n",
      "(3067, 7, 128)\n",
      "(432, 7, 128)\n",
      "(872, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "#读取数据集，进行划分\n",
    "def sliding_window(seq,window_size):\n",
    "    result = []\n",
    "    for i in range(seq.shape[0]- window_size):\n",
    "        result.append(seq[i: i+window_size])\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "\n",
    "def MLPreshape(set):\n",
    "    set = set.reshape((set.shape[0],set.shape[1],-1))\n",
    "    return set\n",
    "\n",
    "data_num = BikeNYC_date.shape[0]\n",
    "flow_in_num = 0\n",
    "train_seq = BikeNYC_data[:int(data_num*0.7),flow_in_num,:,:]\n",
    "validation_seq = BikeNYC_data[int(data_num*0.7):int(data_num*0.8),flow_in_num,:,:]\n",
    "test_seq = BikeNYC_data[int(data_num*0.8):,flow_in_num,:,:]\n",
    "print(train_seq.shape,validation_seq.shape,test_seq.shape)\n",
    "\n",
    "window_size = 7\n",
    "train_set = sliding_window(train_seq, window_size)\n",
    "validation_set = sliding_window(validation_seq, window_size)\n",
    "test_set = sliding_window(test_seq, window_size)\n",
    "print(train_set.shape)\n",
    "print(validation_set.shape)\n",
    "print(test_set.shape)\n",
    "\n",
    "train_set = MLPreshape(train_set)\n",
    "validation_set = MLPreshape(validation_set)\n",
    "test_set = MLPreshape(test_set)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(validation_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "torch_lstm = nn.LSTM(input_size=16*8, hidden_size=64, num_layers=1, batch_first=True)\n",
    "output_model = nn.Linear(64, 16*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(list(torch_lstm.parameters()) + list(output_model.parameters()), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#保存打印文件\n",
    "f = open(\"1.4torchLSTM.txt\", 'a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_index = (y_true > 0)\n",
    "    y_true = y_true[non_zero_index]\n",
    "    y_pred = y_pred[non_zero_index]\n",
    "\n",
    "    mape = np.abs((y_true - y_pred) / y_true)\n",
    "    mape[np.isinf(mape)] = 0\n",
    "    return np.mean(mape) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def next_batch(data, batch_size):\n",
    "    data_length = data.shape[0]\n",
    "    num_batches = math.ceil(data_length / batch_size)\n",
    "    for batch_index in range(num_batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = min((batch_index + 1) * batch_size, data_length)\n",
    "        yield data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1, train_loss 394.258759,Time used 0.033000s\n",
      "batch 2, train_loss 511.771667,Time used 0.010000s\n",
      "batch 3, train_loss 472.095856,Time used 0.009001s\n",
      "batch 4, train_loss 420.946655,Time used 0.008999s\n",
      "batch 5, train_loss 443.025238,Time used 0.010010s\n",
      "batch 6, train_loss 450.790558,Time used 0.010989s\n",
      "batch 7, train_loss 368.397614,Time used 0.011003s\n",
      "batch 8, train_loss 403.211639,Time used 0.012035s\n",
      "batch 9, train_loss 329.305603,Time used 0.009964s\n",
      "batch 10, train_loss 404.312744,Time used 0.008001s\n",
      "batch 11, train_loss 386.546997,Time used 0.009003s\n",
      "batch 12, train_loss 349.606293,Time used 0.008997s\n",
      "batch 13, train_loss 462.595734,Time used 0.010001s\n",
      "batch 14, train_loss 330.679291,Time used 0.008003s\n",
      "batch 15, train_loss 379.978088,Time used 0.011996s\n",
      "batch 16, train_loss 393.733429,Time used 0.010016s\n",
      "batch 17, train_loss 440.561584,Time used 0.009983s\n",
      "batch 18, train_loss 313.672974,Time used 0.011002s\n",
      "batch 19, train_loss 382.124542,Time used 0.010002s\n",
      "batch 20, train_loss 530.991638,Time used 0.010001s\n",
      "batch 21, train_loss 384.129242,Time used 0.008001s\n",
      "batch 22, train_loss 411.218018,Time used 0.007998s\n",
      "batch 23, train_loss 442.334686,Time used 0.007998s\n",
      "batch 24, train_loss 452.255646,Time used 0.007003s\n",
      "batch 25, train_loss 352.801971,Time used 0.010002s\n",
      "batch 26, train_loss 436.116821,Time used 0.012998s\n",
      "batch 27, train_loss 408.746124,Time used 0.008002s\n",
      "batch 28, train_loss 389.811188,Time used 0.009010s\n",
      "batch 29, train_loss 450.008179,Time used 0.009988s\n",
      "batch 30, train_loss 322.554932,Time used 0.010002s\n",
      "batch 31, train_loss 380.538086,Time used 0.008996s\n",
      "batch 32, train_loss 397.026764,Time used 0.007000s\n",
      "batch 33, train_loss 335.946899,Time used 0.008003s\n",
      "batch 34, train_loss 386.499237,Time used 0.006996s\n",
      "batch 35, train_loss 398.867371,Time used 0.008004s\n",
      "batch 36, train_loss 436.056488,Time used 0.007999s\n",
      "batch 37, train_loss 415.758667,Time used 0.012000s\n",
      "batch 38, train_loss 395.829071,Time used 0.009998s\n",
      "batch 39, train_loss 451.717926,Time used 0.011000s\n",
      "batch 40, train_loss 359.180634,Time used 0.010000s\n",
      "batch 41, train_loss 385.829590,Time used 0.010001s\n",
      "batch 42, train_loss 314.203033,Time used 0.008997s\n",
      "batch 43, train_loss 431.472504,Time used 0.010002s\n",
      "batch 44, train_loss 522.693054,Time used 0.008000s\n",
      "batch 45, train_loss 414.216248,Time used 0.009004s\n",
      "batch 46, train_loss 454.570404,Time used 0.009001s\n",
      "batch 47, train_loss 453.938599,Time used 0.009000s\n",
      "batch 48, train_loss 511.592377,Time used 0.009996s\n",
      "batch 49, train_loss 396.410217,Time used 0.006997s\n",
      "batch 50, train_loss 444.430481,Time used 0.007002s\n",
      "batch 51, train_loss 479.344727,Time used 0.007000s\n",
      "batch 52, train_loss 406.749512,Time used 0.006998s\n",
      "batch 53, train_loss 410.704559,Time used 0.008000s\n",
      "batch 54, train_loss 476.613495,Time used 0.008002s\n",
      "batch 55, train_loss 346.786469,Time used 0.008999s\n",
      "batch 56, train_loss 399.141418,Time used 0.006000s\n",
      "batch 57, train_loss 378.213135,Time used 0.007999s\n",
      "batch 58, train_loss 508.280609,Time used 0.007000s\n",
      "batch 59, train_loss 392.974243,Time used 0.008999s\n",
      "batch 60, train_loss 504.065277,Time used 0.006999s\n",
      "batch 61, train_loss 373.538208,Time used 0.009001s\n",
      "batch 62, train_loss 329.751038,Time used 0.005999s\n",
      "batch 63, train_loss 440.615692,Time used 0.008000s\n",
      "batch 64, train_loss 428.747131,Time used 0.011003s\n",
      "batch 65, train_loss 307.253723,Time used 0.008004s\n",
      "batch 66, train_loss 429.304932,Time used 0.007000s\n",
      "batch 67, train_loss 336.045197,Time used 0.009001s\n",
      "batch 68, train_loss 436.377197,Time used 0.009998s\n",
      "batch 69, train_loss 375.312927,Time used 0.007000s\n",
      "batch 70, train_loss 370.052826,Time used 0.008000s\n",
      "batch 71, train_loss 381.215759,Time used 0.009001s\n",
      "batch 72, train_loss 380.880249,Time used 0.007999s\n",
      "batch 73, train_loss 362.809570,Time used 0.011000s\n",
      "batch 74, train_loss 461.141388,Time used 0.008999s\n",
      "batch 75, train_loss 426.051849,Time used 0.011003s\n",
      "batch 76, train_loss 344.666077,Time used 0.009998s\n",
      "batch 77, train_loss 373.074707,Time used 0.010001s\n",
      "batch 78, train_loss 501.330109,Time used 0.008000s\n",
      "batch 79, train_loss 472.069366,Time used 0.008001s\n",
      "batch 80, train_loss 417.638367,Time used 0.007000s\n",
      "batch 81, train_loss 350.502075,Time used 0.010000s\n",
      "batch 82, train_loss 414.762756,Time used 0.009999s\n",
      "batch 83, train_loss 374.030579,Time used 0.012000s\n",
      "batch 84, train_loss 457.727600,Time used 0.007001s\n",
      "batch 85, train_loss 403.933197,Time used 0.009998s\n",
      "batch 86, train_loss 383.057404,Time used 0.010003s\n",
      "batch 87, train_loss 395.652802,Time used 0.012015s\n",
      "batch 88, train_loss 392.582458,Time used 0.008983s\n",
      "batch 89, train_loss 384.473785,Time used 0.009000s\n",
      "batch 90, train_loss 375.544891,Time used 0.009998s\n",
      "batch 91, train_loss 371.669830,Time used 0.008000s\n",
      "batch 92, train_loss 346.577179,Time used 0.008002s\n",
      "batch 93, train_loss 301.717621,Time used 0.011999s\n",
      "batch 94, train_loss 403.615692,Time used 0.011002s\n",
      "batch 95, train_loss 509.177246,Time used 0.009001s\n",
      "batch 96, train_loss 426.200714,Time used 0.008996s\n",
      "batch 97, train_loss 430.939941,Time used 0.012000s\n",
      "batch 98, train_loss 377.476196,Time used 0.009997s\n",
      "batch 99, train_loss 375.123077,Time used 0.006999s\n",
      "batch 100, train_loss 313.723999,Time used 0.010998s\n",
      "***************************test_batch 100, test_rmse_loss 22.048754,test_mae_loss 10.057538,test_mape_loss 87.926899,Time used 0.039003s\n",
      "batch 101, train_loss 328.660278,Time used 0.009000s\n",
      "batch 102, train_loss 494.389008,Time used 0.011011s\n",
      "batch 103, train_loss 385.378448,Time used 0.010000s\n",
      "batch 104, train_loss 405.077362,Time used 0.007996s\n",
      "batch 105, train_loss 409.660553,Time used 0.010000s\n",
      "batch 106, train_loss 421.325043,Time used 0.010999s\n",
      "batch 107, train_loss 449.000793,Time used 0.010008s\n",
      "batch 108, train_loss 517.182373,Time used 0.009001s\n",
      "batch 109, train_loss 453.768250,Time used 0.006999s\n",
      "batch 110, train_loss 363.354156,Time used 0.008002s\n",
      "batch 111, train_loss 322.667206,Time used 0.009999s\n",
      "batch 112, train_loss 380.160767,Time used 0.007999s\n",
      "batch 113, train_loss 336.319916,Time used 0.007000s\n",
      "batch 114, train_loss 355.596191,Time used 0.007001s\n",
      "batch 115, train_loss 424.160004,Time used 0.008001s\n",
      "batch 116, train_loss 436.812805,Time used 0.006999s\n",
      "batch 117, train_loss 442.947693,Time used 0.006000s\n",
      "batch 118, train_loss 378.774994,Time used 0.008999s\n",
      "batch 119, train_loss 398.202759,Time used 0.006001s\n",
      "batch 120, train_loss 350.144287,Time used 0.009001s\n",
      "batch 121, train_loss 367.581207,Time used 0.007003s\n",
      "batch 122, train_loss 431.555389,Time used 0.007002s\n",
      "batch 123, train_loss 342.942474,Time used 0.010998s\n",
      "batch 124, train_loss 385.954132,Time used 0.008002s\n",
      "batch 125, train_loss 350.818176,Time used 0.009003s\n",
      "batch 126, train_loss 388.272980,Time used 0.008999s\n",
      "batch 127, train_loss 430.128693,Time used 0.006999s\n",
      "batch 128, train_loss 432.891022,Time used 0.007000s\n",
      "batch 129, train_loss 367.358673,Time used 0.007997s\n",
      "batch 130, train_loss 424.461090,Time used 0.007000s\n",
      "batch 131, train_loss 368.390411,Time used 0.009998s\n",
      "batch 132, train_loss 473.074646,Time used 0.007001s\n",
      "batch 133, train_loss 449.336060,Time used 0.008001s\n",
      "batch 134, train_loss 464.184967,Time used 0.006999s\n",
      "batch 135, train_loss 446.176147,Time used 0.009000s\n",
      "batch 136, train_loss 451.787933,Time used 0.006999s\n",
      "batch 137, train_loss 297.489136,Time used 0.011001s\n",
      "batch 138, train_loss 435.433594,Time used 0.007000s\n",
      "batch 139, train_loss 374.611725,Time used 0.008003s\n",
      "batch 140, train_loss 324.155579,Time used 0.011001s\n",
      "batch 141, train_loss 356.798431,Time used 0.010995s\n",
      "batch 142, train_loss 378.387543,Time used 0.009002s\n",
      "batch 143, train_loss 300.853333,Time used 0.006999s\n",
      "batch 144, train_loss 390.926880,Time used 0.007001s\n",
      "batch 145, train_loss 360.985199,Time used 0.007005s\n",
      "batch 146, train_loss 421.759186,Time used 0.006992s\n",
      "batch 147, train_loss 380.820587,Time used 0.009003s\n",
      "batch 148, train_loss 388.491211,Time used 0.009997s\n",
      "batch 149, train_loss 416.498718,Time used 0.010001s\n",
      "batch 150, train_loss 434.291901,Time used 0.009000s\n",
      "batch 151, train_loss 393.177307,Time used 0.008001s\n",
      "batch 152, train_loss 414.045532,Time used 0.010000s\n",
      "batch 153, train_loss 365.921082,Time used 0.008002s\n",
      "batch 154, train_loss 468.350250,Time used 0.007998s\n",
      "batch 155, train_loss 363.903137,Time used 0.007999s\n",
      "batch 156, train_loss 397.667450,Time used 0.010001s\n",
      "batch 157, train_loss 306.382935,Time used 0.008003s\n",
      "batch 158, train_loss 422.473663,Time used 0.009037s\n",
      "batch 159, train_loss 327.695923,Time used 0.010963s\n",
      "batch 160, train_loss 430.949158,Time used 0.008003s\n",
      "batch 161, train_loss 344.042480,Time used 0.009997s\n",
      "batch 162, train_loss 334.109070,Time used 0.007004s\n",
      "batch 163, train_loss 381.930237,Time used 0.007000s\n",
      "batch 164, train_loss 359.867615,Time used 0.008997s\n",
      "batch 165, train_loss 417.343475,Time used 0.011002s\n",
      "batch 166, train_loss 425.881805,Time used 0.008002s\n",
      "batch 167, train_loss 367.273254,Time used 0.006997s\n",
      "batch 168, train_loss 399.142792,Time used 0.008000s\n",
      "batch 169, train_loss 368.820587,Time used 0.010996s\n",
      "batch 170, train_loss 459.449097,Time used 0.010004s\n",
      "batch 171, train_loss 336.356537,Time used 0.007998s\n",
      "batch 172, train_loss 404.782532,Time used 0.009998s\n",
      "batch 173, train_loss 376.345428,Time used 0.011001s\n",
      "batch 174, train_loss 386.569672,Time used 0.008000s\n",
      "batch 175, train_loss 307.794037,Time used 0.007001s\n",
      "batch 176, train_loss 342.737091,Time used 0.008001s\n",
      "batch 177, train_loss 384.938263,Time used 0.008001s\n",
      "batch 178, train_loss 434.048706,Time used 0.009999s\n",
      "batch 179, train_loss 378.082550,Time used 0.009999s\n",
      "batch 180, train_loss 350.979828,Time used 0.008999s\n",
      "batch 181, train_loss 412.808746,Time used 0.006999s\n",
      "batch 182, train_loss 411.172394,Time used 0.007033s\n",
      "batch 183, train_loss 384.888641,Time used 0.006999s\n",
      "batch 184, train_loss 376.581970,Time used 0.007968s\n",
      "batch 185, train_loss 402.253448,Time used 0.006999s\n",
      "batch 186, train_loss 386.792664,Time used 0.010003s\n",
      "batch 187, train_loss 416.250488,Time used 0.008031s\n",
      "batch 188, train_loss 465.975769,Time used 0.006970s\n",
      "batch 189, train_loss 311.102936,Time used 0.006997s\n",
      "batch 190, train_loss 412.872131,Time used 0.010033s\n",
      "batch 191, train_loss 323.292999,Time used 0.010005s\n",
      "batch 192, train_loss 388.332764,Time used 0.009963s\n",
      "batch 193, train_loss 397.767059,Time used 0.007999s\n",
      "batch 194, train_loss 490.877136,Time used 0.007001s\n",
      "batch 195, train_loss 319.682648,Time used 0.009998s\n",
      "batch 196, train_loss 384.609436,Time used 0.010002s\n",
      "batch 197, train_loss 340.230286,Time used 0.009004s\n",
      "batch 198, train_loss 399.104004,Time used 0.009000s\n",
      "batch 199, train_loss 435.165649,Time used 0.010998s\n",
      "batch 200, train_loss 341.727448,Time used 0.010000s\n",
      "***************************test_batch 200, test_rmse_loss 21.579592,test_mae_loss 9.632040,test_mape_loss 75.281335,Time used 0.042000s\n",
      "batch 201, train_loss 439.149506,Time used 0.012005s\n",
      "batch 202, train_loss 409.602234,Time used 0.012000s\n",
      "batch 203, train_loss 367.379669,Time used 0.008996s\n",
      "batch 204, train_loss 388.733124,Time used 0.008003s\n",
      "batch 205, train_loss 368.717560,Time used 0.009997s\n",
      "batch 206, train_loss 431.969940,Time used 0.006998s\n",
      "batch 207, train_loss 381.443298,Time used 0.007003s\n",
      "batch 208, train_loss 352.628143,Time used 0.005999s\n",
      "batch 209, train_loss 327.691284,Time used 0.007000s\n",
      "batch 210, train_loss 409.977539,Time used 0.007001s\n",
      "batch 211, train_loss 361.336884,Time used 0.005999s\n",
      "batch 212, train_loss 434.416321,Time used 0.008001s\n",
      "batch 213, train_loss 322.743286,Time used 0.008000s\n",
      "batch 214, train_loss 304.310516,Time used 0.009004s\n",
      "batch 215, train_loss 428.486511,Time used 0.006996s\n",
      "batch 216, train_loss 298.895172,Time used 0.007000s\n",
      "batch 217, train_loss 349.205078,Time used 0.006001s\n",
      "batch 218, train_loss 384.830536,Time used 0.007000s\n",
      "batch 219, train_loss 368.130127,Time used 0.007000s\n",
      "batch 220, train_loss 450.409454,Time used 0.007001s\n",
      "batch 221, train_loss 392.712982,Time used 0.006000s\n",
      "batch 222, train_loss 401.453217,Time used 0.008003s\n",
      "batch 223, train_loss 357.535065,Time used 0.006998s\n",
      "batch 224, train_loss 375.664642,Time used 0.008002s\n",
      "batch 225, train_loss 357.231140,Time used 0.006997s\n",
      "batch 226, train_loss 410.284668,Time used 0.009001s\n",
      "batch 227, train_loss 373.565674,Time used 0.006999s\n",
      "batch 228, train_loss 391.213135,Time used 0.008007s\n",
      "batch 229, train_loss 336.887787,Time used 0.010993s\n",
      "batch 230, train_loss 316.038544,Time used 0.008002s\n",
      "batch 231, train_loss 419.191681,Time used 0.010000s\n",
      "batch 232, train_loss 404.283722,Time used 0.007998s\n",
      "batch 233, train_loss 376.476227,Time used 0.006999s\n",
      "batch 234, train_loss 370.498016,Time used 0.008001s\n",
      "batch 235, train_loss 404.213196,Time used 0.008000s\n",
      "batch 236, train_loss 405.916931,Time used 0.008002s\n",
      "batch 237, train_loss 331.677429,Time used 0.009999s\n",
      "batch 238, train_loss 394.184113,Time used 0.009996s\n",
      "batch 239, train_loss 335.674011,Time used 0.010001s\n",
      "batch 240, train_loss 353.242706,Time used 0.010000s\n",
      "batch 241, train_loss 389.123901,Time used 0.006998s\n",
      "batch 242, train_loss 365.896606,Time used 0.007999s\n",
      "batch 243, train_loss 375.023499,Time used 0.008000s\n",
      "batch 244, train_loss 440.482056,Time used 0.007001s\n",
      "batch 245, train_loss 403.903595,Time used 0.010000s\n",
      "batch 246, train_loss 314.791840,Time used 0.012998s\n",
      "batch 247, train_loss 338.233551,Time used 0.010001s\n",
      "batch 248, train_loss 419.170441,Time used 0.010000s\n",
      "batch 249, train_loss 387.113342,Time used 0.011003s\n",
      "batch 250, train_loss 310.415710,Time used 0.008998s\n",
      "batch 251, train_loss 384.363617,Time used 0.009002s\n",
      "batch 252, train_loss 317.437897,Time used 0.007999s\n",
      "batch 253, train_loss 403.546936,Time used 0.007002s\n",
      "batch 254, train_loss 310.722290,Time used 0.009999s\n",
      "batch 255, train_loss 425.923401,Time used 0.009000s\n",
      "batch 256, train_loss 356.188568,Time used 0.006998s\n",
      "batch 257, train_loss 405.569061,Time used 0.007001s\n",
      "batch 258, train_loss 337.105774,Time used 0.006000s\n",
      "batch 259, train_loss 441.611908,Time used 0.011000s\n",
      "batch 260, train_loss 357.208160,Time used 0.008002s\n",
      "batch 261, train_loss 412.670135,Time used 0.007000s\n",
      "batch 262, train_loss 310.786377,Time used 0.006999s\n",
      "batch 263, train_loss 380.366943,Time used 0.009999s\n",
      "batch 264, train_loss 391.718689,Time used 0.008002s\n",
      "batch 265, train_loss 477.799744,Time used 0.005998s\n",
      "batch 266, train_loss 378.918304,Time used 0.009001s\n",
      "batch 267, train_loss 323.963257,Time used 0.009000s\n",
      "batch 268, train_loss 397.346588,Time used 0.009002s\n",
      "batch 269, train_loss 324.339661,Time used 0.007997s\n",
      "batch 270, train_loss 355.972321,Time used 0.007015s\n",
      "batch 271, train_loss 285.815308,Time used 0.007989s\n",
      "batch 272, train_loss 396.604340,Time used 0.009001s\n",
      "batch 273, train_loss 274.342529,Time used 0.008004s\n",
      "batch 274, train_loss 360.534027,Time used 0.006995s\n",
      "batch 275, train_loss 309.058929,Time used 0.009997s\n",
      "batch 276, train_loss 372.384552,Time used 0.007000s\n",
      "batch 277, train_loss 362.408630,Time used 0.008002s\n",
      "batch 278, train_loss 493.358307,Time used 0.007000s\n",
      "batch 279, train_loss 444.534393,Time used 0.009000s\n",
      "batch 280, train_loss 390.526154,Time used 0.006001s\n",
      "batch 281, train_loss 330.006866,Time used 0.008001s\n",
      "batch 282, train_loss 327.633240,Time used 0.006999s\n",
      "batch 283, train_loss 382.872345,Time used 0.011001s\n",
      "batch 284, train_loss 409.964935,Time used 0.010998s\n",
      "batch 285, train_loss 379.856110,Time used 0.006999s\n",
      "batch 286, train_loss 373.263214,Time used 0.006999s\n",
      "batch 287, train_loss 395.086548,Time used 0.006998s\n",
      "batch 288, train_loss 353.706726,Time used 0.007003s\n",
      "batch 289, train_loss 372.867645,Time used 0.008000s\n",
      "batch 290, train_loss 406.189972,Time used 0.010001s\n",
      "batch 291, train_loss 297.645966,Time used 0.006999s\n",
      "batch 292, train_loss 364.093262,Time used 0.006001s\n",
      "batch 293, train_loss 394.697540,Time used 0.009001s\n",
      "batch 294, train_loss 289.646240,Time used 0.009002s\n",
      "batch 295, train_loss 394.063171,Time used 0.008003s\n",
      "batch 296, train_loss 311.080109,Time used 0.009999s\n",
      "batch 297, train_loss 369.650757,Time used 0.008000s\n",
      "batch 298, train_loss 347.472534,Time used 0.006999s\n",
      "batch 299, train_loss 373.128967,Time used 0.009999s\n",
      "batch 300, train_loss 354.737610,Time used 0.005999s\n",
      "***************************test_batch 300, test_rmse_loss 21.217393,test_mae_loss 9.364182,test_mape_loss 73.913471,Time used 0.036999s\n",
      "batch 301, train_loss 398.127350,Time used 0.010001s\n",
      "batch 302, train_loss 386.142456,Time used 0.009000s\n",
      "batch 303, train_loss 268.547943,Time used 0.006002s\n",
      "batch 304, train_loss 389.723419,Time used 0.008001s\n",
      "batch 305, train_loss 395.055908,Time used 0.006000s\n",
      "batch 306, train_loss 445.452209,Time used 0.006998s\n",
      "batch 307, train_loss 394.733215,Time used 0.006001s\n",
      "batch 308, train_loss 418.584961,Time used 0.006000s\n",
      "batch 309, train_loss 372.268219,Time used 0.005998s\n",
      "batch 310, train_loss 366.123932,Time used 0.006000s\n",
      "batch 311, train_loss 330.591339,Time used 0.011005s\n",
      "batch 312, train_loss 381.290894,Time used 0.010995s\n",
      "batch 313, train_loss 431.486267,Time used 0.010014s\n",
      "batch 314, train_loss 316.771851,Time used 0.010988s\n",
      "batch 315, train_loss 338.980927,Time used 0.007996s\n",
      "batch 316, train_loss 307.884094,Time used 0.010999s\n",
      "batch 317, train_loss 315.477936,Time used 0.009002s\n",
      "batch 318, train_loss 412.856232,Time used 0.008998s\n",
      "batch 319, train_loss 338.331055,Time used 0.006001s\n",
      "batch 320, train_loss 328.542084,Time used 0.009000s\n",
      "batch 321, train_loss 418.520355,Time used 0.006000s\n",
      "batch 322, train_loss 356.924744,Time used 0.010003s\n",
      "batch 323, train_loss 353.791656,Time used 0.006996s\n",
      "batch 324, train_loss 377.502441,Time used 0.010003s\n",
      "batch 325, train_loss 328.951141,Time used 0.007001s\n",
      "batch 326, train_loss 332.632385,Time used 0.008999s\n",
      "batch 327, train_loss 387.482880,Time used 0.008001s\n",
      "batch 328, train_loss 377.102905,Time used 0.006997s\n",
      "batch 329, train_loss 347.428802,Time used 0.008003s\n",
      "batch 330, train_loss 445.857361,Time used 0.006997s\n",
      "batch 331, train_loss 353.550629,Time used 0.006003s\n",
      "batch 332, train_loss 348.007294,Time used 0.006001s\n",
      "batch 333, train_loss 398.054718,Time used 0.008001s\n",
      "batch 334, train_loss 351.068176,Time used 0.006998s\n",
      "batch 335, train_loss 359.924774,Time used 0.005999s\n",
      "batch 336, train_loss 419.417938,Time used 0.008002s\n",
      "batch 337, train_loss 412.099213,Time used 0.008997s\n",
      "batch 338, train_loss 280.392334,Time used 0.008000s\n",
      "batch 339, train_loss 375.331329,Time used 0.006002s\n",
      "batch 340, train_loss 364.378204,Time used 0.006999s\n",
      "batch 341, train_loss 379.819489,Time used 0.007002s\n",
      "batch 342, train_loss 402.515472,Time used 0.006000s\n",
      "batch 343, train_loss 295.094543,Time used 0.008000s\n",
      "batch 344, train_loss 332.559387,Time used 0.006000s\n",
      "batch 345, train_loss 353.514557,Time used 0.005999s\n",
      "batch 346, train_loss 397.461060,Time used 0.007001s\n",
      "batch 347, train_loss 405.018036,Time used 0.006001s\n",
      "batch 348, train_loss 440.696747,Time used 0.008003s\n",
      "batch 349, train_loss 374.252594,Time used 0.009999s\n",
      "batch 350, train_loss 406.829773,Time used 0.008997s\n",
      "batch 351, train_loss 365.808441,Time used 0.006000s\n",
      "batch 352, train_loss 306.150452,Time used 0.009000s\n",
      "batch 353, train_loss 381.662476,Time used 0.006002s\n",
      "batch 354, train_loss 285.358246,Time used 0.007000s\n",
      "batch 355, train_loss 305.252319,Time used 0.005997s\n",
      "batch 356, train_loss 379.499359,Time used 0.008001s\n",
      "batch 357, train_loss 422.591980,Time used 0.008000s\n",
      "batch 358, train_loss 352.138855,Time used 0.009001s\n",
      "batch 359, train_loss 325.353729,Time used 0.005999s\n",
      "batch 360, train_loss 328.917694,Time used 0.008003s\n",
      "batch 361, train_loss 366.446228,Time used 0.010999s\n",
      "batch 362, train_loss 351.311401,Time used 0.010000s\n",
      "batch 363, train_loss 395.553009,Time used 0.010000s\n",
      "batch 364, train_loss 395.032166,Time used 0.008999s\n",
      "batch 365, train_loss 310.258270,Time used 0.005999s\n",
      "batch 366, train_loss 337.594482,Time used 0.007004s\n",
      "batch 367, train_loss 282.993988,Time used 0.007999s\n",
      "batch 368, train_loss 361.603699,Time used 0.011000s\n",
      "batch 369, train_loss 422.286774,Time used 0.006000s\n",
      "batch 370, train_loss 271.925446,Time used 0.009002s\n",
      "batch 371, train_loss 377.742432,Time used 0.009999s\n",
      "batch 372, train_loss 343.318298,Time used 0.010999s\n",
      "batch 373, train_loss 464.120667,Time used 0.008002s\n",
      "batch 374, train_loss 413.963440,Time used 0.009999s\n",
      "batch 375, train_loss 398.449829,Time used 0.008002s\n",
      "batch 376, train_loss 372.362274,Time used 0.009001s\n",
      "batch 377, train_loss 385.416473,Time used 0.010002s\n",
      "batch 378, train_loss 337.028839,Time used 0.007998s\n",
      "batch 379, train_loss 295.096405,Time used 0.011001s\n",
      "batch 380, train_loss 356.222748,Time used 0.010000s\n",
      "batch 381, train_loss 329.946014,Time used 0.010999s\n",
      "batch 382, train_loss 346.499054,Time used 0.009999s\n",
      "batch 383, train_loss 325.423706,Time used 0.009999s\n",
      "batch 384, train_loss 362.342468,Time used 0.011000s\n",
      "batch 385, train_loss 372.677551,Time used 0.011002s\n",
      "batch 386, train_loss 416.052216,Time used 0.010000s\n",
      "batch 387, train_loss 336.648895,Time used 0.009998s\n",
      "batch 388, train_loss 393.032745,Time used 0.010000s\n",
      "batch 389, train_loss 384.318604,Time used 0.007000s\n",
      "batch 390, train_loss 383.000244,Time used 0.008001s\n",
      "batch 391, train_loss 346.100708,Time used 0.005996s\n",
      "batch 392, train_loss 355.948303,Time used 0.010002s\n",
      "batch 393, train_loss 363.572388,Time used 0.009998s\n",
      "batch 394, train_loss 315.691315,Time used 0.010000s\n",
      "batch 395, train_loss 293.818970,Time used 0.007003s\n",
      "batch 396, train_loss 356.783875,Time used 0.009000s\n",
      "batch 397, train_loss 294.029724,Time used 0.007001s\n",
      "batch 398, train_loss 407.626190,Time used 0.005999s\n",
      "batch 399, train_loss 346.299042,Time used 0.007001s\n",
      "batch 400, train_loss 346.205444,Time used 0.010001s\n",
      "***************************test_batch 400, test_rmse_loss 20.888061,test_mae_loss 9.137188,test_mape_loss 75.006845,Time used 0.025998s\n",
      "batch 401, train_loss 340.166351,Time used 0.009002s\n",
      "batch 402, train_loss 446.607056,Time used 0.006999s\n",
      "batch 403, train_loss 355.048309,Time used 0.008000s\n",
      "batch 404, train_loss 338.275604,Time used 0.006000s\n",
      "batch 405, train_loss 366.802399,Time used 0.007015s\n",
      "batch 406, train_loss 278.676239,Time used 0.010986s\n",
      "batch 407, train_loss 313.293884,Time used 0.007003s\n",
      "batch 408, train_loss 387.399292,Time used 0.006001s\n",
      "batch 409, train_loss 383.172455,Time used 0.005998s\n",
      "batch 410, train_loss 339.630737,Time used 0.007000s\n",
      "batch 411, train_loss 414.073853,Time used 0.008999s\n",
      "batch 412, train_loss 374.403656,Time used 0.007001s\n",
      "batch 413, train_loss 373.492584,Time used 0.006999s\n",
      "batch 414, train_loss 360.787933,Time used 0.006000s\n",
      "batch 415, train_loss 339.090668,Time used 0.008001s\n",
      "batch 416, train_loss 368.195709,Time used 0.009001s\n",
      "batch 417, train_loss 314.720154,Time used 0.007000s\n",
      "batch 418, train_loss 392.674622,Time used 0.007002s\n",
      "batch 419, train_loss 440.588684,Time used 0.007000s\n",
      "batch 420, train_loss 325.055084,Time used 0.006999s\n",
      "batch 421, train_loss 331.196991,Time used 0.006002s\n",
      "batch 422, train_loss 307.790039,Time used 0.008002s\n",
      "batch 423, train_loss 358.873596,Time used 0.006001s\n",
      "batch 424, train_loss 360.886841,Time used 0.008999s\n",
      "batch 425, train_loss 346.042786,Time used 0.008998s\n",
      "batch 426, train_loss 377.826324,Time used 0.007999s\n",
      "batch 427, train_loss 345.124512,Time used 0.008001s\n",
      "batch 428, train_loss 335.257935,Time used 0.006999s\n",
      "batch 429, train_loss 298.949066,Time used 0.007000s\n",
      "batch 430, train_loss 300.068848,Time used 0.006016s\n",
      "batch 431, train_loss 391.135437,Time used 0.006985s\n",
      "batch 432, train_loss 291.947327,Time used 0.005999s\n",
      "batch 433, train_loss 293.744995,Time used 0.008000s\n",
      "batch 434, train_loss 345.311829,Time used 0.009001s\n",
      "batch 435, train_loss 317.398132,Time used 0.009040s\n",
      "batch 436, train_loss 300.972839,Time used 0.006961s\n",
      "batch 437, train_loss 382.912262,Time used 0.007012s\n",
      "batch 438, train_loss 364.006134,Time used 0.006989s\n",
      "batch 439, train_loss 396.704346,Time used 0.008005s\n",
      "batch 440, train_loss 363.022034,Time used 0.006997s\n",
      "batch 441, train_loss 349.555756,Time used 0.009032s\n",
      "batch 442, train_loss 340.905914,Time used 0.006997s\n",
      "batch 443, train_loss 459.524384,Time used 0.009003s\n",
      "batch 444, train_loss 404.658203,Time used 0.006964s\n",
      "batch 445, train_loss 327.231659,Time used 0.008001s\n",
      "batch 446, train_loss 266.159607,Time used 0.010004s\n",
      "batch 447, train_loss 352.763428,Time used 0.007006s\n",
      "batch 448, train_loss 355.393951,Time used 0.008993s\n",
      "batch 449, train_loss 348.441223,Time used 0.010036s\n",
      "batch 450, train_loss 310.127319,Time used 0.006999s\n",
      "batch 451, train_loss 347.244354,Time used 0.009962s\n",
      "batch 452, train_loss 392.466980,Time used 0.009001s\n",
      "batch 453, train_loss 354.072479,Time used 0.007001s\n",
      "batch 454, train_loss 327.326172,Time used 0.006028s\n",
      "batch 455, train_loss 392.316650,Time used 0.008999s\n",
      "batch 456, train_loss 314.861847,Time used 0.007998s\n",
      "batch 457, train_loss 349.251434,Time used 0.006035s\n",
      "batch 458, train_loss 311.580444,Time used 0.009967s\n",
      "batch 459, train_loss 339.340088,Time used 0.006999s\n",
      "batch 460, train_loss 336.485962,Time used 0.007032s\n",
      "batch 461, train_loss 361.043579,Time used 0.006001s\n",
      "batch 462, train_loss 354.590637,Time used 0.006969s\n",
      "batch 463, train_loss 348.478912,Time used 0.007997s\n",
      "batch 464, train_loss 285.733185,Time used 0.008003s\n",
      "batch 465, train_loss 401.542816,Time used 0.008000s\n",
      "batch 466, train_loss 418.018677,Time used 0.008000s\n",
      "batch 467, train_loss 316.134491,Time used 0.008997s\n",
      "batch 468, train_loss 430.420288,Time used 0.010009s\n",
      "batch 469, train_loss 316.608826,Time used 0.010001s\n",
      "batch 470, train_loss 364.423401,Time used 0.011000s\n",
      "batch 471, train_loss 364.456787,Time used 0.011002s\n",
      "batch 472, train_loss 338.326904,Time used 0.006996s\n",
      "batch 473, train_loss 248.301498,Time used 0.009000s\n",
      "batch 474, train_loss 344.897705,Time used 0.008016s\n",
      "batch 475, train_loss 383.949188,Time used 0.008999s\n",
      "batch 476, train_loss 336.566681,Time used 0.010002s\n",
      "batch 477, train_loss 420.391846,Time used 0.008999s\n",
      "batch 478, train_loss 319.962891,Time used 0.005999s\n",
      "batch 479, train_loss 310.094788,Time used 0.005999s\n",
      "batch 480, train_loss 345.608124,Time used 0.007007s\n",
      "batch 481, train_loss 347.054474,Time used 0.010000s\n",
      "batch 482, train_loss 386.330658,Time used 0.010001s\n",
      "batch 483, train_loss 355.450958,Time used 0.007997s\n",
      "batch 484, train_loss 287.538300,Time used 0.009002s\n",
      "batch 485, train_loss 349.919037,Time used 0.008997s\n",
      "batch 486, train_loss 331.478424,Time used 0.010002s\n",
      "batch 487, train_loss 344.462952,Time used 0.008998s\n",
      "batch 488, train_loss 374.277069,Time used 0.007004s\n",
      "batch 489, train_loss 277.980804,Time used 0.009002s\n",
      "batch 490, train_loss 373.023254,Time used 0.008000s\n",
      "batch 491, train_loss 381.690399,Time used 0.009000s\n",
      "batch 492, train_loss 323.693665,Time used 0.008998s\n",
      "batch 493, train_loss 385.859589,Time used 0.007999s\n",
      "batch 494, train_loss 371.093353,Time used 0.007000s\n",
      "batch 495, train_loss 353.654541,Time used 0.006001s\n",
      "batch 496, train_loss 337.249054,Time used 0.006000s\n",
      "batch 497, train_loss 421.804718,Time used 0.009001s\n",
      "batch 498, train_loss 362.475616,Time used 0.006999s\n",
      "batch 499, train_loss 372.768280,Time used 0.007000s\n",
      "batch 500, train_loss 321.526764,Time used 0.006000s\n",
      "***************************test_batch 500, test_rmse_loss 20.593895,test_mae_loss 8.937310,test_mape_loss 75.885185,Time used 0.023998s\n",
      "batch 501, train_loss 311.186157,Time used 0.010002s\n",
      "batch 502, train_loss 317.044708,Time used 0.009999s\n",
      "batch 503, train_loss 280.524231,Time used 0.007002s\n",
      "batch 504, train_loss 317.421692,Time used 0.007001s\n",
      "batch 505, train_loss 318.047150,Time used 0.006001s\n",
      "batch 506, train_loss 372.324310,Time used 0.006999s\n",
      "batch 507, train_loss 381.927338,Time used 0.008001s\n",
      "batch 508, train_loss 387.540619,Time used 0.010999s\n",
      "batch 509, train_loss 370.427826,Time used 0.008999s\n",
      "batch 510, train_loss 302.094604,Time used 0.005999s\n",
      "batch 511, train_loss 431.017303,Time used 0.006001s\n",
      "batch 512, train_loss 294.160126,Time used 0.006001s\n",
      "batch 513, train_loss 375.956360,Time used 0.006001s\n",
      "batch 514, train_loss 314.920105,Time used 0.008999s\n",
      "batch 515, train_loss 286.325531,Time used 0.009999s\n",
      "batch 516, train_loss 391.617706,Time used 0.007002s\n",
      "batch 517, train_loss 322.520996,Time used 0.007998s\n",
      "batch 518, train_loss 344.531281,Time used 0.007001s\n",
      "batch 519, train_loss 297.119843,Time used 0.006999s\n",
      "batch 520, train_loss 356.150543,Time used 0.009001s\n",
      "batch 521, train_loss 326.274902,Time used 0.006999s\n",
      "batch 522, train_loss 359.586823,Time used 0.007998s\n",
      "batch 523, train_loss 310.547058,Time used 0.006001s\n",
      "batch 524, train_loss 340.188538,Time used 0.008000s\n",
      "batch 525, train_loss 360.022369,Time used 0.007000s\n",
      "batch 526, train_loss 358.282471,Time used 0.007000s\n",
      "batch 527, train_loss 345.569794,Time used 0.009999s\n",
      "batch 528, train_loss 278.533630,Time used 0.009000s\n",
      "batch 529, train_loss 344.616913,Time used 0.008002s\n",
      "batch 530, train_loss 404.846313,Time used 0.006999s\n",
      "batch 531, train_loss 374.939087,Time used 0.008002s\n",
      "batch 532, train_loss 316.197418,Time used 0.007999s\n",
      "batch 533, train_loss 293.077423,Time used 0.009002s\n",
      "batch 534, train_loss 240.641556,Time used 0.006999s\n",
      "batch 535, train_loss 339.150024,Time used 0.011000s\n",
      "batch 536, train_loss 381.186188,Time used 0.006001s\n",
      "batch 537, train_loss 379.699432,Time used 0.006998s\n",
      "batch 538, train_loss 330.791107,Time used 0.006000s\n",
      "batch 539, train_loss 381.522949,Time used 0.008001s\n",
      "batch 540, train_loss 315.556885,Time used 0.007000s\n",
      "batch 541, train_loss 415.987701,Time used 0.008002s\n",
      "batch 542, train_loss 289.096436,Time used 0.008999s\n",
      "batch 543, train_loss 381.547302,Time used 0.008000s\n",
      "batch 544, train_loss 307.430725,Time used 0.007000s\n",
      "batch 545, train_loss 357.093994,Time used 0.008001s\n",
      "batch 546, train_loss 304.887573,Time used 0.009998s\n",
      "batch 547, train_loss 400.776581,Time used 0.007001s\n",
      "batch 548, train_loss 298.957336,Time used 0.005999s\n",
      "batch 549, train_loss 365.162781,Time used 0.006002s\n",
      "batch 550, train_loss 327.122162,Time used 0.006999s\n",
      "batch 551, train_loss 322.880005,Time used 0.007000s\n",
      "batch 552, train_loss 296.415375,Time used 0.006000s\n",
      "batch 553, train_loss 314.496918,Time used 0.010000s\n",
      "batch 554, train_loss 257.308441,Time used 0.008002s\n",
      "batch 555, train_loss 392.465790,Time used 0.010000s\n",
      "batch 556, train_loss 316.083405,Time used 0.009000s\n",
      "batch 557, train_loss 318.474152,Time used 0.008002s\n",
      "batch 558, train_loss 318.204437,Time used 0.010000s\n",
      "batch 559, train_loss 261.604767,Time used 0.009001s\n",
      "batch 560, train_loss 346.479614,Time used 0.010001s\n",
      "batch 561, train_loss 352.611298,Time used 0.006997s\n",
      "batch 562, train_loss 438.498047,Time used 0.006001s\n",
      "batch 563, train_loss 419.653717,Time used 0.008000s\n",
      "batch 564, train_loss 353.310059,Time used 0.009999s\n",
      "batch 565, train_loss 323.987823,Time used 0.009000s\n",
      "batch 566, train_loss 321.191467,Time used 0.007000s\n",
      "batch 567, train_loss 383.209595,Time used 0.010000s\n",
      "batch 568, train_loss 326.215668,Time used 0.009001s\n",
      "batch 569, train_loss 351.486389,Time used 0.006999s\n",
      "batch 570, train_loss 349.434631,Time used 0.010001s\n",
      "batch 571, train_loss 309.756195,Time used 0.008999s\n",
      "batch 572, train_loss 355.617920,Time used 0.011000s\n",
      "batch 573, train_loss 351.533417,Time used 0.009000s\n",
      "batch 574, train_loss 337.816345,Time used 0.009001s\n",
      "batch 575, train_loss 288.009186,Time used 0.009001s\n",
      "batch 576, train_loss 327.820465,Time used 0.010000s\n",
      "batch 577, train_loss 303.579041,Time used 0.009998s\n",
      "batch 578, train_loss 359.003601,Time used 0.006999s\n",
      "batch 579, train_loss 362.019958,Time used 0.008000s\n",
      "batch 580, train_loss 287.637604,Time used 0.007999s\n",
      "batch 581, train_loss 349.006348,Time used 0.005999s\n",
      "batch 582, train_loss 312.205505,Time used 0.008999s\n",
      "batch 583, train_loss 335.433289,Time used 0.010002s\n",
      "batch 584, train_loss 394.209229,Time used 0.008999s\n",
      "batch 585, train_loss 301.192627,Time used 0.010000s\n",
      "batch 586, train_loss 325.915527,Time used 0.007002s\n",
      "batch 587, train_loss 316.111877,Time used 0.007999s\n",
      "batch 588, train_loss 381.349030,Time used 0.010000s\n",
      "batch 589, train_loss 326.920013,Time used 0.009999s\n",
      "batch 590, train_loss 446.950012,Time used 0.009000s\n",
      "batch 591, train_loss 304.356873,Time used 0.008999s\n",
      "batch 592, train_loss 341.883484,Time used 0.010000s\n",
      "batch 593, train_loss 349.156830,Time used 0.008001s\n",
      "batch 594, train_loss 288.312897,Time used 0.007000s\n",
      "batch 595, train_loss 301.346527,Time used 0.007004s\n",
      "batch 596, train_loss 355.777618,Time used 0.007998s\n",
      "batch 597, train_loss 274.397766,Time used 0.011002s\n",
      "batch 598, train_loss 365.024445,Time used 0.011000s\n",
      "batch 599, train_loss 330.685150,Time used 0.010995s\n",
      "batch 600, train_loss 349.055054,Time used 0.010004s\n",
      "***************************test_batch 600, test_rmse_loss 20.326347,test_mae_loss 8.751242,test_mape_loss 76.349761,Time used 0.024999s\n",
      "batch 601, train_loss 322.130981,Time used 0.010000s\n",
      "batch 602, train_loss 353.776855,Time used 0.010000s\n",
      "batch 603, train_loss 366.649323,Time used 0.007000s\n",
      "batch 604, train_loss 386.530273,Time used 0.006001s\n",
      "batch 605, train_loss 327.269348,Time used 0.008999s\n",
      "batch 606, train_loss 378.313812,Time used 0.008000s\n",
      "batch 607, train_loss 367.984650,Time used 0.006002s\n",
      "batch 608, train_loss 323.264130,Time used 0.007002s\n",
      "batch 609, train_loss 284.060944,Time used 0.007000s\n",
      "batch 610, train_loss 339.373108,Time used 0.006998s\n",
      "batch 611, train_loss 305.815460,Time used 0.008002s\n",
      "batch 612, train_loss 301.317413,Time used 0.006000s\n",
      "batch 613, train_loss 346.482422,Time used 0.007999s\n",
      "batch 614, train_loss 257.052948,Time used 0.007000s\n",
      "batch 615, train_loss 449.550629,Time used 0.009004s\n",
      "batch 616, train_loss 323.513062,Time used 0.009995s\n",
      "batch 617, train_loss 264.591339,Time used 0.009000s\n",
      "batch 618, train_loss 395.131073,Time used 0.006001s\n",
      "batch 619, train_loss 326.786835,Time used 0.008999s\n",
      "batch 620, train_loss 298.047394,Time used 0.006001s\n",
      "batch 621, train_loss 321.757385,Time used 0.007001s\n",
      "batch 622, train_loss 351.731110,Time used 0.006996s\n",
      "batch 623, train_loss 336.042542,Time used 0.007003s\n",
      "batch 624, train_loss 278.114471,Time used 0.005998s\n",
      "batch 625, train_loss 295.078552,Time used 0.007001s\n",
      "batch 626, train_loss 284.697510,Time used 0.009000s\n",
      "batch 627, train_loss 294.923462,Time used 0.009998s\n",
      "batch 628, train_loss 342.026215,Time used 0.009005s\n",
      "batch 629, train_loss 350.602356,Time used 0.006999s\n",
      "batch 630, train_loss 358.966858,Time used 0.006001s\n",
      "batch 631, train_loss 370.318146,Time used 0.008999s\n",
      "batch 632, train_loss 362.239685,Time used 0.007000s\n",
      "batch 633, train_loss 233.094833,Time used 0.006001s\n",
      "batch 634, train_loss 285.763092,Time used 0.007000s\n",
      "batch 635, train_loss 357.300049,Time used 0.008002s\n",
      "batch 636, train_loss 340.054596,Time used 0.006997s\n",
      "batch 637, train_loss 293.489075,Time used 0.008002s\n",
      "batch 638, train_loss 331.302307,Time used 0.009000s\n",
      "batch 639, train_loss 389.079620,Time used 0.008000s\n",
      "batch 640, train_loss 321.267120,Time used 0.006002s\n",
      "batch 641, train_loss 298.969208,Time used 0.007998s\n",
      "batch 642, train_loss 387.159943,Time used 0.007002s\n",
      "batch 643, train_loss 292.765472,Time used 0.010000s\n",
      "batch 644, train_loss 301.195526,Time used 0.009999s\n",
      "batch 645, train_loss 398.165924,Time used 0.008000s\n",
      "batch 646, train_loss 328.870972,Time used 0.006000s\n",
      "batch 647, train_loss 394.386932,Time used 0.006999s\n",
      "batch 648, train_loss 343.185303,Time used 0.007001s\n",
      "batch 649, train_loss 355.813812,Time used 0.005999s\n",
      "batch 650, train_loss 359.479248,Time used 0.006999s\n",
      "batch 651, train_loss 289.995728,Time used 0.005999s\n",
      "batch 652, train_loss 272.268555,Time used 0.006001s\n",
      "batch 653, train_loss 344.498810,Time used 0.005999s\n",
      "batch 654, train_loss 352.496094,Time used 0.006002s\n",
      "batch 655, train_loss 308.656342,Time used 0.006999s\n",
      "batch 656, train_loss 337.743805,Time used 0.010001s\n",
      "batch 657, train_loss 314.181396,Time used 0.010999s\n",
      "batch 658, train_loss 320.076965,Time used 0.007033s\n",
      "batch 659, train_loss 356.495789,Time used 0.006965s\n",
      "batch 660, train_loss 263.959625,Time used 0.006042s\n",
      "batch 661, train_loss 327.828522,Time used 0.006957s\n",
      "batch 662, train_loss 361.805115,Time used 0.007010s\n",
      "batch 663, train_loss 325.685608,Time used 0.009028s\n",
      "batch 664, train_loss 373.187592,Time used 0.007005s\n",
      "batch 665, train_loss 301.063690,Time used 0.007964s\n",
      "batch 666, train_loss 289.803131,Time used 0.006031s\n",
      "batch 667, train_loss 326.728729,Time used 0.007003s\n",
      "batch 668, train_loss 353.312744,Time used 0.006971s\n",
      "batch 669, train_loss 392.693542,Time used 0.005991s\n",
      "batch 670, train_loss 346.152618,Time used 0.012006s\n",
      "batch 671, train_loss 262.810181,Time used 0.006997s\n",
      "batch 672, train_loss 367.473480,Time used 0.026000s\n",
      "batch 673, train_loss 329.138062,Time used 0.010000s\n",
      "batch 674, train_loss 323.755798,Time used 0.010002s\n",
      "batch 675, train_loss 303.442413,Time used 0.006998s\n",
      "batch 676, train_loss 323.647949,Time used 0.009000s\n",
      "batch 677, train_loss 322.395172,Time used 0.009000s\n",
      "batch 678, train_loss 264.810669,Time used 0.009998s\n",
      "batch 679, train_loss 348.327026,Time used 0.011001s\n",
      "batch 680, train_loss 327.493561,Time used 0.010002s\n",
      "batch 681, train_loss 350.010681,Time used 0.008000s\n",
      "batch 682, train_loss 343.729370,Time used 0.009998s\n",
      "batch 683, train_loss 275.606720,Time used 0.010002s\n",
      "batch 684, train_loss 386.668610,Time used 0.009999s\n",
      "batch 685, train_loss 336.223083,Time used 0.011003s\n",
      "batch 686, train_loss 363.071991,Time used 0.008001s\n",
      "batch 687, train_loss 286.928040,Time used 0.009998s\n",
      "batch 688, train_loss 332.763947,Time used 0.007001s\n",
      "batch 689, train_loss 317.322021,Time used 0.014997s\n",
      "batch 690, train_loss 314.451538,Time used 0.010000s\n",
      "batch 691, train_loss 338.916443,Time used 0.010001s\n",
      "batch 692, train_loss 350.026733,Time used 0.008998s\n",
      "batch 693, train_loss 368.718170,Time used 0.008003s\n",
      "batch 694, train_loss 332.193024,Time used 0.014002s\n",
      "batch 695, train_loss 297.304352,Time used 0.007998s\n",
      "batch 696, train_loss 313.790741,Time used 0.008999s\n",
      "batch 697, train_loss 300.868500,Time used 0.012001s\n",
      "batch 698, train_loss 448.095764,Time used 0.011002s\n",
      "batch 699, train_loss 296.195251,Time used 0.010997s\n",
      "batch 700, train_loss 339.198242,Time used 0.009002s\n",
      "***************************test_batch 700, test_rmse_loss 20.073360,test_mae_loss 8.575644,test_mape_loss 76.477011,Time used 0.035002s\n",
      "batch 701, train_loss 318.591370,Time used 0.008998s\n",
      "batch 702, train_loss 282.126343,Time used 0.010001s\n",
      "batch 703, train_loss 284.350128,Time used 0.009999s\n",
      "batch 704, train_loss 291.905975,Time used 0.010002s\n",
      "batch 705, train_loss 297.600586,Time used 0.010998s\n",
      "batch 706, train_loss 358.014526,Time used 0.010003s\n",
      "batch 707, train_loss 253.772751,Time used 0.008999s\n",
      "batch 708, train_loss 348.608429,Time used 0.010998s\n",
      "batch 709, train_loss 254.251968,Time used 0.006999s\n",
      "batch 710, train_loss 327.917694,Time used 0.010003s\n",
      "batch 711, train_loss 348.431274,Time used 0.009999s\n",
      "batch 712, train_loss 348.450043,Time used 0.008000s\n",
      "batch 713, train_loss 410.179688,Time used 0.007997s\n",
      "batch 714, train_loss 307.260773,Time used 0.007003s\n",
      "batch 715, train_loss 310.961273,Time used 0.005998s\n",
      "batch 716, train_loss 334.223938,Time used 0.007000s\n",
      "batch 717, train_loss 283.437805,Time used 0.007001s\n",
      "batch 718, train_loss 355.290649,Time used 0.011000s\n",
      "batch 719, train_loss 343.478485,Time used 0.009000s\n",
      "batch 720, train_loss 358.874054,Time used 0.006996s\n",
      "batch 721, train_loss 329.235077,Time used 0.008998s\n",
      "batch 722, train_loss 276.350830,Time used 0.007000s\n",
      "batch 723, train_loss 333.272247,Time used 0.009001s\n",
      "batch 724, train_loss 256.224396,Time used 0.007999s\n",
      "batch 725, train_loss 296.291779,Time used 0.010000s\n",
      "batch 726, train_loss 278.753937,Time used 0.010000s\n",
      "batch 727, train_loss 322.436981,Time used 0.006000s\n",
      "batch 728, train_loss 350.297485,Time used 0.008002s\n",
      "batch 729, train_loss 405.719360,Time used 0.007000s\n",
      "batch 730, train_loss 337.297363,Time used 0.009001s\n",
      "batch 731, train_loss 300.394501,Time used 0.010001s\n",
      "batch 732, train_loss 344.124115,Time used 0.008998s\n",
      "batch 733, train_loss 309.329559,Time used 0.006001s\n",
      "batch 734, train_loss 301.510193,Time used 0.009002s\n",
      "batch 735, train_loss 332.218475,Time used 0.011000s\n",
      "batch 736, train_loss 315.638519,Time used 0.009001s\n",
      "batch 737, train_loss 318.491974,Time used 0.008009s\n",
      "batch 738, train_loss 354.346008,Time used 0.008992s\n",
      "batch 739, train_loss 321.915314,Time used 0.007998s\n",
      "batch 740, train_loss 278.779327,Time used 0.009006s\n",
      "batch 741, train_loss 363.015839,Time used 0.009995s\n",
      "batch 742, train_loss 321.910065,Time used 0.009000s\n",
      "batch 743, train_loss 417.653229,Time used 0.009001s\n",
      "batch 744, train_loss 284.112579,Time used 0.007999s\n",
      "batch 745, train_loss 360.777893,Time used 0.008997s\n",
      "batch 746, train_loss 272.228912,Time used 0.009003s\n",
      "batch 747, train_loss 331.025940,Time used 0.008996s\n",
      "batch 748, train_loss 330.398956,Time used 0.006999s\n",
      "batch 749, train_loss 316.699677,Time used 0.010000s\n",
      "batch 750, train_loss 293.860809,Time used 0.008000s\n",
      "batch 751, train_loss 379.161926,Time used 0.010001s\n",
      "batch 752, train_loss 283.842651,Time used 0.007998s\n",
      "batch 753, train_loss 314.275635,Time used 0.006000s\n",
      "batch 754, train_loss 384.028351,Time used 0.010002s\n",
      "batch 755, train_loss 294.348541,Time used 0.006999s\n",
      "batch 756, train_loss 344.415527,Time used 0.008002s\n",
      "batch 757, train_loss 268.936676,Time used 0.009999s\n",
      "batch 758, train_loss 223.166031,Time used 0.010001s\n",
      "batch 759, train_loss 346.278015,Time used 0.009002s\n",
      "batch 760, train_loss 360.889465,Time used 0.008002s\n",
      "batch 761, train_loss 343.379181,Time used 0.007996s\n",
      "batch 762, train_loss 309.167755,Time used 0.006999s\n",
      "batch 763, train_loss 314.687347,Time used 0.007001s\n",
      "batch 764, train_loss 293.106781,Time used 0.008002s\n",
      "batch 765, train_loss 371.113983,Time used 0.008000s\n",
      "batch 766, train_loss 314.537659,Time used 0.007999s\n",
      "batch 767, train_loss 304.987671,Time used 0.007004s\n",
      "batch 768, train_loss 347.417480,Time used 0.010997s\n",
      "batch 769, train_loss 360.717834,Time used 0.010002s\n",
      "batch 770, train_loss 347.056244,Time used 0.007998s\n",
      "batch 771, train_loss 285.427490,Time used 0.010000s\n",
      "batch 772, train_loss 280.994568,Time used 0.007000s\n",
      "batch 773, train_loss 280.348938,Time used 0.007000s\n",
      "batch 774, train_loss 291.609924,Time used 0.009004s\n",
      "batch 775, train_loss 263.412079,Time used 0.006997s\n",
      "batch 776, train_loss 384.316345,Time used 0.010000s\n",
      "batch 777, train_loss 255.269150,Time used 0.009006s\n",
      "batch 778, train_loss 472.052765,Time used 0.006994s\n",
      "batch 779, train_loss 339.442719,Time used 0.010003s\n",
      "batch 780, train_loss 276.046600,Time used 0.007996s\n",
      "batch 781, train_loss 375.051117,Time used 0.008003s\n",
      "batch 782, train_loss 370.373016,Time used 0.006001s\n",
      "batch 783, train_loss 278.296936,Time used 0.007000s\n",
      "batch 784, train_loss 304.153656,Time used 0.008999s\n",
      "batch 785, train_loss 316.535522,Time used 0.006999s\n",
      "batch 786, train_loss 345.390625,Time used 0.007001s\n",
      "batch 787, train_loss 347.570160,Time used 0.007999s\n",
      "batch 788, train_loss 311.754425,Time used 0.006000s\n",
      "batch 789, train_loss 362.784119,Time used 0.006999s\n",
      "batch 790, train_loss 287.259552,Time used 0.006000s\n",
      "batch 791, train_loss 297.191925,Time used 0.007000s\n",
      "batch 792, train_loss 216.133926,Time used 0.009001s\n",
      "batch 793, train_loss 318.224030,Time used 0.006999s\n",
      "batch 794, train_loss 362.053467,Time used 0.006002s\n",
      "batch 795, train_loss 281.508698,Time used 0.006998s\n",
      "batch 796, train_loss 265.773315,Time used 0.007000s\n",
      "batch 797, train_loss 337.709167,Time used 0.007003s\n",
      "batch 798, train_loss 222.385406,Time used 0.008996s\n",
      "batch 799, train_loss 266.844055,Time used 0.007004s\n",
      "batch 800, train_loss 369.631744,Time used 0.009998s\n",
      "***************************test_batch 800, test_rmse_loss 19.830841,test_mae_loss 8.411324,test_mape_loss 76.498155,Time used 0.033000s\n",
      "batch 801, train_loss 312.539825,Time used 0.010001s\n",
      "batch 802, train_loss 317.403625,Time used 0.009000s\n",
      "batch 803, train_loss 392.498962,Time used 0.009999s\n",
      "batch 804, train_loss 306.272217,Time used 0.006999s\n",
      "batch 805, train_loss 343.691681,Time used 0.006001s\n",
      "batch 806, train_loss 317.233917,Time used 0.005999s\n",
      "batch 807, train_loss 289.638763,Time used 0.009001s\n",
      "batch 808, train_loss 308.887634,Time used 0.006001s\n",
      "batch 809, train_loss 326.737762,Time used 0.009001s\n",
      "batch 810, train_loss 335.886719,Time used 0.010000s\n",
      "batch 811, train_loss 264.848602,Time used 0.012001s\n",
      "batch 812, train_loss 321.029083,Time used 0.008996s\n",
      "batch 813, train_loss 303.528534,Time used 0.016001s\n",
      "batch 814, train_loss 392.517639,Time used 0.008001s\n",
      "batch 815, train_loss 326.053558,Time used 0.007999s\n",
      "batch 816, train_loss 322.156158,Time used 0.010000s\n",
      "batch 817, train_loss 455.809753,Time used 0.010001s\n",
      "batch 818, train_loss 365.551575,Time used 0.010998s\n",
      "batch 819, train_loss 327.135254,Time used 0.011004s\n",
      "batch 820, train_loss 338.048889,Time used 0.006997s\n",
      "batch 821, train_loss 267.860138,Time used 0.009000s\n",
      "batch 822, train_loss 332.452759,Time used 0.011000s\n",
      "batch 823, train_loss 276.278442,Time used 0.010000s\n",
      "batch 824, train_loss 310.191528,Time used 0.009000s\n",
      "batch 825, train_loss 380.436310,Time used 0.009002s\n",
      "batch 826, train_loss 325.235352,Time used 0.006997s\n",
      "batch 827, train_loss 296.146027,Time used 0.008001s\n",
      "batch 828, train_loss 232.217926,Time used 0.009000s\n",
      "batch 829, train_loss 353.858612,Time used 0.008000s\n",
      "batch 830, train_loss 288.106659,Time used 0.007998s\n",
      "batch 831, train_loss 427.767151,Time used 0.007001s\n",
      "batch 832, train_loss 306.113678,Time used 0.005999s\n",
      "batch 833, train_loss 306.547333,Time used 0.007000s\n",
      "batch 834, train_loss 240.874222,Time used 0.010001s\n",
      "batch 835, train_loss 279.375031,Time used 0.010999s\n",
      "batch 836, train_loss 311.697968,Time used 0.006998s\n",
      "batch 837, train_loss 313.465240,Time used 0.009002s\n",
      "batch 838, train_loss 318.458160,Time used 0.008002s\n",
      "batch 839, train_loss 254.293777,Time used 0.010016s\n",
      "batch 840, train_loss 247.468033,Time used 0.006984s\n",
      "batch 841, train_loss 320.977264,Time used 0.008998s\n",
      "batch 842, train_loss 389.404053,Time used 0.010001s\n",
      "batch 843, train_loss 374.021545,Time used 0.008000s\n",
      "batch 844, train_loss 410.396210,Time used 0.008999s\n",
      "batch 845, train_loss 311.752838,Time used 0.008002s\n",
      "batch 846, train_loss 289.483154,Time used 0.006997s\n",
      "batch 847, train_loss 282.877106,Time used 0.006002s\n",
      "batch 848, train_loss 327.189758,Time used 0.005998s\n",
      "batch 849, train_loss 263.882141,Time used 0.007001s\n",
      "batch 850, train_loss 299.655273,Time used 0.009003s\n",
      "batch 851, train_loss 325.075439,Time used 0.006999s\n",
      "batch 852, train_loss 314.465942,Time used 0.009997s\n",
      "batch 853, train_loss 296.940613,Time used 0.006002s\n",
      "batch 854, train_loss 320.274292,Time used 0.009034s\n",
      "batch 855, train_loss 347.488831,Time used 0.008963s\n",
      "batch 856, train_loss 269.585510,Time used 0.008002s\n",
      "batch 857, train_loss 313.099121,Time used 0.008034s\n",
      "batch 858, train_loss 271.376434,Time used 0.007996s\n",
      "batch 859, train_loss 263.617310,Time used 0.007969s\n",
      "batch 860, train_loss 288.172211,Time used 0.008000s\n",
      "batch 861, train_loss 359.911072,Time used 0.009001s\n",
      "batch 862, train_loss 246.358887,Time used 0.009000s\n",
      "batch 863, train_loss 283.675446,Time used 0.009002s\n",
      "batch 864, train_loss 342.267853,Time used 0.009997s\n",
      "batch 865, train_loss 285.596466,Time used 0.006999s\n",
      "batch 866, train_loss 326.503082,Time used 0.008998s\n",
      "batch 867, train_loss 289.602844,Time used 0.010002s\n",
      "batch 868, train_loss 310.634979,Time used 0.009999s\n",
      "batch 869, train_loss 300.340393,Time used 0.008999s\n",
      "batch 870, train_loss 330.450470,Time used 0.007002s\n",
      "batch 871, train_loss 325.701813,Time used 0.008000s\n",
      "batch 872, train_loss 331.633453,Time used 0.007000s\n",
      "batch 873, train_loss 278.522797,Time used 0.009001s\n",
      "batch 874, train_loss 325.726379,Time used 0.006003s\n",
      "batch 875, train_loss 265.393463,Time used 0.007005s\n",
      "batch 876, train_loss 312.555206,Time used 0.006994s\n",
      "batch 877, train_loss 290.095612,Time used 0.009001s\n",
      "batch 878, train_loss 337.275299,Time used 0.006002s\n",
      "batch 879, train_loss 375.772430,Time used 0.007001s\n",
      "batch 880, train_loss 376.688629,Time used 0.008000s\n",
      "batch 881, train_loss 301.195679,Time used 0.007998s\n",
      "batch 882, train_loss 279.958588,Time used 0.007002s\n",
      "batch 883, train_loss 286.886169,Time used 0.005999s\n",
      "batch 884, train_loss 248.292313,Time used 0.007002s\n",
      "batch 885, train_loss 318.059814,Time used 0.007001s\n",
      "batch 886, train_loss 369.646332,Time used 0.009996s\n",
      "batch 887, train_loss 262.431488,Time used 0.010000s\n",
      "batch 888, train_loss 336.385956,Time used 0.005998s\n",
      "batch 889, train_loss 325.411713,Time used 0.010001s\n",
      "batch 890, train_loss 329.915253,Time used 0.006999s\n",
      "batch 891, train_loss 340.068756,Time used 0.006996s\n",
      "batch 892, train_loss 282.734070,Time used 0.005999s\n",
      "batch 893, train_loss 325.917450,Time used 0.005999s\n",
      "batch 894, train_loss 287.717316,Time used 0.006999s\n",
      "batch 895, train_loss 277.885437,Time used 0.006999s\n",
      "batch 896, train_loss 309.308868,Time used 0.006001s\n",
      "batch 897, train_loss 280.337402,Time used 0.007000s\n",
      "batch 898, train_loss 324.148804,Time used 0.007000s\n",
      "batch 899, train_loss 287.992279,Time used 0.006000s\n",
      "batch 900, train_loss 280.343079,Time used 0.007001s\n",
      "***************************test_batch 900, test_rmse_loss 19.596894,test_mae_loss 8.256770,test_mape_loss 76.531988,Time used 0.024001s\n",
      "batch 901, train_loss 366.804779,Time used 0.008000s\n",
      "batch 902, train_loss 357.278687,Time used 0.006999s\n",
      "batch 903, train_loss 355.602020,Time used 0.009001s\n",
      "batch 904, train_loss 308.495209,Time used 0.009000s\n",
      "batch 905, train_loss 360.885193,Time used 0.008004s\n",
      "batch 906, train_loss 288.994385,Time used 0.009996s\n",
      "batch 907, train_loss 301.908264,Time used 0.007016s\n",
      "batch 908, train_loss 289.260071,Time used 0.007002s\n",
      "batch 909, train_loss 346.261627,Time used 0.011999s\n",
      "batch 910, train_loss 273.210358,Time used 0.009999s\n",
      "batch 911, train_loss 284.873352,Time used 0.008001s\n",
      "batch 912, train_loss 230.304703,Time used 0.009998s\n",
      "batch 913, train_loss 246.853256,Time used 0.006001s\n",
      "batch 914, train_loss 316.617859,Time used 0.009000s\n",
      "batch 915, train_loss 226.491928,Time used 0.006000s\n",
      "batch 916, train_loss 325.278748,Time used 0.007004s\n",
      "batch 917, train_loss 292.415131,Time used 0.006996s\n",
      "batch 918, train_loss 280.174103,Time used 0.006999s\n",
      "batch 919, train_loss 343.045624,Time used 0.008999s\n",
      "batch 920, train_loss 278.916138,Time used 0.006002s\n",
      "batch 921, train_loss 351.201630,Time used 0.007002s\n",
      "batch 922, train_loss 302.365112,Time used 0.005997s\n",
      "batch 923, train_loss 228.821457,Time used 0.009036s\n",
      "batch 924, train_loss 346.886749,Time used 0.006965s\n",
      "batch 925, train_loss 277.169312,Time used 0.010998s\n",
      "batch 926, train_loss 302.420288,Time used 0.009004s\n",
      "batch 927, train_loss 264.708923,Time used 0.006998s\n",
      "batch 928, train_loss 320.502411,Time used 0.009999s\n",
      "batch 929, train_loss 344.047638,Time used 0.009002s\n",
      "batch 930, train_loss 353.754761,Time used 0.010997s\n",
      "batch 931, train_loss 253.007965,Time used 0.008000s\n",
      "batch 932, train_loss 334.356689,Time used 0.010000s\n",
      "batch 933, train_loss 405.654449,Time used 0.008003s\n",
      "batch 934, train_loss 366.843292,Time used 0.007995s\n",
      "batch 935, train_loss 370.542633,Time used 0.010007s\n",
      "batch 936, train_loss 238.179092,Time used 0.007996s\n",
      "batch 937, train_loss 342.439728,Time used 0.009998s\n",
      "batch 938, train_loss 270.374451,Time used 0.009000s\n",
      "batch 939, train_loss 308.544189,Time used 0.009999s\n",
      "batch 940, train_loss 268.755890,Time used 0.010001s\n",
      "batch 941, train_loss 368.829956,Time used 0.008999s\n",
      "batch 942, train_loss 329.439819,Time used 0.008000s\n",
      "batch 943, train_loss 302.645294,Time used 0.007999s\n",
      "batch 944, train_loss 308.222961,Time used 0.007001s\n",
      "batch 945, train_loss 306.033325,Time used 0.006999s\n",
      "batch 946, train_loss 266.615753,Time used 0.007003s\n",
      "batch 947, train_loss 293.625977,Time used 0.009000s\n",
      "batch 948, train_loss 293.471588,Time used 0.010998s\n",
      "batch 949, train_loss 315.801758,Time used 0.007999s\n",
      "batch 950, train_loss 343.096100,Time used 0.008998s\n",
      "batch 951, train_loss 315.980103,Time used 0.009003s\n",
      "batch 952, train_loss 304.077576,Time used 0.007000s\n",
      "batch 953, train_loss 273.209839,Time used 0.009001s\n",
      "batch 954, train_loss 281.874268,Time used 0.006998s\n",
      "batch 955, train_loss 305.175446,Time used 0.007001s\n",
      "batch 956, train_loss 321.421295,Time used 0.006999s\n",
      "batch 957, train_loss 234.855057,Time used 0.007000s\n",
      "batch 958, train_loss 349.571655,Time used 0.007000s\n",
      "batch 959, train_loss 308.713837,Time used 0.006999s\n",
      "batch 960, train_loss 315.599396,Time used 0.007000s\n",
      "batch 961, train_loss 371.038025,Time used 0.010001s\n",
      "batch 962, train_loss 277.327820,Time used 0.007002s\n",
      "batch 963, train_loss 306.263214,Time used 0.006997s\n",
      "batch 964, train_loss 302.862274,Time used 0.008003s\n",
      "batch 965, train_loss 306.022980,Time used 0.010999s\n",
      "batch 966, train_loss 267.192688,Time used 0.010000s\n",
      "batch 967, train_loss 293.251740,Time used 0.010000s\n",
      "batch 968, train_loss 324.014832,Time used 0.008999s\n",
      "batch 969, train_loss 338.151825,Time used 0.006002s\n",
      "batch 970, train_loss 329.922668,Time used 0.012999s\n",
      "batch 971, train_loss 334.764221,Time used 0.008002s\n",
      "batch 972, train_loss 356.874603,Time used 0.007002s\n",
      "batch 973, train_loss 293.659149,Time used 0.011999s\n",
      "batch 974, train_loss 369.796631,Time used 0.011001s\n",
      "batch 975, train_loss 281.460846,Time used 0.009999s\n",
      "batch 976, train_loss 278.036682,Time used 0.010000s\n",
      "batch 977, train_loss 293.574371,Time used 0.009006s\n",
      "batch 978, train_loss 182.902054,Time used 0.006995s\n",
      "batch 979, train_loss 292.590149,Time used 0.007998s\n",
      "batch 980, train_loss 278.455566,Time used 0.008998s\n",
      "batch 981, train_loss 284.490997,Time used 0.009001s\n",
      "batch 982, train_loss 314.177612,Time used 0.010002s\n",
      "batch 983, train_loss 310.365234,Time used 0.010997s\n",
      "batch 984, train_loss 293.026520,Time used 0.007001s\n",
      "batch 985, train_loss 261.155457,Time used 0.009001s\n",
      "batch 986, train_loss 258.510681,Time used 0.010002s\n",
      "batch 987, train_loss 261.363800,Time used 0.009999s\n",
      "batch 988, train_loss 365.857849,Time used 0.008993s\n",
      "batch 989, train_loss 345.357483,Time used 0.007001s\n",
      "batch 990, train_loss 283.913757,Time used 0.011000s\n",
      "batch 991, train_loss 273.975922,Time used 0.010000s\n",
      "batch 992, train_loss 308.523071,Time used 0.008999s\n",
      "batch 993, train_loss 244.332397,Time used 0.009001s\n",
      "batch 994, train_loss 342.012177,Time used 0.010002s\n",
      "batch 995, train_loss 304.639526,Time used 0.008999s\n",
      "batch 996, train_loss 299.977966,Time used 0.010002s\n",
      "batch 997, train_loss 357.960846,Time used 0.009997s\n",
      "batch 998, train_loss 244.714111,Time used 0.010998s\n",
      "batch 999, train_loss 296.782990,Time used 0.012002s\n",
      "batch 1000, train_loss 306.216248,Time used 0.009996s\n",
      "***************************test_batch 1000, test_rmse_loss 19.361002,test_mae_loss 8.111344,test_mape_loss 76.568389,Time used 0.039000s\n",
      "batch 1001, train_loss 309.773407,Time used 0.009001s\n",
      "batch 1002, train_loss 350.803772,Time used 0.011998s\n",
      "batch 1003, train_loss 322.297516,Time used 0.012003s\n",
      "batch 1004, train_loss 374.123718,Time used 0.011997s\n",
      "batch 1005, train_loss 248.144272,Time used 0.010997s\n",
      "batch 1006, train_loss 277.132874,Time used 0.010001s\n",
      "batch 1007, train_loss 291.970551,Time used 0.008002s\n",
      "batch 1008, train_loss 304.123077,Time used 0.007998s\n",
      "batch 1009, train_loss 338.121887,Time used 0.013001s\n",
      "batch 1010, train_loss 298.651276,Time used 0.010998s\n",
      "batch 1011, train_loss 344.415222,Time used 0.010003s\n",
      "batch 1012, train_loss 361.382233,Time used 0.010998s\n",
      "batch 1013, train_loss 298.127014,Time used 0.006999s\n",
      "batch 1014, train_loss 329.974945,Time used 0.008000s\n",
      "batch 1015, train_loss 305.674316,Time used 0.008000s\n",
      "batch 1016, train_loss 344.885559,Time used 0.011997s\n",
      "batch 1017, train_loss 276.120422,Time used 0.006001s\n",
      "batch 1018, train_loss 293.784546,Time used 0.007000s\n",
      "batch 1019, train_loss 303.442200,Time used 0.007002s\n",
      "batch 1020, train_loss 296.210297,Time used 0.008001s\n",
      "batch 1021, train_loss 237.884109,Time used 0.007999s\n",
      "batch 1022, train_loss 284.964569,Time used 0.009014s\n",
      "batch 1023, train_loss 253.134064,Time used 0.009987s\n",
      "batch 1024, train_loss 302.760468,Time used 0.008003s\n",
      "batch 1025, train_loss 268.362762,Time used 0.008998s\n",
      "batch 1026, train_loss 281.009430,Time used 0.006997s\n",
      "batch 1027, train_loss 291.285797,Time used 0.008000s\n",
      "batch 1028, train_loss 270.756775,Time used 0.009001s\n",
      "batch 1029, train_loss 316.353180,Time used 0.009001s\n",
      "batch 1030, train_loss 301.455109,Time used 0.010997s\n",
      "batch 1031, train_loss 289.985626,Time used 0.006000s\n",
      "batch 1032, train_loss 299.018158,Time used 0.005998s\n",
      "batch 1033, train_loss 305.819000,Time used 0.009002s\n",
      "batch 1034, train_loss 294.215424,Time used 0.007001s\n",
      "batch 1035, train_loss 256.956848,Time used 0.005998s\n",
      "batch 1036, train_loss 261.262207,Time used 0.009999s\n",
      "batch 1037, train_loss 312.479523,Time used 0.010001s\n",
      "batch 1038, train_loss 293.076782,Time used 0.007000s\n",
      "batch 1039, train_loss 332.532227,Time used 0.008003s\n",
      "batch 1040, train_loss 312.158112,Time used 0.006999s\n",
      "batch 1041, train_loss 362.820831,Time used 0.008999s\n",
      "batch 1042, train_loss 280.999969,Time used 0.007000s\n",
      "batch 1043, train_loss 282.580414,Time used 0.008001s\n",
      "batch 1044, train_loss 283.429443,Time used 0.008002s\n",
      "batch 1045, train_loss 259.482910,Time used 0.009000s\n",
      "batch 1046, train_loss 280.877502,Time used 0.010000s\n",
      "batch 1047, train_loss 284.135193,Time used 0.009001s\n",
      "batch 1048, train_loss 285.484406,Time used 0.009998s\n",
      "batch 1049, train_loss 326.194580,Time used 0.011000s\n",
      "batch 1050, train_loss 351.887146,Time used 0.007000s\n",
      "batch 1051, train_loss 279.643250,Time used 0.007001s\n",
      "batch 1052, train_loss 305.022827,Time used 0.008999s\n",
      "batch 1053, train_loss 314.370636,Time used 0.008999s\n",
      "batch 1054, train_loss 265.818939,Time used 0.008998s\n",
      "batch 1055, train_loss 275.708557,Time used 0.008004s\n",
      "batch 1056, train_loss 337.002625,Time used 0.008995s\n",
      "batch 1057, train_loss 344.863708,Time used 0.010002s\n",
      "batch 1058, train_loss 363.503662,Time used 0.008998s\n",
      "batch 1059, train_loss 297.693726,Time used 0.010001s\n",
      "batch 1060, train_loss 216.441010,Time used 0.005996s\n",
      "batch 1061, train_loss 248.389648,Time used 0.007010s\n",
      "batch 1062, train_loss 289.882507,Time used 0.009991s\n",
      "batch 1063, train_loss 253.953903,Time used 0.010001s\n",
      "batch 1064, train_loss 352.013519,Time used 0.007000s\n",
      "batch 1065, train_loss 279.163269,Time used 0.010000s\n",
      "batch 1066, train_loss 335.026855,Time used 0.008999s\n",
      "batch 1067, train_loss 260.139313,Time used 0.005999s\n",
      "batch 1068, train_loss 335.054260,Time used 0.008001s\n",
      "batch 1069, train_loss 290.260651,Time used 0.008999s\n",
      "batch 1070, train_loss 248.235062,Time used 0.009000s\n",
      "batch 1071, train_loss 282.693665,Time used 0.011000s\n",
      "batch 1072, train_loss 299.726044,Time used 0.006999s\n",
      "batch 1073, train_loss 297.189636,Time used 0.005999s\n",
      "batch 1074, train_loss 344.159821,Time used 0.006000s\n",
      "batch 1075, train_loss 321.105591,Time used 0.007001s\n",
      "batch 1076, train_loss 319.255859,Time used 0.007999s\n",
      "batch 1077, train_loss 299.144806,Time used 0.006000s\n",
      "batch 1078, train_loss 282.592926,Time used 0.006999s\n",
      "batch 1079, train_loss 262.338745,Time used 0.007000s\n",
      "batch 1080, train_loss 274.333466,Time used 0.007002s\n",
      "batch 1081, train_loss 277.972107,Time used 0.005999s\n",
      "batch 1082, train_loss 286.730225,Time used 0.010001s\n",
      "batch 1083, train_loss 297.313477,Time used 0.006999s\n",
      "batch 1084, train_loss 245.301727,Time used 0.009003s\n",
      "batch 1085, train_loss 340.493225,Time used 0.009998s\n",
      "batch 1086, train_loss 350.698792,Time used 0.006032s\n",
      "batch 1087, train_loss 326.475433,Time used 0.006970s\n",
      "batch 1088, train_loss 280.344971,Time used 0.009997s\n",
      "batch 1089, train_loss 355.567963,Time used 0.008004s\n",
      "batch 1090, train_loss 328.013580,Time used 0.009995s\n",
      "batch 1091, train_loss 285.078430,Time used 0.009000s\n",
      "batch 1092, train_loss 310.259552,Time used 0.009000s\n",
      "batch 1093, train_loss 244.617569,Time used 0.008001s\n",
      "batch 1094, train_loss 302.713043,Time used 0.007002s\n",
      "batch 1095, train_loss 266.533539,Time used 0.010000s\n",
      "batch 1096, train_loss 306.282288,Time used 0.006001s\n",
      "batch 1097, train_loss 301.461792,Time used 0.008002s\n",
      "batch 1098, train_loss 276.726410,Time used 0.005999s\n",
      "batch 1099, train_loss 315.523804,Time used 0.007999s\n",
      "batch 1100, train_loss 240.078873,Time used 0.005996s\n",
      "***************************test_batch 1100, test_rmse_loss 19.130044,test_mae_loss 7.963772,test_mape_loss 76.528756,Time used 0.027002s\n",
      "batch 1101, train_loss 349.524872,Time used 0.010001s\n",
      "batch 1102, train_loss 235.097244,Time used 0.010000s\n",
      "batch 1103, train_loss 255.382706,Time used 0.009005s\n",
      "batch 1104, train_loss 275.352386,Time used 0.006999s\n",
      "batch 1105, train_loss 268.894379,Time used 0.008003s\n",
      "batch 1106, train_loss 254.261307,Time used 0.007999s\n",
      "batch 1107, train_loss 282.311768,Time used 0.008003s\n",
      "batch 1108, train_loss 244.537872,Time used 0.006998s\n",
      "batch 1109, train_loss 293.294037,Time used 0.005997s\n",
      "batch 1110, train_loss 304.297150,Time used 0.010002s\n",
      "batch 1111, train_loss 268.452484,Time used 0.006999s\n",
      "batch 1112, train_loss 314.305084,Time used 0.008002s\n",
      "batch 1113, train_loss 250.141388,Time used 0.011003s\n",
      "batch 1114, train_loss 314.993652,Time used 0.009997s\n",
      "batch 1115, train_loss 286.567963,Time used 0.010000s\n",
      "batch 1116, train_loss 268.282715,Time used 0.008002s\n",
      "batch 1117, train_loss 304.590424,Time used 0.011002s\n",
      "batch 1118, train_loss 277.574310,Time used 0.010999s\n",
      "batch 1119, train_loss 366.553162,Time used 0.008999s\n",
      "batch 1120, train_loss 257.227722,Time used 0.010000s\n",
      "batch 1121, train_loss 335.574158,Time used 0.008002s\n",
      "batch 1122, train_loss 368.292297,Time used 0.010998s\n",
      "batch 1123, train_loss 264.126923,Time used 0.010001s\n",
      "batch 1124, train_loss 324.547302,Time used 0.009002s\n",
      "batch 1125, train_loss 326.851654,Time used 0.009999s\n",
      "batch 1126, train_loss 267.777679,Time used 0.011003s\n",
      "batch 1127, train_loss 256.435638,Time used 0.010000s\n",
      "batch 1128, train_loss 311.742676,Time used 0.009997s\n",
      "batch 1129, train_loss 249.735779,Time used 0.008000s\n",
      "batch 1130, train_loss 259.833557,Time used 0.008003s\n",
      "batch 1131, train_loss 274.545959,Time used 0.010998s\n",
      "batch 1132, train_loss 313.363495,Time used 0.011000s\n",
      "batch 1133, train_loss 244.585510,Time used 0.009003s\n",
      "batch 1134, train_loss 244.694931,Time used 0.007995s\n",
      "batch 1135, train_loss 323.479187,Time used 0.008002s\n",
      "batch 1136, train_loss 347.207062,Time used 0.011001s\n",
      "batch 1137, train_loss 277.682404,Time used 0.008999s\n",
      "batch 1138, train_loss 295.707672,Time used 0.011002s\n",
      "batch 1139, train_loss 301.462372,Time used 0.006999s\n",
      "batch 1140, train_loss 261.381683,Time used 0.005999s\n",
      "batch 1141, train_loss 342.785156,Time used 0.011001s\n",
      "batch 1142, train_loss 252.750061,Time used 0.009998s\n",
      "batch 1143, train_loss 255.916779,Time used 0.010001s\n",
      "batch 1144, train_loss 310.356232,Time used 0.009003s\n",
      "batch 1145, train_loss 310.102020,Time used 0.009999s\n",
      "batch 1146, train_loss 284.774933,Time used 0.009999s\n",
      "batch 1147, train_loss 306.193024,Time used 0.009000s\n",
      "batch 1148, train_loss 299.808472,Time used 0.008000s\n",
      "batch 1149, train_loss 286.070862,Time used 0.009001s\n",
      "batch 1150, train_loss 323.893555,Time used 0.008001s\n",
      "batch 1151, train_loss 299.955902,Time used 0.009000s\n",
      "batch 1152, train_loss 302.620972,Time used 0.008999s\n",
      "batch 1153, train_loss 297.084869,Time used 0.008003s\n",
      "batch 1154, train_loss 264.872681,Time used 0.007034s\n",
      "batch 1155, train_loss 329.724884,Time used 0.006962s\n",
      "batch 1156, train_loss 231.611359,Time used 0.009014s\n",
      "batch 1157, train_loss 270.041199,Time used 0.006986s\n",
      "batch 1158, train_loss 274.596161,Time used 0.007002s\n",
      "batch 1159, train_loss 340.135590,Time used 0.005997s\n",
      "batch 1160, train_loss 215.579163,Time used 0.008001s\n",
      "batch 1161, train_loss 278.917480,Time used 0.006000s\n",
      "batch 1162, train_loss 243.603973,Time used 0.007000s\n",
      "batch 1163, train_loss 290.747955,Time used 0.005999s\n",
      "batch 1164, train_loss 330.466583,Time used 0.007002s\n",
      "batch 1165, train_loss 289.651581,Time used 0.009999s\n",
      "batch 1166, train_loss 326.365662,Time used 0.007001s\n",
      "batch 1167, train_loss 261.476593,Time used 0.007036s\n",
      "batch 1168, train_loss 290.041290,Time used 0.008966s\n",
      "batch 1169, train_loss 338.390656,Time used 0.009998s\n",
      "batch 1170, train_loss 367.254700,Time used 0.009998s\n",
      "batch 1171, train_loss 258.285004,Time used 0.010003s\n",
      "batch 1172, train_loss 294.143829,Time used 0.007999s\n",
      "batch 1173, train_loss 283.056824,Time used 0.007000s\n",
      "batch 1174, train_loss 327.733459,Time used 0.008000s\n",
      "batch 1175, train_loss 273.432373,Time used 0.005999s\n",
      "batch 1176, train_loss 247.654984,Time used 0.008001s\n",
      "batch 1177, train_loss 223.226120,Time used 0.010002s\n",
      "batch 1178, train_loss 258.066345,Time used 0.011000s\n",
      "batch 1179, train_loss 215.365341,Time used 0.005999s\n",
      "batch 1180, train_loss 294.943726,Time used 0.008999s\n",
      "batch 1181, train_loss 256.414886,Time used 0.010000s\n",
      "batch 1182, train_loss 271.160889,Time used 0.009000s\n",
      "batch 1183, train_loss 286.812042,Time used 0.008001s\n",
      "batch 1184, train_loss 228.226105,Time used 0.010999s\n",
      "batch 1185, train_loss 333.618805,Time used 0.008004s\n",
      "batch 1186, train_loss 269.827271,Time used 0.009996s\n",
      "batch 1187, train_loss 278.606567,Time used 0.010999s\n",
      "batch 1188, train_loss 329.886322,Time used 0.007999s\n",
      "batch 1189, train_loss 328.557922,Time used 0.010000s\n",
      "batch 1190, train_loss 287.554199,Time used 0.011003s\n",
      "batch 1191, train_loss 301.068176,Time used 0.010998s\n",
      "batch 1192, train_loss 364.218811,Time used 0.009001s\n",
      "batch 1193, train_loss 371.062012,Time used 0.009998s\n",
      "batch 1194, train_loss 289.812805,Time used 0.010001s\n",
      "batch 1195, train_loss 282.043335,Time used 0.010999s\n",
      "batch 1196, train_loss 325.796478,Time used 0.011001s\n",
      "batch 1197, train_loss 303.995422,Time used 0.009999s\n",
      "batch 1198, train_loss 253.023972,Time used 0.007998s\n",
      "batch 1199, train_loss 238.824661,Time used 0.007001s\n",
      "batch 1200, train_loss 293.029358,Time used 0.008001s\n",
      "***************************test_batch 1200, test_rmse_loss 18.910285,test_mae_loss 7.827338,test_mape_loss 76.618869,Time used 0.034996s\n",
      "batch 1201, train_loss 269.858612,Time used 0.008999s\n",
      "batch 1202, train_loss 260.658630,Time used 0.006001s\n",
      "batch 1203, train_loss 250.254593,Time used 0.008000s\n",
      "batch 1204, train_loss 342.861603,Time used 0.006999s\n",
      "batch 1205, train_loss 267.296173,Time used 0.008000s\n",
      "batch 1206, train_loss 284.369171,Time used 0.007997s\n",
      "batch 1207, train_loss 321.449127,Time used 0.008003s\n",
      "batch 1208, train_loss 266.586090,Time used 0.006018s\n",
      "batch 1209, train_loss 292.179016,Time used 0.006980s\n",
      "batch 1210, train_loss 311.695679,Time used 0.007002s\n",
      "batch 1211, train_loss 266.667694,Time used 0.005997s\n",
      "batch 1212, train_loss 312.595825,Time used 0.005999s\n",
      "batch 1213, train_loss 289.840240,Time used 0.007001s\n",
      "batch 1214, train_loss 306.678436,Time used 0.007000s\n",
      "batch 1215, train_loss 221.554443,Time used 0.008000s\n",
      "batch 1216, train_loss 301.958130,Time used 0.008999s\n",
      "batch 1217, train_loss 336.833740,Time used 0.009003s\n",
      "batch 1218, train_loss 240.388306,Time used 0.007000s\n",
      "batch 1219, train_loss 317.718170,Time used 0.010001s\n",
      "batch 1220, train_loss 230.016068,Time used 0.010000s\n",
      "batch 1221, train_loss 266.079285,Time used 0.006999s\n",
      "batch 1222, train_loss 325.856659,Time used 0.006000s\n",
      "batch 1223, train_loss 214.919739,Time used 0.007000s\n",
      "batch 1224, train_loss 347.974548,Time used 0.007000s\n",
      "batch 1225, train_loss 314.133820,Time used 0.008998s\n",
      "batch 1226, train_loss 328.458313,Time used 0.007998s\n",
      "batch 1227, train_loss 291.177979,Time used 0.007003s\n",
      "batch 1228, train_loss 298.855591,Time used 0.006998s\n",
      "batch 1229, train_loss 358.846924,Time used 0.006997s\n",
      "batch 1230, train_loss 276.885712,Time used 0.009001s\n",
      "batch 1231, train_loss 318.395813,Time used 0.008002s\n",
      "batch 1232, train_loss 243.707382,Time used 0.010001s\n",
      "batch 1233, train_loss 264.287079,Time used 0.009000s\n",
      "batch 1234, train_loss 275.440582,Time used 0.006997s\n",
      "batch 1235, train_loss 301.407166,Time used 0.009002s\n",
      "batch 1236, train_loss 259.658173,Time used 0.006998s\n",
      "batch 1237, train_loss 276.826141,Time used 0.009002s\n",
      "batch 1238, train_loss 307.782593,Time used 0.009000s\n",
      "batch 1239, train_loss 230.521240,Time used 0.010996s\n",
      "batch 1240, train_loss 228.879883,Time used 0.008001s\n",
      "batch 1241, train_loss 279.706329,Time used 0.007999s\n",
      "batch 1242, train_loss 310.784729,Time used 0.009001s\n",
      "batch 1243, train_loss 234.066879,Time used 0.009001s\n",
      "batch 1244, train_loss 311.472565,Time used 0.008999s\n",
      "batch 1245, train_loss 303.489929,Time used 0.005999s\n",
      "batch 1246, train_loss 260.032867,Time used 0.011002s\n",
      "batch 1247, train_loss 240.023392,Time used 0.011001s\n",
      "batch 1248, train_loss 288.599426,Time used 0.008000s\n",
      "batch 1249, train_loss 270.481049,Time used 0.008001s\n",
      "batch 1250, train_loss 418.807495,Time used 0.008001s\n",
      "batch 1251, train_loss 301.400177,Time used 0.006998s\n",
      "batch 1252, train_loss 314.363007,Time used 0.010000s\n",
      "batch 1253, train_loss 245.419571,Time used 0.009999s\n",
      "batch 1254, train_loss 272.055817,Time used 0.007999s\n",
      "batch 1255, train_loss 233.782516,Time used 0.008004s\n",
      "batch 1256, train_loss 262.412750,Time used 0.006997s\n",
      "batch 1257, train_loss 257.748383,Time used 0.006001s\n",
      "batch 1258, train_loss 214.968628,Time used 0.006999s\n",
      "batch 1259, train_loss 315.511566,Time used 0.007001s\n",
      "batch 1260, train_loss 302.958130,Time used 0.006003s\n",
      "batch 1261, train_loss 306.375641,Time used 0.005997s\n",
      "batch 1262, train_loss 273.234802,Time used 0.007001s\n",
      "batch 1263, train_loss 257.044861,Time used 0.006002s\n",
      "batch 1264, train_loss 311.512726,Time used 0.006997s\n",
      "batch 1265, train_loss 266.585754,Time used 0.009002s\n",
      "batch 1266, train_loss 336.045471,Time used 0.008003s\n",
      "batch 1267, train_loss 259.538910,Time used 0.006998s\n",
      "batch 1268, train_loss 236.937973,Time used 0.006998s\n",
      "batch 1269, train_loss 313.038544,Time used 0.006001s\n",
      "batch 1270, train_loss 296.376160,Time used 0.005999s\n",
      "batch 1271, train_loss 249.582108,Time used 0.006000s\n",
      "batch 1272, train_loss 245.376099,Time used 0.006038s\n",
      "batch 1273, train_loss 231.046204,Time used 0.007000s\n",
      "batch 1274, train_loss 240.893463,Time used 0.007000s\n",
      "batch 1275, train_loss 333.754761,Time used 0.006002s\n",
      "batch 1276, train_loss 294.904480,Time used 0.006999s\n",
      "batch 1277, train_loss 277.272308,Time used 0.005999s\n",
      "batch 1278, train_loss 299.416595,Time used 0.007003s\n",
      "batch 1279, train_loss 293.753265,Time used 0.010001s\n",
      "batch 1280, train_loss 371.549225,Time used 0.007999s\n",
      "batch 1281, train_loss 250.179977,Time used 0.006999s\n",
      "batch 1282, train_loss 255.760254,Time used 0.006001s\n",
      "batch 1283, train_loss 285.243591,Time used 0.006000s\n",
      "batch 1284, train_loss 297.655640,Time used 0.006000s\n",
      "batch 1285, train_loss 326.348419,Time used 0.007000s\n",
      "batch 1286, train_loss 318.101318,Time used 0.007000s\n",
      "batch 1287, train_loss 243.716583,Time used 0.005999s\n",
      "batch 1288, train_loss 248.368027,Time used 0.007000s\n",
      "batch 1289, train_loss 195.124252,Time used 0.009000s\n",
      "batch 1290, train_loss 279.748718,Time used 0.009002s\n",
      "batch 1291, train_loss 294.691742,Time used 0.010999s\n",
      "batch 1292, train_loss 241.054962,Time used 0.009999s\n",
      "batch 1293, train_loss 279.959869,Time used 0.009007s\n",
      "batch 1294, train_loss 370.358490,Time used 0.009035s\n",
      "batch 1295, train_loss 256.900970,Time used 0.009971s\n",
      "batch 1296, train_loss 235.715652,Time used 0.006996s\n",
      "batch 1297, train_loss 286.977997,Time used 0.011029s\n",
      "batch 1298, train_loss 279.016541,Time used 0.009964s\n",
      "batch 1299, train_loss 279.148651,Time used 0.012000s\n",
      "batch 1300, train_loss 325.592102,Time used 0.008999s\n",
      "***************************test_batch 1300, test_rmse_loss 18.696993,test_mae_loss 7.695828,test_mape_loss 76.457317,Time used 0.032005s\n",
      "batch 1301, train_loss 264.958099,Time used 0.010998s\n",
      "batch 1302, train_loss 255.426498,Time used 0.006001s\n",
      "batch 1303, train_loss 288.259491,Time used 0.009001s\n",
      "batch 1304, train_loss 286.293854,Time used 0.009001s\n",
      "batch 1305, train_loss 280.415466,Time used 0.007998s\n",
      "batch 1306, train_loss 238.987549,Time used 0.007001s\n",
      "batch 1307, train_loss 238.381546,Time used 0.007999s\n",
      "batch 1308, train_loss 297.591858,Time used 0.007002s\n",
      "batch 1309, train_loss 302.535309,Time used 0.009000s\n",
      "batch 1310, train_loss 277.471527,Time used 0.009000s\n",
      "batch 1311, train_loss 353.816345,Time used 0.008001s\n",
      "batch 1312, train_loss 238.434036,Time used 0.010997s\n",
      "batch 1313, train_loss 309.479980,Time used 0.009001s\n",
      "batch 1314, train_loss 205.066666,Time used 0.005999s\n",
      "batch 1315, train_loss 279.223907,Time used 0.007000s\n",
      "batch 1316, train_loss 223.012421,Time used 0.007000s\n",
      "batch 1317, train_loss 307.303101,Time used 0.006999s\n",
      "batch 1318, train_loss 336.600159,Time used 0.006001s\n",
      "batch 1319, train_loss 240.716614,Time used 0.007999s\n",
      "batch 1320, train_loss 289.640961,Time used 0.007003s\n",
      "batch 1321, train_loss 308.632172,Time used 0.009998s\n",
      "batch 1322, train_loss 313.116577,Time used 0.010002s\n",
      "batch 1323, train_loss 245.404907,Time used 0.009000s\n",
      "batch 1324, train_loss 224.313339,Time used 0.006999s\n",
      "batch 1325, train_loss 321.475616,Time used 0.008001s\n",
      "batch 1326, train_loss 196.233093,Time used 0.009999s\n",
      "batch 1327, train_loss 287.502838,Time used 0.009001s\n",
      "batch 1328, train_loss 224.736008,Time used 0.008001s\n",
      "batch 1329, train_loss 298.430023,Time used 0.006000s\n",
      "batch 1330, train_loss 290.402649,Time used 0.007003s\n",
      "batch 1331, train_loss 346.975769,Time used 0.005997s\n",
      "batch 1332, train_loss 269.686981,Time used 0.006000s\n",
      "batch 1333, train_loss 290.185455,Time used 0.008998s\n",
      "batch 1334, train_loss 255.346054,Time used 0.007000s\n",
      "batch 1335, train_loss 273.804138,Time used 0.008002s\n",
      "batch 1336, train_loss 291.660370,Time used 0.007999s\n",
      "batch 1337, train_loss 278.259918,Time used 0.008001s\n",
      "batch 1338, train_loss 244.816925,Time used 0.011002s\n",
      "batch 1339, train_loss 323.673370,Time used 0.008996s\n",
      "batch 1340, train_loss 226.023865,Time used 0.007004s\n",
      "batch 1341, train_loss 332.573334,Time used 0.006997s\n",
      "batch 1342, train_loss 218.789093,Time used 0.007003s\n",
      "batch 1343, train_loss 307.303619,Time used 0.009997s\n",
      "batch 1344, train_loss 275.468903,Time used 0.009002s\n",
      "batch 1345, train_loss 285.182861,Time used 0.009002s\n",
      "batch 1346, train_loss 272.685638,Time used 0.005999s\n",
      "batch 1347, train_loss 252.529968,Time used 0.007999s\n",
      "batch 1348, train_loss 304.275513,Time used 0.007000s\n",
      "batch 1349, train_loss 228.309479,Time used 0.006000s\n",
      "batch 1350, train_loss 279.659088,Time used 0.008000s\n",
      "batch 1351, train_loss 317.694366,Time used 0.007000s\n",
      "batch 1352, train_loss 258.766052,Time used 0.009000s\n",
      "batch 1353, train_loss 266.279694,Time used 0.009020s\n",
      "batch 1354, train_loss 250.638153,Time used 0.007997s\n",
      "batch 1355, train_loss 326.792450,Time used 0.005985s\n",
      "batch 1356, train_loss 247.722076,Time used 0.009999s\n",
      "batch 1357, train_loss 260.868896,Time used 0.007005s\n",
      "batch 1358, train_loss 306.599945,Time used 0.010997s\n",
      "batch 1359, train_loss 323.256378,Time used 0.009002s\n",
      "batch 1360, train_loss 278.150726,Time used 0.006998s\n",
      "batch 1361, train_loss 182.444702,Time used 0.009003s\n",
      "batch 1362, train_loss 273.989258,Time used 0.005998s\n",
      "batch 1363, train_loss 305.523773,Time used 0.007002s\n",
      "batch 1364, train_loss 299.711670,Time used 0.006999s\n",
      "batch 1365, train_loss 236.692490,Time used 0.008997s\n",
      "batch 1366, train_loss 321.985138,Time used 0.008002s\n",
      "batch 1367, train_loss 263.061737,Time used 0.007998s\n",
      "batch 1368, train_loss 263.120239,Time used 0.008000s\n",
      "batch 1369, train_loss 318.693207,Time used 0.010999s\n",
      "batch 1370, train_loss 231.056396,Time used 0.008002s\n",
      "batch 1371, train_loss 327.226929,Time used 0.007000s\n",
      "batch 1372, train_loss 287.947205,Time used 0.008999s\n",
      "batch 1373, train_loss 299.941376,Time used 0.009002s\n",
      "batch 1374, train_loss 206.676895,Time used 0.009999s\n",
      "batch 1375, train_loss 322.056488,Time used 0.007999s\n",
      "batch 1376, train_loss 320.051514,Time used 0.010000s\n",
      "batch 1377, train_loss 277.496185,Time used 0.009999s\n",
      "batch 1378, train_loss 269.662964,Time used 0.006001s\n",
      "batch 1379, train_loss 229.725693,Time used 0.009001s\n",
      "batch 1380, train_loss 227.073822,Time used 0.006000s\n",
      "batch 1381, train_loss 255.446014,Time used 0.008001s\n",
      "batch 1382, train_loss 265.407806,Time used 0.008000s\n",
      "batch 1383, train_loss 253.068405,Time used 0.009001s\n",
      "batch 1384, train_loss 230.494659,Time used 0.007999s\n",
      "batch 1385, train_loss 318.670898,Time used 0.008996s\n",
      "batch 1386, train_loss 231.845047,Time used 0.010001s\n",
      "batch 1387, train_loss 364.397583,Time used 0.006999s\n",
      "batch 1388, train_loss 319.601013,Time used 0.007004s\n",
      "batch 1389, train_loss 277.903412,Time used 0.008999s\n",
      "batch 1390, train_loss 241.976440,Time used 0.008000s\n",
      "batch 1391, train_loss 263.635681,Time used 0.005998s\n",
      "batch 1392, train_loss 226.258331,Time used 0.007002s\n",
      "batch 1393, train_loss 285.396759,Time used 0.006000s\n",
      "batch 1394, train_loss 249.100723,Time used 0.006000s\n",
      "batch 1395, train_loss 248.320953,Time used 0.006000s\n",
      "batch 1396, train_loss 262.532806,Time used 0.007999s\n",
      "batch 1397, train_loss 276.346771,Time used 0.007001s\n",
      "batch 1398, train_loss 226.504883,Time used 0.007999s\n",
      "batch 1399, train_loss 276.687347,Time used 0.006001s\n",
      "batch 1400, train_loss 311.256195,Time used 0.009999s\n",
      "***************************test_batch 1400, test_rmse_loss 18.490499,test_mae_loss 7.569219,test_mape_loss 76.051357,Time used 0.028001s\n",
      "batch 1401, train_loss 251.930756,Time used 0.010000s\n",
      "batch 1402, train_loss 304.520477,Time used 0.009000s\n",
      "batch 1403, train_loss 259.518127,Time used 0.006000s\n",
      "batch 1404, train_loss 280.410278,Time used 0.005999s\n",
      "batch 1405, train_loss 316.902161,Time used 0.005999s\n",
      "batch 1406, train_loss 249.410675,Time used 0.007001s\n",
      "batch 1407, train_loss 247.536407,Time used 0.006999s\n",
      "batch 1408, train_loss 282.827454,Time used 0.009004s\n",
      "batch 1409, train_loss 281.045898,Time used 0.007997s\n",
      "batch 1410, train_loss 294.222076,Time used 0.006000s\n",
      "batch 1411, train_loss 231.160156,Time used 0.008001s\n",
      "batch 1412, train_loss 237.590515,Time used 0.006000s\n",
      "batch 1413, train_loss 279.444275,Time used 0.006998s\n",
      "batch 1414, train_loss 286.425385,Time used 0.007004s\n",
      "batch 1415, train_loss 351.526367,Time used 0.005998s\n",
      "batch 1416, train_loss 238.375229,Time used 0.009999s\n",
      "batch 1417, train_loss 311.373993,Time used 0.010001s\n",
      "batch 1418, train_loss 281.742920,Time used 0.010001s\n",
      "batch 1419, train_loss 224.818497,Time used 0.008994s\n",
      "batch 1420, train_loss 319.971405,Time used 0.010004s\n",
      "batch 1421, train_loss 262.393951,Time used 0.010000s\n",
      "batch 1422, train_loss 226.152344,Time used 0.006000s\n",
      "batch 1423, train_loss 244.660873,Time used 0.008997s\n",
      "batch 1424, train_loss 310.130096,Time used 0.009001s\n",
      "batch 1425, train_loss 223.494568,Time used 0.009000s\n",
      "batch 1426, train_loss 329.055969,Time used 0.009002s\n",
      "batch 1427, train_loss 254.150726,Time used 0.006999s\n",
      "batch 1428, train_loss 205.001968,Time used 0.007000s\n",
      "batch 1429, train_loss 304.848083,Time used 0.007000s\n",
      "batch 1430, train_loss 247.675079,Time used 0.006001s\n",
      "batch 1431, train_loss 288.927734,Time used 0.008999s\n",
      "batch 1432, train_loss 259.942169,Time used 0.009002s\n",
      "batch 1433, train_loss 223.394348,Time used 0.009999s\n",
      "batch 1434, train_loss 299.252441,Time used 0.006004s\n",
      "batch 1435, train_loss 215.301178,Time used 0.006002s\n",
      "batch 1436, train_loss 303.755219,Time used 0.006999s\n",
      "batch 1437, train_loss 320.034454,Time used 0.005998s\n",
      "batch 1438, train_loss 262.248138,Time used 0.008000s\n",
      "batch 1439, train_loss 289.748993,Time used 0.009002s\n",
      "batch 1440, train_loss 285.357758,Time used 0.005998s\n",
      "batch 1441, train_loss 232.786041,Time used 0.007999s\n",
      "batch 1442, train_loss 230.005127,Time used 0.008000s\n",
      "batch 1443, train_loss 248.688217,Time used 0.006999s\n",
      "batch 1444, train_loss 286.909241,Time used 0.009000s\n",
      "batch 1445, train_loss 270.271637,Time used 0.009000s\n",
      "batch 1446, train_loss 310.142578,Time used 0.006004s\n",
      "batch 1447, train_loss 308.011292,Time used 0.007001s\n",
      "batch 1448, train_loss 247.775803,Time used 0.007998s\n",
      "batch 1449, train_loss 270.166779,Time used 0.007001s\n",
      "batch 1450, train_loss 238.148651,Time used 0.007999s\n",
      "batch 1451, train_loss 294.756622,Time used 0.006000s\n",
      "batch 1452, train_loss 232.083099,Time used 0.009005s\n",
      "batch 1453, train_loss 263.461304,Time used 0.008997s\n",
      "batch 1454, train_loss 238.719940,Time used 0.011000s\n",
      "batch 1455, train_loss 265.418182,Time used 0.008999s\n",
      "batch 1456, train_loss 298.047241,Time used 0.007008s\n",
      "batch 1457, train_loss 293.791473,Time used 0.005994s\n",
      "batch 1458, train_loss 279.231415,Time used 0.006998s\n",
      "batch 1459, train_loss 275.381042,Time used 0.006999s\n",
      "batch 1460, train_loss 350.302734,Time used 0.006002s\n",
      "batch 1461, train_loss 196.479691,Time used 0.006999s\n",
      "batch 1462, train_loss 289.810028,Time used 0.007010s\n",
      "batch 1463, train_loss 259.228607,Time used 0.006993s\n",
      "batch 1464, train_loss 276.453461,Time used 0.006000s\n",
      "batch 1465, train_loss 234.969696,Time used 0.006000s\n",
      "batch 1466, train_loss 291.433960,Time used 0.008000s\n",
      "batch 1467, train_loss 318.113678,Time used 0.006001s\n",
      "batch 1468, train_loss 250.705429,Time used 0.007000s\n",
      "batch 1469, train_loss 254.560333,Time used 0.006000s\n",
      "batch 1470, train_loss 193.281555,Time used 0.006001s\n",
      "batch 1471, train_loss 279.823608,Time used 0.006000s\n",
      "batch 1472, train_loss 235.144775,Time used 0.007000s\n",
      "batch 1473, train_loss 314.518555,Time used 0.007008s\n",
      "batch 1474, train_loss 257.932495,Time used 0.008026s\n",
      "batch 1475, train_loss 263.941895,Time used 0.008000s\n",
      "batch 1476, train_loss 268.701904,Time used 0.006966s\n",
      "batch 1477, train_loss 249.524628,Time used 0.006999s\n",
      "batch 1478, train_loss 287.878113,Time used 0.007002s\n",
      "batch 1479, train_loss 272.071411,Time used 0.011001s\n",
      "batch 1480, train_loss 283.673157,Time used 0.007999s\n",
      "batch 1481, train_loss 237.338623,Time used 0.007001s\n",
      "batch 1482, train_loss 263.853027,Time used 0.006001s\n",
      "batch 1483, train_loss 303.941254,Time used 0.008996s\n",
      "batch 1484, train_loss 231.623032,Time used 0.007003s\n",
      "batch 1485, train_loss 273.425232,Time used 0.008000s\n",
      "batch 1486, train_loss 268.403992,Time used 0.006999s\n",
      "batch 1487, train_loss 333.261719,Time used 0.008001s\n",
      "batch 1488, train_loss 250.260681,Time used 0.007000s\n",
      "batch 1489, train_loss 339.268372,Time used 0.009979s\n",
      "batch 1490, train_loss 247.483978,Time used 0.007999s\n",
      "batch 1491, train_loss 223.621307,Time used 0.005998s\n",
      "batch 1492, train_loss 272.442810,Time used 0.008001s\n",
      "batch 1493, train_loss 226.849487,Time used 0.009998s\n",
      "batch 1494, train_loss 276.100586,Time used 0.011000s\n",
      "batch 1495, train_loss 306.704010,Time used 0.005999s\n",
      "batch 1496, train_loss 253.519226,Time used 0.008004s\n",
      "batch 1497, train_loss 309.577576,Time used 0.006994s\n",
      "batch 1498, train_loss 228.862350,Time used 0.009001s\n",
      "batch 1499, train_loss 174.777847,Time used 0.007000s\n",
      "batch 1500, train_loss 262.460541,Time used 0.010001s\n",
      "***************************test_batch 1500, test_rmse_loss 18.288324,test_mae_loss 7.449805,test_mape_loss 76.033309,Time used 0.039998s\n",
      "batch 1501, train_loss 299.277771,Time used 0.009001s\n",
      "batch 1502, train_loss 294.938782,Time used 0.007003s\n",
      "batch 1503, train_loss 289.184967,Time used 0.006997s\n",
      "batch 1504, train_loss 205.943359,Time used 0.007003s\n",
      "batch 1505, train_loss 238.736450,Time used 0.008999s\n",
      "batch 1506, train_loss 221.096573,Time used 0.008001s\n",
      "batch 1507, train_loss 256.341125,Time used 0.006998s\n",
      "batch 1508, train_loss 286.910370,Time used 0.006998s\n",
      "batch 1509, train_loss 293.065643,Time used 0.008003s\n",
      "batch 1510, train_loss 349.628387,Time used 0.011001s\n",
      "batch 1511, train_loss 270.457794,Time used 0.007005s\n",
      "batch 1512, train_loss 254.928864,Time used 0.006996s\n",
      "batch 1513, train_loss 248.835617,Time used 0.007998s\n",
      "batch 1514, train_loss 236.488174,Time used 0.009999s\n",
      "batch 1515, train_loss 198.460266,Time used 0.007001s\n",
      "batch 1516, train_loss 259.773285,Time used 0.006999s\n",
      "batch 1517, train_loss 278.178986,Time used 0.007000s\n",
      "batch 1518, train_loss 250.360764,Time used 0.007001s\n",
      "batch 1519, train_loss 204.887146,Time used 0.008008s\n",
      "batch 1520, train_loss 268.774689,Time used 0.006001s\n",
      "batch 1521, train_loss 274.476501,Time used 0.010999s\n",
      "batch 1522, train_loss 242.550323,Time used 0.007000s\n",
      "batch 1523, train_loss 290.659729,Time used 0.007001s\n",
      "batch 1524, train_loss 293.917236,Time used 0.009000s\n",
      "batch 1525, train_loss 259.508087,Time used 0.008003s\n",
      "batch 1526, train_loss 242.900055,Time used 0.010998s\n",
      "batch 1527, train_loss 243.725555,Time used 0.010000s\n",
      "batch 1528, train_loss 262.819458,Time used 0.007999s\n",
      "batch 1529, train_loss 326.664246,Time used 0.008998s\n",
      "batch 1530, train_loss 226.089371,Time used 0.010999s\n",
      "batch 1531, train_loss 271.335144,Time used 0.008002s\n",
      "batch 1532, train_loss 286.594025,Time used 0.007999s\n",
      "batch 1533, train_loss 260.451874,Time used 0.010999s\n",
      "batch 1534, train_loss 335.658691,Time used 0.010001s\n",
      "batch 1535, train_loss 291.803711,Time used 0.009997s\n",
      "batch 1536, train_loss 292.584167,Time used 0.009000s\n",
      "batch 1537, train_loss 260.831207,Time used 0.011000s\n",
      "batch 1538, train_loss 217.041245,Time used 0.008002s\n",
      "batch 1539, train_loss 239.515625,Time used 0.007001s\n",
      "batch 1540, train_loss 258.038269,Time used 0.010000s\n",
      "batch 1541, train_loss 298.350311,Time used 0.010998s\n",
      "batch 1542, train_loss 229.439774,Time used 0.010001s\n",
      "batch 1543, train_loss 222.834412,Time used 0.007001s\n",
      "batch 1544, train_loss 230.005142,Time used 0.010999s\n",
      "batch 1545, train_loss 218.519440,Time used 0.011002s\n",
      "batch 1546, train_loss 268.986237,Time used 0.010000s\n",
      "batch 1547, train_loss 324.763000,Time used 0.008998s\n",
      "batch 1548, train_loss 345.244263,Time used 0.010001s\n",
      "batch 1549, train_loss 279.717194,Time used 0.008001s\n",
      "batch 1550, train_loss 246.190460,Time used 0.008000s\n",
      "batch 1551, train_loss 199.227203,Time used 0.009997s\n",
      "batch 1552, train_loss 275.929199,Time used 0.007002s\n",
      "batch 1553, train_loss 307.874725,Time used 0.009999s\n",
      "batch 1554, train_loss 303.853271,Time used 0.008001s\n",
      "batch 1555, train_loss 227.762589,Time used 0.006996s\n",
      "batch 1556, train_loss 226.666077,Time used 0.007003s\n",
      "batch 1557, train_loss 310.856567,Time used 0.006999s\n",
      "batch 1558, train_loss 349.532440,Time used 0.006999s\n",
      "batch 1559, train_loss 247.003632,Time used 0.008002s\n",
      "batch 1560, train_loss 221.058685,Time used 0.006002s\n",
      "batch 1561, train_loss 217.725250,Time used 0.009000s\n",
      "batch 1562, train_loss 241.307480,Time used 0.010000s\n",
      "batch 1563, train_loss 262.346466,Time used 0.010000s\n",
      "batch 1564, train_loss 213.782669,Time used 0.007000s\n",
      "batch 1565, train_loss 254.293045,Time used 0.006001s\n",
      "batch 1566, train_loss 320.203918,Time used 0.012999s\n",
      "batch 1567, train_loss 238.975327,Time used 0.010003s\n",
      "batch 1568, train_loss 260.334961,Time used 0.008999s\n",
      "batch 1569, train_loss 237.067947,Time used 0.008999s\n",
      "batch 1570, train_loss 295.233643,Time used 0.007003s\n",
      "batch 1571, train_loss 247.402405,Time used 0.006999s\n",
      "batch 1572, train_loss 300.659180,Time used 0.008001s\n",
      "batch 1573, train_loss 265.156281,Time used 0.007000s\n",
      "batch 1574, train_loss 239.402435,Time used 0.009996s\n",
      "batch 1575, train_loss 254.940491,Time used 0.009003s\n",
      "batch 1576, train_loss 279.566528,Time used 0.007998s\n",
      "batch 1577, train_loss 264.657928,Time used 0.008000s\n",
      "batch 1578, train_loss 239.114807,Time used 0.008002s\n",
      "batch 1579, train_loss 248.671814,Time used 0.009999s\n",
      "batch 1580, train_loss 324.562195,Time used 0.009003s\n",
      "batch 1581, train_loss 253.996796,Time used 0.014996s\n",
      "batch 1582, train_loss 261.144073,Time used 0.010001s\n",
      "batch 1583, train_loss 264.559937,Time used 0.012001s\n",
      "batch 1584, train_loss 291.414673,Time used 0.011997s\n",
      "batch 1585, train_loss 265.815460,Time used 0.011001s\n",
      "batch 1586, train_loss 176.331390,Time used 0.010996s\n",
      "batch 1587, train_loss 270.955750,Time used 0.011003s\n",
      "batch 1588, train_loss 321.264191,Time used 0.008998s\n",
      "batch 1589, train_loss 264.018951,Time used 0.012000s\n",
      "batch 1590, train_loss 251.403763,Time used 0.012001s\n",
      "batch 1591, train_loss 275.524048,Time used 0.011999s\n",
      "batch 1592, train_loss 218.774078,Time used 0.012002s\n",
      "batch 1593, train_loss 275.751221,Time used 0.009997s\n",
      "batch 1594, train_loss 231.828903,Time used 0.010004s\n",
      "batch 1595, train_loss 312.204651,Time used 0.009996s\n",
      "batch 1596, train_loss 266.495972,Time used 0.010999s\n",
      "batch 1597, train_loss 225.497482,Time used 0.011000s\n",
      "batch 1598, train_loss 297.567322,Time used 0.011002s\n",
      "batch 1599, train_loss 266.777802,Time used 0.008998s\n",
      "batch 1600, train_loss 257.363525,Time used 0.010001s\n",
      "***************************test_batch 1600, test_rmse_loss 18.092063,test_mae_loss 7.332700,test_mape_loss 75.528332,Time used 0.041996s\n",
      "batch 1601, train_loss 201.229340,Time used 0.011001s\n",
      "batch 1602, train_loss 245.587067,Time used 0.012001s\n",
      "batch 1603, train_loss 242.701736,Time used 0.012000s\n",
      "batch 1604, train_loss 270.594879,Time used 0.012009s\n",
      "batch 1605, train_loss 236.974686,Time used 0.020001s\n",
      "batch 1606, train_loss 288.186676,Time used 0.011999s\n",
      "batch 1607, train_loss 297.358917,Time used 0.011001s\n",
      "batch 1608, train_loss 280.790955,Time used 0.011000s\n",
      "batch 1609, train_loss 302.500793,Time used 0.012001s\n",
      "batch 1610, train_loss 299.298248,Time used 0.010000s\n",
      "batch 1611, train_loss 261.132050,Time used 0.011999s\n",
      "batch 1612, train_loss 223.245712,Time used 0.011001s\n",
      "batch 1613, train_loss 316.539490,Time used 0.011001s\n",
      "batch 1614, train_loss 290.797455,Time used 0.010998s\n",
      "batch 1615, train_loss 255.948639,Time used 0.010001s\n",
      "batch 1616, train_loss 285.721649,Time used 0.010999s\n",
      "batch 1617, train_loss 220.776367,Time used 0.010999s\n",
      "batch 1618, train_loss 233.145767,Time used 0.010001s\n",
      "batch 1619, train_loss 275.360291,Time used 0.010000s\n",
      "batch 1620, train_loss 259.072906,Time used 0.010003s\n",
      "batch 1621, train_loss 237.965042,Time used 0.011995s\n",
      "batch 1622, train_loss 284.773712,Time used 0.010004s\n",
      "batch 1623, train_loss 250.662659,Time used 0.011000s\n",
      "batch 1624, train_loss 244.750641,Time used 0.008998s\n",
      "batch 1625, train_loss 277.214569,Time used 0.006001s\n",
      "batch 1626, train_loss 225.574173,Time used 0.007015s\n",
      "batch 1627, train_loss 240.095749,Time used 0.006987s\n",
      "batch 1628, train_loss 242.309433,Time used 0.006999s\n",
      "batch 1629, train_loss 184.895370,Time used 0.007016s\n",
      "batch 1630, train_loss 262.877441,Time used 0.008984s\n",
      "batch 1631, train_loss 287.435150,Time used 0.009999s\n",
      "batch 1632, train_loss 242.873154,Time used 0.008002s\n",
      "batch 1633, train_loss 211.091400,Time used 0.009996s\n",
      "batch 1634, train_loss 274.224854,Time used 0.007001s\n",
      "batch 1635, train_loss 268.807190,Time used 0.005999s\n",
      "batch 1636, train_loss 220.830383,Time used 0.006000s\n",
      "batch 1637, train_loss 291.285614,Time used 0.009003s\n",
      "batch 1638, train_loss 288.636719,Time used 0.006001s\n",
      "batch 1639, train_loss 242.544357,Time used 0.007001s\n",
      "batch 1640, train_loss 247.681580,Time used 0.005999s\n",
      "batch 1641, train_loss 202.697479,Time used 0.007000s\n",
      "batch 1642, train_loss 266.962097,Time used 0.006000s\n",
      "batch 1643, train_loss 263.730225,Time used 0.007001s\n",
      "batch 1644, train_loss 326.159363,Time used 0.009999s\n",
      "batch 1645, train_loss 215.080246,Time used 0.008999s\n",
      "batch 1646, train_loss 312.297028,Time used 0.007000s\n",
      "batch 1647, train_loss 255.599274,Time used 0.008002s\n",
      "batch 1648, train_loss 281.845062,Time used 0.006999s\n",
      "batch 1649, train_loss 268.964874,Time used 0.009000s\n",
      "batch 1650, train_loss 242.654907,Time used 0.009001s\n",
      "batch 1651, train_loss 225.708786,Time used 0.008999s\n",
      "batch 1652, train_loss 235.548645,Time used 0.008998s\n",
      "batch 1653, train_loss 308.292877,Time used 0.009001s\n",
      "batch 1654, train_loss 243.182953,Time used 0.008999s\n",
      "batch 1655, train_loss 267.764221,Time used 0.009002s\n",
      "batch 1656, train_loss 207.368256,Time used 0.009998s\n",
      "batch 1657, train_loss 222.856949,Time used 0.010999s\n",
      "batch 1658, train_loss 239.331802,Time used 0.012003s\n",
      "batch 1659, train_loss 264.103668,Time used 0.010000s\n",
      "batch 1660, train_loss 269.108215,Time used 0.005997s\n",
      "batch 1661, train_loss 231.950684,Time used 0.007000s\n",
      "batch 1662, train_loss 257.240845,Time used 0.009000s\n",
      "batch 1663, train_loss 222.500732,Time used 0.007001s\n",
      "batch 1664, train_loss 219.607224,Time used 0.009000s\n",
      "batch 1665, train_loss 249.545883,Time used 0.010001s\n",
      "batch 1666, train_loss 234.240875,Time used 0.010000s\n",
      "batch 1667, train_loss 276.369171,Time used 0.010999s\n",
      "batch 1668, train_loss 263.496796,Time used 0.011003s\n",
      "batch 1669, train_loss 237.301315,Time used 0.010000s\n",
      "batch 1670, train_loss 327.962189,Time used 0.009000s\n",
      "batch 1671, train_loss 257.416412,Time used 0.007999s\n",
      "batch 1672, train_loss 237.764877,Time used 0.008999s\n",
      "batch 1673, train_loss 243.764282,Time used 0.007002s\n",
      "batch 1674, train_loss 213.583481,Time used 0.010998s\n",
      "batch 1675, train_loss 307.914459,Time used 0.010002s\n",
      "batch 1676, train_loss 257.784729,Time used 0.008001s\n",
      "batch 1677, train_loss 288.384186,Time used 0.009001s\n",
      "batch 1678, train_loss 276.227692,Time used 0.009001s\n",
      "batch 1679, train_loss 260.798584,Time used 0.006998s\n",
      "batch 1680, train_loss 278.311218,Time used 0.008002s\n",
      "batch 1681, train_loss 248.216064,Time used 0.010001s\n",
      "batch 1682, train_loss 246.027298,Time used 0.006999s\n",
      "batch 1683, train_loss 274.430634,Time used 0.008002s\n",
      "batch 1684, train_loss 270.894043,Time used 0.006999s\n",
      "batch 1685, train_loss 228.334137,Time used 0.008001s\n",
      "batch 1686, train_loss 208.178925,Time used 0.006999s\n",
      "batch 1687, train_loss 274.072571,Time used 0.010001s\n",
      "batch 1688, train_loss 257.296539,Time used 0.010001s\n",
      "batch 1689, train_loss 258.322937,Time used 0.009001s\n",
      "batch 1690, train_loss 247.178848,Time used 0.010999s\n",
      "batch 1691, train_loss 255.891144,Time used 0.010001s\n",
      "batch 1692, train_loss 276.116241,Time used 0.010999s\n",
      "batch 1693, train_loss 242.395554,Time used 0.010001s\n",
      "batch 1694, train_loss 284.779694,Time used 0.007999s\n",
      "batch 1695, train_loss 160.940414,Time used 0.009001s\n",
      "batch 1696, train_loss 296.289001,Time used 0.009997s\n",
      "batch 1697, train_loss 236.534241,Time used 0.008001s\n",
      "batch 1698, train_loss 281.993164,Time used 0.009000s\n",
      "batch 1699, train_loss 259.679108,Time used 0.009000s\n",
      "batch 1700, train_loss 258.615692,Time used 0.010000s\n",
      "***************************test_batch 1700, test_rmse_loss 17.900012,test_mae_loss 7.222080,test_mape_loss 75.246113,Time used 0.025000s\n",
      "batch 1701, train_loss 310.906311,Time used 0.005999s\n",
      "batch 1702, train_loss 296.921631,Time used 0.007000s\n",
      "batch 1703, train_loss 194.007584,Time used 0.007001s\n",
      "batch 1704, train_loss 234.110336,Time used 0.006999s\n",
      "batch 1705, train_loss 273.295715,Time used 0.005999s\n",
      "batch 1706, train_loss 316.513397,Time used 0.007999s\n",
      "batch 1707, train_loss 244.734573,Time used 0.008001s\n",
      "batch 1708, train_loss 236.513397,Time used 0.009997s\n",
      "batch 1709, train_loss 295.731232,Time used 0.006001s\n",
      "batch 1710, train_loss 241.420685,Time used 0.008002s\n",
      "batch 1711, train_loss 257.641022,Time used 0.009000s\n",
      "batch 1712, train_loss 216.811569,Time used 0.011000s\n",
      "batch 1713, train_loss 290.934692,Time used 0.006998s\n",
      "batch 1714, train_loss 264.472839,Time used 0.009002s\n",
      "batch 1715, train_loss 265.068665,Time used 0.010000s\n",
      "batch 1716, train_loss 295.558136,Time used 0.009998s\n",
      "batch 1717, train_loss 180.936310,Time used 0.006015s\n",
      "batch 1718, train_loss 260.966309,Time used 0.010002s\n",
      "batch 1719, train_loss 224.795151,Time used 0.009001s\n",
      "batch 1720, train_loss 255.783798,Time used 0.007998s\n",
      "batch 1721, train_loss 284.946991,Time used 0.009002s\n",
      "batch 1722, train_loss 214.073273,Time used 0.009999s\n",
      "batch 1723, train_loss 240.414169,Time used 0.009000s\n",
      "batch 1724, train_loss 228.980652,Time used 0.009000s\n",
      "batch 1725, train_loss 258.652283,Time used 0.011000s\n",
      "batch 1726, train_loss 197.419983,Time used 0.008003s\n",
      "batch 1727, train_loss 253.163925,Time used 0.007998s\n",
      "batch 1728, train_loss 271.263000,Time used 0.007000s\n",
      "batch 1729, train_loss 286.905884,Time used 0.008999s\n",
      "batch 1730, train_loss 278.995850,Time used 0.011002s\n",
      "batch 1731, train_loss 222.929031,Time used 0.010997s\n",
      "batch 1732, train_loss 310.474762,Time used 0.009005s\n",
      "batch 1733, train_loss 292.965546,Time used 0.008997s\n",
      "batch 1734, train_loss 218.010788,Time used 0.010000s\n",
      "batch 1735, train_loss 202.635986,Time used 0.010000s\n",
      "batch 1736, train_loss 235.186798,Time used 0.009000s\n",
      "batch 1737, train_loss 294.536499,Time used 0.011007s\n",
      "batch 1738, train_loss 251.336258,Time used 0.009994s\n",
      "batch 1739, train_loss 282.820679,Time used 0.008001s\n",
      "batch 1740, train_loss 247.618652,Time used 0.010999s\n",
      "batch 1741, train_loss 266.867310,Time used 0.011000s\n",
      "batch 1742, train_loss 209.421432,Time used 0.010998s\n",
      "batch 1743, train_loss 331.590912,Time used 0.008002s\n",
      "batch 1744, train_loss 271.212006,Time used 0.008999s\n",
      "batch 1745, train_loss 246.621338,Time used 0.009002s\n",
      "batch 1746, train_loss 216.992203,Time used 0.010999s\n",
      "batch 1747, train_loss 241.126862,Time used 0.010999s\n",
      "batch 1748, train_loss 213.647598,Time used 0.008002s\n",
      "batch 1749, train_loss 258.133270,Time used 0.009999s\n",
      "batch 1750, train_loss 217.297211,Time used 0.010001s\n",
      "batch 1751, train_loss 211.955902,Time used 0.006999s\n",
      "batch 1752, train_loss 225.796341,Time used 0.010000s\n",
      "batch 1753, train_loss 266.838959,Time used 0.009998s\n",
      "batch 1754, train_loss 238.201569,Time used 0.007001s\n",
      "batch 1755, train_loss 227.925201,Time used 0.007000s\n",
      "batch 1756, train_loss 282.953430,Time used 0.007000s\n",
      "batch 1757, train_loss 246.735107,Time used 0.009000s\n",
      "batch 1758, train_loss 289.180969,Time used 0.009995s\n",
      "batch 1759, train_loss 200.683197,Time used 0.005999s\n",
      "batch 1760, train_loss 255.530167,Time used 0.009002s\n",
      "batch 1761, train_loss 281.620850,Time used 0.010001s\n",
      "batch 1762, train_loss 260.827332,Time used 0.015000s\n",
      "batch 1763, train_loss 243.570480,Time used 0.010000s\n",
      "batch 1764, train_loss 204.280579,Time used 0.009999s\n",
      "batch 1765, train_loss 255.332932,Time used 0.011002s\n",
      "batch 1766, train_loss 250.273666,Time used 0.011001s\n",
      "batch 1767, train_loss 259.052399,Time used 0.009998s\n",
      "batch 1768, train_loss 252.202423,Time used 0.010001s\n",
      "batch 1769, train_loss 242.341721,Time used 0.008000s\n",
      "batch 1770, train_loss 256.653656,Time used 0.009998s\n",
      "batch 1771, train_loss 218.267365,Time used 0.008999s\n",
      "batch 1772, train_loss 242.944397,Time used 0.011001s\n",
      "batch 1773, train_loss 256.817139,Time used 0.008002s\n",
      "batch 1774, train_loss 214.628006,Time used 0.009000s\n",
      "batch 1775, train_loss 317.317688,Time used 0.011000s\n",
      "batch 1776, train_loss 238.157303,Time used 0.009000s\n",
      "batch 1777, train_loss 213.073074,Time used 0.008001s\n",
      "batch 1778, train_loss 259.569641,Time used 0.006998s\n",
      "batch 1779, train_loss 268.780884,Time used 0.006001s\n",
      "batch 1780, train_loss 248.783630,Time used 0.007000s\n",
      "batch 1781, train_loss 273.817719,Time used 0.006000s\n",
      "batch 1782, train_loss 263.642303,Time used 0.006000s\n",
      "batch 1783, train_loss 227.258636,Time used 0.006999s\n",
      "batch 1784, train_loss 242.403824,Time used 0.008001s\n",
      "batch 1785, train_loss 290.912750,Time used 0.007000s\n",
      "batch 1786, train_loss 210.421860,Time used 0.008000s\n",
      "batch 1787, train_loss 225.439026,Time used 0.009999s\n",
      "batch 1788, train_loss 397.062103,Time used 0.011003s\n",
      "batch 1789, train_loss 251.803284,Time used 0.009998s\n",
      "batch 1790, train_loss 197.017426,Time used 0.008002s\n",
      "batch 1791, train_loss 280.657043,Time used 0.007997s\n",
      "batch 1792, train_loss 312.027069,Time used 0.007004s\n",
      "batch 1793, train_loss 259.389923,Time used 0.010996s\n",
      "batch 1794, train_loss 249.235107,Time used 0.009000s\n",
      "batch 1795, train_loss 192.683472,Time used 0.007002s\n",
      "batch 1796, train_loss 257.930450,Time used 0.007999s\n",
      "batch 1797, train_loss 196.603424,Time used 0.009999s\n",
      "batch 1798, train_loss 232.526184,Time used 0.008003s\n",
      "batch 1799, train_loss 223.090942,Time used 0.008997s\n",
      "batch 1800, train_loss 194.141846,Time used 0.010003s\n",
      "***************************test_batch 1800, test_rmse_loss 17.711978,test_mae_loss 7.116164,test_mape_loss 75.054581,Time used 0.033000s\n",
      "batch 1801, train_loss 255.404785,Time used 0.011018s\n",
      "batch 1802, train_loss 257.249420,Time used 0.008981s\n",
      "batch 1803, train_loss 210.677277,Time used 0.008002s\n",
      "batch 1804, train_loss 252.940369,Time used 0.008032s\n",
      "batch 1805, train_loss 227.170898,Time used 0.007967s\n",
      "batch 1806, train_loss 281.658844,Time used 0.010000s\n",
      "batch 1807, train_loss 234.788513,Time used 0.010000s\n",
      "batch 1808, train_loss 217.680511,Time used 0.010000s\n",
      "batch 1809, train_loss 252.888580,Time used 0.009002s\n",
      "batch 1810, train_loss 296.032501,Time used 0.010000s\n",
      "batch 1811, train_loss 245.559616,Time used 0.009001s\n",
      "batch 1812, train_loss 220.262405,Time used 0.007999s\n",
      "batch 1813, train_loss 165.116943,Time used 0.009999s\n",
      "batch 1814, train_loss 299.504364,Time used 0.007001s\n",
      "batch 1815, train_loss 275.793976,Time used 0.006997s\n",
      "batch 1816, train_loss 235.704697,Time used 0.010004s\n",
      "batch 1817, train_loss 256.890259,Time used 0.009998s\n",
      "batch 1818, train_loss 255.104874,Time used 0.008999s\n",
      "batch 1819, train_loss 274.153717,Time used 0.010001s\n",
      "batch 1820, train_loss 196.628067,Time used 0.008002s\n",
      "batch 1821, train_loss 280.922791,Time used 0.010002s\n",
      "batch 1822, train_loss 303.099457,Time used 0.010998s\n",
      "batch 1823, train_loss 196.705597,Time used 0.008001s\n",
      "batch 1824, train_loss 245.671936,Time used 0.008996s\n",
      "batch 1825, train_loss 218.732727,Time used 0.010001s\n",
      "batch 1826, train_loss 251.417740,Time used 0.008002s\n",
      "batch 1827, train_loss 250.807510,Time used 0.008996s\n",
      "batch 1828, train_loss 192.050003,Time used 0.010998s\n",
      "batch 1829, train_loss 264.542572,Time used 0.010003s\n",
      "batch 1830, train_loss 247.689575,Time used 0.009999s\n",
      "batch 1831, train_loss 204.774796,Time used 0.008001s\n",
      "batch 1832, train_loss 245.665115,Time used 0.007997s\n",
      "batch 1833, train_loss 195.840973,Time used 0.006001s\n",
      "batch 1834, train_loss 264.475006,Time used 0.007000s\n",
      "batch 1835, train_loss 248.741165,Time used 0.005999s\n",
      "batch 1836, train_loss 297.044403,Time used 0.006002s\n",
      "batch 1837, train_loss 218.463043,Time used 0.008000s\n",
      "batch 1838, train_loss 327.354462,Time used 0.006999s\n",
      "batch 1839, train_loss 233.940521,Time used 0.007000s\n",
      "batch 1840, train_loss 321.761719,Time used 0.008000s\n",
      "batch 1841, train_loss 215.049271,Time used 0.009001s\n",
      "batch 1842, train_loss 243.197083,Time used 0.007999s\n",
      "batch 1843, train_loss 287.700684,Time used 0.008999s\n",
      "batch 1844, train_loss 232.820541,Time used 0.009003s\n",
      "batch 1845, train_loss 208.452728,Time used 0.007998s\n",
      "batch 1846, train_loss 291.669830,Time used 0.009000s\n",
      "batch 1847, train_loss 193.499054,Time used 0.008000s\n",
      "batch 1848, train_loss 250.073959,Time used 0.006000s\n",
      "batch 1849, train_loss 247.002350,Time used 0.009001s\n",
      "batch 1850, train_loss 214.953369,Time used 0.006001s\n",
      "batch 1851, train_loss 242.131699,Time used 0.007003s\n",
      "batch 1852, train_loss 250.626541,Time used 0.008996s\n",
      "batch 1853, train_loss 239.743286,Time used 0.011004s\n",
      "batch 1854, train_loss 273.240387,Time used 0.009996s\n",
      "batch 1855, train_loss 259.604584,Time used 0.010999s\n",
      "batch 1856, train_loss 230.850845,Time used 0.009002s\n",
      "batch 1857, train_loss 292.421539,Time used 0.006999s\n",
      "batch 1858, train_loss 220.328262,Time used 0.007008s\n",
      "batch 1859, train_loss 180.460205,Time used 0.006999s\n",
      "batch 1860, train_loss 237.939529,Time used 0.007002s\n",
      "batch 1861, train_loss 283.064850,Time used 0.007000s\n",
      "batch 1862, train_loss 226.307739,Time used 0.006998s\n",
      "batch 1863, train_loss 273.766815,Time used 0.010002s\n",
      "batch 1864, train_loss 275.764496,Time used 0.008998s\n",
      "batch 1865, train_loss 222.368057,Time used 0.010001s\n",
      "batch 1866, train_loss 267.099518,Time used 0.011000s\n",
      "batch 1867, train_loss 211.592636,Time used 0.011999s\n",
      "batch 1868, train_loss 240.945724,Time used 0.009999s\n",
      "batch 1869, train_loss 250.844269,Time used 0.009998s\n",
      "batch 1870, train_loss 273.473999,Time used 0.006000s\n",
      "batch 1871, train_loss 247.546494,Time used 0.007000s\n",
      "batch 1872, train_loss 210.287140,Time used 0.009001s\n",
      "batch 1873, train_loss 223.951218,Time used 0.006000s\n",
      "batch 1874, train_loss 269.271973,Time used 0.008000s\n",
      "batch 1875, train_loss 203.338531,Time used 0.008000s\n",
      "batch 1876, train_loss 228.760757,Time used 0.011001s\n",
      "batch 1877, train_loss 254.413879,Time used 0.010000s\n",
      "batch 1878, train_loss 188.208817,Time used 0.008002s\n",
      "batch 1879, train_loss 256.609039,Time used 0.009997s\n",
      "batch 1880, train_loss 197.123047,Time used 0.008010s\n",
      "batch 1881, train_loss 267.950897,Time used 0.010991s\n",
      "batch 1882, train_loss 222.473679,Time used 0.007999s\n",
      "batch 1883, train_loss 229.986481,Time used 0.010999s\n",
      "batch 1884, train_loss 238.727173,Time used 0.011003s\n",
      "batch 1885, train_loss 257.264221,Time used 0.008997s\n",
      "batch 1886, train_loss 267.213837,Time used 0.009001s\n",
      "batch 1887, train_loss 269.984894,Time used 0.007999s\n",
      "batch 1888, train_loss 257.264404,Time used 0.007001s\n",
      "batch 1889, train_loss 291.834656,Time used 0.007998s\n",
      "batch 1890, train_loss 264.317047,Time used 0.008001s\n",
      "batch 1891, train_loss 219.237076,Time used 0.007002s\n",
      "batch 1892, train_loss 290.119385,Time used 0.006997s\n",
      "batch 1893, train_loss 242.523529,Time used 0.007004s\n",
      "batch 1894, train_loss 248.836121,Time used 0.007000s\n",
      "batch 1895, train_loss 224.507828,Time used 0.008000s\n",
      "batch 1896, train_loss 227.456772,Time used 0.006997s\n",
      "batch 1897, train_loss 300.695007,Time used 0.006002s\n",
      "batch 1898, train_loss 247.878250,Time used 0.008002s\n",
      "batch 1899, train_loss 229.201584,Time used 0.008999s\n",
      "batch 1900, train_loss 244.710007,Time used 0.008001s\n",
      "***************************test_batch 1900, test_rmse_loss 17.529069,test_mae_loss 7.013682,test_mape_loss 74.692252,Time used 0.031998s\n",
      "batch 1901, train_loss 246.582764,Time used 0.008002s\n",
      "batch 1902, train_loss 205.452454,Time used 0.009997s\n",
      "batch 1903, train_loss 239.956253,Time used 0.008000s\n",
      "batch 1904, train_loss 234.937042,Time used 0.007003s\n",
      "batch 1905, train_loss 232.566879,Time used 0.007997s\n",
      "batch 1906, train_loss 228.843689,Time used 0.008005s\n",
      "batch 1907, train_loss 195.252502,Time used 0.009996s\n",
      "batch 1908, train_loss 214.928604,Time used 0.010003s\n",
      "batch 1909, train_loss 254.559311,Time used 0.007996s\n",
      "batch 1910, train_loss 191.383560,Time used 0.011002s\n",
      "batch 1911, train_loss 233.101135,Time used 0.007001s\n",
      "batch 1912, train_loss 306.622314,Time used 0.007000s\n",
      "batch 1913, train_loss 319.071594,Time used 0.008001s\n",
      "batch 1914, train_loss 174.836777,Time used 0.008997s\n",
      "batch 1915, train_loss 285.466736,Time used 0.009001s\n",
      "batch 1916, train_loss 243.467911,Time used 0.007001s\n",
      "batch 1917, train_loss 186.350616,Time used 0.008997s\n",
      "batch 1918, train_loss 261.449493,Time used 0.010002s\n",
      "batch 1919, train_loss 225.228226,Time used 0.008998s\n",
      "batch 1920, train_loss 310.749176,Time used 0.007000s\n",
      "batch 1921, train_loss 287.616730,Time used 0.007999s\n",
      "batch 1922, train_loss 289.386871,Time used 0.007000s\n",
      "batch 1923, train_loss 264.605469,Time used 0.007000s\n",
      "batch 1924, train_loss 217.716766,Time used 0.010004s\n",
      "batch 1925, train_loss 276.891785,Time used 0.007035s\n",
      "batch 1926, train_loss 252.383026,Time used 0.006964s\n",
      "batch 1927, train_loss 233.925690,Time used 0.007000s\n",
      "batch 1928, train_loss 237.040787,Time used 0.006030s\n",
      "batch 1929, train_loss 219.091263,Time used 0.006968s\n",
      "batch 1930, train_loss 204.370178,Time used 0.006999s\n",
      "batch 1931, train_loss 238.715576,Time used 0.007000s\n",
      "batch 1932, train_loss 257.220123,Time used 0.007036s\n",
      "batch 1933, train_loss 247.234848,Time used 0.010000s\n",
      "batch 1934, train_loss 241.239746,Time used 0.009962s\n",
      "batch 1935, train_loss 195.643311,Time used 0.006000s\n",
      "batch 1936, train_loss 198.021103,Time used 0.010004s\n",
      "batch 1937, train_loss 261.674225,Time used 0.006997s\n",
      "batch 1938, train_loss 248.940292,Time used 0.007001s\n",
      "batch 1939, train_loss 287.640686,Time used 0.008000s\n",
      "batch 1940, train_loss 215.368988,Time used 0.007999s\n",
      "batch 1941, train_loss 233.527557,Time used 0.007000s\n",
      "batch 1942, train_loss 215.169800,Time used 0.007000s\n",
      "batch 1943, train_loss 227.912888,Time used 0.007007s\n",
      "batch 1944, train_loss 227.789795,Time used 0.008995s\n",
      "batch 1945, train_loss 264.484375,Time used 0.008001s\n",
      "batch 1946, train_loss 191.904068,Time used 0.008000s\n",
      "batch 1947, train_loss 206.153229,Time used 0.007002s\n",
      "batch 1948, train_loss 268.743744,Time used 0.010000s\n",
      "batch 1949, train_loss 242.692078,Time used 0.008001s\n",
      "batch 1950, train_loss 267.717346,Time used 0.007000s\n",
      "batch 1951, train_loss 249.167542,Time used 0.010000s\n",
      "batch 1952, train_loss 332.122620,Time used 0.008002s\n",
      "batch 1953, train_loss 178.909088,Time used 0.010999s\n",
      "batch 1954, train_loss 261.754913,Time used 0.010001s\n",
      "batch 1955, train_loss 234.163589,Time used 0.011002s\n",
      "batch 1956, train_loss 220.293564,Time used 0.009997s\n",
      "batch 1957, train_loss 212.549072,Time used 0.008000s\n",
      "batch 1958, train_loss 197.564529,Time used 0.008000s\n",
      "batch 1959, train_loss 253.776245,Time used 0.011001s\n",
      "batch 1960, train_loss 312.773773,Time used 0.008999s\n",
      "batch 1961, train_loss 211.514404,Time used 0.006000s\n",
      "batch 1962, train_loss 249.421677,Time used 0.008002s\n",
      "batch 1963, train_loss 270.619843,Time used 0.007999s\n",
      "batch 1964, train_loss 205.213348,Time used 0.006000s\n",
      "batch 1965, train_loss 193.359009,Time used 0.010002s\n",
      "batch 1966, train_loss 251.984879,Time used 0.007999s\n",
      "batch 1967, train_loss 262.827545,Time used 0.009001s\n",
      "batch 1968, train_loss 207.678528,Time used 0.010001s\n",
      "batch 1969, train_loss 243.366821,Time used 0.007994s\n",
      "batch 1970, train_loss 237.961472,Time used 0.007034s\n",
      "batch 1971, train_loss 222.183395,Time used 0.006970s\n",
      "batch 1972, train_loss 205.014481,Time used 0.007994s\n",
      "batch 1973, train_loss 239.437439,Time used 0.009041s\n",
      "batch 1974, train_loss 226.075226,Time used 0.009963s\n",
      "batch 1975, train_loss 277.615265,Time used 0.009000s\n",
      "batch 1976, train_loss 254.438995,Time used 0.010999s\n",
      "batch 1977, train_loss 284.050262,Time used 0.009999s\n",
      "batch 1978, train_loss 241.181442,Time used 0.009000s\n",
      "batch 1979, train_loss 217.064850,Time used 0.007001s\n",
      "batch 1980, train_loss 233.659180,Time used 0.007999s\n",
      "batch 1981, train_loss 256.563232,Time used 0.009000s\n",
      "batch 1982, train_loss 283.206207,Time used 0.008002s\n",
      "batch 1983, train_loss 253.827896,Time used 0.006002s\n",
      "batch 1984, train_loss 224.506561,Time used 0.008000s\n",
      "batch 1985, train_loss 226.261917,Time used 0.006999s\n",
      "batch 1986, train_loss 201.564499,Time used 0.007003s\n",
      "batch 1987, train_loss 199.838364,Time used 0.008998s\n",
      "batch 1988, train_loss 177.846542,Time used 0.008998s\n",
      "batch 1989, train_loss 212.834839,Time used 0.010000s\n",
      "batch 1990, train_loss 256.157928,Time used 0.011035s\n",
      "batch 1991, train_loss 269.926697,Time used 0.007965s\n",
      "batch 1992, train_loss 274.804688,Time used 0.009998s\n",
      "batch 1993, train_loss 236.996262,Time used 0.007999s\n",
      "batch 1994, train_loss 266.147522,Time used 0.007002s\n",
      "batch 1995, train_loss 216.589066,Time used 0.006998s\n",
      "batch 1996, train_loss 215.634109,Time used 0.008004s\n",
      "batch 1997, train_loss 215.586548,Time used 0.007006s\n",
      "batch 1998, train_loss 240.571503,Time used 0.009989s\n",
      "batch 1999, train_loss 246.084442,Time used 0.010000s\n",
      "batch 2000, train_loss 211.617508,Time used 0.009002s\n",
      "***************************test_batch 2000, test_rmse_loss 17.350081,test_mae_loss 6.914137,test_mape_loss 74.182520,Time used 0.033000s\n",
      "batch 2001, train_loss 248.513336,Time used 0.010998s\n",
      "batch 2002, train_loss 252.867874,Time used 0.011003s\n",
      "batch 2003, train_loss 239.789459,Time used 0.010996s\n",
      "batch 2004, train_loss 249.124130,Time used 0.011000s\n",
      "batch 2005, train_loss 230.506149,Time used 0.010002s\n",
      "batch 2006, train_loss 250.533218,Time used 0.010997s\n",
      "batch 2007, train_loss 257.671509,Time used 0.009001s\n",
      "batch 2008, train_loss 233.661972,Time used 0.007998s\n",
      "batch 2009, train_loss 227.575516,Time used 0.010001s\n",
      "batch 2010, train_loss 216.463226,Time used 0.010007s\n",
      "batch 2011, train_loss 221.824387,Time used 0.007990s\n",
      "batch 2012, train_loss 203.282227,Time used 0.009002s\n",
      "batch 2013, train_loss 223.547836,Time used 0.005998s\n",
      "batch 2014, train_loss 227.425934,Time used 0.008004s\n",
      "batch 2015, train_loss 318.194214,Time used 0.006998s\n",
      "batch 2016, train_loss 237.425537,Time used 0.008001s\n",
      "batch 2017, train_loss 248.306030,Time used 0.008997s\n",
      "batch 2018, train_loss 251.846756,Time used 0.010001s\n",
      "batch 2019, train_loss 194.657990,Time used 0.007000s\n",
      "batch 2020, train_loss 229.550858,Time used 0.009998s\n",
      "batch 2021, train_loss 233.787354,Time used 0.009001s\n",
      "batch 2022, train_loss 212.624908,Time used 0.008001s\n",
      "batch 2023, train_loss 193.920471,Time used 0.007001s\n",
      "batch 2024, train_loss 252.255173,Time used 0.006999s\n",
      "batch 2025, train_loss 240.147858,Time used 0.006001s\n",
      "batch 2026, train_loss 251.179306,Time used 0.006998s\n",
      "batch 2027, train_loss 257.238007,Time used 0.009002s\n",
      "batch 2028, train_loss 264.331573,Time used 0.007000s\n",
      "batch 2029, train_loss 214.236969,Time used 0.006001s\n",
      "batch 2030, train_loss 199.282898,Time used 0.008998s\n",
      "batch 2031, train_loss 244.903854,Time used 0.006001s\n",
      "batch 2032, train_loss 267.874390,Time used 0.007000s\n",
      "batch 2033, train_loss 228.837677,Time used 0.007001s\n",
      "batch 2034, train_loss 198.136200,Time used 0.007000s\n",
      "batch 2035, train_loss 226.246201,Time used 0.007999s\n",
      "batch 2036, train_loss 252.783554,Time used 0.009001s\n",
      "batch 2037, train_loss 313.531342,Time used 0.008000s\n",
      "batch 2038, train_loss 195.961395,Time used 0.007000s\n",
      "batch 2039, train_loss 228.240753,Time used 0.010001s\n",
      "batch 2040, train_loss 258.544250,Time used 0.008000s\n",
      "batch 2041, train_loss 206.816391,Time used 0.009000s\n",
      "batch 2042, train_loss 196.214081,Time used 0.009001s\n",
      "batch 2043, train_loss 307.955475,Time used 0.009002s\n",
      "batch 2044, train_loss 217.529510,Time used 0.005998s\n",
      "batch 2045, train_loss 229.967285,Time used 0.008002s\n",
      "batch 2046, train_loss 231.493393,Time used 0.006999s\n",
      "batch 2047, train_loss 255.434708,Time used 0.007001s\n",
      "batch 2048, train_loss 249.292450,Time used 0.010000s\n",
      "batch 2049, train_loss 213.661240,Time used 0.008999s\n",
      "batch 2050, train_loss 229.151642,Time used 0.007001s\n",
      "batch 2051, train_loss 248.262787,Time used 0.011002s\n",
      "batch 2052, train_loss 236.823456,Time used 0.006997s\n",
      "batch 2053, train_loss 226.794128,Time used 0.010005s\n",
      "batch 2054, train_loss 285.631012,Time used 0.005996s\n",
      "batch 2055, train_loss 179.102112,Time used 0.008999s\n",
      "batch 2056, train_loss 203.082352,Time used 0.010005s\n",
      "batch 2057, train_loss 258.521210,Time used 0.009998s\n",
      "batch 2058, train_loss 254.184631,Time used 0.009002s\n",
      "batch 2059, train_loss 178.382462,Time used 0.009006s\n",
      "batch 2060, train_loss 250.532242,Time used 0.007997s\n",
      "batch 2061, train_loss 241.969681,Time used 0.008001s\n",
      "batch 2062, train_loss 232.760300,Time used 0.009001s\n",
      "batch 2063, train_loss 299.230682,Time used 0.009002s\n",
      "batch 2064, train_loss 193.178879,Time used 0.009001s\n",
      "batch 2065, train_loss 253.027130,Time used 0.008999s\n",
      "batch 2066, train_loss 241.745941,Time used 0.010001s\n",
      "batch 2067, train_loss 199.143509,Time used 0.008998s\n",
      "batch 2068, train_loss 257.865540,Time used 0.010001s\n",
      "batch 2069, train_loss 246.520020,Time used 0.008997s\n",
      "batch 2070, train_loss 201.177734,Time used 0.008002s\n",
      "batch 2071, train_loss 262.117188,Time used 0.006998s\n",
      "batch 2072, train_loss 266.574829,Time used 0.010000s\n",
      "batch 2073, train_loss 267.157593,Time used 0.008002s\n",
      "batch 2074, train_loss 216.434280,Time used 0.008997s\n",
      "batch 2075, train_loss 223.078583,Time used 0.010003s\n",
      "batch 2076, train_loss 286.409576,Time used 0.008001s\n",
      "batch 2077, train_loss 219.412338,Time used 0.006998s\n",
      "batch 2078, train_loss 252.059601,Time used 0.008002s\n",
      "batch 2079, train_loss 239.397049,Time used 0.008999s\n",
      "batch 2080, train_loss 231.193283,Time used 0.007000s\n",
      "batch 2081, train_loss 240.307709,Time used 0.006999s\n",
      "batch 2082, train_loss 253.696854,Time used 0.009001s\n",
      "batch 2083, train_loss 230.093094,Time used 0.009002s\n",
      "batch 2084, train_loss 189.782089,Time used 0.014999s\n",
      "batch 2085, train_loss 231.596451,Time used 0.007999s\n",
      "batch 2086, train_loss 181.411591,Time used 0.007000s\n",
      "batch 2087, train_loss 177.176620,Time used 0.008001s\n",
      "batch 2088, train_loss 230.630035,Time used 0.006999s\n",
      "batch 2089, train_loss 266.994446,Time used 0.006000s\n",
      "batch 2090, train_loss 251.400711,Time used 0.007011s\n",
      "batch 2091, train_loss 228.262604,Time used 0.006988s\n",
      "batch 2092, train_loss 233.378952,Time used 0.006001s\n",
      "batch 2093, train_loss 227.540115,Time used 0.005999s\n",
      "batch 2094, train_loss 230.561203,Time used 0.006000s\n",
      "batch 2095, train_loss 253.007538,Time used 0.007002s\n",
      "batch 2096, train_loss 257.410187,Time used 0.010000s\n",
      "batch 2097, train_loss 300.258759,Time used 0.009001s\n",
      "batch 2098, train_loss 175.147079,Time used 0.010000s\n",
      "batch 2099, train_loss 228.502136,Time used 0.008000s\n",
      "batch 2100, train_loss 232.077896,Time used 0.010000s\n",
      "***************************test_batch 2100, test_rmse_loss 17.173684,test_mae_loss 6.819531,test_mape_loss 74.005440,Time used 0.040000s\n",
      "batch 2101, train_loss 192.294525,Time used 0.008001s\n",
      "batch 2102, train_loss 196.691513,Time used 0.011001s\n",
      "batch 2103, train_loss 265.456360,Time used 0.010999s\n",
      "batch 2104, train_loss 281.769928,Time used 0.008000s\n",
      "batch 2105, train_loss 192.791412,Time used 0.008014s\n",
      "batch 2106, train_loss 293.115570,Time used 0.007997s\n",
      "batch 2107, train_loss 215.773605,Time used 0.005990s\n",
      "batch 2108, train_loss 179.733246,Time used 0.009998s\n",
      "batch 2109, train_loss 254.152969,Time used 0.009001s\n",
      "batch 2110, train_loss 195.220688,Time used 0.006001s\n",
      "batch 2111, train_loss 198.509903,Time used 0.007000s\n",
      "batch 2112, train_loss 217.931641,Time used 0.009001s\n",
      "batch 2113, train_loss 228.272018,Time used 0.009998s\n",
      "batch 2114, train_loss 277.780701,Time used 0.010003s\n",
      "batch 2115, train_loss 245.591858,Time used 0.010995s\n",
      "batch 2116, train_loss 243.509369,Time used 0.007000s\n",
      "batch 2117, train_loss 240.371094,Time used 0.007002s\n",
      "batch 2118, train_loss 258.619751,Time used 0.007999s\n",
      "batch 2119, train_loss 249.039429,Time used 0.007000s\n",
      "batch 2120, train_loss 224.895065,Time used 0.009002s\n",
      "batch 2121, train_loss 233.321106,Time used 0.009997s\n",
      "batch 2122, train_loss 229.103424,Time used 0.009999s\n",
      "batch 2123, train_loss 217.972473,Time used 0.010002s\n",
      "batch 2124, train_loss 202.585022,Time used 0.008998s\n",
      "batch 2125, train_loss 217.894608,Time used 0.008000s\n",
      "batch 2126, train_loss 155.773956,Time used 0.009001s\n",
      "batch 2127, train_loss 187.901489,Time used 0.007999s\n",
      "batch 2128, train_loss 185.955276,Time used 0.006000s\n",
      "batch 2129, train_loss 235.563477,Time used 0.007001s\n",
      "batch 2130, train_loss 238.099503,Time used 0.006999s\n",
      "batch 2131, train_loss 262.127930,Time used 0.006999s\n",
      "batch 2132, train_loss 220.620438,Time used 0.007000s\n",
      "batch 2133, train_loss 263.565918,Time used 0.007002s\n",
      "batch 2134, train_loss 299.777832,Time used 0.006000s\n",
      "batch 2135, train_loss 225.719025,Time used 0.007001s\n",
      "batch 2136, train_loss 193.770981,Time used 0.006999s\n",
      "batch 2137, train_loss 251.551270,Time used 0.008998s\n",
      "batch 2138, train_loss 186.073181,Time used 0.007000s\n",
      "batch 2139, train_loss 215.535324,Time used 0.009000s\n",
      "batch 2140, train_loss 203.033813,Time used 0.006001s\n",
      "batch 2141, train_loss 211.743607,Time used 0.008009s\n",
      "batch 2142, train_loss 239.096786,Time used 0.005991s\n",
      "batch 2143, train_loss 272.834595,Time used 0.007998s\n",
      "batch 2144, train_loss 232.596268,Time used 0.006001s\n",
      "batch 2145, train_loss 190.605652,Time used 0.007003s\n",
      "batch 2146, train_loss 174.059235,Time used 0.006999s\n",
      "batch 2147, train_loss 279.503967,Time used 0.007000s\n",
      "batch 2148, train_loss 219.667068,Time used 0.006999s\n",
      "batch 2149, train_loss 275.159576,Time used 0.006999s\n",
      "batch 2150, train_loss 175.673019,Time used 0.008002s\n",
      "batch 2151, train_loss 224.130386,Time used 0.011000s\n",
      "batch 2152, train_loss 260.440491,Time used 0.009001s\n",
      "batch 2153, train_loss 225.408569,Time used 0.010015s\n",
      "batch 2154, train_loss 190.868729,Time used 0.007985s\n",
      "batch 2155, train_loss 216.748276,Time used 0.007000s\n",
      "batch 2156, train_loss 201.235641,Time used 0.008000s\n",
      "batch 2157, train_loss 325.297424,Time used 0.007000s\n",
      "batch 2158, train_loss 244.584671,Time used 0.007999s\n",
      "batch 2159, train_loss 247.121948,Time used 0.007999s\n",
      "batch 2160, train_loss 248.119705,Time used 0.007001s\n",
      "batch 2161, train_loss 248.417557,Time used 0.009998s\n",
      "batch 2162, train_loss 204.005096,Time used 0.008002s\n",
      "batch 2163, train_loss 251.102310,Time used 0.007000s\n",
      "batch 2164, train_loss 194.278442,Time used 0.007999s\n",
      "batch 2165, train_loss 170.809586,Time used 0.010000s\n",
      "batch 2166, train_loss 259.554413,Time used 0.006998s\n",
      "batch 2167, train_loss 226.859787,Time used 0.006002s\n",
      "batch 2168, train_loss 206.620316,Time used 0.007998s\n",
      "batch 2169, train_loss 236.519958,Time used 0.007000s\n",
      "batch 2170, train_loss 236.698944,Time used 0.009000s\n",
      "batch 2171, train_loss 243.219620,Time used 0.006999s\n",
      "batch 2172, train_loss 271.473328,Time used 0.008001s\n",
      "batch 2173, train_loss 252.182114,Time used 0.007000s\n",
      "batch 2174, train_loss 215.887024,Time used 0.010001s\n",
      "batch 2175, train_loss 247.556000,Time used 0.010003s\n",
      "batch 2176, train_loss 185.920547,Time used 0.014998s\n",
      "batch 2177, train_loss 230.670914,Time used 0.010000s\n",
      "batch 2178, train_loss 268.688843,Time used 0.009999s\n",
      "batch 2179, train_loss 254.569550,Time used 0.006999s\n",
      "batch 2180, train_loss 224.166855,Time used 0.006001s\n",
      "batch 2181, train_loss 183.366257,Time used 0.006999s\n",
      "batch 2182, train_loss 205.357620,Time used 0.008003s\n",
      "batch 2183, train_loss 266.099823,Time used 0.009998s\n",
      "batch 2184, train_loss 196.567841,Time used 0.005999s\n",
      "batch 2185, train_loss 216.157013,Time used 0.008998s\n",
      "batch 2186, train_loss 229.014130,Time used 0.007999s\n",
      "batch 2187, train_loss 263.314087,Time used 0.007000s\n",
      "batch 2188, train_loss 256.954498,Time used 0.007000s\n",
      "batch 2189, train_loss 190.090836,Time used 0.008001s\n",
      "batch 2190, train_loss 214.117783,Time used 0.007000s\n",
      "batch 2191, train_loss 223.888229,Time used 0.007000s\n",
      "batch 2192, train_loss 221.507019,Time used 0.008006s\n",
      "batch 2193, train_loss 209.470444,Time used 0.005995s\n",
      "batch 2194, train_loss 230.078491,Time used 0.009000s\n",
      "batch 2195, train_loss 276.911072,Time used 0.007998s\n",
      "batch 2196, train_loss 231.193710,Time used 0.011999s\n",
      "batch 2197, train_loss 218.435760,Time used 0.008000s\n",
      "batch 2198, train_loss 280.313416,Time used 0.007000s\n",
      "batch 2199, train_loss 195.469681,Time used 0.008000s\n",
      "batch 2200, train_loss 241.325943,Time used 0.009999s\n",
      "***************************test_batch 2200, test_rmse_loss 17.002166,test_mae_loss 6.726647,test_mape_loss 73.515820,Time used 0.031002s\n",
      "batch 2201, train_loss 234.176483,Time used 0.007999s\n",
      "batch 2202, train_loss 234.338440,Time used 0.007000s\n",
      "batch 2203, train_loss 171.124039,Time used 0.005999s\n",
      "batch 2204, train_loss 214.706100,Time used 0.007001s\n",
      "batch 2205, train_loss 216.876770,Time used 0.008999s\n",
      "batch 2206, train_loss 195.283722,Time used 0.006000s\n",
      "batch 2207, train_loss 228.633194,Time used 0.007000s\n",
      "batch 2208, train_loss 261.166199,Time used 0.007000s\n",
      "batch 2209, train_loss 192.992462,Time used 0.006999s\n",
      "batch 2210, train_loss 227.148468,Time used 0.008001s\n",
      "batch 2211, train_loss 230.389847,Time used 0.009001s\n",
      "batch 2212, train_loss 198.443756,Time used 0.005998s\n",
      "batch 2213, train_loss 246.090897,Time used 0.008003s\n",
      "batch 2214, train_loss 208.414810,Time used 0.010000s\n",
      "batch 2215, train_loss 205.371307,Time used 0.006999s\n",
      "batch 2216, train_loss 166.056656,Time used 0.006999s\n",
      "batch 2217, train_loss 252.087662,Time used 0.009001s\n",
      "batch 2218, train_loss 224.470932,Time used 0.006999s\n",
      "batch 2219, train_loss 285.530212,Time used 0.007001s\n",
      "batch 2220, train_loss 225.259430,Time used 0.006999s\n",
      "batch 2221, train_loss 202.614227,Time used 0.008001s\n",
      "batch 2222, train_loss 205.894821,Time used 0.007000s\n",
      "batch 2223, train_loss 265.339874,Time used 0.005999s\n",
      "batch 2224, train_loss 257.020233,Time used 0.010999s\n",
      "batch 2225, train_loss 235.996185,Time used 0.009002s\n",
      "batch 2226, train_loss 232.162613,Time used 0.006000s\n",
      "batch 2227, train_loss 228.648041,Time used 0.006003s\n",
      "batch 2228, train_loss 271.910736,Time used 0.005996s\n",
      "batch 2229, train_loss 240.485077,Time used 0.006000s\n",
      "batch 2230, train_loss 188.482391,Time used 0.006999s\n",
      "batch 2231, train_loss 201.720581,Time used 0.007000s\n",
      "batch 2232, train_loss 232.649048,Time used 0.007000s\n",
      "batch 2233, train_loss 185.181870,Time used 0.008001s\n",
      "batch 2234, train_loss 264.049866,Time used 0.009999s\n",
      "batch 2235, train_loss 252.334305,Time used 0.008001s\n",
      "batch 2236, train_loss 291.986450,Time used 0.006999s\n",
      "batch 2237, train_loss 153.225159,Time used 0.008001s\n",
      "batch 2238, train_loss 223.195206,Time used 0.008001s\n",
      "batch 2239, train_loss 248.846924,Time used 0.007999s\n",
      "batch 2240, train_loss 274.137085,Time used 0.007000s\n",
      "batch 2241, train_loss 262.657623,Time used 0.007002s\n",
      "batch 2242, train_loss 230.918823,Time used 0.007017s\n",
      "batch 2243, train_loss 244.376282,Time used 0.009979s\n",
      "batch 2244, train_loss 200.662933,Time used 0.010001s\n",
      "batch 2245, train_loss 260.176422,Time used 0.007999s\n",
      "batch 2246, train_loss 232.946045,Time used 0.007000s\n",
      "batch 2247, train_loss 217.538589,Time used 0.010001s\n",
      "batch 2248, train_loss 200.637192,Time used 0.009999s\n",
      "batch 2249, train_loss 221.459137,Time used 0.008000s\n",
      "batch 2250, train_loss 210.318375,Time used 0.009001s\n",
      "batch 2251, train_loss 185.736191,Time used 0.006000s\n",
      "batch 2252, train_loss 220.292648,Time used 0.009001s\n",
      "batch 2253, train_loss 173.895493,Time used 0.007001s\n",
      "batch 2254, train_loss 276.577820,Time used 0.007997s\n",
      "batch 2255, train_loss 193.710770,Time used 0.011002s\n",
      "batch 2256, train_loss 170.112274,Time used 0.007000s\n",
      "batch 2257, train_loss 209.410706,Time used 0.005999s\n",
      "batch 2258, train_loss 208.362442,Time used 0.007000s\n",
      "batch 2259, train_loss 189.377090,Time used 0.009002s\n",
      "batch 2260, train_loss 287.063599,Time used 0.007004s\n",
      "batch 2261, train_loss 217.837570,Time used 0.007994s\n",
      "batch 2262, train_loss 222.089508,Time used 0.009002s\n",
      "batch 2263, train_loss 218.878052,Time used 0.009998s\n",
      "batch 2264, train_loss 233.488617,Time used 0.009000s\n",
      "batch 2265, train_loss 217.110641,Time used 0.007000s\n",
      "batch 2266, train_loss 198.772949,Time used 0.006999s\n",
      "batch 2267, train_loss 204.140671,Time used 0.007003s\n",
      "batch 2268, train_loss 223.874969,Time used 0.007001s\n",
      "batch 2269, train_loss 256.269318,Time used 0.006999s\n",
      "batch 2270, train_loss 224.436401,Time used 0.007000s\n",
      "batch 2271, train_loss 146.740479,Time used 0.006999s\n",
      "batch 2272, train_loss 248.595032,Time used 0.007000s\n",
      "batch 2273, train_loss 222.524094,Time used 0.006000s\n",
      "batch 2274, train_loss 272.104889,Time used 0.010001s\n",
      "batch 2275, train_loss 211.005005,Time used 0.006001s\n",
      "batch 2276, train_loss 214.941559,Time used 0.009996s\n",
      "batch 2277, train_loss 272.484711,Time used 0.007016s\n",
      "batch 2278, train_loss 197.301971,Time used 0.007986s\n",
      "batch 2279, train_loss 260.802155,Time used 0.006031s\n",
      "batch 2280, train_loss 210.824936,Time used 0.006965s\n",
      "batch 2281, train_loss 228.331284,Time used 0.008001s\n",
      "batch 2282, train_loss 188.693024,Time used 0.006999s\n",
      "batch 2283, train_loss 230.723648,Time used 0.006002s\n",
      "batch 2284, train_loss 224.454224,Time used 0.007998s\n",
      "batch 2285, train_loss 197.389023,Time used 0.008001s\n",
      "batch 2286, train_loss 278.040955,Time used 0.005999s\n",
      "batch 2287, train_loss 211.004669,Time used 0.007001s\n",
      "batch 2288, train_loss 196.779022,Time used 0.006997s\n",
      "batch 2289, train_loss 233.103287,Time used 0.006002s\n",
      "batch 2290, train_loss 208.490067,Time used 0.007001s\n",
      "batch 2291, train_loss 228.602173,Time used 0.009002s\n",
      "batch 2292, train_loss 203.574051,Time used 0.008998s\n",
      "batch 2293, train_loss 267.353119,Time used 0.007016s\n",
      "batch 2294, train_loss 236.778168,Time used 0.008984s\n",
      "batch 2295, train_loss 214.256790,Time used 0.009999s\n",
      "batch 2296, train_loss 183.191208,Time used 0.007002s\n",
      "batch 2297, train_loss 268.897278,Time used 0.006998s\n",
      "batch 2298, train_loss 235.153107,Time used 0.010000s\n",
      "batch 2299, train_loss 224.647293,Time used 0.009000s\n",
      "batch 2300, train_loss 198.954224,Time used 0.005999s\n",
      "***************************test_batch 2300, test_rmse_loss 16.833217,test_mae_loss 6.639277,test_mape_loss 73.424375,Time used 0.035000s\n",
      "batch 2301, train_loss 204.190414,Time used 0.010001s\n",
      "batch 2302, train_loss 200.477158,Time used 0.006999s\n",
      "batch 2303, train_loss 207.211945,Time used 0.006998s\n",
      "batch 2304, train_loss 273.118103,Time used 0.007001s\n",
      "batch 2305, train_loss 221.380524,Time used 0.010000s\n",
      "batch 2306, train_loss 195.154282,Time used 0.009002s\n",
      "batch 2307, train_loss 223.018143,Time used 0.005999s\n",
      "batch 2308, train_loss 209.733795,Time used 0.006001s\n",
      "batch 2309, train_loss 205.523163,Time used 0.006999s\n",
      "batch 2310, train_loss 251.717514,Time used 0.011002s\n",
      "batch 2311, train_loss 224.577454,Time used 0.011998s\n",
      "batch 2312, train_loss 206.253632,Time used 0.008001s\n",
      "batch 2313, train_loss 233.290436,Time used 0.007999s\n",
      "batch 2314, train_loss 204.160690,Time used 0.007000s\n",
      "batch 2315, train_loss 228.085236,Time used 0.008001s\n",
      "batch 2316, train_loss 232.896851,Time used 0.010002s\n",
      "batch 2317, train_loss 217.004456,Time used 0.006996s\n",
      "batch 2318, train_loss 219.850510,Time used 0.006002s\n",
      "batch 2319, train_loss 258.098236,Time used 0.007002s\n",
      "batch 2320, train_loss 230.361053,Time used 0.005998s\n",
      "batch 2321, train_loss 195.597107,Time used 0.007000s\n",
      "batch 2322, train_loss 237.390625,Time used 0.006000s\n",
      "batch 2323, train_loss 234.255417,Time used 0.011001s\n",
      "batch 2324, train_loss 224.398346,Time used 0.008001s\n",
      "batch 2325, train_loss 264.362091,Time used 0.009997s\n",
      "batch 2326, train_loss 187.596283,Time used 0.008002s\n",
      "batch 2327, train_loss 216.538574,Time used 0.007998s\n",
      "batch 2328, train_loss 191.757462,Time used 0.009004s\n",
      "batch 2329, train_loss 162.541656,Time used 0.009000s\n",
      "batch 2330, train_loss 194.843674,Time used 0.007998s\n",
      "batch 2331, train_loss 297.901154,Time used 0.006999s\n",
      "batch 2332, train_loss 214.417847,Time used 0.011000s\n",
      "batch 2333, train_loss 245.493912,Time used 0.008999s\n",
      "batch 2334, train_loss 237.734299,Time used 0.007001s\n",
      "batch 2335, train_loss 205.047745,Time used 0.008002s\n",
      "batch 2336, train_loss 238.719543,Time used 0.008998s\n",
      "batch 2337, train_loss 223.512787,Time used 0.009998s\n",
      "batch 2338, train_loss 192.916306,Time used 0.010002s\n",
      "batch 2339, train_loss 241.073822,Time used 0.007999s\n",
      "batch 2340, train_loss 265.713318,Time used 0.007003s\n",
      "batch 2341, train_loss 172.467941,Time used 0.006997s\n",
      "batch 2342, train_loss 206.581284,Time used 0.006000s\n",
      "batch 2343, train_loss 195.337540,Time used 0.009999s\n",
      "batch 2344, train_loss 191.590057,Time used 0.010014s\n",
      "batch 2345, train_loss 245.532837,Time used 0.006986s\n",
      "batch 2346, train_loss 216.842194,Time used 0.008003s\n",
      "batch 2347, train_loss 232.874130,Time used 0.007999s\n",
      "batch 2348, train_loss 246.294357,Time used 0.009000s\n",
      "batch 2349, train_loss 184.858109,Time used 0.011002s\n",
      "batch 2350, train_loss 283.552429,Time used 0.010036s\n",
      "batch 2351, train_loss 218.918777,Time used 0.006962s\n",
      "batch 2352, train_loss 170.187973,Time used 0.009001s\n",
      "batch 2353, train_loss 176.985382,Time used 0.010000s\n",
      "batch 2354, train_loss 246.630234,Time used 0.006999s\n",
      "batch 2355, train_loss 215.362579,Time used 0.006000s\n",
      "batch 2356, train_loss 255.417435,Time used 0.007001s\n",
      "batch 2357, train_loss 209.577682,Time used 0.010003s\n",
      "batch 2358, train_loss 183.611130,Time used 0.008001s\n",
      "batch 2359, train_loss 180.054108,Time used 0.009996s\n",
      "batch 2360, train_loss 220.716934,Time used 0.008001s\n",
      "batch 2361, train_loss 242.919556,Time used 0.006000s\n",
      "batch 2362, train_loss 201.101776,Time used 0.007998s\n",
      "batch 2363, train_loss 270.469971,Time used 0.006015s\n",
      "batch 2364, train_loss 221.201279,Time used 0.006986s\n",
      "batch 2365, train_loss 273.970123,Time used 0.006000s\n",
      "batch 2366, train_loss 184.495224,Time used 0.007000s\n",
      "batch 2367, train_loss 235.937363,Time used 0.007000s\n",
      "batch 2368, train_loss 246.472717,Time used 0.008001s\n",
      "batch 2369, train_loss 203.385406,Time used 0.010003s\n",
      "batch 2370, train_loss 225.962631,Time used 0.007995s\n",
      "batch 2371, train_loss 188.223862,Time used 0.010002s\n",
      "batch 2372, train_loss 186.786377,Time used 0.012001s\n",
      "batch 2373, train_loss 168.704559,Time used 0.010000s\n",
      "batch 2374, train_loss 270.929840,Time used 0.010999s\n",
      "batch 2375, train_loss 194.014160,Time used 0.012001s\n",
      "batch 2376, train_loss 258.494659,Time used 0.009000s\n",
      "batch 2377, train_loss 170.116257,Time used 0.009000s\n",
      "batch 2378, train_loss 253.831604,Time used 0.007001s\n",
      "batch 2379, train_loss 171.987762,Time used 0.008001s\n",
      "batch 2380, train_loss 235.557220,Time used 0.010997s\n",
      "batch 2381, train_loss 176.023712,Time used 0.008001s\n",
      "batch 2382, train_loss 252.949127,Time used 0.006999s\n",
      "batch 2383, train_loss 231.069275,Time used 0.007002s\n",
      "batch 2384, train_loss 255.247650,Time used 0.006999s\n",
      "batch 2385, train_loss 277.545288,Time used 0.007003s\n",
      "batch 2386, train_loss 216.622757,Time used 0.006999s\n",
      "batch 2387, train_loss 247.001389,Time used 0.006001s\n",
      "batch 2388, train_loss 236.762833,Time used 0.006999s\n",
      "batch 2389, train_loss 185.533340,Time used 0.006999s\n",
      "batch 2390, train_loss 203.130096,Time used 0.005999s\n",
      "batch 2391, train_loss 221.567871,Time used 0.007001s\n",
      "batch 2392, train_loss 211.571625,Time used 0.008000s\n",
      "batch 2393, train_loss 179.444016,Time used 0.010000s\n",
      "batch 2394, train_loss 191.190247,Time used 0.010000s\n",
      "batch 2395, train_loss 202.631546,Time used 0.007009s\n",
      "batch 2396, train_loss 182.284485,Time used 0.006992s\n",
      "batch 2397, train_loss 222.449692,Time used 0.006999s\n",
      "batch 2398, train_loss 191.416656,Time used 0.007000s\n",
      "batch 2399, train_loss 299.752045,Time used 0.007001s\n",
      "batch 2400, train_loss 217.424911,Time used 0.009996s\n",
      "***************************test_batch 2400, test_rmse_loss 16.667596,test_mae_loss 6.552979,test_mape_loss 73.083989,Time used 0.036001s\n",
      "batch 2401, train_loss 260.243378,Time used 0.010000s\n",
      "batch 2402, train_loss 187.661972,Time used 0.008001s\n",
      "batch 2403, train_loss 203.769592,Time used 0.006000s\n",
      "batch 2404, train_loss 230.226181,Time used 0.008999s\n",
      "batch 2405, train_loss 296.232117,Time used 0.010000s\n",
      "batch 2406, train_loss 289.554474,Time used 0.010001s\n",
      "batch 2407, train_loss 213.889420,Time used 0.009000s\n",
      "batch 2408, train_loss 221.284439,Time used 0.006000s\n",
      "batch 2409, train_loss 197.524429,Time used 0.005999s\n",
      "batch 2410, train_loss 165.127167,Time used 0.010002s\n",
      "batch 2411, train_loss 230.512817,Time used 0.008999s\n",
      "batch 2412, train_loss 284.953766,Time used 0.006003s\n",
      "batch 2413, train_loss 183.250168,Time used 0.009000s\n",
      "batch 2414, train_loss 216.490479,Time used 0.006001s\n",
      "batch 2415, train_loss 170.959961,Time used 0.007000s\n",
      "batch 2416, train_loss 232.261368,Time used 0.007001s\n",
      "batch 2417, train_loss 169.391571,Time used 0.007000s\n",
      "batch 2418, train_loss 215.483200,Time used 0.007000s\n",
      "batch 2419, train_loss 248.018280,Time used 0.006999s\n",
      "batch 2420, train_loss 237.674774,Time used 0.007001s\n",
      "batch 2421, train_loss 168.556671,Time used 0.006999s\n",
      "batch 2422, train_loss 241.709244,Time used 0.008005s\n",
      "batch 2423, train_loss 187.356400,Time used 0.010996s\n",
      "batch 2424, train_loss 152.028748,Time used 0.006999s\n",
      "batch 2425, train_loss 189.917145,Time used 0.008999s\n",
      "batch 2426, train_loss 206.552475,Time used 0.006997s\n",
      "batch 2427, train_loss 258.200623,Time used 0.008001s\n",
      "batch 2428, train_loss 229.514069,Time used 0.007000s\n",
      "batch 2429, train_loss 170.705200,Time used 0.007000s\n",
      "batch 2430, train_loss 220.369080,Time used 0.007001s\n",
      "batch 2431, train_loss 248.072556,Time used 0.009999s\n",
      "batch 2432, train_loss 213.677338,Time used 0.007009s\n",
      "batch 2433, train_loss 223.579880,Time used 0.008991s\n",
      "batch 2434, train_loss 184.478394,Time used 0.007000s\n",
      "batch 2435, train_loss 175.990005,Time used 0.006999s\n",
      "batch 2436, train_loss 212.656143,Time used 0.007000s\n",
      "batch 2437, train_loss 147.596634,Time used 0.011002s\n",
      "batch 2438, train_loss 209.693298,Time used 0.006999s\n",
      "batch 2439, train_loss 208.473312,Time used 0.008003s\n",
      "batch 2440, train_loss 226.500336,Time used 0.008996s\n",
      "batch 2441, train_loss 263.846649,Time used 0.007000s\n",
      "batch 2442, train_loss 207.106644,Time used 0.005999s\n",
      "batch 2443, train_loss 277.481995,Time used 0.007001s\n",
      "batch 2444, train_loss 267.224609,Time used 0.006000s\n",
      "batch 2445, train_loss 251.871597,Time used 0.008000s\n",
      "batch 2446, train_loss 177.178207,Time used 0.006000s\n",
      "batch 2447, train_loss 224.560715,Time used 0.008000s\n",
      "batch 2448, train_loss 183.602570,Time used 0.006998s\n",
      "batch 2449, train_loss 226.059280,Time used 0.007000s\n",
      "batch 2450, train_loss 212.547485,Time used 0.007000s\n",
      "batch 2451, train_loss 262.125610,Time used 0.008998s\n",
      "batch 2452, train_loss 226.921921,Time used 0.010000s\n",
      "batch 2453, train_loss 166.407257,Time used 0.007000s\n",
      "batch 2454, train_loss 232.067551,Time used 0.006000s\n",
      "batch 2455, train_loss 226.396713,Time used 0.007002s\n",
      "batch 2456, train_loss 255.873260,Time used 0.008001s\n",
      "batch 2457, train_loss 223.139511,Time used 0.007999s\n",
      "batch 2458, train_loss 219.598251,Time used 0.006000s\n",
      "batch 2459, train_loss 191.335327,Time used 0.007000s\n",
      "batch 2460, train_loss 183.906921,Time used 0.008000s\n",
      "batch 2461, train_loss 202.731735,Time used 0.011002s\n",
      "batch 2462, train_loss 242.212509,Time used 0.010999s\n",
      "batch 2463, train_loss 206.822098,Time used 0.011000s\n",
      "batch 2464, train_loss 217.934311,Time used 0.009000s\n",
      "batch 2465, train_loss 226.715683,Time used 0.010998s\n",
      "batch 2466, train_loss 180.170563,Time used 0.010000s\n",
      "batch 2467, train_loss 281.186737,Time used 0.009999s\n",
      "batch 2468, train_loss 188.071854,Time used 0.008001s\n",
      "batch 2469, train_loss 231.653656,Time used 0.007002s\n",
      "batch 2470, train_loss 141.687759,Time used 0.006000s\n",
      "batch 2471, train_loss 182.079727,Time used 0.009999s\n",
      "batch 2472, train_loss 227.035110,Time used 0.009002s\n",
      "batch 2473, train_loss 151.257019,Time used 0.006996s\n",
      "batch 2474, train_loss 216.353088,Time used 0.007000s\n",
      "batch 2475, train_loss 139.991974,Time used 0.007001s\n",
      "batch 2476, train_loss 225.880554,Time used 0.007011s\n",
      "batch 2477, train_loss 179.385818,Time used 0.005988s\n",
      "batch 2478, train_loss 183.355103,Time used 0.008002s\n",
      "batch 2479, train_loss 223.946350,Time used 0.010000s\n",
      "batch 2480, train_loss 222.547333,Time used 0.010000s\n",
      "batch 2481, train_loss 190.119537,Time used 0.009001s\n",
      "batch 2482, train_loss 292.509460,Time used 0.006999s\n",
      "batch 2483, train_loss 240.473694,Time used 0.009002s\n",
      "batch 2484, train_loss 208.980942,Time used 0.009999s\n",
      "batch 2485, train_loss 207.329300,Time used 0.009999s\n",
      "batch 2486, train_loss 215.474503,Time used 0.010000s\n",
      "batch 2487, train_loss 261.590179,Time used 0.010001s\n",
      "batch 2488, train_loss 172.449249,Time used 0.007008s\n",
      "batch 2489, train_loss 226.813232,Time used 0.006990s\n",
      "batch 2490, train_loss 198.987305,Time used 0.008000s\n",
      "batch 2491, train_loss 213.932999,Time used 0.007999s\n",
      "batch 2492, train_loss 251.848389,Time used 0.008002s\n",
      "batch 2493, train_loss 210.427963,Time used 0.006999s\n",
      "batch 2494, train_loss 253.534958,Time used 0.007003s\n",
      "batch 2495, train_loss 232.441849,Time used 0.008000s\n",
      "batch 2496, train_loss 208.130173,Time used 0.008000s\n",
      "batch 2497, train_loss 186.754410,Time used 0.005997s\n",
      "batch 2498, train_loss 210.774780,Time used 0.010001s\n",
      "batch 2499, train_loss 229.388000,Time used 0.010001s\n",
      "batch 2500, train_loss 207.123657,Time used 0.006999s\n",
      "***************************test_batch 2500, test_rmse_loss 16.505476,test_mae_loss 6.470334,test_mape_loss 72.838527,Time used 0.033000s\n",
      "batch 2501, train_loss 275.839478,Time used 0.008998s\n",
      "batch 2502, train_loss 225.314117,Time used 0.011000s\n",
      "batch 2503, train_loss 181.742920,Time used 0.010000s\n",
      "batch 2504, train_loss 223.166916,Time used 0.007002s\n",
      "batch 2505, train_loss 202.699890,Time used 0.006999s\n",
      "batch 2506, train_loss 271.798492,Time used 0.006999s\n",
      "batch 2507, train_loss 212.053909,Time used 0.006000s\n",
      "batch 2508, train_loss 180.902420,Time used 0.006000s\n",
      "batch 2509, train_loss 212.366867,Time used 0.006000s\n",
      "batch 2510, train_loss 203.689743,Time used 0.006002s\n",
      "batch 2511, train_loss 187.835114,Time used 0.009035s\n",
      "batch 2512, train_loss 224.265762,Time used 0.006964s\n",
      "batch 2513, train_loss 193.649536,Time used 0.007002s\n",
      "batch 2514, train_loss 234.715897,Time used 0.006001s\n",
      "batch 2515, train_loss 216.332199,Time used 0.006998s\n",
      "batch 2516, train_loss 214.178070,Time used 0.007001s\n",
      "batch 2517, train_loss 220.092316,Time used 0.008001s\n",
      "batch 2518, train_loss 214.181946,Time used 0.010996s\n",
      "batch 2519, train_loss 174.532944,Time used 0.009000s\n",
      "batch 2520, train_loss 198.513657,Time used 0.011002s\n",
      "batch 2521, train_loss 199.538116,Time used 0.007000s\n",
      "batch 2522, train_loss 184.326401,Time used 0.006999s\n",
      "batch 2523, train_loss 211.263718,Time used 0.009002s\n",
      "batch 2524, train_loss 229.110474,Time used 0.008999s\n",
      "batch 2525, train_loss 251.460602,Time used 0.008998s\n",
      "batch 2526, train_loss 180.194397,Time used 0.012001s\n",
      "batch 2527, train_loss 215.112732,Time used 0.010001s\n",
      "batch 2528, train_loss 229.163773,Time used 0.008999s\n",
      "batch 2529, train_loss 237.384232,Time used 0.010999s\n",
      "batch 2530, train_loss 213.086777,Time used 0.011000s\n",
      "batch 2531, train_loss 232.480377,Time used 0.010001s\n",
      "batch 2532, train_loss 194.053955,Time used 0.008001s\n",
      "batch 2533, train_loss 275.068695,Time used 0.011001s\n",
      "batch 2534, train_loss 245.630539,Time used 0.010000s\n",
      "batch 2535, train_loss 240.144196,Time used 0.009002s\n",
      "batch 2536, train_loss 143.221085,Time used 0.005999s\n",
      "batch 2537, train_loss 204.400513,Time used 0.008000s\n",
      "batch 2538, train_loss 183.810913,Time used 0.010000s\n",
      "batch 2539, train_loss 184.365097,Time used 0.011001s\n",
      "batch 2540, train_loss 201.282059,Time used 0.008000s\n",
      "batch 2541, train_loss 182.180893,Time used 0.009000s\n",
      "batch 2542, train_loss 246.184082,Time used 0.006998s\n",
      "batch 2543, train_loss 184.635788,Time used 0.008001s\n",
      "batch 2544, train_loss 208.596100,Time used 0.011002s\n",
      "batch 2545, train_loss 229.330414,Time used 0.007999s\n",
      "batch 2546, train_loss 177.194687,Time used 0.008999s\n",
      "batch 2547, train_loss 235.696869,Time used 0.010999s\n",
      "batch 2548, train_loss 201.741867,Time used 0.011001s\n",
      "batch 2549, train_loss 185.406693,Time used 0.009001s\n",
      "batch 2550, train_loss 171.018784,Time used 0.010999s\n",
      "batch 2551, train_loss 270.306641,Time used 0.011001s\n",
      "batch 2552, train_loss 222.356827,Time used 0.009999s\n",
      "batch 2553, train_loss 211.871460,Time used 0.007001s\n",
      "batch 2554, train_loss 170.293655,Time used 0.008005s\n",
      "batch 2555, train_loss 201.025040,Time used 0.006993s\n",
      "batch 2556, train_loss 252.996857,Time used 0.008004s\n",
      "batch 2557, train_loss 219.996353,Time used 0.008993s\n",
      "batch 2558, train_loss 210.483307,Time used 0.012000s\n",
      "batch 2559, train_loss 190.862274,Time used 0.011001s\n",
      "batch 2560, train_loss 216.669022,Time used 0.010997s\n",
      "batch 2561, train_loss 201.691467,Time used 0.010001s\n",
      "batch 2562, train_loss 227.550674,Time used 0.010001s\n",
      "batch 2563, train_loss 241.010284,Time used 0.011000s\n",
      "batch 2564, train_loss 203.597260,Time used 0.007000s\n",
      "batch 2565, train_loss 204.773834,Time used 0.007000s\n",
      "batch 2566, train_loss 185.220764,Time used 0.009000s\n",
      "batch 2567, train_loss 201.644562,Time used 0.008002s\n",
      "batch 2568, train_loss 218.976501,Time used 0.009996s\n",
      "batch 2569, train_loss 207.227448,Time used 0.007999s\n",
      "batch 2570, train_loss 208.590530,Time used 0.011001s\n",
      "batch 2571, train_loss 260.881683,Time used 0.009000s\n",
      "batch 2572, train_loss 185.051208,Time used 0.010998s\n",
      "batch 2573, train_loss 221.925842,Time used 0.010006s\n",
      "batch 2574, train_loss 189.041290,Time used 0.010000s\n",
      "batch 2575, train_loss 187.364487,Time used 0.006999s\n",
      "batch 2576, train_loss 219.506210,Time used 0.008007s\n",
      "batch 2577, train_loss 225.176773,Time used 0.006994s\n",
      "batch 2578, train_loss 253.331085,Time used 0.008003s\n",
      "batch 2579, train_loss 246.449463,Time used 0.008996s\n",
      "batch 2580, train_loss 192.404327,Time used 0.006999s\n",
      "batch 2581, train_loss 255.233765,Time used 0.010000s\n",
      "batch 2582, train_loss 187.599075,Time used 0.008003s\n",
      "batch 2583, train_loss 209.326324,Time used 0.007999s\n",
      "batch 2584, train_loss 185.423004,Time used 0.009000s\n",
      "batch 2585, train_loss 234.276886,Time used 0.008004s\n",
      "batch 2586, train_loss 235.508698,Time used 0.008995s\n",
      "batch 2587, train_loss 205.305984,Time used 0.007000s\n",
      "batch 2588, train_loss 207.632645,Time used 0.009002s\n",
      "batch 2589, train_loss 148.230804,Time used 0.008000s\n",
      "batch 2590, train_loss 170.365189,Time used 0.010001s\n",
      "batch 2591, train_loss 171.771347,Time used 0.007998s\n",
      "batch 2592, train_loss 219.120041,Time used 0.009002s\n",
      "batch 2593, train_loss 254.799377,Time used 0.008997s\n",
      "batch 2594, train_loss 177.060165,Time used 0.008001s\n",
      "batch 2595, train_loss 193.142990,Time used 0.007000s\n",
      "batch 2596, train_loss 242.266800,Time used 0.009003s\n",
      "batch 2597, train_loss 177.674103,Time used 0.010997s\n",
      "batch 2598, train_loss 196.132706,Time used 0.010003s\n",
      "batch 2599, train_loss 199.856918,Time used 0.011998s\n",
      "batch 2600, train_loss 180.871964,Time used 0.012000s\n",
      "***************************test_batch 2600, test_rmse_loss 16.346083,test_mae_loss 6.389131,test_mape_loss 72.471949,Time used 0.039001s\n",
      "batch 2601, train_loss 229.261215,Time used 0.008998s\n",
      "batch 2602, train_loss 206.277390,Time used 0.009001s\n",
      "batch 2603, train_loss 213.358795,Time used 0.010999s\n",
      "batch 2604, train_loss 223.665421,Time used 0.012000s\n",
      "batch 2605, train_loss 181.645447,Time used 0.012003s\n",
      "batch 2606, train_loss 198.595398,Time used 0.012000s\n",
      "batch 2607, train_loss 179.799316,Time used 0.010997s\n",
      "batch 2608, train_loss 191.247208,Time used 0.012000s\n",
      "batch 2609, train_loss 213.209198,Time used 0.011000s\n",
      "batch 2610, train_loss 219.376816,Time used 0.013002s\n",
      "batch 2611, train_loss 222.923874,Time used 0.011999s\n",
      "batch 2612, train_loss 189.698685,Time used 0.009001s\n",
      "batch 2613, train_loss 229.834763,Time used 0.009001s\n",
      "batch 2614, train_loss 233.088562,Time used 0.012998s\n",
      "batch 2615, train_loss 231.288666,Time used 0.006998s\n",
      "batch 2616, train_loss 216.422195,Time used 0.011000s\n",
      "batch 2617, train_loss 185.200836,Time used 0.010999s\n",
      "batch 2618, train_loss 202.985229,Time used 0.010001s\n",
      "batch 2619, train_loss 159.688232,Time used 0.007999s\n",
      "batch 2620, train_loss 178.533798,Time used 0.009000s\n",
      "batch 2621, train_loss 254.812515,Time used 0.008001s\n",
      "batch 2622, train_loss 193.495819,Time used 0.011000s\n",
      "batch 2623, train_loss 174.339447,Time used 0.008000s\n",
      "batch 2624, train_loss 175.532303,Time used 0.007000s\n",
      "batch 2625, train_loss 238.123489,Time used 0.008000s\n",
      "batch 2626, train_loss 232.579697,Time used 0.007000s\n",
      "batch 2627, train_loss 188.186493,Time used 0.008001s\n",
      "batch 2628, train_loss 188.375870,Time used 0.009999s\n",
      "batch 2629, train_loss 267.349792,Time used 0.010999s\n",
      "batch 2630, train_loss 193.300583,Time used 0.010001s\n",
      "batch 2631, train_loss 242.854950,Time used 0.014998s\n",
      "batch 2632, train_loss 179.004715,Time used 0.011001s\n",
      "batch 2633, train_loss 223.488739,Time used 0.010001s\n",
      "batch 2634, train_loss 205.794495,Time used 0.008000s\n",
      "batch 2635, train_loss 231.435928,Time used 0.007002s\n",
      "batch 2636, train_loss 203.943695,Time used 0.009000s\n",
      "batch 2637, train_loss 255.142227,Time used 0.010000s\n",
      "batch 2638, train_loss 191.379929,Time used 0.008001s\n",
      "batch 2639, train_loss 204.225067,Time used 0.011002s\n",
      "batch 2640, train_loss 206.634033,Time used 0.011001s\n",
      "batch 2641, train_loss 250.085129,Time used 0.009001s\n",
      "batch 2642, train_loss 170.319061,Time used 0.009996s\n",
      "batch 2643, train_loss 210.622528,Time used 0.011003s\n",
      "batch 2644, train_loss 211.442139,Time used 0.008999s\n",
      "batch 2645, train_loss 200.587601,Time used 0.011000s\n",
      "batch 2646, train_loss 195.368179,Time used 0.011999s\n",
      "batch 2647, train_loss 205.581085,Time used 0.010002s\n",
      "batch 2648, train_loss 203.800873,Time used 0.008000s\n",
      "batch 2649, train_loss 178.701126,Time used 0.008999s\n",
      "batch 2650, train_loss 188.107864,Time used 0.007000s\n",
      "batch 2651, train_loss 181.773315,Time used 0.011001s\n",
      "batch 2652, train_loss 217.318375,Time used 0.010000s\n",
      "batch 2653, train_loss 214.053177,Time used 0.010001s\n",
      "batch 2654, train_loss 228.899155,Time used 0.010000s\n",
      "batch 2655, train_loss 238.841309,Time used 0.009999s\n",
      "batch 2656, train_loss 175.530243,Time used 0.011000s\n",
      "batch 2657, train_loss 219.030960,Time used 0.011002s\n",
      "batch 2658, train_loss 180.262451,Time used 0.011002s\n",
      "batch 2659, train_loss 221.593048,Time used 0.011000s\n",
      "batch 2660, train_loss 185.756805,Time used 0.008000s\n",
      "batch 2661, train_loss 193.903824,Time used 0.012000s\n",
      "batch 2662, train_loss 236.374237,Time used 0.009002s\n",
      "batch 2663, train_loss 216.092712,Time used 0.008999s\n",
      "batch 2664, train_loss 228.633179,Time used 0.009001s\n",
      "batch 2665, train_loss 183.672653,Time used 0.013000s\n",
      "batch 2666, train_loss 204.402420,Time used 0.012007s\n",
      "batch 2667, train_loss 184.222031,Time used 0.006998s\n",
      "batch 2668, train_loss 155.083527,Time used 0.011002s\n",
      "batch 2669, train_loss 165.772324,Time used 0.012002s\n",
      "batch 2670, train_loss 221.871292,Time used 0.010996s\n",
      "batch 2671, train_loss 247.412369,Time used 0.011002s\n",
      "batch 2672, train_loss 226.810257,Time used 0.012000s\n",
      "batch 2673, train_loss 245.329208,Time used 0.011000s\n",
      "batch 2674, train_loss 150.450104,Time used 0.006999s\n",
      "batch 2675, train_loss 176.725937,Time used 0.008000s\n",
      "batch 2676, train_loss 216.960144,Time used 0.008001s\n",
      "batch 2677, train_loss 218.311615,Time used 0.009001s\n",
      "batch 2678, train_loss 157.084518,Time used 0.006999s\n",
      "batch 2679, train_loss 209.209595,Time used 0.009001s\n",
      "batch 2680, train_loss 184.937149,Time used 0.010001s\n",
      "batch 2681, train_loss 207.708145,Time used 0.009998s\n",
      "batch 2682, train_loss 220.069260,Time used 0.011000s\n",
      "batch 2683, train_loss 256.966125,Time used 0.010000s\n",
      "batch 2684, train_loss 227.719040,Time used 0.008998s\n",
      "batch 2685, train_loss 174.276321,Time used 0.011002s\n",
      "batch 2686, train_loss 257.382111,Time used 0.008003s\n",
      "batch 2687, train_loss 248.610489,Time used 0.007995s\n",
      "batch 2688, train_loss 185.565460,Time used 0.011003s\n",
      "batch 2689, train_loss 202.646194,Time used 0.009999s\n",
      "batch 2690, train_loss 180.863190,Time used 0.008000s\n",
      "batch 2691, train_loss 191.256149,Time used 0.011001s\n",
      "batch 2692, train_loss 179.993484,Time used 0.008003s\n",
      "batch 2693, train_loss 201.960480,Time used 0.011000s\n",
      "batch 2694, train_loss 186.642242,Time used 0.007998s\n",
      "batch 2695, train_loss 194.264053,Time used 0.011001s\n",
      "batch 2696, train_loss 229.016479,Time used 0.012002s\n",
      "batch 2697, train_loss 195.388962,Time used 0.009999s\n",
      "batch 2698, train_loss 174.483948,Time used 0.008999s\n",
      "batch 2699, train_loss 213.042557,Time used 0.010000s\n",
      "batch 2700, train_loss 230.681900,Time used 0.008003s\n",
      "***************************test_batch 2700, test_rmse_loss 16.190419,test_mae_loss 6.311118,test_mape_loss 72.142039,Time used 0.045997s\n",
      "batch 2701, train_loss 223.467926,Time used 0.011000s\n",
      "batch 2702, train_loss 212.062515,Time used 0.008000s\n",
      "batch 2703, train_loss 206.084473,Time used 0.008999s\n",
      "batch 2704, train_loss 194.543930,Time used 0.010001s\n",
      "batch 2705, train_loss 205.204788,Time used 0.009002s\n",
      "batch 2706, train_loss 214.060974,Time used 0.011001s\n",
      "batch 2707, train_loss 194.827362,Time used 0.010996s\n",
      "batch 2708, train_loss 202.400955,Time used 0.010000s\n",
      "batch 2709, train_loss 232.306564,Time used 0.011001s\n",
      "batch 2710, train_loss 195.019684,Time used 0.012000s\n",
      "batch 2711, train_loss 222.665161,Time used 0.011000s\n",
      "batch 2712, train_loss 220.946106,Time used 0.012001s\n",
      "batch 2713, train_loss 238.234039,Time used 0.010998s\n",
      "batch 2714, train_loss 212.445633,Time used 0.011004s\n",
      "batch 2715, train_loss 198.202820,Time used 0.009000s\n",
      "batch 2716, train_loss 237.964020,Time used 0.011999s\n",
      "batch 2717, train_loss 212.515732,Time used 0.011998s\n",
      "batch 2718, train_loss 178.760941,Time used 0.012002s\n",
      "batch 2719, train_loss 221.552322,Time used 0.012001s\n",
      "batch 2720, train_loss 204.680008,Time used 0.012001s\n",
      "batch 2721, train_loss 181.647003,Time used 0.010001s\n",
      "batch 2722, train_loss 163.858826,Time used 0.008999s\n",
      "batch 2723, train_loss 181.594193,Time used 0.008999s\n",
      "batch 2724, train_loss 173.364761,Time used 0.009001s\n",
      "batch 2725, train_loss 193.034958,Time used 0.009001s\n",
      "batch 2726, train_loss 203.426849,Time used 0.011999s\n",
      "batch 2727, train_loss 228.998291,Time used 0.012000s\n",
      "batch 2728, train_loss 213.118744,Time used 0.009999s\n",
      "batch 2729, train_loss 194.069016,Time used 0.008999s\n",
      "batch 2730, train_loss 204.791458,Time used 0.008001s\n",
      "batch 2731, train_loss 160.186737,Time used 0.011999s\n",
      "batch 2732, train_loss 195.060532,Time used 0.011003s\n",
      "batch 2733, train_loss 265.567505,Time used 0.010998s\n",
      "batch 2734, train_loss 186.727997,Time used 0.010999s\n",
      "batch 2735, train_loss 228.390076,Time used 0.012001s\n",
      "batch 2736, train_loss 200.734116,Time used 0.011998s\n",
      "batch 2737, train_loss 169.931351,Time used 0.010999s\n",
      "batch 2738, train_loss 203.063309,Time used 0.010000s\n",
      "batch 2739, train_loss 198.853317,Time used 0.007999s\n",
      "batch 2740, train_loss 212.687088,Time used 0.009001s\n",
      "batch 2741, train_loss 182.631165,Time used 0.011000s\n",
      "batch 2742, train_loss 225.404419,Time used 0.009000s\n",
      "batch 2743, train_loss 214.423996,Time used 0.009000s\n",
      "batch 2744, train_loss 223.872177,Time used 0.007000s\n",
      "batch 2745, train_loss 178.563873,Time used 0.011002s\n",
      "batch 2746, train_loss 199.794174,Time used 0.006999s\n",
      "batch 2747, train_loss 209.490189,Time used 0.009000s\n",
      "batch 2748, train_loss 189.139893,Time used 0.010000s\n",
      "batch 2749, train_loss 206.116425,Time used 0.006999s\n",
      "batch 2750, train_loss 240.221817,Time used 0.008001s\n",
      "batch 2751, train_loss 231.470062,Time used 0.010999s\n",
      "batch 2752, train_loss 205.542328,Time used 0.009000s\n",
      "batch 2753, train_loss 195.483856,Time used 0.006999s\n",
      "batch 2754, train_loss 215.713959,Time used 0.009002s\n",
      "batch 2755, train_loss 164.927811,Time used 0.007003s\n",
      "batch 2756, train_loss 194.520859,Time used 0.014997s\n",
      "batch 2757, train_loss 157.065567,Time used 0.013999s\n",
      "batch 2758, train_loss 208.374527,Time used 0.011000s\n",
      "batch 2759, train_loss 191.230026,Time used 0.010994s\n",
      "batch 2760, train_loss 238.022247,Time used 0.012999s\n",
      "batch 2761, train_loss 220.796265,Time used 0.011000s\n",
      "batch 2762, train_loss 197.784470,Time used 0.011001s\n",
      "batch 2763, train_loss 174.877258,Time used 0.011000s\n",
      "batch 2764, train_loss 202.393372,Time used 0.009000s\n",
      "batch 2765, train_loss 176.501465,Time used 0.012000s\n",
      "batch 2766, train_loss 259.662659,Time used 0.012000s\n",
      "batch 2767, train_loss 247.626816,Time used 0.012000s\n",
      "batch 2768, train_loss 186.240829,Time used 0.011999s\n",
      "batch 2769, train_loss 207.724304,Time used 0.012000s\n",
      "batch 2770, train_loss 189.208878,Time used 0.011002s\n",
      "batch 2771, train_loss 249.497833,Time used 0.010999s\n",
      "batch 2772, train_loss 232.629364,Time used 0.011002s\n",
      "batch 2773, train_loss 202.839386,Time used 0.009000s\n",
      "batch 2774, train_loss 166.308167,Time used 0.010999s\n",
      "batch 2775, train_loss 216.035904,Time used 0.011001s\n",
      "batch 2776, train_loss 139.081451,Time used 0.010999s\n",
      "batch 2777, train_loss 206.562500,Time used 0.012001s\n",
      "batch 2778, train_loss 162.717880,Time used 0.013001s\n",
      "batch 2779, train_loss 223.775589,Time used 0.011001s\n",
      "batch 2780, train_loss 205.283951,Time used 0.012999s\n",
      "batch 2781, train_loss 145.481018,Time used 0.013999s\n",
      "batch 2782, train_loss 204.698792,Time used 0.012000s\n",
      "batch 2783, train_loss 190.874176,Time used 0.018999s\n",
      "batch 2784, train_loss 223.695099,Time used 0.015003s\n",
      "batch 2785, train_loss 198.705643,Time used 0.012000s\n",
      "batch 2786, train_loss 182.099274,Time used 0.010000s\n",
      "batch 2787, train_loss 170.437668,Time used 0.012000s\n",
      "batch 2788, train_loss 204.502136,Time used 0.010999s\n",
      "batch 2789, train_loss 224.429520,Time used 0.011001s\n",
      "batch 2790, train_loss 203.814865,Time used 0.010002s\n",
      "batch 2791, train_loss 228.082977,Time used 0.012001s\n",
      "batch 2792, train_loss 218.661926,Time used 0.011997s\n",
      "batch 2793, train_loss 189.634918,Time used 0.012001s\n",
      "batch 2794, train_loss 199.656265,Time used 0.011003s\n",
      "batch 2795, train_loss 184.507141,Time used 0.009004s\n",
      "batch 2796, train_loss 211.792969,Time used 0.011000s\n",
      "batch 2797, train_loss 182.597015,Time used 0.014001s\n",
      "batch 2798, train_loss 210.916412,Time used 0.012002s\n",
      "batch 2799, train_loss 233.897690,Time used 0.011000s\n",
      "batch 2800, train_loss 207.643158,Time used 0.012001s\n",
      "***************************test_batch 2800, test_rmse_loss 16.036586,test_mae_loss 6.235610,test_mape_loss 71.840368,Time used 0.038999s\n",
      "batch 2801, train_loss 185.768982,Time used 0.012002s\n",
      "batch 2802, train_loss 188.352524,Time used 0.012999s\n",
      "batch 2803, train_loss 191.413330,Time used 0.011999s\n",
      "batch 2804, train_loss 179.442810,Time used 0.012000s\n",
      "batch 2805, train_loss 164.455017,Time used 0.011001s\n",
      "batch 2806, train_loss 232.231979,Time used 0.011999s\n",
      "batch 2807, train_loss 183.859085,Time used 0.009000s\n",
      "batch 2808, train_loss 232.149384,Time used 0.007000s\n",
      "batch 2809, train_loss 178.652161,Time used 0.006999s\n",
      "batch 2810, train_loss 213.532394,Time used 0.010003s\n",
      "batch 2811, train_loss 230.484192,Time used 0.006998s\n",
      "batch 2812, train_loss 249.198563,Time used 0.008000s\n",
      "batch 2813, train_loss 195.359756,Time used 0.008001s\n",
      "batch 2814, train_loss 270.327545,Time used 0.009000s\n",
      "batch 2815, train_loss 154.473358,Time used 0.009001s\n",
      "batch 2816, train_loss 207.736191,Time used 0.006999s\n",
      "batch 2817, train_loss 102.581703,Time used 0.007002s\n",
      "batch 2818, train_loss 155.238205,Time used 0.007998s\n",
      "batch 2819, train_loss 212.090332,Time used 0.007000s\n",
      "batch 2820, train_loss 203.781158,Time used 0.007000s\n",
      "batch 2821, train_loss 237.862152,Time used 0.008006s\n",
      "batch 2822, train_loss 199.415634,Time used 0.006995s\n",
      "batch 2823, train_loss 175.930725,Time used 0.007001s\n",
      "batch 2824, train_loss 181.478821,Time used 0.008000s\n",
      "batch 2825, train_loss 227.838654,Time used 0.006999s\n",
      "batch 2826, train_loss 195.457703,Time used 0.008000s\n",
      "batch 2827, train_loss 162.070877,Time used 0.007002s\n",
      "batch 2828, train_loss 194.704300,Time used 0.007999s\n",
      "batch 2829, train_loss 207.870361,Time used 0.007001s\n",
      "batch 2830, train_loss 251.230316,Time used 0.006998s\n",
      "batch 2831, train_loss 185.505646,Time used 0.010002s\n",
      "batch 2832, train_loss 191.298080,Time used 0.006999s\n",
      "batch 2833, train_loss 207.218536,Time used 0.009035s\n",
      "batch 2834, train_loss 195.472961,Time used 0.006964s\n",
      "batch 2835, train_loss 170.619904,Time used 0.008003s\n",
      "batch 2836, train_loss 162.798645,Time used 0.007035s\n",
      "batch 2837, train_loss 203.718445,Time used 0.006961s\n",
      "batch 2838, train_loss 191.955811,Time used 0.007036s\n",
      "batch 2839, train_loss 200.694092,Time used 0.006004s\n",
      "batch 2840, train_loss 240.617615,Time used 0.007961s\n",
      "batch 2841, train_loss 158.804306,Time used 0.008999s\n",
      "batch 2842, train_loss 179.218185,Time used 0.007000s\n",
      "batch 2843, train_loss 200.583817,Time used 0.007003s\n",
      "batch 2844, train_loss 189.087952,Time used 0.008997s\n",
      "batch 2845, train_loss 204.061707,Time used 0.007000s\n",
      "batch 2846, train_loss 231.072830,Time used 0.008002s\n",
      "batch 2847, train_loss 224.127640,Time used 0.009999s\n",
      "batch 2848, train_loss 214.005264,Time used 0.010000s\n",
      "batch 2849, train_loss 202.043167,Time used 0.007001s\n",
      "batch 2850, train_loss 218.896805,Time used 0.011001s\n",
      "batch 2851, train_loss 184.343185,Time used 0.011001s\n",
      "batch 2852, train_loss 200.533691,Time used 0.010000s\n",
      "batch 2853, train_loss 226.567230,Time used 0.010997s\n",
      "batch 2854, train_loss 185.342728,Time used 0.009003s\n",
      "batch 2855, train_loss 179.682785,Time used 0.008999s\n",
      "batch 2856, train_loss 189.450150,Time used 0.007000s\n",
      "batch 2857, train_loss 200.916702,Time used 0.008001s\n",
      "batch 2858, train_loss 258.260559,Time used 0.006998s\n",
      "batch 2859, train_loss 218.815231,Time used 0.007998s\n",
      "batch 2860, train_loss 169.341263,Time used 0.008002s\n",
      "batch 2861, train_loss 199.658279,Time used 0.007999s\n",
      "batch 2862, train_loss 194.841675,Time used 0.008001s\n",
      "batch 2863, train_loss 215.248474,Time used 0.008999s\n",
      "batch 2864, train_loss 227.095627,Time used 0.011001s\n",
      "batch 2865, train_loss 185.587402,Time used 0.009999s\n",
      "batch 2866, train_loss 172.180344,Time used 0.008002s\n",
      "batch 2867, train_loss 185.502808,Time used 0.007004s\n",
      "batch 2868, train_loss 170.818466,Time used 0.010000s\n",
      "batch 2869, train_loss 193.455673,Time used 0.009004s\n",
      "batch 2870, train_loss 185.260239,Time used 0.010999s\n",
      "batch 2871, train_loss 195.952011,Time used 0.009001s\n",
      "batch 2872, train_loss 200.387070,Time used 0.008000s\n",
      "batch 2873, train_loss 198.219437,Time used 0.011001s\n",
      "batch 2874, train_loss 223.167450,Time used 0.009999s\n",
      "batch 2875, train_loss 231.589188,Time used 0.010002s\n",
      "batch 2876, train_loss 191.616440,Time used 0.008999s\n",
      "batch 2877, train_loss 172.620438,Time used 0.007001s\n",
      "batch 2878, train_loss 163.741302,Time used 0.009998s\n",
      "batch 2879, train_loss 212.768036,Time used 0.009001s\n",
      "batch 2880, train_loss 170.214661,Time used 0.011000s\n",
      "batch 2881, train_loss 186.589661,Time used 0.011999s\n",
      "batch 2882, train_loss 200.877533,Time used 0.009999s\n",
      "batch 2883, train_loss 210.406799,Time used 0.008996s\n",
      "batch 2884, train_loss 243.263855,Time used 0.010000s\n",
      "batch 2885, train_loss 258.877533,Time used 0.011000s\n",
      "batch 2886, train_loss 202.872375,Time used 0.008000s\n",
      "batch 2887, train_loss 175.424561,Time used 0.012000s\n",
      "batch 2888, train_loss 168.310562,Time used 0.007000s\n",
      "batch 2889, train_loss 189.274338,Time used 0.007997s\n",
      "batch 2890, train_loss 177.427994,Time used 0.009001s\n",
      "batch 2891, train_loss 213.718567,Time used 0.009001s\n",
      "batch 2892, train_loss 157.862534,Time used 0.009997s\n",
      "batch 2893, train_loss 192.084412,Time used 0.008000s\n",
      "batch 2894, train_loss 179.641632,Time used 0.006999s\n",
      "batch 2895, train_loss 258.735931,Time used 0.007000s\n",
      "batch 2896, train_loss 174.838593,Time used 0.008003s\n",
      "batch 2897, train_loss 150.775620,Time used 0.010997s\n",
      "batch 2898, train_loss 240.059265,Time used 0.012002s\n",
      "batch 2899, train_loss 166.353638,Time used 0.007000s\n",
      "batch 2900, train_loss 169.762772,Time used 0.011003s\n",
      "***************************test_batch 2900, test_rmse_loss 15.887316,test_mae_loss 6.160169,test_mape_loss 71.141170,Time used 0.037997s\n",
      "batch 2901, train_loss 152.286255,Time used 0.010002s\n",
      "batch 2902, train_loss 242.495148,Time used 0.007997s\n",
      "batch 2903, train_loss 228.320175,Time used 0.013000s\n",
      "batch 2904, train_loss 174.227341,Time used 0.010000s\n",
      "batch 2905, train_loss 165.088593,Time used 0.013004s\n",
      "batch 2906, train_loss 177.415680,Time used 0.010996s\n",
      "batch 2907, train_loss 193.795975,Time used 0.009002s\n",
      "batch 2908, train_loss 179.358490,Time used 0.008000s\n",
      "batch 2909, train_loss 228.649704,Time used 0.011000s\n",
      "batch 2910, train_loss 206.066650,Time used 0.007000s\n",
      "batch 2911, train_loss 220.663300,Time used 0.007998s\n",
      "batch 2912, train_loss 208.825089,Time used 0.006999s\n",
      "batch 2913, train_loss 184.452927,Time used 0.010002s\n",
      "batch 2914, train_loss 191.511581,Time used 0.008999s\n",
      "batch 2915, train_loss 142.815964,Time used 0.007999s\n",
      "batch 2916, train_loss 182.971146,Time used 0.008000s\n",
      "batch 2917, train_loss 179.839340,Time used 0.010002s\n",
      "batch 2918, train_loss 221.513031,Time used 0.008998s\n",
      "batch 2919, train_loss 141.741043,Time used 0.009001s\n",
      "batch 2920, train_loss 202.770248,Time used 0.008999s\n",
      "batch 2921, train_loss 232.658752,Time used 0.010001s\n",
      "batch 2922, train_loss 237.566147,Time used 0.008998s\n",
      "batch 2923, train_loss 193.690170,Time used 0.010999s\n",
      "batch 2924, train_loss 199.953644,Time used 0.011001s\n",
      "batch 2925, train_loss 193.381699,Time used 0.012002s\n",
      "batch 2926, train_loss 200.277100,Time used 0.010999s\n",
      "batch 2927, train_loss 215.843185,Time used 0.007998s\n",
      "batch 2928, train_loss 191.600723,Time used 0.007001s\n",
      "batch 2929, train_loss 187.535370,Time used 0.007999s\n",
      "batch 2930, train_loss 192.481918,Time used 0.010997s\n",
      "batch 2931, train_loss 214.778305,Time used 0.009002s\n",
      "batch 2932, train_loss 187.649292,Time used 0.010999s\n",
      "batch 2933, train_loss 165.169586,Time used 0.011002s\n",
      "batch 2934, train_loss 129.887543,Time used 0.008998s\n",
      "batch 2935, train_loss 186.940277,Time used 0.009000s\n",
      "batch 2936, train_loss 209.144028,Time used 0.008001s\n",
      "batch 2937, train_loss 169.379684,Time used 0.008000s\n",
      "batch 2938, train_loss 149.567322,Time used 0.007001s\n",
      "batch 2939, train_loss 237.983246,Time used 0.008998s\n",
      "batch 2940, train_loss 192.252563,Time used 0.010003s\n",
      "batch 2941, train_loss 233.135056,Time used 0.010001s\n",
      "batch 2942, train_loss 227.825806,Time used 0.010000s\n",
      "batch 2943, train_loss 183.125412,Time used 0.007000s\n",
      "batch 2944, train_loss 171.647049,Time used 0.008002s\n",
      "batch 2945, train_loss 214.161789,Time used 0.009998s\n",
      "batch 2946, train_loss 234.992172,Time used 0.009000s\n",
      "batch 2947, train_loss 187.988861,Time used 0.008001s\n",
      "batch 2948, train_loss 195.347412,Time used 0.011002s\n",
      "batch 2949, train_loss 180.787781,Time used 0.011000s\n",
      "batch 2950, train_loss 229.094696,Time used 0.011000s\n",
      "batch 2951, train_loss 244.358749,Time used 0.012001s\n",
      "batch 2952, train_loss 142.859985,Time used 0.009999s\n",
      "batch 2953, train_loss 154.824036,Time used 0.011998s\n",
      "batch 2954, train_loss 161.262390,Time used 0.011000s\n",
      "batch 2955, train_loss 242.776367,Time used 0.010002s\n",
      "batch 2956, train_loss 167.256653,Time used 0.008999s\n",
      "batch 2957, train_loss 184.624802,Time used 0.009002s\n",
      "batch 2958, train_loss 195.163300,Time used 0.008000s\n",
      "batch 2959, train_loss 202.766693,Time used 0.010996s\n",
      "batch 2960, train_loss 192.926224,Time used 0.010003s\n",
      "batch 2961, train_loss 149.924225,Time used 0.008998s\n",
      "batch 2962, train_loss 186.240143,Time used 0.008999s\n",
      "batch 2963, train_loss 239.973358,Time used 0.008002s\n",
      "batch 2964, train_loss 210.802429,Time used 0.011003s\n",
      "batch 2965, train_loss 191.934525,Time used 0.010998s\n",
      "batch 2966, train_loss 184.018082,Time used 0.011999s\n",
      "batch 2967, train_loss 171.286545,Time used 0.011001s\n",
      "batch 2968, train_loss 232.189407,Time used 0.011000s\n",
      "batch 2969, train_loss 191.526840,Time used 0.009999s\n",
      "batch 2970, train_loss 217.834229,Time used 0.010999s\n",
      "batch 2971, train_loss 198.148636,Time used 0.011000s\n",
      "batch 2972, train_loss 216.260422,Time used 0.010000s\n",
      "batch 2973, train_loss 241.652512,Time used 0.007998s\n",
      "batch 2974, train_loss 173.019104,Time used 0.009000s\n",
      "batch 2975, train_loss 149.003799,Time used 0.011002s\n",
      "batch 2976, train_loss 192.289230,Time used 0.010998s\n",
      "batch 2977, train_loss 183.320389,Time used 0.010000s\n",
      "batch 2978, train_loss 179.797516,Time used 0.011000s\n",
      "batch 2979, train_loss 225.613861,Time used 0.011001s\n",
      "batch 2980, train_loss 149.130737,Time used 0.011001s\n",
      "batch 2981, train_loss 162.635895,Time used 0.008999s\n",
      "batch 2982, train_loss 201.543930,Time used 0.008999s\n",
      "batch 2983, train_loss 230.499680,Time used 0.007999s\n",
      "batch 2984, train_loss 182.037064,Time used 0.008000s\n",
      "batch 2985, train_loss 159.564560,Time used 0.010003s\n",
      "batch 2986, train_loss 248.343445,Time used 0.011001s\n",
      "batch 2987, train_loss 247.599243,Time used 0.010999s\n",
      "batch 2988, train_loss 212.149246,Time used 0.008000s\n",
      "batch 2989, train_loss 160.888397,Time used 0.007999s\n",
      "batch 2990, train_loss 203.052048,Time used 0.012001s\n",
      "batch 2991, train_loss 128.096664,Time used 0.007999s\n",
      "batch 2992, train_loss 175.192627,Time used 0.010002s\n",
      "batch 2993, train_loss 193.162567,Time used 0.009998s\n",
      "batch 2994, train_loss 224.774750,Time used 0.008998s\n",
      "batch 2995, train_loss 190.078674,Time used 0.008001s\n",
      "batch 2996, train_loss 189.116074,Time used 0.009002s\n",
      "batch 2997, train_loss 202.721802,Time used 0.007998s\n",
      "batch 2998, train_loss 192.410278,Time used 0.009002s\n",
      "batch 2999, train_loss 208.763977,Time used 0.009999s\n",
      "batch 3000, train_loss 174.380188,Time used 0.010999s\n",
      "***************************test_batch 3000, test_rmse_loss 15.739325,test_mae_loss 6.090798,test_mape_loss 71.065196,Time used 0.048999s\n",
      "batch 3001, train_loss 180.584503,Time used 0.012001s\n",
      "batch 3002, train_loss 169.097366,Time used 0.011998s\n",
      "batch 3003, train_loss 211.498306,Time used 0.008002s\n",
      "batch 3004, train_loss 190.703537,Time used 0.009000s\n",
      "batch 3005, train_loss 161.964554,Time used 0.011998s\n",
      "batch 3006, train_loss 203.231186,Time used 0.011001s\n",
      "batch 3007, train_loss 169.990906,Time used 0.008998s\n",
      "batch 3008, train_loss 179.920349,Time used 0.006999s\n",
      "batch 3009, train_loss 174.258240,Time used 0.008004s\n",
      "batch 3010, train_loss 191.162033,Time used 0.011997s\n",
      "batch 3011, train_loss 180.191788,Time used 0.009999s\n",
      "batch 3012, train_loss 169.208420,Time used 0.010000s\n",
      "batch 3013, train_loss 223.514282,Time used 0.010000s\n",
      "batch 3014, train_loss 192.254333,Time used 0.009000s\n",
      "batch 3015, train_loss 232.599747,Time used 0.008998s\n",
      "batch 3016, train_loss 163.482132,Time used 0.011001s\n",
      "batch 3017, train_loss 185.683838,Time used 0.012000s\n",
      "batch 3018, train_loss 222.567932,Time used 0.011996s\n",
      "batch 3019, train_loss 203.380081,Time used 0.012002s\n",
      "batch 3020, train_loss 231.099487,Time used 0.010999s\n",
      "batch 3021, train_loss 199.490906,Time used 0.013002s\n",
      "batch 3022, train_loss 198.432098,Time used 0.012000s\n",
      "batch 3023, train_loss 202.652710,Time used 0.009001s\n",
      "batch 3024, train_loss 165.428650,Time used 0.010998s\n",
      "batch 3025, train_loss 198.050430,Time used 0.010000s\n",
      "batch 3026, train_loss 198.674438,Time used 0.011002s\n",
      "batch 3027, train_loss 258.813477,Time used 0.008999s\n",
      "batch 3028, train_loss 207.906830,Time used 0.008001s\n",
      "batch 3029, train_loss 167.887207,Time used 0.010001s\n",
      "batch 3030, train_loss 147.704773,Time used 0.012001s\n",
      "batch 3031, train_loss 200.837006,Time used 0.011998s\n",
      "batch 3032, train_loss 155.883835,Time used 0.008000s\n",
      "batch 3033, train_loss 161.673828,Time used 0.010000s\n",
      "batch 3034, train_loss 164.240891,Time used 0.007001s\n",
      "batch 3035, train_loss 180.324051,Time used 0.008999s\n",
      "batch 3036, train_loss 185.142914,Time used 0.010001s\n",
      "batch 3037, train_loss 162.553467,Time used 0.007999s\n",
      "batch 3038, train_loss 152.726227,Time used 0.007002s\n",
      "batch 3039, train_loss 167.153030,Time used 0.011003s\n",
      "batch 3040, train_loss 269.215302,Time used 0.009999s\n",
      "batch 3041, train_loss 192.917755,Time used 0.010997s\n",
      "batch 3042, train_loss 180.775391,Time used 0.008998s\n",
      "batch 3043, train_loss 223.869431,Time used 0.010001s\n",
      "batch 3044, train_loss 240.823303,Time used 0.007001s\n",
      "batch 3045, train_loss 172.647568,Time used 0.009998s\n",
      "batch 3046, train_loss 160.335419,Time used 0.008000s\n",
      "batch 3047, train_loss 220.162354,Time used 0.008001s\n",
      "batch 3048, train_loss 212.135162,Time used 0.007005s\n",
      "batch 3049, train_loss 230.152985,Time used 0.009999s\n",
      "batch 3050, train_loss 183.421143,Time used 0.007998s\n",
      "batch 3051, train_loss 157.261658,Time used 0.010001s\n",
      "batch 3052, train_loss 181.999176,Time used 0.008003s\n",
      "batch 3053, train_loss 209.119476,Time used 0.006999s\n",
      "batch 3054, train_loss 178.936279,Time used 0.007000s\n",
      "batch 3055, train_loss 153.841736,Time used 0.008000s\n",
      "batch 3056, train_loss 205.527115,Time used 0.011000s\n",
      "batch 3057, train_loss 177.052338,Time used 0.007999s\n",
      "batch 3058, train_loss 178.019852,Time used 0.007001s\n",
      "batch 3059, train_loss 186.117081,Time used 0.008001s\n",
      "batch 3060, train_loss 147.562912,Time used 0.007000s\n",
      "batch 3061, train_loss 237.931000,Time used 0.006999s\n",
      "batch 3062, train_loss 151.223404,Time used 0.006998s\n",
      "batch 3063, train_loss 233.007812,Time used 0.009002s\n",
      "batch 3064, train_loss 168.598099,Time used 0.008000s\n",
      "batch 3065, train_loss 191.614853,Time used 0.007000s\n",
      "batch 3066, train_loss 228.202713,Time used 0.011005s\n",
      "batch 3067, train_loss 189.115952,Time used 0.008033s\n",
      "batch 3068, train_loss 163.513443,Time used 0.006000s\n",
      "batch 3069, train_loss 227.404709,Time used 0.007002s\n",
      "batch 3070, train_loss 206.223801,Time used 0.006998s\n",
      "batch 3071, train_loss 135.446793,Time used 0.005963s\n",
      "batch 3072, train_loss 240.591248,Time used 0.011003s\n",
      "batch 3073, train_loss 162.483002,Time used 0.006001s\n",
      "batch 3074, train_loss 212.952667,Time used 0.007967s\n",
      "batch 3075, train_loss 163.640259,Time used 0.009032s\n",
      "batch 3076, train_loss 190.585892,Time used 0.006969s\n",
      "batch 3077, train_loss 188.735184,Time used 0.006999s\n",
      "batch 3078, train_loss 137.852371,Time used 0.007001s\n",
      "batch 3079, train_loss 160.529175,Time used 0.006997s\n",
      "batch 3080, train_loss 202.677353,Time used 0.007998s\n",
      "batch 3081, train_loss 188.835220,Time used 0.008001s\n",
      "batch 3082, train_loss 248.545578,Time used 0.009000s\n",
      "batch 3083, train_loss 167.400253,Time used 0.008999s\n",
      "batch 3084, train_loss 152.164124,Time used 0.011001s\n",
      "batch 3085, train_loss 237.019943,Time used 0.006999s\n",
      "batch 3086, train_loss 195.264282,Time used 0.007000s\n",
      "batch 3087, train_loss 190.084290,Time used 0.008999s\n",
      "batch 3088, train_loss 235.065887,Time used 0.010001s\n",
      "batch 3089, train_loss 173.593857,Time used 0.011001s\n",
      "batch 3090, train_loss 146.920624,Time used 0.008000s\n",
      "batch 3091, train_loss 191.239746,Time used 0.010000s\n",
      "batch 3092, train_loss 187.351410,Time used 0.010999s\n",
      "batch 3093, train_loss 192.376312,Time used 0.007999s\n",
      "batch 3094, train_loss 174.074280,Time used 0.010004s\n",
      "batch 3095, train_loss 250.200623,Time used 0.011998s\n",
      "batch 3096, train_loss 188.601776,Time used 0.009999s\n",
      "batch 3097, train_loss 212.526611,Time used 0.008996s\n",
      "batch 3098, train_loss 241.059677,Time used 0.010002s\n",
      "batch 3099, train_loss 197.504715,Time used 0.011001s\n",
      "batch 3100, train_loss 165.511749,Time used 0.013000s\n",
      "***************************test_batch 3100, test_rmse_loss 15.594107,test_mae_loss 6.023009,test_mape_loss 70.865854,Time used 0.035002s\n",
      "batch 3101, train_loss 188.883636,Time used 0.009998s\n",
      "batch 3102, train_loss 125.708397,Time used 0.010000s\n",
      "batch 3103, train_loss 187.149750,Time used 0.011004s\n",
      "batch 3104, train_loss 161.196472,Time used 0.007999s\n",
      "batch 3105, train_loss 167.511124,Time used 0.008002s\n",
      "batch 3106, train_loss 167.755859,Time used 0.007999s\n",
      "batch 3107, train_loss 147.898285,Time used 0.008001s\n",
      "batch 3108, train_loss 238.527817,Time used 0.011002s\n",
      "batch 3109, train_loss 182.708878,Time used 0.008997s\n",
      "batch 3110, train_loss 175.686005,Time used 0.007001s\n",
      "batch 3111, train_loss 142.884949,Time used 0.007999s\n",
      "batch 3112, train_loss 181.984940,Time used 0.009000s\n",
      "batch 3113, train_loss 225.262192,Time used 0.011001s\n",
      "batch 3114, train_loss 181.927795,Time used 0.009001s\n",
      "batch 3115, train_loss 199.568954,Time used 0.006998s\n",
      "batch 3116, train_loss 209.491547,Time used 0.009003s\n",
      "batch 3117, train_loss 198.295822,Time used 0.009996s\n",
      "batch 3118, train_loss 246.235443,Time used 0.011003s\n",
      "batch 3119, train_loss 172.893921,Time used 0.009998s\n",
      "batch 3120, train_loss 199.087357,Time used 0.009001s\n",
      "batch 3121, train_loss 174.123367,Time used 0.006999s\n",
      "batch 3122, train_loss 145.521942,Time used 0.008001s\n",
      "batch 3123, train_loss 200.458115,Time used 0.008997s\n",
      "batch 3124, train_loss 245.577179,Time used 0.008001s\n",
      "batch 3125, train_loss 182.751205,Time used 0.006998s\n",
      "batch 3126, train_loss 234.732986,Time used 0.007002s\n",
      "batch 3127, train_loss 121.642570,Time used 0.008000s\n",
      "batch 3128, train_loss 171.614441,Time used 0.009001s\n",
      "batch 3129, train_loss 152.515152,Time used 0.009002s\n",
      "batch 3130, train_loss 140.744354,Time used 0.008001s\n",
      "batch 3131, train_loss 192.092560,Time used 0.008998s\n",
      "batch 3132, train_loss 207.299911,Time used 0.010998s\n",
      "batch 3133, train_loss 175.080124,Time used 0.011000s\n",
      "batch 3134, train_loss 176.339554,Time used 0.011002s\n",
      "batch 3135, train_loss 172.953842,Time used 0.007999s\n",
      "batch 3136, train_loss 176.805222,Time used 0.009002s\n",
      "batch 3137, train_loss 191.486481,Time used 0.006998s\n",
      "batch 3138, train_loss 229.675812,Time used 0.007001s\n",
      "batch 3139, train_loss 157.792892,Time used 0.007001s\n",
      "batch 3140, train_loss 244.822052,Time used 0.010998s\n",
      "batch 3141, train_loss 222.784775,Time used 0.009005s\n",
      "batch 3142, train_loss 197.298523,Time used 0.010997s\n",
      "batch 3143, train_loss 199.650604,Time used 0.010998s\n",
      "batch 3144, train_loss 181.638931,Time used 0.008003s\n",
      "batch 3145, train_loss 187.765793,Time used 0.009999s\n",
      "batch 3146, train_loss 199.859650,Time used 0.010995s\n",
      "batch 3147, train_loss 182.532516,Time used 0.006999s\n",
      "batch 3148, train_loss 188.475250,Time used 0.008003s\n",
      "batch 3149, train_loss 140.944458,Time used 0.010998s\n",
      "batch 3150, train_loss 167.192780,Time used 0.008001s\n",
      "batch 3151, train_loss 111.792587,Time used 0.008001s\n",
      "batch 3152, train_loss 234.198853,Time used 0.006999s\n",
      "batch 3153, train_loss 199.779236,Time used 0.008002s\n",
      "batch 3154, train_loss 160.787140,Time used 0.007997s\n",
      "batch 3155, train_loss 172.667313,Time used 0.007002s\n",
      "batch 3156, train_loss 160.543228,Time used 0.007997s\n",
      "batch 3157, train_loss 192.872665,Time used 0.008000s\n",
      "batch 3158, train_loss 197.732834,Time used 0.011003s\n",
      "batch 3159, train_loss 189.155151,Time used 0.011997s\n",
      "batch 3160, train_loss 204.214905,Time used 0.011004s\n",
      "batch 3161, train_loss 223.258575,Time used 0.009995s\n",
      "batch 3162, train_loss 177.368088,Time used 0.009005s\n",
      "batch 3163, train_loss 175.038879,Time used 0.008000s\n",
      "batch 3164, train_loss 247.737259,Time used 0.011997s\n",
      "batch 3165, train_loss 203.589005,Time used 0.011003s\n",
      "batch 3166, train_loss 174.924362,Time used 0.011998s\n",
      "batch 3167, train_loss 226.055771,Time used 0.009000s\n",
      "batch 3168, train_loss 154.713638,Time used 0.006998s\n",
      "batch 3169, train_loss 231.144577,Time used 0.008997s\n",
      "batch 3170, train_loss 166.909683,Time used 0.010001s\n",
      "batch 3171, train_loss 230.783554,Time used 0.009999s\n",
      "batch 3172, train_loss 202.639603,Time used 0.008000s\n",
      "batch 3173, train_loss 175.643784,Time used 0.009001s\n",
      "batch 3174, train_loss 189.391876,Time used 0.010000s\n",
      "batch 3175, train_loss 152.593124,Time used 0.010002s\n",
      "batch 3176, train_loss 128.871475,Time used 0.009999s\n",
      "batch 3177, train_loss 181.974686,Time used 0.011000s\n",
      "batch 3178, train_loss 168.528244,Time used 0.009998s\n",
      "batch 3179, train_loss 180.813629,Time used 0.010000s\n",
      "batch 3180, train_loss 178.516846,Time used 0.006998s\n",
      "batch 3181, train_loss 182.126709,Time used 0.007001s\n",
      "batch 3182, train_loss 224.111694,Time used 0.008999s\n",
      "batch 3183, train_loss 200.842606,Time used 0.010002s\n",
      "batch 3184, train_loss 188.991776,Time used 0.010999s\n",
      "batch 3185, train_loss 178.753708,Time used 0.007999s\n",
      "batch 3186, train_loss 167.529327,Time used 0.009001s\n",
      "batch 3187, train_loss 208.484375,Time used 0.011002s\n",
      "batch 3188, train_loss 197.951736,Time used 0.006998s\n",
      "batch 3189, train_loss 206.907379,Time used 0.007999s\n",
      "batch 3190, train_loss 98.815453,Time used 0.007001s\n",
      "batch 3191, train_loss 217.594223,Time used 0.010000s\n",
      "batch 3192, train_loss 194.054825,Time used 0.006999s\n",
      "batch 3193, train_loss 117.785141,Time used 0.011002s\n",
      "batch 3194, train_loss 188.182114,Time used 0.006998s\n",
      "batch 3195, train_loss 192.358963,Time used 0.008002s\n",
      "batch 3196, train_loss 169.235519,Time used 0.010998s\n",
      "batch 3197, train_loss 214.497635,Time used 0.011000s\n",
      "batch 3198, train_loss 177.806564,Time used 0.008000s\n",
      "batch 3199, train_loss 195.963638,Time used 0.007998s\n",
      "batch 3200, train_loss 208.971390,Time used 0.011002s\n",
      "***************************test_batch 3200, test_rmse_loss 15.450968,test_mae_loss 5.958783,test_mape_loss 70.918504,Time used 0.030999s\n",
      "batch 3201, train_loss 178.178528,Time used 0.007001s\n",
      "batch 3202, train_loss 184.688660,Time used 0.010000s\n",
      "batch 3203, train_loss 236.957275,Time used 0.010003s\n",
      "batch 3204, train_loss 188.035934,Time used 0.008997s\n",
      "batch 3205, train_loss 168.013489,Time used 0.011005s\n",
      "batch 3206, train_loss 175.600815,Time used 0.010996s\n",
      "batch 3207, train_loss 127.572151,Time used 0.007999s\n",
      "batch 3208, train_loss 212.470779,Time used 0.008002s\n",
      "batch 3209, train_loss 171.600266,Time used 0.008004s\n",
      "batch 3210, train_loss 247.274994,Time used 0.007000s\n",
      "batch 3211, train_loss 203.833817,Time used 0.007001s\n",
      "batch 3212, train_loss 160.561005,Time used 0.011001s\n",
      "batch 3213, train_loss 194.784149,Time used 0.012000s\n",
      "batch 3214, train_loss 174.972961,Time used 0.009000s\n",
      "batch 3215, train_loss 172.865112,Time used 0.009001s\n",
      "batch 3216, train_loss 169.896118,Time used 0.012001s\n",
      "batch 3217, train_loss 261.342804,Time used 0.010000s\n",
      "batch 3218, train_loss 196.907150,Time used 0.006999s\n",
      "batch 3219, train_loss 153.882645,Time used 0.009001s\n",
      "batch 3220, train_loss 181.198593,Time used 0.007000s\n",
      "batch 3221, train_loss 229.978455,Time used 0.007000s\n",
      "batch 3222, train_loss 187.500748,Time used 0.006999s\n",
      "batch 3223, train_loss 195.858185,Time used 0.008001s\n",
      "batch 3224, train_loss 186.115555,Time used 0.009000s\n",
      "batch 3225, train_loss 205.967697,Time used 0.009998s\n",
      "batch 3226, train_loss 154.538589,Time used 0.010002s\n",
      "batch 3227, train_loss 168.609268,Time used 0.010002s\n",
      "batch 3228, train_loss 195.461456,Time used 0.013999s\n",
      "batch 3229, train_loss 179.684052,Time used 0.009002s\n",
      "batch 3230, train_loss 191.534790,Time used 0.009999s\n",
      "batch 3231, train_loss 149.264160,Time used 0.010000s\n",
      "batch 3232, train_loss 221.772858,Time used 0.008000s\n",
      "batch 3233, train_loss 207.991699,Time used 0.010998s\n",
      "batch 3234, train_loss 163.482330,Time used 0.008999s\n",
      "batch 3235, train_loss 183.115677,Time used 0.006998s\n",
      "batch 3236, train_loss 134.733932,Time used 0.009001s\n",
      "batch 3237, train_loss 184.391846,Time used 0.007002s\n",
      "batch 3238, train_loss 176.639175,Time used 0.007999s\n",
      "batch 3239, train_loss 151.583572,Time used 0.010001s\n",
      "batch 3240, train_loss 149.302032,Time used 0.007001s\n",
      "batch 3241, train_loss 159.892715,Time used 0.011002s\n",
      "batch 3242, train_loss 203.390625,Time used 0.008998s\n",
      "batch 3243, train_loss 174.398071,Time used 0.012003s\n",
      "batch 3244, train_loss 221.651215,Time used 0.012000s\n",
      "batch 3245, train_loss 182.240479,Time used 0.010997s\n",
      "batch 3246, train_loss 170.485733,Time used 0.011000s\n",
      "batch 3247, train_loss 134.550980,Time used 0.011002s\n",
      "batch 3248, train_loss 156.129990,Time used 0.011001s\n",
      "batch 3249, train_loss 160.624756,Time used 0.009998s\n",
      "batch 3250, train_loss 160.590363,Time used 0.008001s\n",
      "batch 3251, train_loss 163.866776,Time used 0.010000s\n",
      "batch 3252, train_loss 175.159271,Time used 0.009002s\n",
      "batch 3253, train_loss 186.009521,Time used 0.006999s\n",
      "batch 3254, train_loss 269.331268,Time used 0.010998s\n",
      "batch 3255, train_loss 145.110703,Time used 0.011001s\n",
      "batch 3256, train_loss 199.434647,Time used 0.006999s\n",
      "batch 3257, train_loss 206.525467,Time used 0.006999s\n",
      "batch 3258, train_loss 201.491287,Time used 0.008000s\n",
      "batch 3259, train_loss 206.315857,Time used 0.009001s\n",
      "batch 3260, train_loss 138.460068,Time used 0.008999s\n",
      "batch 3261, train_loss 196.590393,Time used 0.007001s\n",
      "batch 3262, train_loss 202.026459,Time used 0.007998s\n",
      "batch 3263, train_loss 195.516266,Time used 0.007000s\n",
      "batch 3264, train_loss 181.562485,Time used 0.011003s\n",
      "batch 3265, train_loss 135.000671,Time used 0.010996s\n",
      "batch 3266, train_loss 139.071014,Time used 0.008000s\n",
      "batch 3267, train_loss 182.813934,Time used 0.007000s\n",
      "batch 3268, train_loss 197.716949,Time used 0.008004s\n",
      "batch 3269, train_loss 193.449463,Time used 0.010997s\n",
      "batch 3270, train_loss 216.994064,Time used 0.009003s\n",
      "batch 3271, train_loss 233.989838,Time used 0.009998s\n",
      "batch 3272, train_loss 177.720413,Time used 0.008002s\n",
      "batch 3273, train_loss 187.310791,Time used 0.010999s\n",
      "batch 3274, train_loss 159.517288,Time used 0.009000s\n",
      "batch 3275, train_loss 191.539078,Time used 0.010000s\n",
      "batch 3276, train_loss 186.153183,Time used 0.007998s\n",
      "batch 3277, train_loss 154.703506,Time used 0.008001s\n",
      "batch 3278, train_loss 199.598007,Time used 0.008000s\n",
      "batch 3279, train_loss 189.352295,Time used 0.007000s\n",
      "batch 3280, train_loss 177.268173,Time used 0.006999s\n",
      "batch 3281, train_loss 195.782928,Time used 0.007001s\n",
      "batch 3282, train_loss 187.692139,Time used 0.011003s\n",
      "batch 3283, train_loss 124.784615,Time used 0.010000s\n",
      "batch 3284, train_loss 225.838257,Time used 0.008995s\n",
      "batch 3285, train_loss 192.330566,Time used 0.008003s\n",
      "batch 3286, train_loss 212.031311,Time used 0.009998s\n",
      "batch 3287, train_loss 147.553513,Time used 0.009001s\n",
      "batch 3288, train_loss 162.292023,Time used 0.006995s\n",
      "batch 3289, train_loss 124.700180,Time used 0.006999s\n",
      "batch 3290, train_loss 168.971741,Time used 0.009998s\n",
      "batch 3291, train_loss 200.942993,Time used 0.010000s\n",
      "batch 3292, train_loss 176.213806,Time used 0.007000s\n",
      "batch 3293, train_loss 176.191864,Time used 0.008001s\n",
      "batch 3294, train_loss 205.688553,Time used 0.010997s\n",
      "batch 3295, train_loss 136.859329,Time used 0.009002s\n",
      "batch 3296, train_loss 177.428696,Time used 0.007002s\n",
      "batch 3297, train_loss 203.741898,Time used 0.011998s\n",
      "batch 3298, train_loss 201.066757,Time used 0.009002s\n",
      "batch 3299, train_loss 177.211975,Time used 0.008996s\n",
      "batch 3300, train_loss 160.791962,Time used 0.011003s\n",
      "***************************test_batch 3300, test_rmse_loss 15.310863,test_mae_loss 5.895243,test_mape_loss 70.753093,Time used 0.043998s\n",
      "batch 3301, train_loss 229.075027,Time used 0.007998s\n",
      "batch 3302, train_loss 226.097275,Time used 0.007004s\n",
      "batch 3303, train_loss 170.089218,Time used 0.006997s\n",
      "batch 3304, train_loss 234.419525,Time used 0.016002s\n",
      "batch 3305, train_loss 144.455048,Time used 0.009000s\n",
      "batch 3306, train_loss 186.540787,Time used 0.012000s\n",
      "batch 3307, train_loss 173.486526,Time used 0.011000s\n",
      "batch 3308, train_loss 158.508163,Time used 0.007999s\n",
      "batch 3309, train_loss 164.675552,Time used 0.008000s\n",
      "batch 3310, train_loss 228.133408,Time used 0.007999s\n",
      "batch 3311, train_loss 186.424454,Time used 0.008002s\n",
      "batch 3312, train_loss 137.593536,Time used 0.009000s\n",
      "batch 3313, train_loss 233.627090,Time used 0.008999s\n",
      "batch 3314, train_loss 204.647125,Time used 0.009000s\n",
      "batch 3315, train_loss 183.705200,Time used 0.010000s\n",
      "batch 3316, train_loss 203.816483,Time used 0.011000s\n",
      "batch 3317, train_loss 157.780640,Time used 0.007001s\n",
      "batch 3318, train_loss 181.725006,Time used 0.010999s\n",
      "batch 3319, train_loss 197.718430,Time used 0.009999s\n",
      "batch 3320, train_loss 178.010086,Time used 0.009000s\n",
      "batch 3321, train_loss 170.712112,Time used 0.009002s\n",
      "batch 3322, train_loss 190.272446,Time used 0.010006s\n",
      "batch 3323, train_loss 160.401581,Time used 0.010999s\n",
      "batch 3324, train_loss 175.182404,Time used 0.008999s\n",
      "batch 3325, train_loss 171.958374,Time used 0.011003s\n",
      "batch 3326, train_loss 178.328766,Time used 0.009997s\n",
      "batch 3327, train_loss 205.463699,Time used 0.008997s\n",
      "batch 3328, train_loss 197.332291,Time used 0.007000s\n",
      "batch 3329, train_loss 158.984909,Time used 0.006999s\n",
      "batch 3330, train_loss 155.623474,Time used 0.007001s\n",
      "batch 3331, train_loss 173.785599,Time used 0.008005s\n",
      "batch 3332, train_loss 152.752411,Time used 0.008996s\n",
      "batch 3333, train_loss 183.469666,Time used 0.007999s\n",
      "batch 3334, train_loss 162.700790,Time used 0.007001s\n",
      "batch 3335, train_loss 174.251480,Time used 0.009000s\n",
      "batch 3336, train_loss 178.672760,Time used 0.007037s\n",
      "batch 3337, train_loss 186.237122,Time used 0.006999s\n",
      "batch 3338, train_loss 150.133713,Time used 0.009001s\n",
      "batch 3339, train_loss 180.903656,Time used 0.008040s\n",
      "batch 3340, train_loss 241.770859,Time used 0.006958s\n",
      "batch 3341, train_loss 204.014008,Time used 0.010000s\n",
      "batch 3342, train_loss 156.855820,Time used 0.007039s\n",
      "batch 3343, train_loss 170.978882,Time used 0.006999s\n",
      "batch 3344, train_loss 166.053696,Time used 0.007965s\n",
      "batch 3345, train_loss 221.714294,Time used 0.010998s\n",
      "batch 3346, train_loss 128.813919,Time used 0.011999s\n",
      "batch 3347, train_loss 195.685303,Time used 0.009005s\n",
      "batch 3348, train_loss 192.506622,Time used 0.009996s\n",
      "batch 3349, train_loss 160.273819,Time used 0.012002s\n",
      "batch 3350, train_loss 183.783813,Time used 0.010000s\n",
      "batch 3351, train_loss 139.570526,Time used 0.008000s\n",
      "batch 3352, train_loss 175.329422,Time used 0.009003s\n",
      "batch 3353, train_loss 205.940689,Time used 0.010998s\n",
      "batch 3354, train_loss 182.122742,Time used 0.007999s\n",
      "batch 3355, train_loss 221.116562,Time used 0.008000s\n",
      "batch 3356, train_loss 154.004166,Time used 0.008000s\n",
      "batch 3357, train_loss 195.646713,Time used 0.009999s\n",
      "batch 3358, train_loss 183.521500,Time used 0.010998s\n",
      "batch 3359, train_loss 134.646820,Time used 0.008000s\n",
      "batch 3360, train_loss 179.352798,Time used 0.009001s\n",
      "batch 3361, train_loss 162.735947,Time used 0.010001s\n",
      "batch 3362, train_loss 198.806992,Time used 0.010999s\n",
      "batch 3363, train_loss 182.962646,Time used 0.009000s\n",
      "batch 3364, train_loss 154.613708,Time used 0.009001s\n",
      "batch 3365, train_loss 185.641556,Time used 0.010000s\n",
      "batch 3366, train_loss 162.459991,Time used 0.010003s\n",
      "batch 3367, train_loss 175.829987,Time used 0.010999s\n",
      "batch 3368, train_loss 158.668945,Time used 0.010000s\n",
      "batch 3369, train_loss 200.669250,Time used 0.010999s\n",
      "batch 3370, train_loss 146.329773,Time used 0.011000s\n",
      "batch 3371, train_loss 197.588531,Time used 0.011002s\n",
      "batch 3372, train_loss 219.496033,Time used 0.007995s\n",
      "batch 3373, train_loss 154.402710,Time used 0.009003s\n",
      "batch 3374, train_loss 187.857422,Time used 0.007997s\n",
      "batch 3375, train_loss 207.280914,Time used 0.010001s\n",
      "batch 3376, train_loss 189.881561,Time used 0.012001s\n",
      "batch 3377, train_loss 196.537796,Time used 0.010999s\n",
      "batch 3378, train_loss 121.232391,Time used 0.010001s\n",
      "batch 3379, train_loss 221.809799,Time used 0.008999s\n",
      "batch 3380, train_loss 216.934128,Time used 0.011001s\n",
      "batch 3381, train_loss 159.051697,Time used 0.011997s\n",
      "batch 3382, train_loss 165.469681,Time used 0.009001s\n",
      "batch 3383, train_loss 181.076324,Time used 0.011000s\n",
      "batch 3384, train_loss 142.475571,Time used 0.008000s\n",
      "batch 3385, train_loss 167.500580,Time used 0.008001s\n",
      "batch 3386, train_loss 200.031219,Time used 0.011000s\n",
      "batch 3387, train_loss 173.167572,Time used 0.009998s\n",
      "batch 3388, train_loss 130.434433,Time used 0.009002s\n",
      "batch 3389, train_loss 189.882401,Time used 0.011001s\n",
      "batch 3390, train_loss 159.475723,Time used 0.011998s\n",
      "batch 3391, train_loss 182.311432,Time used 0.009997s\n",
      "batch 3392, train_loss 142.732361,Time used 0.011003s\n",
      "batch 3393, train_loss 174.447235,Time used 0.011000s\n",
      "batch 3394, train_loss 151.432999,Time used 0.011001s\n",
      "batch 3395, train_loss 197.499588,Time used 0.010998s\n",
      "batch 3396, train_loss 219.466843,Time used 0.016000s\n",
      "batch 3397, train_loss 144.244461,Time used 0.009003s\n",
      "batch 3398, train_loss 169.478516,Time used 0.008996s\n",
      "batch 3399, train_loss 178.363846,Time used 0.012001s\n",
      "batch 3400, train_loss 183.775116,Time used 0.011004s\n",
      "***************************test_batch 3400, test_rmse_loss 15.174625,test_mae_loss 5.830983,test_mape_loss 70.195227,Time used 0.030996s\n",
      "batch 3401, train_loss 202.198685,Time used 0.010000s\n",
      "batch 3402, train_loss 200.014984,Time used 0.009003s\n",
      "batch 3403, train_loss 157.011887,Time used 0.009000s\n",
      "batch 3404, train_loss 178.045822,Time used 0.009999s\n",
      "batch 3405, train_loss 154.345459,Time used 0.011007s\n",
      "batch 3406, train_loss 237.538177,Time used 0.010992s\n",
      "batch 3407, train_loss 163.759933,Time used 0.010001s\n",
      "batch 3408, train_loss 215.815781,Time used 0.007000s\n",
      "batch 3409, train_loss 158.563873,Time used 0.010001s\n",
      "batch 3410, train_loss 156.941315,Time used 0.008002s\n",
      "batch 3411, train_loss 199.139755,Time used 0.010000s\n",
      "batch 3412, train_loss 186.106323,Time used 0.007998s\n",
      "batch 3413, train_loss 221.319275,Time used 0.008000s\n",
      "batch 3414, train_loss 147.769867,Time used 0.008001s\n",
      "batch 3415, train_loss 187.395172,Time used 0.007002s\n",
      "batch 3416, train_loss 186.776245,Time used 0.008998s\n",
      "batch 3417, train_loss 154.619415,Time used 0.009002s\n",
      "batch 3418, train_loss 178.986893,Time used 0.009997s\n",
      "batch 3419, train_loss 144.406677,Time used 0.009999s\n",
      "batch 3420, train_loss 196.206741,Time used 0.010002s\n",
      "batch 3421, train_loss 161.192688,Time used 0.009001s\n",
      "batch 3422, train_loss 159.553253,Time used 0.008000s\n",
      "batch 3423, train_loss 160.405289,Time used 0.007000s\n",
      "batch 3424, train_loss 206.458023,Time used 0.007999s\n",
      "batch 3425, train_loss 195.997406,Time used 0.008000s\n",
      "batch 3426, train_loss 189.560013,Time used 0.010999s\n",
      "batch 3427, train_loss 164.643326,Time used 0.010000s\n",
      "batch 3428, train_loss 173.189575,Time used 0.006998s\n",
      "batch 3429, train_loss 153.752960,Time used 0.008002s\n",
      "batch 3430, train_loss 185.290329,Time used 0.006999s\n",
      "batch 3431, train_loss 200.340225,Time used 0.008999s\n",
      "batch 3432, train_loss 183.782471,Time used 0.006999s\n",
      "batch 3433, train_loss 127.641930,Time used 0.007002s\n",
      "batch 3434, train_loss 210.768127,Time used 0.007999s\n",
      "batch 3435, train_loss 167.002274,Time used 0.006998s\n",
      "batch 3436, train_loss 151.836548,Time used 0.007004s\n",
      "batch 3437, train_loss 184.808594,Time used 0.007997s\n",
      "batch 3438, train_loss 219.232071,Time used 0.007000s\n",
      "batch 3439, train_loss 203.972321,Time used 0.010002s\n",
      "batch 3440, train_loss 190.837112,Time used 0.010000s\n",
      "batch 3441, train_loss 119.136261,Time used 0.012000s\n",
      "batch 3442, train_loss 157.589386,Time used 0.012000s\n",
      "batch 3443, train_loss 151.462051,Time used 0.009001s\n",
      "batch 3444, train_loss 175.794113,Time used 0.011001s\n",
      "batch 3445, train_loss 178.746689,Time used 0.011995s\n",
      "batch 3446, train_loss 153.913773,Time used 0.009002s\n",
      "batch 3447, train_loss 163.134659,Time used 0.007002s\n",
      "batch 3448, train_loss 189.918335,Time used 0.006999s\n",
      "batch 3449, train_loss 144.261063,Time used 0.007000s\n",
      "batch 3450, train_loss 205.843674,Time used 0.007003s\n",
      "batch 3451, train_loss 174.252838,Time used 0.007002s\n",
      "batch 3452, train_loss 150.894196,Time used 0.007995s\n",
      "batch 3453, train_loss 215.363251,Time used 0.007004s\n",
      "batch 3454, train_loss 178.313309,Time used 0.009996s\n",
      "batch 3455, train_loss 198.034698,Time used 0.009036s\n",
      "batch 3456, train_loss 221.722229,Time used 0.008964s\n",
      "batch 3457, train_loss 187.408325,Time used 0.010998s\n",
      "batch 3458, train_loss 186.744705,Time used 0.008007s\n",
      "batch 3459, train_loss 201.047165,Time used 0.006997s\n",
      "batch 3460, train_loss 154.891144,Time used 0.007998s\n",
      "batch 3461, train_loss 185.426376,Time used 0.008000s\n",
      "batch 3462, train_loss 185.846619,Time used 0.008000s\n",
      "batch 3463, train_loss 178.458008,Time used 0.007999s\n",
      "batch 3464, train_loss 187.359024,Time used 0.009000s\n",
      "batch 3465, train_loss 183.617569,Time used 0.007000s\n",
      "batch 3466, train_loss 138.022858,Time used 0.009999s\n",
      "batch 3467, train_loss 154.144196,Time used 0.010001s\n",
      "batch 3468, train_loss 163.404053,Time used 0.011000s\n",
      "batch 3469, train_loss 141.366562,Time used 0.009002s\n",
      "batch 3470, train_loss 191.254517,Time used 0.007999s\n",
      "batch 3471, train_loss 146.173798,Time used 0.008002s\n",
      "batch 3472, train_loss 185.398010,Time used 0.010999s\n",
      "batch 3473, train_loss 203.582092,Time used 0.007998s\n",
      "batch 3474, train_loss 216.372437,Time used 0.007000s\n",
      "batch 3475, train_loss 149.849747,Time used 0.009001s\n",
      "batch 3476, train_loss 171.495911,Time used 0.011001s\n",
      "batch 3477, train_loss 175.268478,Time used 0.010999s\n",
      "batch 3478, train_loss 150.567307,Time used 0.008003s\n",
      "batch 3479, train_loss 208.191666,Time used 0.006997s\n",
      "batch 3480, train_loss 167.353119,Time used 0.010002s\n",
      "batch 3481, train_loss 142.305634,Time used 0.009000s\n",
      "batch 3482, train_loss 180.967468,Time used 0.008001s\n",
      "batch 3483, train_loss 178.568054,Time used 0.009000s\n",
      "batch 3484, train_loss 160.984940,Time used 0.006999s\n",
      "batch 3485, train_loss 141.169571,Time used 0.008000s\n",
      "batch 3486, train_loss 167.009613,Time used 0.007996s\n",
      "batch 3487, train_loss 198.798019,Time used 0.007002s\n",
      "batch 3488, train_loss 227.885147,Time used 0.006998s\n",
      "batch 3489, train_loss 191.415451,Time used 0.009001s\n",
      "batch 3490, train_loss 196.426239,Time used 0.007000s\n",
      "batch 3491, train_loss 166.405014,Time used 0.007000s\n",
      "batch 3492, train_loss 199.038528,Time used 0.007001s\n",
      "batch 3493, train_loss 149.256561,Time used 0.006999s\n",
      "batch 3494, train_loss 181.159119,Time used 0.009999s\n",
      "batch 3495, train_loss 147.979187,Time used 0.007002s\n",
      "batch 3496, train_loss 174.297913,Time used 0.006999s\n",
      "batch 3497, train_loss 164.185822,Time used 0.010001s\n",
      "batch 3498, train_loss 170.011780,Time used 0.007003s\n",
      "batch 3499, train_loss 184.989899,Time used 0.007966s\n",
      "batch 3500, train_loss 183.957870,Time used 0.010999s\n",
      "***************************test_batch 3500, test_rmse_loss 15.038968,test_mae_loss 5.771392,test_mape_loss 70.072436,Time used 0.043036s\n",
      "batch 3501, train_loss 155.526459,Time used 0.009964s\n",
      "batch 3502, train_loss 183.362961,Time used 0.009035s\n",
      "batch 3503, train_loss 175.198959,Time used 0.008965s\n",
      "batch 3504, train_loss 173.431900,Time used 0.010037s\n",
      "batch 3505, train_loss 151.258545,Time used 0.011034s\n",
      "batch 3506, train_loss 122.904144,Time used 0.006999s\n",
      "batch 3507, train_loss 159.270905,Time used 0.007968s\n",
      "batch 3508, train_loss 206.722946,Time used 0.008000s\n",
      "batch 3509, train_loss 119.445656,Time used 0.009003s\n",
      "batch 3510, train_loss 149.166870,Time used 0.008997s\n",
      "batch 3511, train_loss 150.085709,Time used 0.007035s\n",
      "batch 3512, train_loss 154.276657,Time used 0.011002s\n",
      "batch 3513, train_loss 224.258621,Time used 0.012036s\n",
      "batch 3514, train_loss 172.345612,Time used 0.010965s\n",
      "batch 3515, train_loss 186.643951,Time used 0.008039s\n",
      "batch 3516, train_loss 161.837234,Time used 0.008960s\n",
      "batch 3517, train_loss 213.197388,Time used 0.009965s\n",
      "batch 3518, train_loss 140.768250,Time used 0.009001s\n",
      "batch 3519, train_loss 170.218613,Time used 0.010999s\n",
      "batch 3520, train_loss 214.133682,Time used 0.008000s\n",
      "batch 3521, train_loss 207.159821,Time used 0.006999s\n",
      "batch 3522, train_loss 158.483307,Time used 0.007000s\n",
      "batch 3523, train_loss 218.686691,Time used 0.011000s\n",
      "batch 3524, train_loss 148.333344,Time used 0.008002s\n",
      "batch 3525, train_loss 190.282791,Time used 0.011000s\n",
      "batch 3526, train_loss 196.098724,Time used 0.012000s\n",
      "batch 3527, train_loss 180.714523,Time used 0.009998s\n",
      "batch 3528, train_loss 179.430420,Time used 0.010999s\n",
      "batch 3529, train_loss 189.971863,Time used 0.010004s\n",
      "batch 3530, train_loss 167.195007,Time used 0.010997s\n",
      "batch 3531, train_loss 172.672852,Time used 0.008000s\n",
      "batch 3532, train_loss 228.029922,Time used 0.007001s\n",
      "batch 3533, train_loss 166.373413,Time used 0.006999s\n",
      "batch 3534, train_loss 161.193542,Time used 0.009000s\n",
      "batch 3535, train_loss 133.524368,Time used 0.007001s\n",
      "batch 3536, train_loss 145.687927,Time used 0.007999s\n",
      "batch 3537, train_loss 200.059113,Time used 0.007000s\n",
      "batch 3538, train_loss 207.144409,Time used 0.006999s\n",
      "batch 3539, train_loss 166.889923,Time used 0.008004s\n",
      "batch 3540, train_loss 190.982941,Time used 0.006998s\n",
      "batch 3541, train_loss 125.185211,Time used 0.008000s\n",
      "batch 3542, train_loss 191.439697,Time used 0.007000s\n",
      "batch 3543, train_loss 188.111893,Time used 0.006999s\n",
      "batch 3544, train_loss 155.703568,Time used 0.008001s\n",
      "batch 3545, train_loss 148.658981,Time used 0.006999s\n",
      "batch 3546, train_loss 201.319656,Time used 0.008002s\n",
      "batch 3547, train_loss 190.689560,Time used 0.007001s\n",
      "batch 3548, train_loss 171.168488,Time used 0.007002s\n",
      "batch 3549, train_loss 153.910889,Time used 0.007998s\n",
      "batch 3550, train_loss 155.604584,Time used 0.009000s\n",
      "batch 3551, train_loss 192.243454,Time used 0.008001s\n",
      "batch 3552, train_loss 152.163177,Time used 0.010996s\n",
      "batch 3553, train_loss 186.861511,Time used 0.009998s\n",
      "batch 3554, train_loss 155.347839,Time used 0.007002s\n",
      "batch 3555, train_loss 200.722382,Time used 0.007006s\n",
      "batch 3556, train_loss 177.447098,Time used 0.007992s\n",
      "batch 3557, train_loss 163.938293,Time used 0.007001s\n",
      "batch 3558, train_loss 201.823288,Time used 0.007000s\n",
      "batch 3559, train_loss 137.882050,Time used 0.007000s\n",
      "batch 3560, train_loss 168.158310,Time used 0.008002s\n",
      "batch 3561, train_loss 150.075577,Time used 0.006999s\n",
      "batch 3562, train_loss 187.062271,Time used 0.006999s\n",
      "batch 3563, train_loss 160.753143,Time used 0.007000s\n",
      "batch 3564, train_loss 177.794861,Time used 0.008001s\n",
      "batch 3565, train_loss 197.117645,Time used 0.007999s\n",
      "batch 3566, train_loss 186.782928,Time used 0.007002s\n",
      "batch 3567, train_loss 159.885391,Time used 0.010997s\n",
      "batch 3568, train_loss 152.183563,Time used 0.010003s\n",
      "batch 3569, train_loss 185.874557,Time used 0.009000s\n",
      "batch 3570, train_loss 154.717041,Time used 0.010000s\n",
      "batch 3571, train_loss 203.935684,Time used 0.009001s\n",
      "batch 3572, train_loss 190.826828,Time used 0.008000s\n",
      "batch 3573, train_loss 170.726776,Time used 0.008000s\n",
      "batch 3574, train_loss 132.166626,Time used 0.007999s\n",
      "batch 3575, train_loss 172.574371,Time used 0.009001s\n",
      "batch 3576, train_loss 163.002182,Time used 0.010998s\n",
      "batch 3577, train_loss 196.296021,Time used 0.007995s\n",
      "batch 3578, train_loss 173.446259,Time used 0.011003s\n",
      "batch 3579, train_loss 135.294922,Time used 0.010999s\n",
      "batch 3580, train_loss 156.734497,Time used 0.011002s\n",
      "batch 3581, train_loss 176.972076,Time used 0.010999s\n",
      "batch 3582, train_loss 205.932098,Time used 0.011999s\n",
      "batch 3583, train_loss 157.323929,Time used 0.008000s\n",
      "batch 3584, train_loss 130.361801,Time used 0.011001s\n",
      "batch 3585, train_loss 173.088730,Time used 0.007998s\n",
      "batch 3586, train_loss 159.936600,Time used 0.007002s\n",
      "batch 3587, train_loss 179.094482,Time used 0.011002s\n",
      "batch 3588, train_loss 163.694397,Time used 0.010000s\n",
      "batch 3589, train_loss 150.002350,Time used 0.007000s\n",
      "batch 3590, train_loss 207.854767,Time used 0.010002s\n",
      "batch 3591, train_loss 205.670212,Time used 0.009999s\n",
      "batch 3592, train_loss 178.981003,Time used 0.010998s\n",
      "batch 3593, train_loss 198.371292,Time used 0.008001s\n",
      "batch 3594, train_loss 132.935333,Time used 0.007000s\n",
      "batch 3595, train_loss 119.083572,Time used 0.006000s\n",
      "batch 3596, train_loss 172.103363,Time used 0.007000s\n",
      "batch 3597, train_loss 193.698151,Time used 0.007001s\n",
      "batch 3598, train_loss 152.524780,Time used 0.007999s\n",
      "batch 3599, train_loss 192.852966,Time used 0.006000s\n",
      "batch 3600, train_loss 208.592712,Time used 0.007000s\n",
      "***************************test_batch 3600, test_rmse_loss 14.906930,test_mae_loss 5.712423,test_mape_loss 69.713517,Time used 0.035001s\n",
      "batch 3601, train_loss 136.369537,Time used 0.018001s\n",
      "batch 3602, train_loss 180.220932,Time used 0.007004s\n",
      "batch 3603, train_loss 190.283051,Time used 0.007999s\n",
      "batch 3604, train_loss 157.620392,Time used 0.009998s\n",
      "batch 3605, train_loss 171.751999,Time used 0.008999s\n",
      "batch 3606, train_loss 176.667786,Time used 0.008002s\n",
      "batch 3607, train_loss 199.089203,Time used 0.007000s\n",
      "batch 3608, train_loss 161.560806,Time used 0.007999s\n",
      "batch 3609, train_loss 133.192657,Time used 0.011000s\n",
      "batch 3610, train_loss 146.777298,Time used 0.009001s\n",
      "batch 3611, train_loss 158.599213,Time used 0.006999s\n",
      "batch 3612, train_loss 174.163879,Time used 0.007004s\n",
      "batch 3613, train_loss 160.254395,Time used 0.007996s\n",
      "batch 3614, train_loss 157.190643,Time used 0.008001s\n",
      "batch 3615, train_loss 189.068604,Time used 0.008003s\n",
      "batch 3616, train_loss 194.258362,Time used 0.007996s\n",
      "batch 3617, train_loss 240.236099,Time used 0.007999s\n",
      "batch 3618, train_loss 177.023361,Time used 0.007002s\n",
      "batch 3619, train_loss 169.303741,Time used 0.006999s\n",
      "batch 3620, train_loss 177.563431,Time used 0.008002s\n",
      "batch 3621, train_loss 180.281525,Time used 0.011997s\n",
      "batch 3622, train_loss 152.048447,Time used 0.007002s\n",
      "batch 3623, train_loss 134.844971,Time used 0.008001s\n",
      "batch 3624, train_loss 183.148697,Time used 0.009998s\n",
      "batch 3625, train_loss 193.515961,Time used 0.007995s\n",
      "batch 3626, train_loss 165.124588,Time used 0.007001s\n",
      "batch 3627, train_loss 176.254501,Time used 0.006999s\n",
      "batch 3628, train_loss 160.455750,Time used 0.008004s\n",
      "batch 3629, train_loss 209.442734,Time used 0.007996s\n",
      "batch 3630, train_loss 165.706787,Time used 0.008001s\n",
      "batch 3631, train_loss 163.948227,Time used 0.007001s\n",
      "batch 3632, train_loss 139.912125,Time used 0.008001s\n",
      "batch 3633, train_loss 213.486832,Time used 0.007999s\n",
      "batch 3634, train_loss 159.694412,Time used 0.007000s\n",
      "batch 3635, train_loss 174.590637,Time used 0.009001s\n",
      "batch 3636, train_loss 164.715698,Time used 0.006997s\n",
      "batch 3637, train_loss 162.593613,Time used 0.006002s\n",
      "batch 3638, train_loss 188.927887,Time used 0.008000s\n",
      "batch 3639, train_loss 158.174072,Time used 0.007998s\n",
      "batch 3640, train_loss 158.700073,Time used 0.007000s\n",
      "batch 3641, train_loss 143.652435,Time used 0.007000s\n",
      "batch 3642, train_loss 179.569885,Time used 0.008000s\n",
      "batch 3643, train_loss 126.089615,Time used 0.008000s\n",
      "batch 3644, train_loss 173.539520,Time used 0.006999s\n",
      "batch 3645, train_loss 158.818817,Time used 0.007003s\n",
      "batch 3646, train_loss 176.400894,Time used 0.009999s\n",
      "batch 3647, train_loss 194.823761,Time used 0.010000s\n",
      "batch 3648, train_loss 174.795380,Time used 0.009001s\n",
      "batch 3649, train_loss 166.845993,Time used 0.008000s\n",
      "batch 3650, train_loss 184.392609,Time used 0.011001s\n",
      "batch 3651, train_loss 189.127182,Time used 0.007999s\n",
      "batch 3652, train_loss 138.073853,Time used 0.007000s\n",
      "batch 3653, train_loss 167.015076,Time used 0.010000s\n",
      "batch 3654, train_loss 152.879379,Time used 0.009999s\n",
      "batch 3655, train_loss 168.760071,Time used 0.009000s\n",
      "batch 3656, train_loss 179.850266,Time used 0.009000s\n",
      "batch 3657, train_loss 164.744675,Time used 0.006999s\n",
      "batch 3658, train_loss 121.113098,Time used 0.007004s\n",
      "batch 3659, train_loss 151.849899,Time used 0.008999s\n",
      "batch 3660, train_loss 151.016312,Time used 0.010000s\n",
      "batch 3661, train_loss 180.092606,Time used 0.007001s\n",
      "batch 3662, train_loss 140.466675,Time used 0.007998s\n",
      "batch 3663, train_loss 179.343048,Time used 0.010004s\n",
      "batch 3664, train_loss 153.216446,Time used 0.011000s\n",
      "batch 3665, train_loss 164.337479,Time used 0.011000s\n",
      "batch 3666, train_loss 183.506744,Time used 0.010003s\n",
      "batch 3667, train_loss 182.326324,Time used 0.011997s\n",
      "batch 3668, train_loss 220.563507,Time used 0.009003s\n",
      "batch 3669, train_loss 202.715469,Time used 0.010998s\n",
      "batch 3670, train_loss 147.732407,Time used 0.007999s\n",
      "batch 3671, train_loss 176.110031,Time used 0.008001s\n",
      "batch 3672, train_loss 199.616638,Time used 0.006999s\n",
      "batch 3673, train_loss 177.141068,Time used 0.007997s\n",
      "batch 3674, train_loss 177.542358,Time used 0.007002s\n",
      "batch 3675, train_loss 166.709656,Time used 0.007999s\n",
      "batch 3676, train_loss 183.392578,Time used 0.008000s\n",
      "batch 3677, train_loss 156.651291,Time used 0.011001s\n",
      "batch 3678, train_loss 174.677017,Time used 0.008000s\n",
      "batch 3679, train_loss 126.310577,Time used 0.007999s\n",
      "batch 3680, train_loss 192.533539,Time used 0.010999s\n",
      "batch 3681, train_loss 159.176559,Time used 0.008001s\n",
      "batch 3682, train_loss 170.920624,Time used 0.007000s\n",
      "batch 3683, train_loss 153.202942,Time used 0.007000s\n",
      "batch 3684, train_loss 174.161087,Time used 0.006999s\n",
      "batch 3685, train_loss 206.730865,Time used 0.009002s\n",
      "batch 3686, train_loss 119.533051,Time used 0.006998s\n",
      "batch 3687, train_loss 168.970840,Time used 0.007000s\n",
      "batch 3688, train_loss 166.028107,Time used 0.007998s\n",
      "batch 3689, train_loss 159.046127,Time used 0.008000s\n",
      "batch 3690, train_loss 123.424484,Time used 0.009001s\n",
      "batch 3691, train_loss 173.571274,Time used 0.007000s\n",
      "batch 3692, train_loss 193.302597,Time used 0.007002s\n",
      "batch 3693, train_loss 227.851227,Time used 0.007035s\n",
      "batch 3694, train_loss 166.831787,Time used 0.006964s\n",
      "batch 3695, train_loss 159.256241,Time used 0.007004s\n",
      "batch 3696, train_loss 169.749542,Time used 0.007991s\n",
      "batch 3697, train_loss 211.454269,Time used 0.011998s\n",
      "batch 3698, train_loss 158.660339,Time used 0.010001s\n",
      "batch 3699, train_loss 205.464264,Time used 0.009000s\n",
      "batch 3700, train_loss 189.763931,Time used 0.010000s\n",
      "***************************test_batch 3700, test_rmse_loss 14.775072,test_mae_loss 5.658684,test_mape_loss 69.987466,Time used 0.042000s\n",
      "batch 3701, train_loss 146.862259,Time used 0.009998s\n",
      "batch 3702, train_loss 162.457458,Time used 0.007004s\n",
      "batch 3703, train_loss 137.596725,Time used 0.009999s\n",
      "batch 3704, train_loss 173.224228,Time used 0.006998s\n",
      "batch 3705, train_loss 171.994598,Time used 0.007000s\n",
      "batch 3706, train_loss 166.424713,Time used 0.009000s\n",
      "batch 3707, train_loss 158.444122,Time used 0.009000s\n",
      "batch 3708, train_loss 200.601379,Time used 0.008003s\n",
      "batch 3709, train_loss 133.784409,Time used 0.011998s\n",
      "batch 3710, train_loss 172.886215,Time used 0.007998s\n",
      "batch 3711, train_loss 158.728180,Time used 0.009003s\n",
      "batch 3712, train_loss 185.679031,Time used 0.007999s\n",
      "batch 3713, train_loss 153.931137,Time used 0.010999s\n",
      "batch 3714, train_loss 171.835388,Time used 0.012000s\n",
      "batch 3715, train_loss 166.171997,Time used 0.009998s\n",
      "batch 3716, train_loss 156.092438,Time used 0.008998s\n",
      "batch 3717, train_loss 185.505020,Time used 0.011001s\n",
      "batch 3718, train_loss 158.208649,Time used 0.010999s\n",
      "batch 3719, train_loss 132.492294,Time used 0.008998s\n",
      "batch 3720, train_loss 170.547714,Time used 0.009003s\n",
      "batch 3721, train_loss 158.442154,Time used 0.008000s\n",
      "batch 3722, train_loss 129.283279,Time used 0.007999s\n",
      "batch 3723, train_loss 141.271973,Time used 0.006998s\n",
      "batch 3724, train_loss 141.362411,Time used 0.010000s\n",
      "batch 3725, train_loss 169.066284,Time used 0.008002s\n",
      "batch 3726, train_loss 222.906555,Time used 0.007997s\n",
      "batch 3727, train_loss 173.370926,Time used 0.006999s\n",
      "batch 3728, train_loss 187.639999,Time used 0.009001s\n",
      "batch 3729, train_loss 171.677063,Time used 0.006998s\n",
      "batch 3730, train_loss 161.933884,Time used 0.009000s\n",
      "batch 3731, train_loss 167.160416,Time used 0.007002s\n",
      "batch 3732, train_loss 150.864822,Time used 0.011000s\n",
      "batch 3733, train_loss 188.478775,Time used 0.009999s\n",
      "batch 3734, train_loss 139.278824,Time used 0.007000s\n",
      "batch 3735, train_loss 148.513321,Time used 0.008000s\n",
      "batch 3736, train_loss 181.372681,Time used 0.006999s\n",
      "batch 3737, train_loss 182.634506,Time used 0.010002s\n",
      "batch 3738, train_loss 191.293686,Time used 0.006998s\n",
      "batch 3739, train_loss 129.094269,Time used 0.008004s\n",
      "batch 3740, train_loss 175.854721,Time used 0.008999s\n",
      "batch 3741, train_loss 202.490509,Time used 0.007998s\n",
      "batch 3742, train_loss 156.589340,Time used 0.007000s\n",
      "batch 3743, train_loss 161.728317,Time used 0.010002s\n",
      "batch 3744, train_loss 179.004196,Time used 0.009000s\n",
      "batch 3745, train_loss 209.273041,Time used 0.006999s\n",
      "batch 3746, train_loss 186.436920,Time used 0.006999s\n",
      "batch 3747, train_loss 156.062347,Time used 0.008000s\n",
      "batch 3748, train_loss 155.762024,Time used 0.008000s\n",
      "batch 3749, train_loss 166.488266,Time used 0.006999s\n",
      "batch 3750, train_loss 137.772202,Time used 0.007035s\n",
      "batch 3751, train_loss 109.978188,Time used 0.010002s\n",
      "batch 3752, train_loss 186.914001,Time used 0.006998s\n",
      "batch 3753, train_loss 139.434891,Time used 0.007964s\n",
      "batch 3754, train_loss 178.357773,Time used 0.007001s\n",
      "batch 3755, train_loss 171.059235,Time used 0.011000s\n",
      "batch 3756, train_loss 182.161575,Time used 0.007035s\n",
      "batch 3757, train_loss 152.425217,Time used 0.006965s\n",
      "batch 3758, train_loss 188.264069,Time used 0.006999s\n",
      "batch 3759, train_loss 176.743851,Time used 0.007004s\n",
      "batch 3760, train_loss 191.751892,Time used 0.007000s\n",
      "batch 3761, train_loss 154.341949,Time used 0.008000s\n",
      "batch 3762, train_loss 139.148071,Time used 0.009000s\n",
      "batch 3763, train_loss 169.332016,Time used 0.006999s\n",
      "batch 3764, train_loss 171.242722,Time used 0.007998s\n",
      "batch 3765, train_loss 210.693954,Time used 0.008001s\n",
      "batch 3766, train_loss 138.499237,Time used 0.007002s\n",
      "batch 3767, train_loss 172.897827,Time used 0.007001s\n",
      "batch 3768, train_loss 147.498108,Time used 0.011999s\n",
      "batch 3769, train_loss 132.613068,Time used 0.007998s\n",
      "batch 3770, train_loss 129.803345,Time used 0.008002s\n",
      "batch 3771, train_loss 155.743408,Time used 0.007001s\n",
      "batch 3772, train_loss 179.927887,Time used 0.007001s\n",
      "batch 3773, train_loss 152.893967,Time used 0.007000s\n",
      "batch 3774, train_loss 164.542908,Time used 0.007000s\n",
      "batch 3775, train_loss 185.161880,Time used 0.009999s\n",
      "batch 3776, train_loss 168.611984,Time used 0.009999s\n",
      "batch 3777, train_loss 127.900795,Time used 0.009000s\n",
      "batch 3778, train_loss 170.614166,Time used 0.008002s\n",
      "batch 3779, train_loss 187.667938,Time used 0.008998s\n",
      "batch 3780, train_loss 213.156158,Time used 0.008000s\n",
      "batch 3781, train_loss 180.799500,Time used 0.007999s\n",
      "batch 3782, train_loss 155.065628,Time used 0.007003s\n",
      "batch 3783, train_loss 166.002991,Time used 0.007000s\n",
      "batch 3784, train_loss 187.748810,Time used 0.009999s\n",
      "batch 3785, train_loss 195.304123,Time used 0.008000s\n",
      "batch 3786, train_loss 163.253555,Time used 0.007034s\n",
      "batch 3787, train_loss 131.054123,Time used 0.006967s\n",
      "batch 3788, train_loss 156.603760,Time used 0.006998s\n",
      "batch 3789, train_loss 175.246277,Time used 0.008000s\n",
      "batch 3790, train_loss 170.664124,Time used 0.007036s\n",
      "batch 3791, train_loss 187.836456,Time used 0.006964s\n",
      "batch 3792, train_loss 136.322128,Time used 0.008034s\n",
      "batch 3793, train_loss 191.434525,Time used 0.007970s\n",
      "batch 3794, train_loss 158.739990,Time used 0.007031s\n",
      "batch 3795, train_loss 99.590240,Time used 0.006993s\n",
      "batch 3796, train_loss 166.224152,Time used 0.009034s\n",
      "batch 3797, train_loss 217.878891,Time used 0.008965s\n",
      "batch 3798, train_loss 184.489929,Time used 0.007002s\n",
      "batch 3799, train_loss 170.309341,Time used 0.009999s\n",
      "batch 3800, train_loss 157.460983,Time used 0.011037s\n",
      "***************************test_batch 3800, test_rmse_loss 14.647350,test_mae_loss 5.603893,test_mape_loss 69.747957,Time used 0.030964s\n",
      "batch 3801, train_loss 221.850662,Time used 0.006999s\n",
      "batch 3802, train_loss 175.309433,Time used 0.007000s\n",
      "batch 3803, train_loss 144.038956,Time used 0.007000s\n",
      "batch 3804, train_loss 136.925476,Time used 0.007001s\n",
      "batch 3805, train_loss 191.532043,Time used 0.008000s\n",
      "batch 3806, train_loss 133.994446,Time used 0.006999s\n",
      "batch 3807, train_loss 201.892502,Time used 0.007997s\n",
      "batch 3808, train_loss 172.094696,Time used 0.007002s\n",
      "batch 3809, train_loss 148.343048,Time used 0.008000s\n",
      "batch 3810, train_loss 160.604080,Time used 0.006999s\n",
      "batch 3811, train_loss 140.411804,Time used 0.007001s\n",
      "batch 3812, train_loss 200.730392,Time used 0.008001s\n",
      "batch 3813, train_loss 140.925720,Time used 0.008001s\n",
      "batch 3814, train_loss 104.606773,Time used 0.009998s\n",
      "batch 3815, train_loss 183.987579,Time used 0.008000s\n",
      "batch 3816, train_loss 154.613297,Time used 0.009000s\n",
      "batch 3817, train_loss 157.309937,Time used 0.011003s\n",
      "batch 3818, train_loss 158.799377,Time used 0.011001s\n",
      "batch 3819, train_loss 184.965759,Time used 0.012997s\n",
      "batch 3820, train_loss 159.141678,Time used 0.012000s\n",
      "batch 3821, train_loss 155.665344,Time used 0.009002s\n",
      "batch 3822, train_loss 156.636292,Time used 0.009998s\n",
      "batch 3823, train_loss 200.446228,Time used 0.009001s\n",
      "batch 3824, train_loss 126.316940,Time used 0.012000s\n",
      "batch 3825, train_loss 147.119720,Time used 0.010001s\n",
      "batch 3826, train_loss 144.774780,Time used 0.008000s\n",
      "batch 3827, train_loss 188.731796,Time used 0.009001s\n",
      "batch 3828, train_loss 149.635590,Time used 0.007998s\n",
      "batch 3829, train_loss 191.074219,Time used 0.009000s\n",
      "batch 3830, train_loss 174.547485,Time used 0.007999s\n",
      "batch 3831, train_loss 126.857819,Time used 0.007000s\n",
      "batch 3832, train_loss 163.971085,Time used 0.007000s\n",
      "batch 3833, train_loss 175.814835,Time used 0.007002s\n",
      "batch 3834, train_loss 170.837814,Time used 0.007001s\n",
      "batch 3835, train_loss 172.915787,Time used 0.008001s\n",
      "batch 3836, train_loss 188.089157,Time used 0.007996s\n",
      "batch 3837, train_loss 174.877701,Time used 0.007002s\n",
      "batch 3838, train_loss 144.324295,Time used 0.008999s\n",
      "batch 3839, train_loss 139.997528,Time used 0.009040s\n",
      "batch 3840, train_loss 189.089569,Time used 0.006999s\n",
      "batch 3841, train_loss 155.017334,Time used 0.007997s\n",
      "batch 3842, train_loss 182.342728,Time used 0.009000s\n",
      "batch 3843, train_loss 181.628448,Time used 0.007002s\n",
      "batch 3844, train_loss 160.888306,Time used 0.009032s\n",
      "batch 3845, train_loss 130.469330,Time used 0.007965s\n",
      "batch 3846, train_loss 170.403885,Time used 0.010000s\n",
      "batch 3847, train_loss 142.631744,Time used 0.008999s\n",
      "batch 3848, train_loss 153.462280,Time used 0.007038s\n",
      "batch 3849, train_loss 168.331772,Time used 0.006962s\n",
      "batch 3850, train_loss 193.788315,Time used 0.010034s\n",
      "batch 3851, train_loss 167.341125,Time used 0.007969s\n",
      "batch 3852, train_loss 218.986649,Time used 0.007998s\n",
      "batch 3853, train_loss 176.503098,Time used 0.008034s\n",
      "batch 3854, train_loss 177.069351,Time used 0.007999s\n",
      "batch 3855, train_loss 163.108902,Time used 0.007966s\n",
      "batch 3856, train_loss 123.811806,Time used 0.010000s\n",
      "batch 3857, train_loss 178.650406,Time used 0.010038s\n",
      "batch 3858, train_loss 147.008301,Time used 0.008999s\n",
      "batch 3859, train_loss 136.527328,Time used 0.010000s\n",
      "batch 3860, train_loss 170.039581,Time used 0.007000s\n",
      "batch 3861, train_loss 169.051422,Time used 0.011034s\n",
      "batch 3862, train_loss 138.363037,Time used 0.008967s\n",
      "batch 3863, train_loss 156.075607,Time used 0.006998s\n",
      "batch 3864, train_loss 162.401352,Time used 0.007001s\n",
      "batch 3865, train_loss 153.033386,Time used 0.008000s\n",
      "batch 3866, train_loss 137.204956,Time used 0.006999s\n",
      "batch 3867, train_loss 167.510925,Time used 0.009002s\n",
      "batch 3868, train_loss 144.261032,Time used 0.006999s\n",
      "batch 3869, train_loss 141.199997,Time used 0.006999s\n",
      "batch 3870, train_loss 192.541153,Time used 0.011001s\n",
      "batch 3871, train_loss 142.387024,Time used 0.008999s\n",
      "batch 3872, train_loss 126.865814,Time used 0.007000s\n",
      "batch 3873, train_loss 155.814743,Time used 0.007002s\n",
      "batch 3874, train_loss 172.938385,Time used 0.006999s\n",
      "batch 3875, train_loss 157.750626,Time used 0.009000s\n",
      "batch 3876, train_loss 166.440140,Time used 0.007000s\n",
      "batch 3877, train_loss 153.029587,Time used 0.010998s\n",
      "batch 3878, train_loss 139.237015,Time used 0.007000s\n",
      "batch 3879, train_loss 201.851227,Time used 0.007000s\n",
      "batch 3880, train_loss 165.979599,Time used 0.006999s\n",
      "batch 3881, train_loss 166.427322,Time used 0.010003s\n",
      "batch 3882, train_loss 163.937897,Time used 0.009999s\n",
      "batch 3883, train_loss 171.721115,Time used 0.010004s\n",
      "batch 3884, train_loss 149.940094,Time used 0.010996s\n",
      "batch 3885, train_loss 198.467514,Time used 0.008002s\n",
      "batch 3886, train_loss 177.852676,Time used 0.008998s\n",
      "batch 3887, train_loss 172.673050,Time used 0.007998s\n",
      "batch 3888, train_loss 188.646194,Time used 0.007001s\n",
      "batch 3889, train_loss 172.182388,Time used 0.008000s\n",
      "batch 3890, train_loss 169.056854,Time used 0.008999s\n",
      "batch 3891, train_loss 158.067505,Time used 0.010000s\n",
      "batch 3892, train_loss 163.679398,Time used 0.008001s\n",
      "batch 3893, train_loss 124.767715,Time used 0.007000s\n",
      "batch 3894, train_loss 200.849655,Time used 0.008002s\n",
      "batch 3895, train_loss 137.703598,Time used 0.009000s\n",
      "batch 3896, train_loss 180.076859,Time used 0.010999s\n",
      "batch 3897, train_loss 132.399887,Time used 0.011000s\n",
      "batch 3898, train_loss 164.082245,Time used 0.011000s\n",
      "batch 3899, train_loss 172.418915,Time used 0.010000s\n",
      "batch 3900, train_loss 165.155579,Time used 0.011001s\n",
      "***************************test_batch 3900, test_rmse_loss 14.521611,test_mae_loss 5.551335,test_mape_loss 69.595327,Time used 0.035000s\n",
      "batch 3901, train_loss 207.003113,Time used 0.007000s\n",
      "batch 3902, train_loss 142.635696,Time used 0.010999s\n",
      "batch 3903, train_loss 158.968430,Time used 0.007999s\n",
      "batch 3904, train_loss 152.495026,Time used 0.010999s\n",
      "batch 3905, train_loss 176.536179,Time used 0.010999s\n",
      "batch 3906, train_loss 140.757599,Time used 0.010000s\n",
      "batch 3907, train_loss 155.990723,Time used 0.011002s\n",
      "batch 3908, train_loss 133.745651,Time used 0.010000s\n",
      "batch 3909, train_loss 158.635986,Time used 0.011997s\n",
      "batch 3910, train_loss 142.585403,Time used 0.011002s\n",
      "batch 3911, train_loss 204.249222,Time used 0.012000s\n",
      "batch 3912, train_loss 176.489304,Time used 0.010999s\n",
      "batch 3913, train_loss 162.256973,Time used 0.009000s\n",
      "batch 3914, train_loss 172.312912,Time used 0.011000s\n",
      "batch 3915, train_loss 207.447266,Time used 0.008001s\n",
      "batch 3916, train_loss 196.611572,Time used 0.009001s\n",
      "batch 3917, train_loss 181.930222,Time used 0.008999s\n",
      "batch 3918, train_loss 114.418106,Time used 0.007001s\n",
      "batch 3919, train_loss 156.235855,Time used 0.007998s\n",
      "batch 3920, train_loss 140.735596,Time used 0.007998s\n",
      "batch 3921, train_loss 186.445068,Time used 0.008001s\n",
      "batch 3922, train_loss 180.282913,Time used 0.007001s\n",
      "batch 3923, train_loss 137.226105,Time used 0.010000s\n",
      "batch 3924, train_loss 155.479431,Time used 0.008000s\n",
      "batch 3925, train_loss 125.558617,Time used 0.008000s\n",
      "batch 3926, train_loss 205.069839,Time used 0.008002s\n",
      "batch 3927, train_loss 147.475632,Time used 0.010000s\n",
      "batch 3928, train_loss 146.258331,Time used 0.006999s\n",
      "batch 3929, train_loss 139.284363,Time used 0.007001s\n",
      "batch 3930, train_loss 128.299820,Time used 0.006999s\n",
      "batch 3931, train_loss 160.320206,Time used 0.007001s\n",
      "batch 3932, train_loss 146.384125,Time used 0.007002s\n",
      "batch 3933, train_loss 183.498795,Time used 0.007999s\n",
      "batch 3934, train_loss 145.529282,Time used 0.009002s\n",
      "batch 3935, train_loss 148.422546,Time used 0.015997s\n",
      "batch 3936, train_loss 207.502960,Time used 0.010999s\n",
      "batch 3937, train_loss 151.952591,Time used 0.014001s\n",
      "batch 3938, train_loss 189.331772,Time used 0.012001s\n",
      "batch 3939, train_loss 158.903580,Time used 0.010000s\n",
      "batch 3940, train_loss 134.106522,Time used 0.011000s\n",
      "batch 3941, train_loss 197.371872,Time used 0.011998s\n",
      "batch 3942, train_loss 202.742599,Time used 0.010000s\n",
      "batch 3943, train_loss 171.360687,Time used 0.012001s\n",
      "batch 3944, train_loss 147.946228,Time used 0.008002s\n",
      "batch 3945, train_loss 173.745087,Time used 0.008001s\n",
      "batch 3946, train_loss 144.329529,Time used 0.008000s\n",
      "batch 3947, train_loss 151.378891,Time used 0.011998s\n",
      "batch 3948, train_loss 147.185059,Time used 0.010999s\n",
      "batch 3949, train_loss 226.493515,Time used 0.010000s\n",
      "batch 3950, train_loss 141.523239,Time used 0.012000s\n",
      "batch 3951, train_loss 148.179916,Time used 0.011003s\n",
      "batch 3952, train_loss 155.665771,Time used 0.012999s\n",
      "batch 3953, train_loss 144.381287,Time used 0.011000s\n",
      "batch 3954, train_loss 156.613495,Time used 0.010998s\n",
      "batch 3955, train_loss 178.415085,Time used 0.008999s\n",
      "batch 3956, train_loss 143.927521,Time used 0.008000s\n",
      "batch 3957, train_loss 201.383804,Time used 0.012002s\n",
      "batch 3958, train_loss 140.692459,Time used 0.012000s\n",
      "batch 3959, train_loss 141.497711,Time used 0.013002s\n",
      "batch 3960, train_loss 105.251427,Time used 0.013000s\n",
      "batch 3961, train_loss 181.836014,Time used 0.011999s\n",
      "batch 3962, train_loss 187.316025,Time used 0.015001s\n",
      "batch 3963, train_loss 212.662949,Time used 0.012002s\n",
      "batch 3964, train_loss 125.877419,Time used 0.015000s\n",
      "batch 3965, train_loss 153.828796,Time used 0.013000s\n",
      "batch 3966, train_loss 163.964615,Time used 0.011000s\n",
      "batch 3967, train_loss 178.583771,Time used 0.009001s\n",
      "batch 3968, train_loss 138.195358,Time used 0.010002s\n",
      "batch 3969, train_loss 132.838608,Time used 0.014002s\n",
      "batch 3970, train_loss 133.699875,Time used 0.007999s\n",
      "batch 3971, train_loss 179.455765,Time used 0.011001s\n",
      "batch 3972, train_loss 161.532654,Time used 0.011004s\n",
      "batch 3973, train_loss 126.651154,Time used 0.011986s\n",
      "batch 3974, train_loss 117.882317,Time used 0.013999s\n",
      "batch 3975, train_loss 149.592392,Time used 0.013000s\n",
      "batch 3976, train_loss 183.167068,Time used 0.023002s\n",
      "batch 3977, train_loss 142.705307,Time used 0.009998s\n",
      "batch 3978, train_loss 115.260704,Time used 0.011000s\n",
      "batch 3979, train_loss 138.562851,Time used 0.009000s\n",
      "batch 3980, train_loss 168.836884,Time used 0.008000s\n",
      "batch 3981, train_loss 218.529694,Time used 0.008000s\n",
      "batch 3982, train_loss 170.746353,Time used 0.008000s\n",
      "batch 3983, train_loss 171.990265,Time used 0.009002s\n",
      "batch 3984, train_loss 187.186752,Time used 0.011000s\n",
      "batch 3985, train_loss 185.610489,Time used 0.011999s\n",
      "batch 3986, train_loss 170.182968,Time used 0.010998s\n",
      "batch 3987, train_loss 137.664749,Time used 0.011000s\n",
      "batch 3988, train_loss 140.278992,Time used 0.008001s\n",
      "batch 3989, train_loss 148.535248,Time used 0.006999s\n",
      "batch 3990, train_loss 152.375916,Time used 0.007000s\n",
      "batch 3991, train_loss 162.913483,Time used 0.007000s\n",
      "batch 3992, train_loss 147.938217,Time used 0.008001s\n",
      "batch 3993, train_loss 169.485931,Time used 0.008001s\n",
      "batch 3994, train_loss 201.958878,Time used 0.006998s\n",
      "batch 3995, train_loss 136.103745,Time used 0.007002s\n",
      "batch 3996, train_loss 126.741379,Time used 0.008001s\n",
      "batch 3997, train_loss 156.973328,Time used 0.007998s\n",
      "batch 3998, train_loss 152.626022,Time used 0.008001s\n",
      "batch 3999, train_loss 164.707016,Time used 0.011001s\n",
      "batch 4000, train_loss 156.541565,Time used 0.010998s\n",
      "***************************test_batch 4000, test_rmse_loss 14.399260,test_mae_loss 5.499016,test_mape_loss 69.221630,Time used 0.039002s\n",
      "batch 4001, train_loss 126.562454,Time used 0.009999s\n",
      "batch 4002, train_loss 159.839325,Time used 0.010001s\n",
      "batch 4003, train_loss 136.529617,Time used 0.006999s\n",
      "batch 4004, train_loss 158.100616,Time used 0.008001s\n",
      "batch 4005, train_loss 235.810974,Time used 0.008000s\n",
      "batch 4006, train_loss 160.949371,Time used 0.008002s\n",
      "batch 4007, train_loss 165.926605,Time used 0.007000s\n",
      "batch 4008, train_loss 169.361786,Time used 0.006997s\n",
      "batch 4009, train_loss 178.091553,Time used 0.011001s\n",
      "batch 4010, train_loss 163.364197,Time used 0.007002s\n",
      "batch 4011, train_loss 162.977097,Time used 0.007998s\n",
      "batch 4012, train_loss 120.579025,Time used 0.007000s\n",
      "batch 4013, train_loss 181.741943,Time used 0.008001s\n",
      "batch 4014, train_loss 132.235657,Time used 0.011999s\n",
      "batch 4015, train_loss 207.273468,Time used 0.010000s\n",
      "batch 4016, train_loss 136.962646,Time used 0.008001s\n",
      "batch 4017, train_loss 170.505142,Time used 0.011000s\n",
      "batch 4018, train_loss 130.251907,Time used 0.010001s\n",
      "batch 4019, train_loss 160.219986,Time used 0.011001s\n",
      "batch 4020, train_loss 131.829407,Time used 0.008000s\n",
      "batch 4021, train_loss 195.723846,Time used 0.008000s\n",
      "batch 4022, train_loss 181.861938,Time used 0.009000s\n",
      "batch 4023, train_loss 132.887695,Time used 0.010999s\n",
      "batch 4024, train_loss 169.393463,Time used 0.007000s\n",
      "batch 4025, train_loss 152.986206,Time used 0.009999s\n",
      "batch 4026, train_loss 136.293030,Time used 0.007001s\n",
      "batch 4027, train_loss 153.404968,Time used 0.006999s\n",
      "batch 4028, train_loss 170.354691,Time used 0.007001s\n",
      "batch 4029, train_loss 133.405228,Time used 0.007001s\n",
      "batch 4030, train_loss 163.964355,Time used 0.009001s\n",
      "batch 4031, train_loss 172.859970,Time used 0.007999s\n",
      "batch 4032, train_loss 168.380356,Time used 0.007002s\n",
      "batch 4033, train_loss 168.172546,Time used 0.010000s\n",
      "batch 4034, train_loss 173.871597,Time used 0.009000s\n",
      "batch 4035, train_loss 183.536331,Time used 0.011000s\n",
      "batch 4036, train_loss 227.579895,Time used 0.012000s\n",
      "batch 4037, train_loss 144.540543,Time used 0.008999s\n",
      "batch 4038, train_loss 138.728638,Time used 0.010003s\n",
      "batch 4039, train_loss 180.433029,Time used 0.010000s\n",
      "batch 4040, train_loss 137.927521,Time used 0.011000s\n",
      "batch 4041, train_loss 157.491333,Time used 0.009001s\n",
      "batch 4042, train_loss 184.335327,Time used 0.011000s\n",
      "batch 4043, train_loss 174.407425,Time used 0.009998s\n",
      "batch 4044, train_loss 132.549500,Time used 0.008002s\n",
      "batch 4045, train_loss 165.315765,Time used 0.008001s\n",
      "batch 4046, train_loss 156.455826,Time used 0.008000s\n",
      "batch 4047, train_loss 152.081711,Time used 0.008002s\n",
      "batch 4048, train_loss 130.684753,Time used 0.006999s\n",
      "batch 4049, train_loss 149.361053,Time used 0.007001s\n",
      "batch 4050, train_loss 139.132416,Time used 0.006998s\n",
      "batch 4051, train_loss 140.081070,Time used 0.007000s\n",
      "batch 4052, train_loss 159.808563,Time used 0.008001s\n",
      "batch 4053, train_loss 151.208755,Time used 0.006999s\n",
      "batch 4054, train_loss 156.043549,Time used 0.008001s\n",
      "batch 4055, train_loss 170.808289,Time used 0.006001s\n",
      "batch 4056, train_loss 114.771538,Time used 0.006999s\n",
      "batch 4057, train_loss 144.164581,Time used 0.009003s\n",
      "batch 4058, train_loss 173.776260,Time used 0.006996s\n",
      "batch 4059, train_loss 183.168884,Time used 0.009003s\n",
      "batch 4060, train_loss 153.039795,Time used 0.010998s\n",
      "batch 4061, train_loss 172.260880,Time used 0.010997s\n",
      "batch 4062, train_loss 143.386322,Time used 0.010002s\n",
      "batch 4063, train_loss 142.589890,Time used 0.010998s\n",
      "batch 4064, train_loss 154.977402,Time used 0.008997s\n",
      "batch 4065, train_loss 192.807388,Time used 0.010997s\n",
      "batch 4066, train_loss 166.779236,Time used 0.010004s\n",
      "batch 4067, train_loss 138.383545,Time used 0.006997s\n",
      "batch 4068, train_loss 173.828583,Time used 0.007000s\n",
      "batch 4069, train_loss 119.425186,Time used 0.007003s\n",
      "batch 4070, train_loss 153.854034,Time used 0.007999s\n",
      "batch 4071, train_loss 171.503937,Time used 0.010000s\n",
      "batch 4072, train_loss 110.448685,Time used 0.006999s\n",
      "batch 4073, train_loss 187.903549,Time used 0.010001s\n",
      "batch 4074, train_loss 163.491455,Time used 0.009000s\n",
      "batch 4075, train_loss 127.303604,Time used 0.009998s\n",
      "batch 4076, train_loss 203.945618,Time used 0.009000s\n",
      "batch 4077, train_loss 178.110306,Time used 0.007000s\n",
      "batch 4078, train_loss 151.036835,Time used 0.009003s\n",
      "batch 4079, train_loss 132.419647,Time used 0.009000s\n",
      "batch 4080, train_loss 135.312485,Time used 0.007998s\n",
      "batch 4081, train_loss 169.064529,Time used 0.010001s\n",
      "batch 4082, train_loss 181.891937,Time used 0.011001s\n",
      "batch 4083, train_loss 159.821915,Time used 0.010000s\n",
      "batch 4084, train_loss 185.930038,Time used 0.010998s\n",
      "batch 4085, train_loss 190.553329,Time used 0.008001s\n",
      "batch 4086, train_loss 167.321396,Time used 0.011034s\n",
      "batch 4087, train_loss 130.332611,Time used 0.007970s\n",
      "batch 4088, train_loss 165.946075,Time used 0.009002s\n",
      "batch 4089, train_loss 185.133209,Time used 0.007995s\n",
      "batch 4090, train_loss 151.332520,Time used 0.008037s\n",
      "batch 4091, train_loss 132.514160,Time used 0.007000s\n",
      "batch 4092, train_loss 143.570145,Time used 0.007003s\n",
      "batch 4093, train_loss 125.645020,Time used 0.008003s\n",
      "batch 4094, train_loss 123.139130,Time used 0.006959s\n",
      "batch 4095, train_loss 162.315430,Time used 0.007036s\n",
      "batch 4096, train_loss 138.920471,Time used 0.006989s\n",
      "batch 4097, train_loss 172.013474,Time used 0.007011s\n",
      "batch 4098, train_loss 132.001404,Time used 0.006000s\n",
      "batch 4099, train_loss 190.120575,Time used 0.007003s\n",
      "batch 4100, train_loss 179.679886,Time used 0.006034s\n",
      "***************************test_batch 4100, test_rmse_loss 14.276812,test_mae_loss 5.449483,test_mape_loss 69.171952,Time used 0.028000s\n",
      "batch 4101, train_loss 165.869232,Time used 0.007001s\n",
      "batch 4102, train_loss 137.074066,Time used 0.008973s\n",
      "batch 4103, train_loss 160.186462,Time used 0.006994s\n",
      "batch 4104, train_loss 106.499962,Time used 0.009997s\n",
      "batch 4105, train_loss 156.943939,Time used 0.009000s\n",
      "batch 4106, train_loss 148.405319,Time used 0.010998s\n",
      "batch 4107, train_loss 181.687286,Time used 0.009035s\n",
      "batch 4108, train_loss 133.935242,Time used 0.007000s\n",
      "batch 4109, train_loss 188.159592,Time used 0.007966s\n",
      "batch 4110, train_loss 136.975037,Time used 0.010000s\n",
      "batch 4111, train_loss 156.940399,Time used 0.009001s\n",
      "batch 4112, train_loss 131.952225,Time used 0.010000s\n",
      "batch 4113, train_loss 162.405243,Time used 0.006999s\n",
      "batch 4114, train_loss 156.316635,Time used 0.010001s\n",
      "batch 4115, train_loss 152.178452,Time used 0.006998s\n",
      "batch 4116, train_loss 150.177246,Time used 0.008008s\n",
      "batch 4117, train_loss 182.426132,Time used 0.010026s\n",
      "batch 4118, train_loss 143.381943,Time used 0.007966s\n",
      "batch 4119, train_loss 140.583038,Time used 0.006999s\n",
      "batch 4120, train_loss 155.115082,Time used 0.012002s\n",
      "batch 4121, train_loss 173.123138,Time used 0.008997s\n",
      "batch 4122, train_loss 152.891037,Time used 0.008000s\n",
      "batch 4123, train_loss 188.792068,Time used 0.007001s\n",
      "batch 4124, train_loss 174.661224,Time used 0.007999s\n",
      "batch 4125, train_loss 98.237709,Time used 0.010000s\n",
      "batch 4126, train_loss 142.062149,Time used 0.010001s\n",
      "batch 4127, train_loss 174.587173,Time used 0.007000s\n",
      "batch 4128, train_loss 161.073120,Time used 0.006998s\n",
      "batch 4129, train_loss 124.374664,Time used 0.012000s\n",
      "batch 4130, train_loss 168.636826,Time used 0.007001s\n",
      "batch 4131, train_loss 206.594421,Time used 0.008997s\n",
      "batch 4132, train_loss 200.788452,Time used 0.007001s\n",
      "batch 4133, train_loss 156.196075,Time used 0.009997s\n",
      "batch 4134, train_loss 152.825439,Time used 0.007002s\n",
      "batch 4135, train_loss 176.190231,Time used 0.006999s\n",
      "batch 4136, train_loss 187.572510,Time used 0.007002s\n",
      "batch 4137, train_loss 127.970726,Time used 0.009999s\n",
      "batch 4138, train_loss 134.326523,Time used 0.008001s\n",
      "batch 4139, train_loss 166.605270,Time used 0.006999s\n",
      "batch 4140, train_loss 122.730309,Time used 0.008001s\n",
      "batch 4141, train_loss 144.138824,Time used 0.007999s\n",
      "batch 4142, train_loss 167.043884,Time used 0.007001s\n",
      "batch 4143, train_loss 203.476974,Time used 0.010000s\n",
      "batch 4144, train_loss 178.239166,Time used 0.006998s\n",
      "batch 4145, train_loss 199.909546,Time used 0.008000s\n",
      "batch 4146, train_loss 127.471191,Time used 0.011000s\n",
      "batch 4147, train_loss 100.635170,Time used 0.011003s\n",
      "batch 4148, train_loss 133.091156,Time used 0.008001s\n",
      "batch 4149, train_loss 134.683533,Time used 0.010997s\n",
      "batch 4150, train_loss 177.636658,Time used 0.006999s\n",
      "batch 4151, train_loss 107.613029,Time used 0.007002s\n",
      "batch 4152, train_loss 127.335930,Time used 0.007999s\n",
      "batch 4153, train_loss 142.904953,Time used 0.008002s\n",
      "batch 4154, train_loss 173.721786,Time used 0.009000s\n",
      "batch 4155, train_loss 147.533401,Time used 0.009999s\n",
      "batch 4156, train_loss 158.767624,Time used 0.011000s\n",
      "batch 4157, train_loss 184.158264,Time used 0.011001s\n",
      "batch 4158, train_loss 139.149475,Time used 0.009001s\n",
      "batch 4159, train_loss 133.356750,Time used 0.008999s\n",
      "batch 4160, train_loss 144.131638,Time used 0.010000s\n",
      "batch 4161, train_loss 146.671005,Time used 0.007001s\n",
      "batch 4162, train_loss 158.527252,Time used 0.009000s\n",
      "batch 4163, train_loss 96.107407,Time used 0.007000s\n",
      "batch 4164, train_loss 139.810806,Time used 0.008000s\n",
      "batch 4165, train_loss 153.906723,Time used 0.010998s\n",
      "batch 4166, train_loss 201.294312,Time used 0.011000s\n",
      "batch 4167, train_loss 157.867371,Time used 0.007001s\n",
      "batch 4168, train_loss 147.220673,Time used 0.008002s\n",
      "batch 4169, train_loss 176.220749,Time used 0.007000s\n",
      "batch 4170, train_loss 133.005630,Time used 0.007999s\n",
      "batch 4171, train_loss 173.789261,Time used 0.008000s\n",
      "batch 4172, train_loss 147.133209,Time used 0.010001s\n",
      "batch 4173, train_loss 131.123978,Time used 0.007001s\n",
      "batch 4174, train_loss 186.128891,Time used 0.010999s\n",
      "batch 4175, train_loss 186.131180,Time used 0.008000s\n",
      "batch 4176, train_loss 152.616394,Time used 0.009999s\n",
      "batch 4177, train_loss 147.142960,Time used 0.009999s\n",
      "batch 4178, train_loss 145.971176,Time used 0.007000s\n",
      "batch 4179, train_loss 135.545990,Time used 0.008002s\n",
      "batch 4180, train_loss 132.168350,Time used 0.006999s\n",
      "batch 4181, train_loss 157.840179,Time used 0.006999s\n",
      "batch 4182, train_loss 183.806824,Time used 0.010001s\n",
      "batch 4183, train_loss 175.241623,Time used 0.011000s\n",
      "batch 4184, train_loss 141.437149,Time used 0.011001s\n",
      "batch 4185, train_loss 154.163696,Time used 0.006997s\n",
      "batch 4186, train_loss 116.475128,Time used 0.006999s\n",
      "batch 4187, train_loss 194.024506,Time used 0.008000s\n",
      "batch 4188, train_loss 127.940704,Time used 0.007002s\n",
      "batch 4189, train_loss 128.096817,Time used 0.007002s\n",
      "batch 4190, train_loss 148.347000,Time used 0.007001s\n",
      "batch 4191, train_loss 144.300827,Time used 0.007003s\n",
      "batch 4192, train_loss 146.687347,Time used 0.007993s\n",
      "batch 4193, train_loss 176.715225,Time used 0.008000s\n",
      "batch 4194, train_loss 218.578857,Time used 0.007999s\n",
      "batch 4195, train_loss 161.473755,Time used 0.007999s\n",
      "batch 4196, train_loss 184.926514,Time used 0.007001s\n",
      "batch 4197, train_loss 136.418015,Time used 0.007000s\n",
      "batch 4198, train_loss 169.927155,Time used 0.008001s\n",
      "batch 4199, train_loss 163.450043,Time used 0.010005s\n",
      "batch 4200, train_loss 103.295105,Time used 0.008996s\n",
      "***************************test_batch 4200, test_rmse_loss 14.158213,test_mae_loss 5.401661,test_mape_loss 68.970920,Time used 0.026999s\n",
      "batch 4201, train_loss 198.763885,Time used 0.006999s\n",
      "batch 4202, train_loss 153.761719,Time used 0.007001s\n",
      "batch 4203, train_loss 156.530731,Time used 0.009001s\n",
      "batch 4204, train_loss 151.199600,Time used 0.006001s\n",
      "batch 4205, train_loss 168.326752,Time used 0.009000s\n",
      "batch 4206, train_loss 165.456116,Time used 0.007999s\n",
      "batch 4207, train_loss 156.153000,Time used 0.010998s\n",
      "batch 4208, train_loss 168.530838,Time used 0.009001s\n",
      "batch 4209, train_loss 117.765587,Time used 0.006998s\n",
      "batch 4210, train_loss 137.467789,Time used 0.010004s\n",
      "batch 4211, train_loss 179.409546,Time used 0.006997s\n",
      "batch 4212, train_loss 126.442802,Time used 0.008002s\n",
      "batch 4213, train_loss 126.210747,Time used 0.006999s\n",
      "batch 4214, train_loss 195.792343,Time used 0.008001s\n",
      "batch 4215, train_loss 180.643036,Time used 0.008998s\n",
      "batch 4216, train_loss 170.049759,Time used 0.008000s\n",
      "batch 4217, train_loss 173.005112,Time used 0.006999s\n",
      "batch 4218, train_loss 128.475143,Time used 0.008002s\n",
      "batch 4219, train_loss 131.997726,Time used 0.009999s\n",
      "batch 4220, train_loss 97.548485,Time used 0.008999s\n",
      "batch 4221, train_loss 174.057617,Time used 0.010000s\n",
      "batch 4222, train_loss 136.798538,Time used 0.006000s\n",
      "batch 4223, train_loss 149.493149,Time used 0.008001s\n",
      "batch 4224, train_loss 135.952377,Time used 0.006999s\n",
      "batch 4225, train_loss 119.168350,Time used 0.007000s\n",
      "batch 4226, train_loss 177.324661,Time used 0.007000s\n",
      "batch 4227, train_loss 207.419022,Time used 0.007004s\n",
      "batch 4228, train_loss 91.956375,Time used 0.007998s\n",
      "batch 4229, train_loss 191.273132,Time used 0.012999s\n",
      "batch 4230, train_loss 146.337082,Time used 0.009997s\n",
      "batch 4231, train_loss 141.552734,Time used 0.010002s\n",
      "batch 4232, train_loss 128.752899,Time used 0.010004s\n",
      "batch 4233, train_loss 151.430908,Time used 0.009996s\n",
      "batch 4234, train_loss 200.206543,Time used 0.006996s\n",
      "batch 4235, train_loss 199.321533,Time used 0.009000s\n",
      "batch 4236, train_loss 152.706543,Time used 0.007000s\n",
      "batch 4237, train_loss 135.528854,Time used 0.008001s\n",
      "batch 4238, train_loss 134.026886,Time used 0.010003s\n",
      "batch 4239, train_loss 167.404465,Time used 0.007996s\n",
      "batch 4240, train_loss 154.128708,Time used 0.007035s\n",
      "batch 4241, train_loss 146.856720,Time used 0.008001s\n",
      "batch 4242, train_loss 156.356537,Time used 0.008998s\n",
      "batch 4243, train_loss 182.078445,Time used 0.008004s\n",
      "batch 4244, train_loss 103.443443,Time used 0.006996s\n",
      "batch 4245, train_loss 116.650459,Time used 0.010036s\n",
      "batch 4246, train_loss 133.388855,Time used 0.007000s\n",
      "batch 4247, train_loss 167.136353,Time used 0.007965s\n",
      "batch 4248, train_loss 160.951721,Time used 0.007038s\n",
      "batch 4249, train_loss 122.433182,Time used 0.006998s\n",
      "batch 4250, train_loss 164.391922,Time used 0.006970s\n",
      "batch 4251, train_loss 102.930328,Time used 0.006995s\n",
      "batch 4252, train_loss 194.057892,Time used 0.008001s\n",
      "batch 4253, train_loss 161.200394,Time used 0.008001s\n",
      "batch 4254, train_loss 158.196320,Time used 0.008999s\n",
      "batch 4255, train_loss 119.454529,Time used 0.008000s\n",
      "batch 4256, train_loss 172.573395,Time used 0.011000s\n",
      "batch 4257, train_loss 198.571182,Time used 0.008036s\n",
      "batch 4258, train_loss 170.665253,Time used 0.007966s\n",
      "batch 4259, train_loss 183.467972,Time used 0.006999s\n",
      "batch 4260, train_loss 151.044159,Time used 0.007001s\n",
      "batch 4261, train_loss 163.010178,Time used 0.006999s\n",
      "batch 4262, train_loss 151.677246,Time used 0.007002s\n",
      "batch 4263, train_loss 143.645325,Time used 0.007999s\n",
      "batch 4264, train_loss 153.567047,Time used 0.006999s\n",
      "batch 4265, train_loss 124.592049,Time used 0.006999s\n",
      "batch 4266, train_loss 138.780853,Time used 0.008002s\n",
      "batch 4267, train_loss 124.786613,Time used 0.007000s\n",
      "batch 4268, train_loss 124.815651,Time used 0.006998s\n",
      "batch 4269, train_loss 136.359482,Time used 0.007002s\n",
      "batch 4270, train_loss 138.033081,Time used 0.006998s\n",
      "batch 4271, train_loss 157.833038,Time used 0.007002s\n",
      "batch 4272, train_loss 195.584122,Time used 0.005999s\n",
      "batch 4273, train_loss 107.588242,Time used 0.008001s\n",
      "batch 4274, train_loss 129.002289,Time used 0.007999s\n",
      "batch 4275, train_loss 182.428452,Time used 0.007002s\n",
      "batch 4276, train_loss 187.839752,Time used 0.006004s\n",
      "batch 4277, train_loss 167.181442,Time used 0.006996s\n",
      "batch 4278, train_loss 143.584930,Time used 0.009003s\n",
      "batch 4279, train_loss 166.229202,Time used 0.010995s\n",
      "batch 4280, train_loss 138.406082,Time used 0.011004s\n",
      "batch 4281, train_loss 170.049057,Time used 0.010999s\n",
      "batch 4282, train_loss 129.072281,Time used 0.010996s\n",
      "batch 4283, train_loss 185.337891,Time used 0.011024s\n",
      "batch 4284, train_loss 144.849258,Time used 0.010001s\n",
      "batch 4285, train_loss 140.028931,Time used 0.010962s\n",
      "batch 4286, train_loss 133.836594,Time used 0.007999s\n",
      "batch 4287, train_loss 153.068848,Time used 0.007997s\n",
      "batch 4288, train_loss 159.425491,Time used 0.007000s\n",
      "batch 4289, train_loss 139.530685,Time used 0.007036s\n",
      "batch 4290, train_loss 155.314651,Time used 0.007965s\n",
      "batch 4291, train_loss 115.617516,Time used 0.009003s\n",
      "batch 4292, train_loss 169.138565,Time used 0.007997s\n",
      "batch 4293, train_loss 180.403824,Time used 0.008000s\n",
      "batch 4294, train_loss 117.097855,Time used 0.008001s\n",
      "batch 4295, train_loss 171.492996,Time used 0.011001s\n",
      "batch 4296, train_loss 148.157257,Time used 0.007001s\n",
      "batch 4297, train_loss 113.501404,Time used 0.008001s\n",
      "batch 4298, train_loss 172.397308,Time used 0.011001s\n",
      "batch 4299, train_loss 129.444595,Time used 0.009003s\n",
      "batch 4300, train_loss 123.319473,Time used 0.010001s\n",
      "***************************test_batch 4300, test_rmse_loss 14.040289,test_mae_loss 5.356996,test_mape_loss 69.153589,Time used 0.031997s\n",
      "batch 4301, train_loss 160.379105,Time used 0.007000s\n",
      "batch 4302, train_loss 139.242355,Time used 0.008005s\n",
      "batch 4303, train_loss 147.556229,Time used 0.010994s\n",
      "batch 4304, train_loss 131.009140,Time used 0.006999s\n",
      "batch 4305, train_loss 140.045090,Time used 0.008002s\n",
      "batch 4306, train_loss 177.356949,Time used 0.011000s\n",
      "batch 4307, train_loss 144.730469,Time used 0.008000s\n",
      "batch 4308, train_loss 141.316177,Time used 0.007001s\n",
      "batch 4309, train_loss 184.947296,Time used 0.011001s\n",
      "batch 4310, train_loss 167.233292,Time used 0.009001s\n",
      "batch 4311, train_loss 161.918854,Time used 0.008002s\n",
      "batch 4312, train_loss 135.850693,Time used 0.008997s\n",
      "batch 4313, train_loss 137.936996,Time used 0.006999s\n",
      "batch 4314, train_loss 165.401230,Time used 0.008002s\n",
      "batch 4315, train_loss 163.690567,Time used 0.006999s\n",
      "batch 4316, train_loss 152.754303,Time used 0.008998s\n",
      "batch 4317, train_loss 158.339828,Time used 0.010003s\n",
      "batch 4318, train_loss 158.336060,Time used 0.008999s\n",
      "batch 4319, train_loss 150.172577,Time used 0.007000s\n",
      "batch 4320, train_loss 163.426804,Time used 0.008005s\n",
      "batch 4321, train_loss 130.740509,Time used 0.007002s\n",
      "batch 4322, train_loss 171.182907,Time used 0.007999s\n",
      "batch 4323, train_loss 117.195999,Time used 0.006999s\n",
      "batch 4324, train_loss 161.929016,Time used 0.007000s\n",
      "batch 4325, train_loss 109.212860,Time used 0.007000s\n",
      "batch 4326, train_loss 128.253235,Time used 0.008000s\n",
      "batch 4327, train_loss 186.770920,Time used 0.007002s\n",
      "batch 4328, train_loss 159.744751,Time used 0.006998s\n",
      "batch 4329, train_loss 136.064575,Time used 0.008002s\n",
      "batch 4330, train_loss 166.882156,Time used 0.008999s\n",
      "batch 4331, train_loss 168.337387,Time used 0.008999s\n",
      "batch 4332, train_loss 134.296829,Time used 0.010999s\n",
      "batch 4333, train_loss 140.260361,Time used 0.007001s\n",
      "batch 4334, train_loss 159.282349,Time used 0.008001s\n",
      "batch 4335, train_loss 172.297882,Time used 0.007999s\n",
      "batch 4336, train_loss 190.041855,Time used 0.009000s\n",
      "batch 4337, train_loss 144.865219,Time used 0.008997s\n",
      "batch 4338, train_loss 138.161453,Time used 0.010002s\n",
      "batch 4339, train_loss 129.554337,Time used 0.010997s\n",
      "batch 4340, train_loss 149.391983,Time used 0.011000s\n",
      "batch 4341, train_loss 160.666824,Time used 0.010004s\n",
      "batch 4342, train_loss 175.763290,Time used 0.007996s\n",
      "batch 4343, train_loss 116.073036,Time used 0.006999s\n",
      "batch 4344, train_loss 158.181732,Time used 0.007000s\n",
      "batch 4345, train_loss 175.463989,Time used 0.006997s\n",
      "batch 4346, train_loss 160.541718,Time used 0.009001s\n",
      "batch 4347, train_loss 198.253769,Time used 0.007000s\n",
      "batch 4348, train_loss 176.388245,Time used 0.008003s\n",
      "batch 4349, train_loss 137.349091,Time used 0.008004s\n",
      "batch 4350, train_loss 154.118591,Time used 0.009994s\n",
      "batch 4351, train_loss 159.533035,Time used 0.007003s\n",
      "batch 4352, train_loss 154.149292,Time used 0.007999s\n",
      "batch 4353, train_loss 142.183426,Time used 0.008002s\n",
      "batch 4354, train_loss 136.024567,Time used 0.011001s\n",
      "batch 4355, train_loss 153.516556,Time used 0.009001s\n",
      "batch 4356, train_loss 184.631042,Time used 0.007998s\n",
      "batch 4357, train_loss 180.321075,Time used 0.007001s\n",
      "batch 4358, train_loss 103.598930,Time used 0.011002s\n",
      "batch 4359, train_loss 141.551712,Time used 0.009999s\n",
      "batch 4360, train_loss 132.761963,Time used 0.008000s\n",
      "batch 4361, train_loss 118.658203,Time used 0.007002s\n",
      "batch 4362, train_loss 110.089645,Time used 0.007000s\n",
      "batch 4363, train_loss 159.235443,Time used 0.007002s\n",
      "batch 4364, train_loss 113.865067,Time used 0.010998s\n",
      "batch 4365, train_loss 138.633408,Time used 0.011002s\n",
      "batch 4366, train_loss 134.638107,Time used 0.007997s\n",
      "batch 4367, train_loss 169.930908,Time used 0.007001s\n",
      "batch 4368, train_loss 154.814560,Time used 0.007000s\n",
      "batch 4369, train_loss 132.556412,Time used 0.008003s\n",
      "batch 4370, train_loss 127.854591,Time used 0.006998s\n",
      "batch 4371, train_loss 177.500763,Time used 0.008999s\n",
      "batch 4372, train_loss 144.402527,Time used 0.007001s\n",
      "batch 4373, train_loss 127.822121,Time used 0.007999s\n",
      "batch 4374, train_loss 186.805328,Time used 0.006999s\n",
      "batch 4375, train_loss 155.405960,Time used 0.009001s\n",
      "batch 4376, train_loss 180.674637,Time used 0.006998s\n",
      "batch 4377, train_loss 131.394684,Time used 0.007000s\n",
      "batch 4378, train_loss 147.872177,Time used 0.006000s\n",
      "batch 4379, train_loss 134.040878,Time used 0.009000s\n",
      "batch 4380, train_loss 132.767792,Time used 0.011000s\n",
      "batch 4381, train_loss 128.442719,Time used 0.009996s\n",
      "batch 4382, train_loss 154.437378,Time used 0.009003s\n",
      "batch 4383, train_loss 148.129501,Time used 0.009996s\n",
      "batch 4384, train_loss 157.103409,Time used 0.011001s\n",
      "batch 4385, train_loss 124.290276,Time used 0.010002s\n",
      "batch 4386, train_loss 169.877426,Time used 0.011001s\n",
      "batch 4387, train_loss 154.495224,Time used 0.010997s\n",
      "batch 4388, train_loss 171.840393,Time used 0.010003s\n",
      "batch 4389, train_loss 167.269684,Time used 0.010999s\n",
      "batch 4390, train_loss 161.332184,Time used 0.007998s\n",
      "batch 4391, train_loss 131.604553,Time used 0.009001s\n",
      "batch 4392, train_loss 126.412666,Time used 0.007004s\n",
      "batch 4393, train_loss 145.437485,Time used 0.009999s\n",
      "batch 4394, train_loss 148.977524,Time used 0.012001s\n",
      "batch 4395, train_loss 158.764160,Time used 0.010999s\n",
      "batch 4396, train_loss 122.690437,Time used 0.010000s\n",
      "batch 4397, train_loss 154.321396,Time used 0.009002s\n",
      "batch 4398, train_loss 111.878632,Time used 0.006999s\n",
      "batch 4399, train_loss 128.116776,Time used 0.009000s\n",
      "batch 4400, train_loss 147.025131,Time used 0.007999s\n",
      "***************************test_batch 4400, test_rmse_loss 13.926679,test_mae_loss 5.309097,test_mape_loss 68.563317,Time used 0.041001s\n",
      "batch 4401, train_loss 150.216568,Time used 0.011001s\n",
      "batch 4402, train_loss 134.487259,Time used 0.008001s\n",
      "batch 4403, train_loss 141.380127,Time used 0.011998s\n",
      "batch 4404, train_loss 172.486252,Time used 0.008001s\n",
      "batch 4405, train_loss 125.399742,Time used 0.006999s\n",
      "batch 4406, train_loss 161.706100,Time used 0.006999s\n",
      "batch 4407, train_loss 206.911209,Time used 0.007999s\n",
      "batch 4408, train_loss 191.222595,Time used 0.007000s\n",
      "batch 4409, train_loss 187.837967,Time used 0.009001s\n",
      "batch 4410, train_loss 121.862053,Time used 0.011000s\n",
      "batch 4411, train_loss 111.658028,Time used 0.008000s\n",
      "batch 4412, train_loss 141.488159,Time used 0.007000s\n",
      "batch 4413, train_loss 148.615799,Time used 0.011000s\n",
      "batch 4414, train_loss 111.788437,Time used 0.010001s\n",
      "batch 4415, train_loss 159.542465,Time used 0.007001s\n",
      "batch 4416, train_loss 177.966156,Time used 0.008006s\n",
      "batch 4417, train_loss 132.773895,Time used 0.008000s\n",
      "batch 4418, train_loss 191.085083,Time used 0.007999s\n",
      "batch 4419, train_loss 131.884735,Time used 0.009002s\n",
      "batch 4420, train_loss 183.744736,Time used 0.009999s\n",
      "batch 4421, train_loss 127.322121,Time used 0.008001s\n",
      "batch 4422, train_loss 157.395752,Time used 0.006999s\n",
      "batch 4423, train_loss 131.335159,Time used 0.009002s\n",
      "batch 4424, train_loss 154.382446,Time used 0.008996s\n",
      "batch 4425, train_loss 130.102310,Time used 0.007001s\n",
      "batch 4426, train_loss 150.190292,Time used 0.007006s\n",
      "batch 4427, train_loss 171.812332,Time used 0.006998s\n",
      "batch 4428, train_loss 156.140350,Time used 0.007999s\n",
      "batch 4429, train_loss 127.655449,Time used 0.007000s\n",
      "batch 4430, train_loss 153.804077,Time used 0.007999s\n",
      "batch 4431, train_loss 158.404846,Time used 0.006999s\n",
      "batch 4432, train_loss 126.426842,Time used 0.007000s\n",
      "batch 4433, train_loss 136.594528,Time used 0.007000s\n",
      "batch 4434, train_loss 152.949051,Time used 0.007002s\n",
      "batch 4435, train_loss 158.955597,Time used 0.007999s\n",
      "batch 4436, train_loss 125.017143,Time used 0.007002s\n",
      "batch 4437, train_loss 139.622406,Time used 0.008998s\n",
      "batch 4438, train_loss 151.161316,Time used 0.008003s\n",
      "batch 4439, train_loss 138.280197,Time used 0.009998s\n",
      "batch 4440, train_loss 159.503174,Time used 0.007000s\n",
      "batch 4441, train_loss 157.305145,Time used 0.010002s\n",
      "batch 4442, train_loss 126.518356,Time used 0.012002s\n",
      "batch 4443, train_loss 148.126572,Time used 0.012001s\n",
      "batch 4444, train_loss 115.088539,Time used 0.010996s\n",
      "batch 4445, train_loss 132.683929,Time used 0.009002s\n",
      "batch 4446, train_loss 155.339905,Time used 0.010000s\n",
      "batch 4447, train_loss 154.093689,Time used 0.007001s\n",
      "batch 4448, train_loss 131.819336,Time used 0.006999s\n",
      "batch 4449, train_loss 150.823349,Time used 0.009001s\n",
      "batch 4450, train_loss 134.332443,Time used 0.012001s\n",
      "batch 4451, train_loss 137.736557,Time used 0.007997s\n",
      "batch 4452, train_loss 125.519020,Time used 0.007999s\n",
      "batch 4453, train_loss 173.736816,Time used 0.007001s\n",
      "batch 4454, train_loss 184.984741,Time used 0.006999s\n",
      "batch 4455, train_loss 177.996445,Time used 0.008001s\n",
      "batch 4456, train_loss 151.739120,Time used 0.007001s\n",
      "batch 4457, train_loss 137.359909,Time used 0.008999s\n",
      "batch 4458, train_loss 131.870895,Time used 0.008998s\n",
      "batch 4459, train_loss 143.196640,Time used 0.007999s\n",
      "batch 4460, train_loss 151.746719,Time used 0.007002s\n",
      "batch 4461, train_loss 159.194962,Time used 0.009001s\n",
      "batch 4462, train_loss 168.547745,Time used 0.009000s\n",
      "batch 4463, train_loss 143.348267,Time used 0.007999s\n",
      "batch 4464, train_loss 138.190277,Time used 0.007001s\n",
      "batch 4465, train_loss 141.358871,Time used 0.010998s\n",
      "batch 4466, train_loss 138.541992,Time used 0.008000s\n",
      "batch 4467, train_loss 101.151482,Time used 0.007000s\n",
      "batch 4468, train_loss 112.006905,Time used 0.007003s\n",
      "batch 4469, train_loss 140.883865,Time used 0.008999s\n",
      "batch 4470, train_loss 124.160973,Time used 0.007000s\n",
      "batch 4471, train_loss 155.845688,Time used 0.008002s\n",
      "batch 4472, train_loss 134.637024,Time used 0.006999s\n",
      "batch 4473, train_loss 204.134796,Time used 0.006999s\n",
      "batch 4474, train_loss 138.267731,Time used 0.006999s\n",
      "batch 4475, train_loss 157.151688,Time used 0.007001s\n",
      "batch 4476, train_loss 147.347900,Time used 0.008001s\n",
      "batch 4477, train_loss 120.537262,Time used 0.006998s\n",
      "batch 4478, train_loss 134.334000,Time used 0.008000s\n",
      "batch 4479, train_loss 173.072937,Time used 0.007001s\n",
      "batch 4480, train_loss 173.695007,Time used 0.008998s\n",
      "batch 4481, train_loss 134.795044,Time used 0.007000s\n",
      "batch 4482, train_loss 161.648880,Time used 0.009003s\n",
      "batch 4483, train_loss 136.182617,Time used 0.006997s\n",
      "batch 4484, train_loss 125.897598,Time used 0.009998s\n",
      "batch 4485, train_loss 195.225403,Time used 0.010000s\n",
      "batch 4486, train_loss 154.257935,Time used 0.010000s\n",
      "batch 4487, train_loss 181.927383,Time used 0.009002s\n",
      "batch 4488, train_loss 129.720810,Time used 0.009000s\n",
      "batch 4489, train_loss 159.782227,Time used 0.007001s\n",
      "batch 4490, train_loss 135.098969,Time used 0.009997s\n",
      "batch 4491, train_loss 150.908539,Time used 0.009001s\n",
      "batch 4492, train_loss 142.818634,Time used 0.010002s\n",
      "batch 4493, train_loss 137.377182,Time used 0.009999s\n",
      "batch 4494, train_loss 190.764938,Time used 0.008002s\n",
      "batch 4495, train_loss 143.639023,Time used 0.007999s\n",
      "batch 4496, train_loss 119.219299,Time used 0.007000s\n",
      "batch 4497, train_loss 147.814102,Time used 0.008999s\n",
      "batch 4498, train_loss 175.687683,Time used 0.007000s\n",
      "batch 4499, train_loss 156.100586,Time used 0.010000s\n",
      "batch 4500, train_loss 148.612152,Time used 0.008006s\n",
      "***************************test_batch 4500, test_rmse_loss 13.812856,test_mae_loss 5.266472,test_mape_loss 68.677580,Time used 0.029001s\n",
      "batch 4501, train_loss 151.011673,Time used 0.011002s\n",
      "batch 4502, train_loss 147.151413,Time used 0.009997s\n",
      "batch 4503, train_loss 184.642075,Time used 0.011000s\n",
      "batch 4504, train_loss 102.618538,Time used 0.010001s\n",
      "batch 4505, train_loss 115.689995,Time used 0.016999s\n",
      "batch 4506, train_loss 171.512283,Time used 0.009999s\n",
      "batch 4507, train_loss 139.392441,Time used 0.010001s\n",
      "batch 4508, train_loss 134.571121,Time used 0.012002s\n",
      "batch 4509, train_loss 146.283035,Time used 0.011000s\n",
      "batch 4510, train_loss 153.088791,Time used 0.012997s\n",
      "batch 4511, train_loss 132.984970,Time used 0.013001s\n",
      "batch 4512, train_loss 115.301010,Time used 0.007999s\n",
      "batch 4513, train_loss 174.283340,Time used 0.008000s\n",
      "batch 4514, train_loss 171.542816,Time used 0.010002s\n",
      "batch 4515, train_loss 151.519287,Time used 0.009997s\n",
      "batch 4516, train_loss 183.804352,Time used 0.011000s\n",
      "batch 4517, train_loss 148.878220,Time used 0.010000s\n",
      "batch 4518, train_loss 154.090042,Time used 0.009998s\n",
      "batch 4519, train_loss 102.649277,Time used 0.012001s\n",
      "batch 4520, train_loss 167.162003,Time used 0.007999s\n",
      "batch 4521, train_loss 130.825043,Time used 0.009001s\n",
      "batch 4522, train_loss 130.037949,Time used 0.010997s\n",
      "batch 4523, train_loss 129.797897,Time used 0.007003s\n",
      "batch 4524, train_loss 138.811020,Time used 0.007999s\n",
      "batch 4525, train_loss 143.545868,Time used 0.009001s\n",
      "batch 4526, train_loss 125.949532,Time used 0.009001s\n",
      "batch 4527, train_loss 167.880066,Time used 0.006998s\n",
      "batch 4528, train_loss 190.595764,Time used 0.008001s\n",
      "batch 4529, train_loss 126.282806,Time used 0.006999s\n",
      "batch 4530, train_loss 138.641693,Time used 0.007000s\n",
      "batch 4531, train_loss 123.470253,Time used 0.010000s\n",
      "batch 4532, train_loss 151.231400,Time used 0.008001s\n",
      "batch 4533, train_loss 128.310471,Time used 0.006998s\n",
      "batch 4534, train_loss 136.260010,Time used 0.007001s\n",
      "batch 4535, train_loss 106.419701,Time used 0.007001s\n",
      "batch 4536, train_loss 167.849350,Time used 0.007999s\n",
      "batch 4537, train_loss 175.961746,Time used 0.007999s\n",
      "batch 4538, train_loss 154.510757,Time used 0.008994s\n",
      "batch 4539, train_loss 168.003967,Time used 0.011002s\n",
      "batch 4540, train_loss 177.257446,Time used 0.007999s\n",
      "batch 4541, train_loss 149.376511,Time used 0.007999s\n",
      "batch 4542, train_loss 144.432159,Time used 0.007002s\n",
      "batch 4543, train_loss 135.573853,Time used 0.007999s\n",
      "batch 4544, train_loss 159.597153,Time used 0.006997s\n",
      "batch 4545, train_loss 131.365234,Time used 0.007001s\n",
      "batch 4546, train_loss 141.066879,Time used 0.007998s\n",
      "batch 4547, train_loss 154.556366,Time used 0.010002s\n",
      "batch 4548, train_loss 119.048386,Time used 0.010999s\n",
      "batch 4549, train_loss 205.353836,Time used 0.012002s\n",
      "batch 4550, train_loss 175.877914,Time used 0.009000s\n",
      "batch 4551, train_loss 102.153519,Time used 0.007999s\n",
      "batch 4552, train_loss 110.915764,Time used 0.010000s\n",
      "batch 4553, train_loss 143.678101,Time used 0.006999s\n",
      "batch 4554, train_loss 103.714005,Time used 0.008000s\n",
      "batch 4555, train_loss 107.602379,Time used 0.006999s\n",
      "batch 4556, train_loss 122.080978,Time used 0.007001s\n",
      "batch 4557, train_loss 142.323837,Time used 0.006999s\n",
      "batch 4558, train_loss 146.800949,Time used 0.007005s\n",
      "batch 4559, train_loss 156.646347,Time used 0.010997s\n",
      "batch 4560, train_loss 147.195724,Time used 0.010001s\n",
      "batch 4561, train_loss 147.081879,Time used 0.008000s\n",
      "batch 4562, train_loss 163.099838,Time used 0.014000s\n",
      "batch 4563, train_loss 151.277878,Time used 0.011001s\n",
      "batch 4564, train_loss 127.861351,Time used 0.008001s\n",
      "batch 4565, train_loss 105.796616,Time used 0.016001s\n",
      "batch 4566, train_loss 193.431946,Time used 0.013001s\n",
      "batch 4567, train_loss 130.174561,Time used 0.013001s\n",
      "batch 4568, train_loss 172.970474,Time used 0.013001s\n",
      "batch 4569, train_loss 148.333282,Time used 0.010998s\n",
      "batch 4570, train_loss 153.181244,Time used 0.011000s\n",
      "batch 4571, train_loss 198.980362,Time used 0.010999s\n",
      "batch 4572, train_loss 151.732513,Time used 0.008002s\n",
      "batch 4573, train_loss 109.403877,Time used 0.010999s\n",
      "batch 4574, train_loss 113.617615,Time used 0.010998s\n",
      "batch 4575, train_loss 118.591003,Time used 0.009001s\n",
      "batch 4576, train_loss 140.214951,Time used 0.010001s\n",
      "batch 4577, train_loss 146.513962,Time used 0.010999s\n",
      "batch 4578, train_loss 124.845581,Time used 0.011002s\n",
      "batch 4579, train_loss 166.501480,Time used 0.010999s\n",
      "batch 4580, train_loss 132.541260,Time used 0.012000s\n",
      "batch 4581, train_loss 125.140724,Time used 0.012000s\n",
      "batch 4582, train_loss 128.917389,Time used 0.007998s\n",
      "batch 4583, train_loss 164.489990,Time used 0.011003s\n",
      "batch 4584, train_loss 146.356400,Time used 0.010999s\n",
      "batch 4585, train_loss 158.584290,Time used 0.013999s\n",
      "batch 4586, train_loss 180.928802,Time used 0.015001s\n",
      "batch 4587, train_loss 140.048691,Time used 0.022000s\n",
      "batch 4588, train_loss 121.254044,Time used 0.010000s\n",
      "batch 4589, train_loss 143.741608,Time used 0.011000s\n",
      "batch 4590, train_loss 138.681702,Time used 0.009002s\n",
      "batch 4591, train_loss 152.245255,Time used 0.011998s\n",
      "batch 4592, train_loss 141.405731,Time used 0.011999s\n",
      "batch 4593, train_loss 167.411438,Time used 0.010000s\n",
      "batch 4594, train_loss 116.216942,Time used 0.014001s\n",
      "batch 4595, train_loss 122.295830,Time used 0.013000s\n",
      "batch 4596, train_loss 152.244522,Time used 0.009999s\n",
      "batch 4597, train_loss 127.343628,Time used 0.008999s\n",
      "batch 4598, train_loss 145.179169,Time used 0.011000s\n",
      "batch 4599, train_loss 148.476685,Time used 0.012001s\n",
      "batch 4600, train_loss 148.125412,Time used 0.010999s\n",
      "***************************test_batch 4600, test_rmse_loss 13.701792,test_mae_loss 5.224529,test_mape_loss 68.581001,Time used 0.045999s\n",
      "batch 4601, train_loss 180.510284,Time used 0.011001s\n",
      "batch 4602, train_loss 168.419724,Time used 0.006999s\n",
      "batch 4603, train_loss 145.511917,Time used 0.006999s\n",
      "batch 4604, train_loss 156.806808,Time used 0.008002s\n",
      "batch 4605, train_loss 95.727791,Time used 0.008999s\n",
      "batch 4606, train_loss 119.618980,Time used 0.007000s\n",
      "batch 4607, train_loss 116.318619,Time used 0.007999s\n",
      "batch 4608, train_loss 160.737579,Time used 0.007001s\n",
      "batch 4609, train_loss 173.118103,Time used 0.007997s\n",
      "batch 4610, train_loss 166.084366,Time used 0.009000s\n",
      "batch 4611, train_loss 202.095169,Time used 0.012001s\n",
      "batch 4612, train_loss 154.239304,Time used 0.010998s\n",
      "batch 4613, train_loss 135.773315,Time used 0.011001s\n",
      "batch 4614, train_loss 106.993401,Time used 0.010006s\n",
      "batch 4615, train_loss 148.724487,Time used 0.010998s\n",
      "batch 4616, train_loss 157.740906,Time used 0.007999s\n",
      "batch 4617, train_loss 155.216324,Time used 0.008002s\n",
      "batch 4618, train_loss 136.295837,Time used 0.006993s\n",
      "batch 4619, train_loss 108.214340,Time used 0.011006s\n",
      "batch 4620, train_loss 124.196068,Time used 0.010996s\n",
      "batch 4621, train_loss 156.854370,Time used 0.010000s\n",
      "batch 4622, train_loss 119.042480,Time used 0.006999s\n",
      "batch 4623, train_loss 156.025726,Time used 0.006998s\n",
      "batch 4624, train_loss 137.670837,Time used 0.007999s\n",
      "batch 4625, train_loss 167.959229,Time used 0.009997s\n",
      "batch 4626, train_loss 152.243469,Time used 0.009003s\n",
      "batch 4627, train_loss 119.574478,Time used 0.007995s\n",
      "batch 4628, train_loss 118.534119,Time used 0.010005s\n",
      "batch 4629, train_loss 126.506241,Time used 0.006998s\n",
      "batch 4630, train_loss 149.606262,Time used 0.008000s\n",
      "batch 4631, train_loss 118.076744,Time used 0.007999s\n",
      "batch 4632, train_loss 142.700836,Time used 0.010001s\n",
      "batch 4633, train_loss 169.575134,Time used 0.010998s\n",
      "batch 4634, train_loss 147.587250,Time used 0.010005s\n",
      "batch 4635, train_loss 111.315071,Time used 0.006998s\n",
      "batch 4636, train_loss 134.579803,Time used 0.006999s\n",
      "batch 4637, train_loss 136.975632,Time used 0.006999s\n",
      "batch 4638, train_loss 171.448898,Time used 0.006999s\n",
      "batch 4639, train_loss 130.512009,Time used 0.012003s\n",
      "batch 4640, train_loss 120.555504,Time used 0.008999s\n",
      "batch 4641, train_loss 154.960739,Time used 0.007000s\n",
      "batch 4642, train_loss 128.836716,Time used 0.008002s\n",
      "batch 4643, train_loss 177.079681,Time used 0.009998s\n",
      "batch 4644, train_loss 111.065971,Time used 0.009006s\n",
      "batch 4645, train_loss 122.036491,Time used 0.010000s\n",
      "batch 4646, train_loss 172.375961,Time used 0.008999s\n",
      "batch 4647, train_loss 123.442757,Time used 0.009033s\n",
      "batch 4648, train_loss 139.958145,Time used 0.008001s\n",
      "batch 4649, train_loss 166.910492,Time used 0.010964s\n",
      "batch 4650, train_loss 140.650635,Time used 0.007034s\n",
      "batch 4651, train_loss 141.488495,Time used 0.006966s\n",
      "batch 4652, train_loss 127.771942,Time used 0.006995s\n",
      "batch 4653, train_loss 113.265106,Time used 0.009970s\n",
      "batch 4654, train_loss 176.485489,Time used 0.006997s\n",
      "batch 4655, train_loss 153.018692,Time used 0.009037s\n",
      "batch 4656, train_loss 147.962067,Time used 0.006963s\n",
      "batch 4657, train_loss 142.920029,Time used 0.009001s\n",
      "batch 4658, train_loss 165.702805,Time used 0.006999s\n",
      "batch 4659, train_loss 138.282364,Time used 0.007000s\n",
      "batch 4660, train_loss 157.983505,Time used 0.006999s\n",
      "batch 4661, train_loss 169.545532,Time used 0.008001s\n",
      "batch 4662, train_loss 150.812927,Time used 0.008003s\n",
      "batch 4663, train_loss 138.113144,Time used 0.007997s\n",
      "batch 4664, train_loss 148.471970,Time used 0.007000s\n",
      "batch 4665, train_loss 148.988312,Time used 0.009036s\n",
      "batch 4666, train_loss 99.905693,Time used 0.006965s\n",
      "batch 4667, train_loss 130.659027,Time used 0.008001s\n",
      "batch 4668, train_loss 176.895767,Time used 0.008000s\n",
      "batch 4669, train_loss 144.286133,Time used 0.008001s\n",
      "batch 4670, train_loss 108.680054,Time used 0.010998s\n",
      "batch 4671, train_loss 140.488998,Time used 0.008003s\n",
      "batch 4672, train_loss 111.902130,Time used 0.007998s\n",
      "batch 4673, train_loss 139.496994,Time used 0.010002s\n",
      "batch 4674, train_loss 122.223953,Time used 0.007999s\n",
      "batch 4675, train_loss 134.439285,Time used 0.006999s\n",
      "batch 4676, train_loss 171.390915,Time used 0.008000s\n",
      "batch 4677, train_loss 182.752777,Time used 0.009001s\n",
      "batch 4678, train_loss 119.997231,Time used 0.007001s\n",
      "batch 4679, train_loss 112.467079,Time used 0.007000s\n",
      "batch 4680, train_loss 150.085114,Time used 0.006000s\n",
      "batch 4681, train_loss 136.054276,Time used 0.010998s\n",
      "batch 4682, train_loss 140.694122,Time used 0.009001s\n",
      "batch 4683, train_loss 152.096725,Time used 0.010000s\n",
      "batch 4684, train_loss 125.429337,Time used 0.008998s\n",
      "batch 4685, train_loss 129.696777,Time used 0.006001s\n",
      "batch 4686, train_loss 171.311356,Time used 0.006998s\n",
      "batch 4687, train_loss 129.162247,Time used 0.007000s\n",
      "batch 4688, train_loss 148.101990,Time used 0.010000s\n",
      "batch 4689, train_loss 137.441315,Time used 0.007001s\n",
      "batch 4690, train_loss 190.420776,Time used 0.006999s\n",
      "batch 4691, train_loss 95.026604,Time used 0.006001s\n",
      "batch 4692, train_loss 154.000366,Time used 0.007004s\n",
      "batch 4693, train_loss 157.387680,Time used 0.006999s\n",
      "batch 4694, train_loss 124.396843,Time used 0.009000s\n",
      "batch 4695, train_loss 123.292419,Time used 0.006998s\n",
      "batch 4696, train_loss 129.881744,Time used 0.008000s\n",
      "batch 4697, train_loss 138.274170,Time used 0.009001s\n",
      "batch 4698, train_loss 139.274124,Time used 0.008000s\n",
      "batch 4699, train_loss 171.865158,Time used 0.008001s\n",
      "batch 4700, train_loss 120.420761,Time used 0.007000s\n",
      "***************************test_batch 4700, test_rmse_loss 13.592565,test_mae_loss 5.182932,test_mape_loss 68.454025,Time used 0.032998s\n",
      "batch 4701, train_loss 168.906342,Time used 0.011002s\n",
      "batch 4702, train_loss 111.449547,Time used 0.008000s\n",
      "batch 4703, train_loss 118.917992,Time used 0.009998s\n",
      "batch 4704, train_loss 180.703964,Time used 0.007000s\n",
      "batch 4705, train_loss 152.606644,Time used 0.006999s\n",
      "batch 4706, train_loss 133.644180,Time used 0.009998s\n",
      "batch 4707, train_loss 101.953941,Time used 0.011002s\n",
      "batch 4708, train_loss 164.839005,Time used 0.011000s\n",
      "batch 4709, train_loss 143.176361,Time used 0.006999s\n",
      "batch 4710, train_loss 138.303589,Time used 0.007000s\n",
      "batch 4711, train_loss 144.941299,Time used 0.010004s\n",
      "batch 4712, train_loss 154.355026,Time used 0.010998s\n",
      "batch 4713, train_loss 131.413834,Time used 0.010998s\n",
      "batch 4714, train_loss 124.389053,Time used 0.011003s\n",
      "batch 4715, train_loss 152.090439,Time used 0.007000s\n",
      "batch 4716, train_loss 159.707535,Time used 0.007999s\n",
      "batch 4717, train_loss 109.806473,Time used 0.007000s\n",
      "batch 4718, train_loss 124.795425,Time used 0.010001s\n",
      "batch 4719, train_loss 120.162704,Time used 0.007999s\n",
      "batch 4720, train_loss 146.885788,Time used 0.008001s\n",
      "batch 4721, train_loss 146.379059,Time used 0.009996s\n",
      "batch 4722, train_loss 149.481140,Time used 0.007000s\n",
      "batch 4723, train_loss 127.976814,Time used 0.009000s\n",
      "batch 4724, train_loss 175.490784,Time used 0.008002s\n",
      "batch 4725, train_loss 132.239502,Time used 0.009000s\n",
      "batch 4726, train_loss 151.203186,Time used 0.007000s\n",
      "batch 4727, train_loss 157.303101,Time used 0.010999s\n",
      "batch 4728, train_loss 135.803543,Time used 0.009999s\n",
      "batch 4729, train_loss 133.967987,Time used 0.010001s\n",
      "batch 4730, train_loss 143.450470,Time used 0.011000s\n",
      "batch 4731, train_loss 147.920212,Time used 0.006998s\n",
      "batch 4732, train_loss 165.699112,Time used 0.007001s\n",
      "batch 4733, train_loss 147.683365,Time used 0.012000s\n",
      "batch 4734, train_loss 116.697189,Time used 0.009999s\n",
      "batch 4735, train_loss 161.486267,Time used 0.011003s\n",
      "batch 4736, train_loss 129.626053,Time used 0.009998s\n",
      "batch 4737, train_loss 143.155380,Time used 0.009000s\n",
      "batch 4738, train_loss 149.225128,Time used 0.009002s\n",
      "batch 4739, train_loss 161.287292,Time used 0.009999s\n",
      "batch 4740, train_loss 138.415619,Time used 0.006998s\n",
      "batch 4741, train_loss 110.607849,Time used 0.008001s\n",
      "batch 4742, train_loss 174.151733,Time used 0.007000s\n",
      "batch 4743, train_loss 109.993225,Time used 0.007999s\n",
      "batch 4744, train_loss 120.555031,Time used 0.008000s\n",
      "batch 4745, train_loss 133.024582,Time used 0.007000s\n",
      "batch 4746, train_loss 145.798950,Time used 0.009001s\n",
      "batch 4747, train_loss 96.306702,Time used 0.011997s\n",
      "batch 4748, train_loss 150.387360,Time used 0.009001s\n",
      "batch 4749, train_loss 126.732346,Time used 0.007001s\n",
      "batch 4750, train_loss 153.844498,Time used 0.006999s\n",
      "batch 4751, train_loss 133.589859,Time used 0.009998s\n",
      "batch 4752, train_loss 173.595703,Time used 0.008002s\n",
      "batch 4753, train_loss 115.513390,Time used 0.008000s\n",
      "batch 4754, train_loss 144.543930,Time used 0.007000s\n",
      "batch 4755, train_loss 156.744675,Time used 0.007002s\n",
      "batch 4756, train_loss 124.560776,Time used 0.007001s\n",
      "batch 4757, train_loss 138.446365,Time used 0.006999s\n",
      "batch 4758, train_loss 148.275436,Time used 0.009000s\n",
      "batch 4759, train_loss 157.692230,Time used 0.007004s\n",
      "batch 4760, train_loss 133.063507,Time used 0.006999s\n",
      "batch 4761, train_loss 155.546478,Time used 0.009035s\n",
      "batch 4762, train_loss 137.277863,Time used 0.007965s\n",
      "batch 4763, train_loss 142.657928,Time used 0.011000s\n",
      "batch 4764, train_loss 184.726624,Time used 0.012002s\n",
      "batch 4765, train_loss 183.902039,Time used 0.010999s\n",
      "batch 4766, train_loss 149.339981,Time used 0.008003s\n",
      "batch 4767, train_loss 102.266846,Time used 0.007998s\n",
      "batch 4768, train_loss 108.309166,Time used 0.011002s\n",
      "batch 4769, train_loss 143.886978,Time used 0.011998s\n",
      "batch 4770, train_loss 175.769287,Time used 0.007001s\n",
      "batch 4771, train_loss 139.806717,Time used 0.009000s\n",
      "batch 4772, train_loss 132.877411,Time used 0.006999s\n",
      "batch 4773, train_loss 131.601120,Time used 0.008001s\n",
      "batch 4774, train_loss 107.449821,Time used 0.009000s\n",
      "batch 4775, train_loss 124.489998,Time used 0.010996s\n",
      "batch 4776, train_loss 112.997070,Time used 0.006999s\n",
      "batch 4777, train_loss 183.482758,Time used 0.014000s\n",
      "batch 4778, train_loss 120.099548,Time used 0.010007s\n",
      "batch 4779, train_loss 137.514496,Time used 0.010995s\n",
      "batch 4780, train_loss 146.470078,Time used 0.009000s\n",
      "batch 4781, train_loss 147.113785,Time used 0.012000s\n",
      "batch 4782, train_loss 161.478012,Time used 0.011999s\n",
      "batch 4783, train_loss 117.654991,Time used 0.011002s\n",
      "batch 4784, train_loss 145.325851,Time used 0.010000s\n",
      "batch 4785, train_loss 146.889526,Time used 0.011001s\n",
      "batch 4786, train_loss 114.359489,Time used 0.011999s\n",
      "batch 4787, train_loss 152.303452,Time used 0.012001s\n",
      "batch 4788, train_loss 135.351715,Time used 0.011001s\n",
      "batch 4789, train_loss 127.789558,Time used 0.008000s\n",
      "batch 4790, train_loss 124.802124,Time used 0.011998s\n",
      "batch 4791, train_loss 144.528091,Time used 0.011999s\n",
      "batch 4792, train_loss 129.959412,Time used 0.011003s\n",
      "batch 4793, train_loss 130.702499,Time used 0.012000s\n",
      "batch 4794, train_loss 145.141159,Time used 0.010001s\n",
      "batch 4795, train_loss 139.850418,Time used 0.009997s\n",
      "batch 4796, train_loss 134.608902,Time used 0.012002s\n",
      "batch 4797, train_loss 191.940857,Time used 0.009001s\n",
      "batch 4798, train_loss 124.116486,Time used 0.011999s\n",
      "batch 4799, train_loss 108.638123,Time used 0.012001s\n",
      "batch 4800, train_loss 128.961456,Time used 0.014001s\n",
      "***************************test_batch 4800, test_rmse_loss 13.486069,test_mae_loss 5.142780,test_mape_loss 68.296229,Time used 0.058002s\n",
      "batch 4801, train_loss 120.611603,Time used 0.010000s\n",
      "batch 4802, train_loss 157.025452,Time used 0.010000s\n",
      "batch 4803, train_loss 124.030212,Time used 0.010002s\n",
      "batch 4804, train_loss 141.220535,Time used 0.015002s\n",
      "batch 4805, train_loss 147.707779,Time used 0.016998s\n",
      "batch 4806, train_loss 106.474190,Time used 0.013001s\n",
      "batch 4807, train_loss 205.780090,Time used 0.011999s\n",
      "batch 4808, train_loss 160.329697,Time used 0.011001s\n",
      "batch 4809, train_loss 131.327499,Time used 0.013003s\n",
      "batch 4810, train_loss 128.219513,Time used 0.012996s\n",
      "batch 4811, train_loss 125.116066,Time used 0.011000s\n",
      "batch 4812, train_loss 91.220825,Time used 0.010002s\n",
      "batch 4813, train_loss 131.681564,Time used 0.006997s\n",
      "batch 4814, train_loss 148.267166,Time used 0.008000s\n",
      "batch 4815, train_loss 128.481644,Time used 0.011000s\n",
      "batch 4816, train_loss 143.035385,Time used 0.009000s\n",
      "batch 4817, train_loss 104.268593,Time used 0.007001s\n",
      "batch 4818, train_loss 136.294113,Time used 0.007000s\n",
      "batch 4819, train_loss 170.220215,Time used 0.008001s\n",
      "batch 4820, train_loss 138.610611,Time used 0.012000s\n",
      "batch 4821, train_loss 123.869492,Time used 0.011003s\n",
      "batch 4822, train_loss 144.437759,Time used 0.013002s\n",
      "batch 4823, train_loss 139.713593,Time used 0.010999s\n",
      "batch 4824, train_loss 180.020264,Time used 0.008000s\n",
      "batch 4825, train_loss 139.497910,Time used 0.010999s\n",
      "batch 4826, train_loss 128.312943,Time used 0.011999s\n",
      "batch 4827, train_loss 146.645309,Time used 0.009000s\n",
      "batch 4828, train_loss 159.544632,Time used 0.010999s\n",
      "batch 4829, train_loss 114.545341,Time used 0.010000s\n",
      "batch 4830, train_loss 182.853790,Time used 0.012000s\n",
      "batch 4831, train_loss 104.828545,Time used 0.012010s\n",
      "batch 4832, train_loss 154.654556,Time used 0.011001s\n",
      "batch 4833, train_loss 157.233551,Time used 0.019000s\n",
      "batch 4834, train_loss 187.839905,Time used 0.013004s\n",
      "batch 4835, train_loss 127.709923,Time used 0.013000s\n",
      "batch 4836, train_loss 106.391357,Time used 0.015000s\n",
      "batch 4837, train_loss 182.511230,Time used 0.010999s\n",
      "batch 4838, train_loss 159.915634,Time used 0.010999s\n",
      "batch 4839, train_loss 115.269218,Time used 0.012003s\n",
      "batch 4840, train_loss 119.027573,Time used 0.012997s\n",
      "batch 4841, train_loss 129.652206,Time used 0.011002s\n",
      "batch 4842, train_loss 103.712364,Time used 0.013003s\n",
      "batch 4843, train_loss 104.308250,Time used 0.016997s\n",
      "batch 4844, train_loss 199.528625,Time used 0.022001s\n",
      "batch 4845, train_loss 130.992737,Time used 0.013000s\n",
      "batch 4846, train_loss 120.489220,Time used 0.014000s\n",
      "batch 4847, train_loss 125.761703,Time used 0.015999s\n",
      "batch 4848, train_loss 111.279129,Time used 0.015002s\n",
      "batch 4849, train_loss 166.680618,Time used 0.012000s\n",
      "batch 4850, train_loss 123.015549,Time used 0.011002s\n",
      "batch 4851, train_loss 156.860062,Time used 0.010997s\n",
      "batch 4852, train_loss 148.749344,Time used 0.010003s\n",
      "batch 4853, train_loss 156.778427,Time used 0.011000s\n",
      "batch 4854, train_loss 131.797989,Time used 0.012000s\n",
      "batch 4855, train_loss 147.215668,Time used 0.010999s\n",
      "batch 4856, train_loss 127.051888,Time used 0.011000s\n",
      "batch 4857, train_loss 129.773483,Time used 0.012001s\n",
      "batch 4858, train_loss 151.933945,Time used 0.011002s\n",
      "batch 4859, train_loss 153.227707,Time used 0.012000s\n",
      "batch 4860, train_loss 130.478012,Time used 0.008000s\n",
      "batch 4861, train_loss 138.700104,Time used 0.007000s\n",
      "batch 4862, train_loss 162.907227,Time used 0.007004s\n",
      "batch 4863, train_loss 118.904190,Time used 0.008997s\n",
      "batch 4864, train_loss 148.165390,Time used 0.008000s\n",
      "batch 4865, train_loss 127.545296,Time used 0.009999s\n",
      "batch 4866, train_loss 104.186195,Time used 0.007003s\n",
      "batch 4867, train_loss 151.763504,Time used 0.012000s\n",
      "batch 4868, train_loss 147.323029,Time used 0.009999s\n",
      "batch 4869, train_loss 108.404076,Time used 0.009000s\n",
      "batch 4870, train_loss 94.090088,Time used 0.007000s\n",
      "batch 4871, train_loss 128.832703,Time used 0.007001s\n",
      "batch 4872, train_loss 146.565353,Time used 0.009000s\n",
      "batch 4873, train_loss 131.578903,Time used 0.010000s\n",
      "batch 4874, train_loss 114.584831,Time used 0.009999s\n",
      "batch 4875, train_loss 114.908081,Time used 0.011001s\n",
      "batch 4876, train_loss 146.954132,Time used 0.012000s\n",
      "batch 4877, train_loss 147.878769,Time used 0.009999s\n",
      "batch 4878, train_loss 184.911514,Time used 0.011002s\n",
      "batch 4879, train_loss 151.519226,Time used 0.010000s\n",
      "batch 4880, train_loss 124.684570,Time used 0.009999s\n",
      "batch 4881, train_loss 124.401764,Time used 0.009001s\n",
      "batch 4882, train_loss 113.410332,Time used 0.011000s\n",
      "batch 4883, train_loss 138.886749,Time used 0.011997s\n",
      "batch 4884, train_loss 142.514465,Time used 0.012001s\n",
      "batch 4885, train_loss 147.296280,Time used 0.011004s\n",
      "batch 4886, train_loss 144.500885,Time used 0.008997s\n",
      "batch 4887, train_loss 100.270996,Time used 0.009000s\n",
      "batch 4888, train_loss 118.559822,Time used 0.010999s\n",
      "batch 4889, train_loss 146.259186,Time used 0.012001s\n",
      "batch 4890, train_loss 151.498505,Time used 0.011001s\n",
      "batch 4891, train_loss 139.254211,Time used 0.010002s\n",
      "batch 4892, train_loss 139.889587,Time used 0.011001s\n",
      "batch 4893, train_loss 169.771194,Time used 0.012997s\n",
      "batch 4894, train_loss 139.766174,Time used 0.013000s\n",
      "batch 4895, train_loss 131.117706,Time used 0.014003s\n",
      "batch 4896, train_loss 122.826447,Time used 0.024001s\n",
      "batch 4897, train_loss 117.720207,Time used 0.011994s\n",
      "batch 4898, train_loss 143.723373,Time used 0.012998s\n",
      "batch 4899, train_loss 145.088547,Time used 0.015002s\n",
      "batch 4900, train_loss 136.620575,Time used 0.014001s\n",
      "***************************test_batch 4900, test_rmse_loss 13.381856,test_mae_loss 5.104099,test_mape_loss 68.102838,Time used 0.052000s\n",
      "batch 4901, train_loss 158.004807,Time used 0.012002s\n",
      "batch 4902, train_loss 136.801208,Time used 0.011998s\n",
      "batch 4903, train_loss 125.374748,Time used 0.012001s\n",
      "batch 4904, train_loss 122.963737,Time used 0.011000s\n",
      "batch 4905, train_loss 117.711060,Time used 0.012001s\n",
      "batch 4906, train_loss 104.403145,Time used 0.008998s\n",
      "batch 4907, train_loss 150.838730,Time used 0.010998s\n",
      "batch 4908, train_loss 107.830505,Time used 0.007001s\n",
      "batch 4909, train_loss 167.778595,Time used 0.008000s\n",
      "batch 4910, train_loss 156.684586,Time used 0.007000s\n",
      "batch 4911, train_loss 123.192917,Time used 0.010998s\n",
      "batch 4912, train_loss 139.250656,Time used 0.008002s\n",
      "batch 4913, train_loss 111.632797,Time used 0.011998s\n",
      "batch 4914, train_loss 150.885971,Time used 0.008001s\n",
      "batch 4915, train_loss 162.104904,Time used 0.007000s\n",
      "batch 4916, train_loss 153.043350,Time used 0.009999s\n",
      "batch 4917, train_loss 135.823334,Time used 0.011003s\n",
      "batch 4918, train_loss 130.515991,Time used 0.009998s\n",
      "batch 4919, train_loss 160.273804,Time used 0.007000s\n",
      "batch 4920, train_loss 116.018448,Time used 0.008003s\n",
      "batch 4921, train_loss 122.501945,Time used 0.008001s\n",
      "batch 4922, train_loss 78.680038,Time used 0.008002s\n",
      "batch 4923, train_loss 165.142670,Time used 0.014002s\n",
      "batch 4924, train_loss 139.493668,Time used 0.011998s\n",
      "batch 4925, train_loss 134.989761,Time used 0.011000s\n",
      "batch 4926, train_loss 173.216797,Time used 0.012000s\n",
      "batch 4927, train_loss 120.319572,Time used 0.015999s\n",
      "batch 4928, train_loss 142.867462,Time used 0.011002s\n",
      "batch 4929, train_loss 150.157639,Time used 0.010001s\n",
      "batch 4930, train_loss 141.859604,Time used 0.012998s\n",
      "batch 4931, train_loss 130.249680,Time used 0.011997s\n",
      "batch 4932, train_loss 130.282669,Time used 0.012003s\n",
      "batch 4933, train_loss 109.969261,Time used 0.011002s\n",
      "batch 4934, train_loss 112.232292,Time used 0.011000s\n",
      "batch 4935, train_loss 143.411057,Time used 0.009000s\n",
      "batch 4936, train_loss 128.681488,Time used 0.011998s\n",
      "batch 4937, train_loss 101.456200,Time used 0.010999s\n",
      "batch 4938, train_loss 152.443573,Time used 0.013002s\n",
      "batch 4939, train_loss 130.303665,Time used 0.011999s\n",
      "batch 4940, train_loss 120.431282,Time used 0.011001s\n",
      "batch 4941, train_loss 167.171432,Time used 0.011998s\n",
      "batch 4942, train_loss 136.921722,Time used 0.011002s\n",
      "batch 4943, train_loss 120.013481,Time used 0.014001s\n",
      "batch 4944, train_loss 212.547165,Time used 0.010999s\n",
      "batch 4945, train_loss 141.527664,Time used 0.015000s\n",
      "batch 4946, train_loss 94.998581,Time used 0.023001s\n",
      "batch 4947, train_loss 137.856247,Time used 0.011999s\n",
      "batch 4948, train_loss 103.515724,Time used 0.009998s\n",
      "batch 4949, train_loss 140.539185,Time used 0.012001s\n",
      "batch 4950, train_loss 145.810959,Time used 0.007999s\n",
      "batch 4951, train_loss 171.365952,Time used 0.011002s\n",
      "batch 4952, train_loss 131.645996,Time used 0.007999s\n",
      "batch 4953, train_loss 121.891983,Time used 0.010000s\n",
      "batch 4954, train_loss 147.871780,Time used 0.009999s\n",
      "batch 4955, train_loss 102.269920,Time used 0.011999s\n",
      "batch 4956, train_loss 148.353226,Time used 0.011001s\n",
      "batch 4957, train_loss 132.922928,Time used 0.010999s\n",
      "batch 4958, train_loss 154.047470,Time used 0.012001s\n",
      "batch 4959, train_loss 104.419289,Time used 0.012999s\n",
      "batch 4960, train_loss 129.780090,Time used 0.011001s\n",
      "batch 4961, train_loss 160.688507,Time used 0.010999s\n",
      "batch 4962, train_loss 147.748764,Time used 0.011001s\n",
      "batch 4963, train_loss 98.031120,Time used 0.009001s\n",
      "batch 4964, train_loss 172.156479,Time used 0.008999s\n",
      "batch 4965, train_loss 168.915268,Time used 0.008001s\n",
      "batch 4966, train_loss 138.031906,Time used 0.007000s\n",
      "batch 4967, train_loss 120.122131,Time used 0.007000s\n",
      "batch 4968, train_loss 135.355392,Time used 0.009000s\n",
      "batch 4969, train_loss 111.612831,Time used 0.009001s\n",
      "batch 4970, train_loss 178.759903,Time used 0.008000s\n",
      "batch 4971, train_loss 134.418823,Time used 0.008999s\n",
      "batch 4972, train_loss 109.999969,Time used 0.008001s\n",
      "batch 4973, train_loss 156.748245,Time used 0.009000s\n",
      "batch 4974, train_loss 144.013885,Time used 0.010000s\n",
      "batch 4975, train_loss 152.492096,Time used 0.010998s\n",
      "batch 4976, train_loss 138.146240,Time used 0.011002s\n",
      "batch 4977, train_loss 135.282562,Time used 0.011999s\n",
      "batch 4978, train_loss 114.687904,Time used 0.013002s\n",
      "batch 4979, train_loss 140.813995,Time used 0.012003s\n",
      "batch 4980, train_loss 141.888382,Time used 0.013998s\n",
      "batch 4981, train_loss 115.415413,Time used 0.015000s\n",
      "batch 4982, train_loss 161.944382,Time used 0.013000s\n",
      "batch 4983, train_loss 83.026398,Time used 0.012002s\n",
      "batch 4984, train_loss 125.292030,Time used 0.012001s\n",
      "batch 4985, train_loss 130.721527,Time used 0.012002s\n",
      "batch 4986, train_loss 145.949020,Time used 0.010998s\n",
      "batch 4987, train_loss 149.030167,Time used 0.011001s\n",
      "batch 4988, train_loss 127.398254,Time used 0.011999s\n",
      "batch 4989, train_loss 111.266907,Time used 0.013002s\n",
      "batch 4990, train_loss 161.136932,Time used 0.010998s\n",
      "batch 4991, train_loss 144.771194,Time used 0.011000s\n",
      "batch 4992, train_loss 122.146072,Time used 0.011002s\n",
      "batch 4993, train_loss 148.013519,Time used 0.012000s\n",
      "batch 4994, train_loss 107.946968,Time used 0.013000s\n",
      "batch 4995, train_loss 129.169815,Time used 0.013999s\n",
      "batch 4996, train_loss 140.607620,Time used 0.030001s\n",
      "batch 4997, train_loss 135.572113,Time used 0.014000s\n",
      "batch 4998, train_loss 119.331879,Time used 0.009000s\n",
      "batch 4999, train_loss 144.693115,Time used 0.011993s\n",
      "batch 5000, train_loss 141.991302,Time used 0.013002s\n",
      "***************************test_batch 5000, test_rmse_loss 13.276908,test_mae_loss 5.068022,test_mape_loss 68.302607,Time used 0.046002s\n",
      "batch 5001, train_loss 147.779343,Time used 0.012998s\n",
      "batch 5002, train_loss 169.801086,Time used 0.013000s\n",
      "batch 5003, train_loss 138.141953,Time used 0.012001s\n",
      "batch 5004, train_loss 130.454605,Time used 0.012998s\n",
      "batch 5005, train_loss 121.069572,Time used 0.015004s\n",
      "batch 5006, train_loss 127.409920,Time used 0.013000s\n",
      "batch 5007, train_loss 122.745995,Time used 0.015006s\n",
      "batch 5008, train_loss 134.957581,Time used 0.011995s\n",
      "batch 5009, train_loss 137.220917,Time used 0.009998s\n",
      "batch 5010, train_loss 135.218033,Time used 0.009001s\n",
      "batch 5011, train_loss 170.811813,Time used 0.011999s\n",
      "batch 5012, train_loss 151.756470,Time used 0.010002s\n",
      "batch 5013, train_loss 120.586891,Time used 0.008000s\n",
      "batch 5014, train_loss 96.176979,Time used 0.008000s\n",
      "batch 5015, train_loss 139.162949,Time used 0.009000s\n",
      "batch 5016, train_loss 113.586243,Time used 0.013999s\n",
      "batch 5017, train_loss 159.827393,Time used 0.011999s\n",
      "batch 5018, train_loss 126.111252,Time used 0.011001s\n",
      "batch 5019, train_loss 135.039032,Time used 0.011000s\n",
      "batch 5020, train_loss 134.565430,Time used 0.010998s\n",
      "batch 5021, train_loss 130.718872,Time used 0.009000s\n",
      "batch 5022, train_loss 143.308075,Time used 0.010999s\n",
      "batch 5023, train_loss 163.107376,Time used 0.011001s\n",
      "batch 5024, train_loss 134.350937,Time used 0.010999s\n",
      "batch 5025, train_loss 148.843552,Time used 0.011000s\n",
      "batch 5026, train_loss 125.562416,Time used 0.009999s\n",
      "batch 5027, train_loss 135.143890,Time used 0.010999s\n",
      "batch 5028, train_loss 108.019142,Time used 0.009998s\n",
      "batch 5029, train_loss 127.061981,Time used 0.010001s\n",
      "batch 5030, train_loss 161.276672,Time used 0.011003s\n",
      "batch 5031, train_loss 141.809357,Time used 0.010999s\n",
      "batch 5032, train_loss 115.968590,Time used 0.011999s\n",
      "batch 5033, train_loss 108.628822,Time used 0.009007s\n",
      "batch 5034, train_loss 121.585587,Time used 0.011994s\n",
      "batch 5035, train_loss 157.660492,Time used 0.010000s\n",
      "batch 5036, train_loss 146.134933,Time used 0.010999s\n",
      "batch 5037, train_loss 127.074059,Time used 0.010000s\n",
      "batch 5038, train_loss 126.216583,Time used 0.010003s\n",
      "batch 5039, train_loss 121.111580,Time used 0.014999s\n",
      "batch 5040, train_loss 112.753510,Time used 0.023000s\n",
      "batch 5041, train_loss 113.565010,Time used 0.011998s\n",
      "batch 5042, train_loss 116.650482,Time used 0.012004s\n",
      "batch 5043, train_loss 186.050430,Time used 0.011996s\n",
      "batch 5044, train_loss 161.826645,Time used 0.010000s\n",
      "batch 5045, train_loss 139.986267,Time used 0.007999s\n",
      "batch 5046, train_loss 106.636604,Time used 0.010001s\n",
      "batch 5047, train_loss 108.504173,Time used 0.010002s\n",
      "batch 5048, train_loss 108.471779,Time used 0.009998s\n",
      "batch 5049, train_loss 106.103981,Time used 0.011002s\n",
      "batch 5050, train_loss 130.112305,Time used 0.012002s\n",
      "batch 5051, train_loss 116.910133,Time used 0.010001s\n",
      "batch 5052, train_loss 133.648895,Time used 0.011999s\n",
      "batch 5053, train_loss 150.311050,Time used 0.012001s\n",
      "batch 5054, train_loss 166.897919,Time used 0.012002s\n",
      "batch 5055, train_loss 148.586639,Time used 0.012000s\n",
      "batch 5056, train_loss 133.013092,Time used 0.016000s\n",
      "batch 5057, train_loss 133.660416,Time used 0.014999s\n",
      "batch 5058, train_loss 117.321991,Time used 0.012000s\n",
      "batch 5059, train_loss 153.119873,Time used 0.012005s\n",
      "batch 5060, train_loss 119.354279,Time used 0.009999s\n",
      "batch 5061, train_loss 134.421997,Time used 0.013001s\n",
      "batch 5062, train_loss 150.281113,Time used 0.011002s\n",
      "batch 5063, train_loss 128.465668,Time used 0.014003s\n",
      "batch 5064, train_loss 136.639343,Time used 0.016998s\n",
      "batch 5065, train_loss 109.542305,Time used 0.012001s\n",
      "batch 5066, train_loss 142.010925,Time used 0.013001s\n",
      "batch 5067, train_loss 156.111374,Time used 0.013000s\n",
      "batch 5068, train_loss 122.190193,Time used 0.013000s\n",
      "batch 5069, train_loss 107.323174,Time used 0.013996s\n",
      "batch 5070, train_loss 126.111191,Time used 0.013003s\n",
      "batch 5071, train_loss 136.779724,Time used 0.014004s\n",
      "batch 5072, train_loss 149.144379,Time used 0.031001s\n",
      "batch 5073, train_loss 113.478027,Time used 0.016000s\n",
      "batch 5074, train_loss 132.480179,Time used 0.015000s\n",
      "batch 5075, train_loss 75.484787,Time used 0.013000s\n",
      "batch 5076, train_loss 117.832802,Time used 0.016002s\n",
      "batch 5077, train_loss 206.948288,Time used 0.023998s\n",
      "batch 5078, train_loss 131.176163,Time used 0.014001s\n",
      "batch 5079, train_loss 126.935722,Time used 0.011999s\n",
      "batch 5080, train_loss 136.487350,Time used 0.010998s\n",
      "batch 5081, train_loss 146.259766,Time used 0.013001s\n",
      "batch 5082, train_loss 150.230530,Time used 0.010999s\n",
      "batch 5083, train_loss 114.284187,Time used 0.018997s\n",
      "batch 5084, train_loss 134.459976,Time used 0.012001s\n",
      "batch 5085, train_loss 154.876480,Time used 0.012002s\n",
      "batch 5086, train_loss 163.981155,Time used 0.012999s\n",
      "batch 5087, train_loss 121.734901,Time used 0.014001s\n",
      "batch 5088, train_loss 111.636642,Time used 0.018000s\n",
      "batch 5089, train_loss 132.618317,Time used 0.012001s\n",
      "batch 5090, train_loss 150.546387,Time used 0.013999s\n",
      "batch 5091, train_loss 143.897171,Time used 0.012998s\n",
      "batch 5092, train_loss 131.447449,Time used 0.007001s\n",
      "batch 5093, train_loss 135.352631,Time used 0.008997s\n",
      "batch 5094, train_loss 98.791916,Time used 0.012001s\n",
      "batch 5095, train_loss 128.101334,Time used 0.013000s\n",
      "batch 5096, train_loss 119.137512,Time used 0.008001s\n",
      "batch 5097, train_loss 104.112701,Time used 0.011001s\n",
      "batch 5098, train_loss 152.447479,Time used 0.011001s\n",
      "batch 5099, train_loss 153.045715,Time used 0.009001s\n",
      "batch 5100, train_loss 131.632370,Time used 0.010000s\n",
      "***************************test_batch 5100, test_rmse_loss 13.178133,test_mae_loss 5.029077,test_mape_loss 67.751176,Time used 0.032999s\n",
      "batch 5101, train_loss 147.395157,Time used 0.011003s\n",
      "batch 5102, train_loss 120.638069,Time used 0.010000s\n",
      "batch 5103, train_loss 103.178452,Time used 0.014999s\n",
      "batch 5104, train_loss 134.090607,Time used 0.011001s\n",
      "batch 5105, train_loss 139.480255,Time used 0.010000s\n",
      "batch 5106, train_loss 162.175674,Time used 0.012002s\n",
      "batch 5107, train_loss 139.132843,Time used 0.011999s\n",
      "batch 5108, train_loss 106.927155,Time used 0.009000s\n",
      "batch 5109, train_loss 149.691986,Time used 0.012001s\n",
      "batch 5110, train_loss 123.359314,Time used 0.022002s\n",
      "batch 5111, train_loss 109.729759,Time used 0.016997s\n",
      "batch 5112, train_loss 160.482574,Time used 0.014001s\n",
      "batch 5113, train_loss 141.344315,Time used 0.015999s\n",
      "batch 5114, train_loss 145.349380,Time used 0.012000s\n",
      "batch 5115, train_loss 171.593338,Time used 0.014001s\n",
      "batch 5116, train_loss 96.632507,Time used 0.013010s\n",
      "batch 5117, train_loss 111.690399,Time used 0.021990s\n",
      "batch 5118, train_loss 120.813766,Time used 0.012001s\n",
      "batch 5119, train_loss 130.177475,Time used 0.012999s\n",
      "batch 5120, train_loss 125.780678,Time used 0.012001s\n",
      "batch 5121, train_loss 116.831360,Time used 0.012000s\n",
      "batch 5122, train_loss 94.924057,Time used 0.014999s\n",
      "batch 5123, train_loss 147.366135,Time used 0.019000s\n",
      "batch 5124, train_loss 129.733688,Time used 0.022001s\n",
      "batch 5125, train_loss 114.221214,Time used 0.014999s\n",
      "batch 5126, train_loss 164.781464,Time used 0.013000s\n",
      "batch 5127, train_loss 148.227768,Time used 0.012999s\n",
      "batch 5128, train_loss 155.166794,Time used 0.014000s\n",
      "batch 5129, train_loss 146.296524,Time used 0.016000s\n",
      "batch 5130, train_loss 109.693344,Time used 0.014000s\n",
      "batch 5131, train_loss 123.624969,Time used 0.015000s\n",
      "batch 5132, train_loss 115.199104,Time used 0.012001s\n",
      "batch 5133, train_loss 158.490509,Time used 0.011000s\n",
      "batch 5134, train_loss 180.624939,Time used 0.012001s\n",
      "batch 5135, train_loss 96.057007,Time used 0.011000s\n",
      "batch 5136, train_loss 119.176582,Time used 0.011003s\n",
      "batch 5137, train_loss 128.056625,Time used 0.013999s\n",
      "batch 5138, train_loss 151.177002,Time used 0.010996s\n",
      "batch 5139, train_loss 105.145134,Time used 0.014004s\n",
      "batch 5140, train_loss 121.552910,Time used 0.008996s\n",
      "batch 5141, train_loss 120.931923,Time used 0.009003s\n",
      "batch 5142, train_loss 134.151642,Time used 0.009001s\n",
      "batch 5143, train_loss 113.125015,Time used 0.011001s\n",
      "batch 5144, train_loss 109.004318,Time used 0.010000s\n",
      "batch 5145, train_loss 159.353485,Time used 0.012000s\n",
      "batch 5146, train_loss 141.476730,Time used 0.012999s\n",
      "batch 5147, train_loss 113.177917,Time used 0.009004s\n",
      "batch 5148, train_loss 181.180008,Time used 0.017997s\n",
      "batch 5149, train_loss 158.492020,Time used 0.012000s\n",
      "batch 5150, train_loss 134.007401,Time used 0.011998s\n",
      "batch 5151, train_loss 124.013145,Time used 0.011002s\n",
      "batch 5152, train_loss 119.620117,Time used 0.011999s\n",
      "batch 5153, train_loss 172.609772,Time used 0.012001s\n",
      "batch 5154, train_loss 119.643707,Time used 0.015999s\n",
      "batch 5155, train_loss 120.819199,Time used 0.014001s\n",
      "batch 5156, train_loss 119.602997,Time used 0.012000s\n",
      "batch 5157, train_loss 111.204529,Time used 0.025001s\n",
      "batch 5158, train_loss 143.270142,Time used 0.041001s\n",
      "batch 5159, train_loss 122.881409,Time used 0.012000s\n",
      "batch 5160, train_loss 127.676315,Time used 0.017001s\n",
      "batch 5161, train_loss 127.397034,Time used 0.012996s\n",
      "batch 5162, train_loss 170.535507,Time used 0.012000s\n",
      "batch 5163, train_loss 125.360855,Time used 0.012001s\n",
      "batch 5164, train_loss 146.425415,Time used 0.017000s\n",
      "batch 5165, train_loss 93.530663,Time used 0.013999s\n",
      "batch 5166, train_loss 154.204422,Time used 0.024001s\n",
      "batch 5167, train_loss 162.043137,Time used 0.014000s\n",
      "batch 5168, train_loss 135.593628,Time used 0.014000s\n",
      "batch 5169, train_loss 140.231705,Time used 0.013000s\n",
      "batch 5170, train_loss 116.517326,Time used 0.016001s\n",
      "batch 5171, train_loss 151.421036,Time used 0.021001s\n",
      "batch 5172, train_loss 116.959129,Time used 0.018999s\n",
      "batch 5173, train_loss 116.578255,Time used 0.010999s\n",
      "batch 5174, train_loss 93.289192,Time used 0.010999s\n",
      "batch 5175, train_loss 146.952423,Time used 0.012000s\n",
      "batch 5176, train_loss 127.203522,Time used 0.013000s\n",
      "batch 5177, train_loss 124.942245,Time used 0.012999s\n",
      "batch 5178, train_loss 134.920197,Time used 0.013002s\n",
      "batch 5179, train_loss 103.365334,Time used 0.012000s\n",
      "batch 5180, train_loss 110.304207,Time used 0.013000s\n",
      "batch 5181, train_loss 141.436768,Time used 0.013001s\n",
      "batch 5182, train_loss 151.786377,Time used 0.007999s\n",
      "batch 5183, train_loss 102.881271,Time used 0.012000s\n",
      "batch 5184, train_loss 147.172333,Time used 0.011999s\n",
      "batch 5185, train_loss 132.659790,Time used 0.011000s\n",
      "batch 5186, train_loss 113.062912,Time used 0.012000s\n",
      "batch 5187, train_loss 154.943985,Time used 0.017999s\n",
      "batch 5188, train_loss 139.387726,Time used 0.011999s\n",
      "batch 5189, train_loss 77.814178,Time used 0.012002s\n",
      "batch 5190, train_loss 120.208649,Time used 0.013006s\n",
      "batch 5191, train_loss 112.957306,Time used 0.014001s\n",
      "batch 5192, train_loss 120.981102,Time used 0.049004s\n",
      "batch 5193, train_loss 133.831467,Time used 0.014999s\n",
      "batch 5194, train_loss 125.966690,Time used 0.014000s\n",
      "batch 5195, train_loss 118.216370,Time used 0.012001s\n",
      "batch 5196, train_loss 138.550797,Time used 0.014000s\n",
      "batch 5197, train_loss 152.432800,Time used 0.012001s\n",
      "batch 5198, train_loss 128.591263,Time used 0.013999s\n",
      "batch 5199, train_loss 120.688179,Time used 0.015000s\n",
      "batch 5200, train_loss 160.821228,Time used 0.013000s\n",
      "***************************test_batch 5200, test_rmse_loss 13.076626,test_mae_loss 4.995656,test_mape_loss 67.971991,Time used 0.064001s\n",
      "batch 5201, train_loss 96.645676,Time used 0.031000s\n",
      "batch 5202, train_loss 133.159470,Time used 0.023998s\n",
      "batch 5203, train_loss 98.381157,Time used 0.011998s\n",
      "batch 5204, train_loss 144.837158,Time used 0.014000s\n",
      "batch 5205, train_loss 169.526352,Time used 0.020000s\n",
      "batch 5206, train_loss 144.508423,Time used 0.013999s\n",
      "batch 5207, train_loss 127.837433,Time used 0.012999s\n",
      "batch 5208, train_loss 163.885208,Time used 0.013002s\n",
      "batch 5209, train_loss 146.411301,Time used 0.015000s\n",
      "batch 5210, train_loss 127.016090,Time used 0.013003s\n",
      "batch 5211, train_loss 142.310120,Time used 0.015001s\n",
      "batch 5212, train_loss 101.303215,Time used 0.017000s\n",
      "batch 5213, train_loss 137.464188,Time used 0.011997s\n",
      "batch 5214, train_loss 197.290207,Time used 0.012001s\n",
      "batch 5215, train_loss 137.604599,Time used 0.012001s\n",
      "batch 5216, train_loss 112.826355,Time used 0.013000s\n",
      "batch 5217, train_loss 121.917046,Time used 0.011000s\n",
      "batch 5218, train_loss 138.428589,Time used 0.008998s\n",
      "batch 5219, train_loss 137.130753,Time used 0.011003s\n",
      "batch 5220, train_loss 147.802719,Time used 0.010997s\n",
      "batch 5221, train_loss 130.622528,Time used 0.007999s\n",
      "batch 5222, train_loss 114.309586,Time used 0.008999s\n",
      "batch 5223, train_loss 142.933777,Time used 0.011002s\n",
      "batch 5224, train_loss 131.083893,Time used 0.010001s\n",
      "batch 5225, train_loss 84.480270,Time used 0.011000s\n",
      "batch 5226, train_loss 107.928818,Time used 0.010999s\n",
      "batch 5227, train_loss 137.855087,Time used 0.010001s\n",
      "batch 5228, train_loss 95.334335,Time used 0.010997s\n",
      "batch 5229, train_loss 130.795197,Time used 0.009001s\n",
      "batch 5230, train_loss 112.177498,Time used 0.010001s\n",
      "batch 5231, train_loss 147.008865,Time used 0.006999s\n",
      "batch 5232, train_loss 135.299072,Time used 0.008000s\n",
      "batch 5233, train_loss 136.884979,Time used 0.009000s\n",
      "batch 5234, train_loss 115.192940,Time used 0.006999s\n",
      "batch 5235, train_loss 125.118805,Time used 0.009001s\n",
      "batch 5236, train_loss 148.876709,Time used 0.011998s\n",
      "batch 5237, train_loss 146.145325,Time used 0.007001s\n",
      "batch 5238, train_loss 100.125397,Time used 0.008000s\n",
      "batch 5239, train_loss 123.307335,Time used 0.010998s\n",
      "batch 5240, train_loss 136.909775,Time used 0.009002s\n",
      "batch 5241, train_loss 160.816025,Time used 0.007999s\n",
      "batch 5242, train_loss 142.861298,Time used 0.008999s\n",
      "batch 5243, train_loss 110.363319,Time used 0.008000s\n",
      "batch 5244, train_loss 123.142235,Time used 0.007999s\n",
      "batch 5245, train_loss 129.529190,Time used 0.011003s\n",
      "batch 5246, train_loss 137.200790,Time used 0.011000s\n",
      "batch 5247, train_loss 136.607452,Time used 0.008999s\n",
      "batch 5248, train_loss 123.084846,Time used 0.011000s\n",
      "batch 5249, train_loss 99.302864,Time used 0.007999s\n",
      "batch 5250, train_loss 143.527054,Time used 0.008001s\n",
      "batch 5251, train_loss 117.603378,Time used 0.008000s\n",
      "batch 5252, train_loss 106.569153,Time used 0.007000s\n",
      "batch 5253, train_loss 145.835510,Time used 0.010998s\n",
      "batch 5254, train_loss 107.850677,Time used 0.007000s\n",
      "batch 5255, train_loss 161.752487,Time used 0.008001s\n",
      "batch 5256, train_loss 126.592049,Time used 0.006999s\n",
      "batch 5257, train_loss 129.632843,Time used 0.008001s\n",
      "batch 5258, train_loss 127.058403,Time used 0.008000s\n",
      "batch 5259, train_loss 131.239395,Time used 0.010998s\n",
      "batch 5260, train_loss 154.103058,Time used 0.010008s\n",
      "batch 5261, train_loss 156.707001,Time used 0.009992s\n",
      "batch 5262, train_loss 139.585785,Time used 0.008001s\n",
      "batch 5263, train_loss 117.209167,Time used 0.010999s\n",
      "batch 5264, train_loss 127.279778,Time used 0.008001s\n",
      "batch 5265, train_loss 129.302322,Time used 0.009999s\n",
      "batch 5266, train_loss 154.129318,Time used 0.006999s\n",
      "batch 5267, train_loss 122.436234,Time used 0.010002s\n",
      "batch 5268, train_loss 132.504318,Time used 0.009997s\n",
      "batch 5269, train_loss 100.779427,Time used 0.011000s\n",
      "batch 5270, train_loss 104.077583,Time used 0.009998s\n",
      "batch 5271, train_loss 157.128952,Time used 0.007005s\n",
      "batch 5272, train_loss 136.022202,Time used 0.008996s\n",
      "batch 5273, train_loss 118.273361,Time used 0.007001s\n",
      "batch 5274, train_loss 131.061584,Time used 0.009000s\n",
      "batch 5275, train_loss 101.311462,Time used 0.007003s\n",
      "batch 5276, train_loss 126.312645,Time used 0.010996s\n",
      "batch 5277, train_loss 122.053284,Time used 0.008003s\n",
      "batch 5278, train_loss 125.965698,Time used 0.007998s\n",
      "batch 5279, train_loss 121.940765,Time used 0.008003s\n",
      "batch 5280, train_loss 127.707642,Time used 0.007999s\n",
      "batch 5281, train_loss 145.402924,Time used 0.009002s\n",
      "batch 5282, train_loss 169.261353,Time used 0.006999s\n",
      "batch 5283, train_loss 147.439011,Time used 0.010001s\n",
      "batch 5284, train_loss 148.296570,Time used 0.010000s\n",
      "batch 5285, train_loss 127.800636,Time used 0.010999s\n",
      "batch 5286, train_loss 126.370773,Time used 0.007002s\n",
      "batch 5287, train_loss 98.944054,Time used 0.007001s\n",
      "batch 5288, train_loss 137.975647,Time used 0.007000s\n",
      "batch 5289, train_loss 130.855408,Time used 0.006999s\n",
      "batch 5290, train_loss 121.332405,Time used 0.006998s\n",
      "batch 5291, train_loss 127.489906,Time used 0.007003s\n",
      "batch 5292, train_loss 124.937454,Time used 0.006997s\n",
      "batch 5293, train_loss 111.873665,Time used 0.006999s\n",
      "batch 5294, train_loss 104.886002,Time used 0.009002s\n",
      "batch 5295, train_loss 141.836792,Time used 0.007999s\n",
      "batch 5296, train_loss 124.507408,Time used 0.010002s\n",
      "batch 5297, train_loss 139.883911,Time used 0.007998s\n",
      "batch 5298, train_loss 109.122169,Time used 0.010997s\n",
      "batch 5299, train_loss 130.077362,Time used 0.008999s\n",
      "batch 5300, train_loss 129.674713,Time used 0.007001s\n",
      "***************************test_batch 5300, test_rmse_loss 12.978959,test_mae_loss 4.960598,test_mape_loss 67.837310,Time used 0.030001s\n",
      "batch 5301, train_loss 128.540604,Time used 0.008967s\n",
      "batch 5302, train_loss 97.396095,Time used 0.010006s\n",
      "batch 5303, train_loss 129.605881,Time used 0.010996s\n",
      "batch 5304, train_loss 128.858353,Time used 0.008001s\n",
      "batch 5305, train_loss 178.474228,Time used 0.011002s\n",
      "batch 5306, train_loss 97.769585,Time used 0.010036s\n",
      "batch 5307, train_loss 131.193146,Time used 0.007000s\n",
      "batch 5308, train_loss 135.370850,Time used 0.007000s\n",
      "batch 5309, train_loss 120.936409,Time used 0.007964s\n",
      "batch 5310, train_loss 115.150970,Time used 0.007000s\n",
      "batch 5311, train_loss 147.226852,Time used 0.008000s\n",
      "batch 5312, train_loss 111.253845,Time used 0.010000s\n",
      "batch 5313, train_loss 104.909439,Time used 0.007999s\n",
      "batch 5314, train_loss 139.710754,Time used 0.007000s\n",
      "batch 5315, train_loss 123.033661,Time used 0.007000s\n",
      "batch 5316, train_loss 114.229362,Time used 0.006999s\n",
      "batch 5317, train_loss 124.846947,Time used 0.008003s\n",
      "batch 5318, train_loss 124.144325,Time used 0.006998s\n",
      "batch 5319, train_loss 106.879456,Time used 0.006999s\n",
      "batch 5320, train_loss 116.559456,Time used 0.007999s\n",
      "batch 5321, train_loss 104.815910,Time used 0.007003s\n",
      "batch 5322, train_loss 147.036514,Time used 0.007999s\n",
      "batch 5323, train_loss 126.207954,Time used 0.010000s\n",
      "batch 5324, train_loss 152.167847,Time used 0.010999s\n",
      "batch 5325, train_loss 143.165604,Time used 0.011002s\n",
      "batch 5326, train_loss 137.481628,Time used 0.011035s\n",
      "batch 5327, train_loss 136.510590,Time used 0.008986s\n",
      "batch 5328, train_loss 131.976257,Time used 0.009999s\n",
      "batch 5329, train_loss 139.503906,Time used 0.011000s\n",
      "batch 5330, train_loss 163.469360,Time used 0.006999s\n",
      "batch 5331, train_loss 130.282730,Time used 0.008000s\n",
      "batch 5332, train_loss 133.514618,Time used 0.007000s\n",
      "batch 5333, train_loss 92.796860,Time used 0.007000s\n",
      "batch 5334, train_loss 100.046761,Time used 0.007000s\n",
      "batch 5335, train_loss 114.785065,Time used 0.008000s\n",
      "batch 5336, train_loss 96.847153,Time used 0.008002s\n",
      "batch 5337, train_loss 133.361374,Time used 0.006999s\n",
      "batch 5338, train_loss 130.550797,Time used 0.010998s\n",
      "batch 5339, train_loss 146.387833,Time used 0.008001s\n",
      "batch 5340, train_loss 113.255165,Time used 0.007000s\n",
      "batch 5341, train_loss 131.071045,Time used 0.008003s\n",
      "batch 5342, train_loss 114.577278,Time used 0.007998s\n",
      "batch 5343, train_loss 145.813339,Time used 0.008000s\n",
      "batch 5344, train_loss 123.374931,Time used 0.007000s\n",
      "batch 5345, train_loss 113.156151,Time used 0.007999s\n",
      "batch 5346, train_loss 163.505325,Time used 0.011000s\n",
      "batch 5347, train_loss 84.627579,Time used 0.010001s\n",
      "batch 5348, train_loss 131.663559,Time used 0.006998s\n",
      "batch 5349, train_loss 148.738770,Time used 0.008003s\n",
      "batch 5350, train_loss 137.260223,Time used 0.006999s\n",
      "batch 5351, train_loss 146.306320,Time used 0.007000s\n",
      "batch 5352, train_loss 124.540512,Time used 0.008000s\n",
      "batch 5353, train_loss 139.986496,Time used 0.010001s\n",
      "batch 5354, train_loss 119.265778,Time used 0.006999s\n",
      "batch 5355, train_loss 146.128632,Time used 0.010002s\n",
      "batch 5356, train_loss 134.057938,Time used 0.006999s\n",
      "batch 5357, train_loss 113.580078,Time used 0.007000s\n",
      "batch 5358, train_loss 147.889191,Time used 0.009999s\n",
      "batch 5359, train_loss 152.815521,Time used 0.007001s\n",
      "batch 5360, train_loss 147.762604,Time used 0.009000s\n",
      "batch 5361, train_loss 128.191742,Time used 0.010000s\n",
      "batch 5362, train_loss 120.592194,Time used 0.007035s\n",
      "batch 5363, train_loss 132.540451,Time used 0.007965s\n",
      "batch 5364, train_loss 111.328056,Time used 0.007000s\n",
      "batch 5365, train_loss 131.693649,Time used 0.007999s\n",
      "batch 5366, train_loss 146.506332,Time used 0.006999s\n",
      "batch 5367, train_loss 135.453415,Time used 0.007999s\n",
      "batch 5368, train_loss 114.410545,Time used 0.006998s\n",
      "batch 5369, train_loss 107.801125,Time used 0.006969s\n",
      "batch 5370, train_loss 124.091385,Time used 0.007997s\n",
      "batch 5371, train_loss 122.984047,Time used 0.009002s\n",
      "batch 5372, train_loss 107.835304,Time used 0.010032s\n",
      "batch 5373, train_loss 134.605453,Time used 0.006966s\n",
      "batch 5374, train_loss 93.933426,Time used 0.008001s\n",
      "batch 5375, train_loss 131.750107,Time used 0.009001s\n",
      "batch 5376, train_loss 102.167175,Time used 0.007001s\n",
      "batch 5377, train_loss 110.978157,Time used 0.006999s\n",
      "batch 5378, train_loss 175.485275,Time used 0.007002s\n",
      "batch 5379, train_loss 95.250923,Time used 0.010002s\n",
      "batch 5380, train_loss 127.392441,Time used 0.006999s\n",
      "batch 5381, train_loss 116.656029,Time used 0.007997s\n",
      "batch 5382, train_loss 133.944351,Time used 0.008005s\n",
      "batch 5383, train_loss 103.595963,Time used 0.008996s\n",
      "batch 5384, train_loss 136.439590,Time used 0.010035s\n",
      "batch 5385, train_loss 132.970230,Time used 0.010966s\n",
      "batch 5386, train_loss 121.361427,Time used 0.011002s\n",
      "batch 5387, train_loss 121.308235,Time used 0.010998s\n",
      "batch 5388, train_loss 92.397041,Time used 0.011001s\n",
      "batch 5389, train_loss 131.283752,Time used 0.009997s\n",
      "batch 5390, train_loss 100.382851,Time used 0.010999s\n",
      "batch 5391, train_loss 145.072113,Time used 0.008002s\n",
      "batch 5392, train_loss 151.726013,Time used 0.007999s\n",
      "batch 5393, train_loss 112.104988,Time used 0.010000s\n",
      "batch 5394, train_loss 133.008209,Time used 0.010999s\n",
      "batch 5395, train_loss 124.618942,Time used 0.008001s\n",
      "batch 5396, train_loss 169.790421,Time used 0.007999s\n",
      "batch 5397, train_loss 111.072861,Time used 0.007000s\n",
      "batch 5398, train_loss 132.704300,Time used 0.008003s\n",
      "batch 5399, train_loss 122.006264,Time used 0.012995s\n",
      "batch 5400, train_loss 135.844955,Time used 0.009000s\n",
      "***************************test_batch 5400, test_rmse_loss 12.883415,test_mae_loss 4.927237,test_mape_loss 67.731368,Time used 0.034002s\n",
      "batch 5401, train_loss 167.481644,Time used 0.007000s\n",
      "batch 5402, train_loss 125.062485,Time used 0.011000s\n",
      "batch 5403, train_loss 136.631210,Time used 0.009002s\n",
      "batch 5404, train_loss 119.992371,Time used 0.007998s\n",
      "batch 5405, train_loss 102.631073,Time used 0.008001s\n",
      "batch 5406, train_loss 129.757538,Time used 0.010001s\n",
      "batch 5407, train_loss 114.533295,Time used 0.009000s\n",
      "batch 5408, train_loss 81.535957,Time used 0.007999s\n",
      "batch 5409, train_loss 157.038376,Time used 0.011001s\n",
      "batch 5410, train_loss 121.295959,Time used 0.009999s\n",
      "batch 5411, train_loss 123.151932,Time used 0.007000s\n",
      "batch 5412, train_loss 132.685760,Time used 0.007002s\n",
      "batch 5413, train_loss 131.790436,Time used 0.007000s\n",
      "batch 5414, train_loss 97.764915,Time used 0.008000s\n",
      "batch 5415, train_loss 155.998245,Time used 0.007000s\n",
      "batch 5416, train_loss 141.492783,Time used 0.008001s\n",
      "batch 5417, train_loss 130.071167,Time used 0.007000s\n",
      "batch 5418, train_loss 103.631836,Time used 0.008002s\n",
      "batch 5419, train_loss 116.140137,Time used 0.006998s\n",
      "batch 5420, train_loss 148.258179,Time used 0.009997s\n",
      "batch 5421, train_loss 125.325172,Time used 0.010000s\n",
      "batch 5422, train_loss 122.065262,Time used 0.007999s\n",
      "batch 5423, train_loss 114.903534,Time used 0.007000s\n",
      "batch 5424, train_loss 126.739288,Time used 0.007003s\n",
      "batch 5425, train_loss 131.080353,Time used 0.010000s\n",
      "batch 5426, train_loss 140.540344,Time used 0.008002s\n",
      "batch 5427, train_loss 109.544983,Time used 0.006998s\n",
      "batch 5428, train_loss 122.083961,Time used 0.009001s\n",
      "batch 5429, train_loss 157.627701,Time used 0.011002s\n",
      "batch 5430, train_loss 152.413315,Time used 0.012002s\n",
      "batch 5431, train_loss 124.422379,Time used 0.010996s\n",
      "batch 5432, train_loss 98.857307,Time used 0.006999s\n",
      "batch 5433, train_loss 100.741196,Time used 0.007999s\n",
      "batch 5434, train_loss 107.763313,Time used 0.010999s\n",
      "batch 5435, train_loss 143.855988,Time used 0.014001s\n",
      "batch 5436, train_loss 141.223358,Time used 0.010001s\n",
      "batch 5437, train_loss 130.095688,Time used 0.011000s\n",
      "batch 5438, train_loss 142.644592,Time used 0.010999s\n",
      "batch 5439, train_loss 122.857658,Time used 0.008000s\n",
      "batch 5440, train_loss 147.799393,Time used 0.007000s\n",
      "batch 5441, train_loss 127.249298,Time used 0.010001s\n",
      "batch 5442, train_loss 116.080978,Time used 0.010001s\n",
      "batch 5443, train_loss 107.261101,Time used 0.007997s\n",
      "batch 5444, train_loss 137.748459,Time used 0.007000s\n",
      "batch 5445, train_loss 104.596947,Time used 0.008005s\n",
      "batch 5446, train_loss 113.254272,Time used 0.009001s\n",
      "batch 5447, train_loss 114.730453,Time used 0.009002s\n",
      "batch 5448, train_loss 120.280525,Time used 0.010002s\n",
      "batch 5449, train_loss 136.805939,Time used 0.008002s\n",
      "batch 5450, train_loss 111.017555,Time used 0.006996s\n",
      "batch 5451, train_loss 137.214752,Time used 0.008003s\n",
      "batch 5452, train_loss 88.355553,Time used 0.006999s\n",
      "batch 5453, train_loss 123.546494,Time used 0.010000s\n",
      "batch 5454, train_loss 121.862694,Time used 0.007002s\n",
      "batch 5455, train_loss 139.228378,Time used 0.007000s\n",
      "batch 5456, train_loss 119.103539,Time used 0.008001s\n",
      "batch 5457, train_loss 127.541031,Time used 0.006997s\n",
      "batch 5458, train_loss 106.577782,Time used 0.007001s\n",
      "batch 5459, train_loss 136.031662,Time used 0.008000s\n",
      "batch 5460, train_loss 121.007202,Time used 0.007002s\n",
      "batch 5461, train_loss 112.293854,Time used 0.006999s\n",
      "batch 5462, train_loss 129.703613,Time used 0.006999s\n",
      "batch 5463, train_loss 142.315582,Time used 0.008000s\n",
      "batch 5464, train_loss 111.138527,Time used 0.007000s\n",
      "batch 5465, train_loss 114.129616,Time used 0.008001s\n",
      "batch 5466, train_loss 109.507858,Time used 0.007002s\n",
      "batch 5467, train_loss 131.786865,Time used 0.007998s\n",
      "batch 5468, train_loss 115.905655,Time used 0.008034s\n",
      "batch 5469, train_loss 133.551636,Time used 0.010002s\n",
      "batch 5470, train_loss 136.129395,Time used 0.007000s\n",
      "batch 5471, train_loss 146.755295,Time used 0.009963s\n",
      "batch 5472, train_loss 153.485840,Time used 0.010005s\n",
      "batch 5473, train_loss 137.378830,Time used 0.007000s\n",
      "batch 5474, train_loss 116.180786,Time used 0.008996s\n",
      "batch 5475, train_loss 134.335938,Time used 0.007000s\n",
      "batch 5476, train_loss 136.085541,Time used 0.007000s\n",
      "batch 5477, train_loss 164.270447,Time used 0.006998s\n",
      "batch 5478, train_loss 110.020157,Time used 0.007000s\n",
      "batch 5479, train_loss 107.667564,Time used 0.006001s\n",
      "batch 5480, train_loss 123.768547,Time used 0.008001s\n",
      "batch 5481, train_loss 155.458923,Time used 0.006998s\n",
      "batch 5482, train_loss 129.810837,Time used 0.009001s\n",
      "batch 5483, train_loss 152.558899,Time used 0.008000s\n",
      "batch 5484, train_loss 107.987167,Time used 0.007034s\n",
      "batch 5485, train_loss 76.647240,Time used 0.007003s\n",
      "batch 5486, train_loss 125.558632,Time used 0.007997s\n",
      "batch 5487, train_loss 113.301773,Time used 0.007001s\n",
      "batch 5488, train_loss 90.882042,Time used 0.007036s\n",
      "batch 5489, train_loss 108.841866,Time used 0.009006s\n",
      "batch 5490, train_loss 110.145264,Time used 0.006963s\n",
      "batch 5491, train_loss 127.658936,Time used 0.007000s\n",
      "batch 5492, train_loss 143.213531,Time used 0.007999s\n",
      "batch 5493, train_loss 141.157761,Time used 0.015001s\n",
      "batch 5494, train_loss 119.093025,Time used 0.012000s\n",
      "batch 5495, train_loss 121.703033,Time used 0.011998s\n",
      "batch 5496, train_loss 139.927399,Time used 0.011000s\n",
      "batch 5497, train_loss 114.374428,Time used 0.006999s\n",
      "batch 5498, train_loss 116.972816,Time used 0.009001s\n",
      "batch 5499, train_loss 141.790756,Time used 0.008002s\n",
      "batch 5500, train_loss 124.559479,Time used 0.008001s\n",
      "***************************test_batch 5500, test_rmse_loss 12.789074,test_mae_loss 4.894389,test_mape_loss 67.575163,Time used 0.030998s\n",
      "batch 5501, train_loss 130.357895,Time used 0.010999s\n",
      "batch 5502, train_loss 132.911346,Time used 0.010001s\n",
      "batch 5503, train_loss 146.672119,Time used 0.008000s\n",
      "batch 5504, train_loss 110.818375,Time used 0.007001s\n",
      "batch 5505, train_loss 118.642342,Time used 0.009999s\n",
      "batch 5506, train_loss 137.237122,Time used 0.006999s\n",
      "batch 5507, train_loss 109.032745,Time used 0.014003s\n",
      "batch 5508, train_loss 121.807709,Time used 0.010000s\n",
      "batch 5509, train_loss 112.686119,Time used 0.007998s\n",
      "batch 5510, train_loss 95.047340,Time used 0.009001s\n",
      "batch 5511, train_loss 145.192078,Time used 0.008002s\n",
      "batch 5512, train_loss 127.212700,Time used 0.006999s\n",
      "batch 5513, train_loss 128.555359,Time used 0.008001s\n",
      "batch 5514, train_loss 105.565674,Time used 0.008000s\n",
      "batch 5515, train_loss 124.537415,Time used 0.008000s\n",
      "batch 5516, train_loss 116.292854,Time used 0.007001s\n",
      "batch 5517, train_loss 120.619804,Time used 0.008999s\n",
      "batch 5518, train_loss 140.929337,Time used 0.007001s\n",
      "batch 5519, train_loss 104.364380,Time used 0.007000s\n",
      "batch 5520, train_loss 157.257385,Time used 0.006999s\n",
      "batch 5521, train_loss 123.981255,Time used 0.007997s\n",
      "batch 5522, train_loss 105.412865,Time used 0.007002s\n",
      "batch 5523, train_loss 121.493271,Time used 0.007000s\n",
      "batch 5524, train_loss 115.473831,Time used 0.007000s\n",
      "batch 5525, train_loss 129.959244,Time used 0.009999s\n",
      "batch 5526, train_loss 144.024734,Time used 0.008002s\n",
      "batch 5527, train_loss 98.150452,Time used 0.008001s\n",
      "batch 5528, train_loss 136.396515,Time used 0.006999s\n",
      "batch 5529, train_loss 134.595413,Time used 0.009999s\n",
      "batch 5530, train_loss 110.026138,Time used 0.010000s\n",
      "batch 5531, train_loss 112.391731,Time used 0.007002s\n",
      "batch 5532, train_loss 98.112923,Time used 0.008000s\n",
      "batch 5533, train_loss 149.624863,Time used 0.007001s\n",
      "batch 5534, train_loss 124.432068,Time used 0.006998s\n",
      "batch 5535, train_loss 142.300644,Time used 0.007001s\n",
      "batch 5536, train_loss 103.052582,Time used 0.006999s\n",
      "batch 5537, train_loss 151.891083,Time used 0.008001s\n",
      "batch 5538, train_loss 97.056541,Time used 0.007000s\n",
      "batch 5539, train_loss 122.186340,Time used 0.008999s\n",
      "batch 5540, train_loss 126.741394,Time used 0.015002s\n",
      "batch 5541, train_loss 126.291931,Time used 0.010999s\n",
      "batch 5542, train_loss 119.041824,Time used 0.012000s\n",
      "batch 5543, train_loss 136.106567,Time used 0.010998s\n",
      "batch 5544, train_loss 143.357468,Time used 0.008001s\n",
      "batch 5545, train_loss 124.225891,Time used 0.010002s\n",
      "batch 5546, train_loss 121.227272,Time used 0.010002s\n",
      "batch 5547, train_loss 126.250443,Time used 0.010997s\n",
      "batch 5548, train_loss 116.390381,Time used 0.009999s\n",
      "batch 5549, train_loss 100.695312,Time used 0.010999s\n",
      "batch 5550, train_loss 113.319038,Time used 0.012001s\n",
      "batch 5551, train_loss 121.085686,Time used 0.011001s\n",
      "batch 5552, train_loss 111.616005,Time used 0.010999s\n",
      "batch 5553, train_loss 139.568161,Time used 0.011000s\n",
      "batch 5554, train_loss 135.974014,Time used 0.010001s\n",
      "batch 5555, train_loss 119.905563,Time used 0.011001s\n",
      "batch 5556, train_loss 176.774887,Time used 0.012000s\n",
      "batch 5557, train_loss 113.108147,Time used 0.010998s\n",
      "batch 5558, train_loss 109.440086,Time used 0.011000s\n",
      "batch 5559, train_loss 120.545593,Time used 0.011003s\n",
      "batch 5560, train_loss 107.433342,Time used 0.010997s\n",
      "batch 5561, train_loss 131.578110,Time used 0.012001s\n",
      "batch 5562, train_loss 122.694427,Time used 0.009000s\n",
      "batch 5563, train_loss 140.272705,Time used 0.012002s\n",
      "batch 5564, train_loss 102.357475,Time used 0.013998s\n",
      "batch 5565, train_loss 106.701447,Time used 0.012999s\n",
      "batch 5566, train_loss 135.022507,Time used 0.020002s\n",
      "batch 5567, train_loss 124.481964,Time used 0.014996s\n",
      "batch 5568, train_loss 140.523560,Time used 0.014002s\n",
      "batch 5569, train_loss 139.856384,Time used 0.012000s\n",
      "batch 5570, train_loss 131.202469,Time used 0.012001s\n",
      "batch 5571, train_loss 121.614609,Time used 0.009997s\n",
      "batch 5572, train_loss 104.247902,Time used 0.009002s\n",
      "batch 5573, train_loss 120.357841,Time used 0.023999s\n",
      "batch 5574, train_loss 119.804726,Time used 0.012001s\n",
      "batch 5575, train_loss 150.770660,Time used 0.012000s\n",
      "batch 5576, train_loss 110.147346,Time used 0.008000s\n",
      "batch 5577, train_loss 122.230598,Time used 0.010000s\n",
      "batch 5578, train_loss 118.434303,Time used 0.010998s\n",
      "batch 5579, train_loss 124.168289,Time used 0.010002s\n",
      "batch 5580, train_loss 128.175278,Time used 0.012001s\n",
      "batch 5581, train_loss 73.991066,Time used 0.012001s\n",
      "batch 5582, train_loss 128.622131,Time used 0.013000s\n",
      "batch 5583, train_loss 157.883392,Time used 0.012002s\n",
      "batch 5584, train_loss 98.048187,Time used 0.009997s\n",
      "batch 5585, train_loss 170.740463,Time used 0.009002s\n",
      "batch 5586, train_loss 100.028397,Time used 0.009000s\n",
      "batch 5587, train_loss 107.011711,Time used 0.010998s\n",
      "batch 5588, train_loss 127.117218,Time used 0.008001s\n",
      "batch 5589, train_loss 116.801437,Time used 0.009000s\n",
      "batch 5590, train_loss 157.423767,Time used 0.007000s\n",
      "batch 5591, train_loss 100.652023,Time used 0.007001s\n",
      "batch 5592, train_loss 120.429573,Time used 0.007999s\n",
      "batch 5593, train_loss 90.136017,Time used 0.009999s\n",
      "batch 5594, train_loss 107.424812,Time used 0.009003s\n",
      "batch 5595, train_loss 111.220772,Time used 0.006999s\n",
      "batch 5596, train_loss 133.946121,Time used 0.007998s\n",
      "batch 5597, train_loss 112.523666,Time used 0.006999s\n",
      "batch 5598, train_loss 142.073318,Time used 0.007999s\n",
      "batch 5599, train_loss 117.973091,Time used 0.007037s\n",
      "batch 5600, train_loss 134.719604,Time used 0.006968s\n",
      "***************************test_batch 5600, test_rmse_loss 12.694910,test_mae_loss 4.863490,test_mape_loss 67.712761,Time used 0.035996s\n",
      "batch 5601, train_loss 127.717224,Time used 0.013001s\n",
      "batch 5602, train_loss 137.524826,Time used 0.007999s\n",
      "batch 5603, train_loss 126.337906,Time used 0.009998s\n",
      "batch 5604, train_loss 104.654564,Time used 0.009001s\n",
      "batch 5605, train_loss 107.289925,Time used 0.007000s\n",
      "batch 5606, train_loss 126.442169,Time used 0.010001s\n",
      "batch 5607, train_loss 117.675621,Time used 0.007034s\n",
      "batch 5608, train_loss 157.433044,Time used 0.008968s\n",
      "batch 5609, train_loss 124.905884,Time used 0.006996s\n",
      "batch 5610, train_loss 110.518372,Time used 0.010035s\n",
      "batch 5611, train_loss 138.062790,Time used 0.007964s\n",
      "batch 5612, train_loss 148.222061,Time used 0.008004s\n",
      "batch 5613, train_loss 111.403404,Time used 0.006996s\n",
      "batch 5614, train_loss 131.552994,Time used 0.009000s\n",
      "batch 5615, train_loss 122.188156,Time used 0.007000s\n",
      "batch 5616, train_loss 96.247917,Time used 0.009036s\n",
      "batch 5617, train_loss 142.240814,Time used 0.009983s\n",
      "batch 5618, train_loss 122.752953,Time used 0.007003s\n",
      "batch 5619, train_loss 119.535149,Time used 0.007000s\n",
      "batch 5620, train_loss 108.096214,Time used 0.008998s\n",
      "batch 5621, train_loss 124.651314,Time used 0.011000s\n",
      "batch 5622, train_loss 106.987831,Time used 0.010999s\n",
      "batch 5623, train_loss 120.930832,Time used 0.008003s\n",
      "batch 5624, train_loss 106.158287,Time used 0.007999s\n",
      "batch 5625, train_loss 154.358902,Time used 0.007000s\n",
      "batch 5626, train_loss 124.153870,Time used 0.006998s\n",
      "batch 5627, train_loss 119.110786,Time used 0.007034s\n",
      "batch 5628, train_loss 119.031517,Time used 0.006968s\n",
      "batch 5629, train_loss 126.338058,Time used 0.006998s\n",
      "batch 5630, train_loss 120.633636,Time used 0.008039s\n",
      "batch 5631, train_loss 146.585938,Time used 0.006960s\n",
      "batch 5632, train_loss 137.882782,Time used 0.007004s\n",
      "batch 5633, train_loss 139.929077,Time used 0.007000s\n",
      "batch 5634, train_loss 117.755127,Time used 0.009996s\n",
      "batch 5635, train_loss 107.050995,Time used 0.009999s\n",
      "batch 5636, train_loss 105.254402,Time used 0.008001s\n",
      "batch 5637, train_loss 118.245445,Time used 0.007004s\n",
      "batch 5638, train_loss 107.832153,Time used 0.010999s\n",
      "batch 5639, train_loss 115.797356,Time used 0.008995s\n",
      "batch 5640, train_loss 117.305840,Time used 0.007037s\n",
      "batch 5641, train_loss 115.477051,Time used 0.009991s\n",
      "batch 5642, train_loss 132.061951,Time used 0.007000s\n",
      "batch 5643, train_loss 125.446091,Time used 0.006999s\n",
      "batch 5644, train_loss 110.206215,Time used 0.007001s\n",
      "batch 5645, train_loss 110.187263,Time used 0.006999s\n",
      "batch 5646, train_loss 110.912193,Time used 0.008003s\n",
      "batch 5647, train_loss 119.288734,Time used 0.010000s\n",
      "batch 5648, train_loss 131.460037,Time used 0.010997s\n",
      "batch 5649, train_loss 137.171616,Time used 0.007002s\n",
      "batch 5650, train_loss 129.652939,Time used 0.010034s\n",
      "batch 5651, train_loss 149.204117,Time used 0.006965s\n",
      "batch 5652, train_loss 133.708664,Time used 0.007000s\n",
      "batch 5653, train_loss 119.582153,Time used 0.007001s\n",
      "batch 5654, train_loss 132.359375,Time used 0.008000s\n",
      "batch 5655, train_loss 102.387238,Time used 0.007034s\n",
      "batch 5656, train_loss 127.284599,Time used 0.006965s\n",
      "batch 5657, train_loss 110.168846,Time used 0.006001s\n",
      "batch 5658, train_loss 113.016975,Time used 0.007000s\n",
      "batch 5659, train_loss 107.062271,Time used 0.007001s\n",
      "batch 5660, train_loss 109.548988,Time used 0.006999s\n",
      "batch 5661, train_loss 95.200966,Time used 0.007002s\n",
      "batch 5662, train_loss 102.834114,Time used 0.007998s\n",
      "batch 5663, train_loss 145.431885,Time used 0.007038s\n",
      "batch 5664, train_loss 149.622879,Time used 0.007000s\n",
      "batch 5665, train_loss 132.618668,Time used 0.006984s\n",
      "batch 5666, train_loss 90.488831,Time used 0.006999s\n",
      "batch 5667, train_loss 128.797653,Time used 0.007000s\n",
      "batch 5668, train_loss 123.323669,Time used 0.006963s\n",
      "batch 5669, train_loss 144.518387,Time used 0.008042s\n",
      "batch 5670, train_loss 122.163757,Time used 0.006962s\n",
      "batch 5671, train_loss 133.642883,Time used 0.008036s\n",
      "batch 5672, train_loss 120.873009,Time used 0.009960s\n",
      "batch 5673, train_loss 113.841797,Time used 0.007000s\n",
      "batch 5674, train_loss 112.132820,Time used 0.008002s\n",
      "batch 5675, train_loss 115.297508,Time used 0.009004s\n",
      "batch 5676, train_loss 124.394463,Time used 0.007035s\n",
      "batch 5677, train_loss 117.120934,Time used 0.006999s\n",
      "batch 5678, train_loss 111.062683,Time used 0.006999s\n",
      "batch 5679, train_loss 153.551559,Time used 0.007000s\n",
      "batch 5680, train_loss 106.405396,Time used 0.006966s\n",
      "batch 5681, train_loss 117.107079,Time used 0.007034s\n",
      "batch 5682, train_loss 93.938202,Time used 0.006964s\n",
      "batch 5683, train_loss 146.655106,Time used 0.006999s\n",
      "batch 5684, train_loss 142.084534,Time used 0.008042s\n",
      "batch 5685, train_loss 134.160492,Time used 0.006959s\n",
      "batch 5686, train_loss 95.057793,Time used 0.009039s\n",
      "batch 5687, train_loss 120.946548,Time used 0.006961s\n",
      "batch 5688, train_loss 107.073128,Time used 0.008002s\n",
      "batch 5689, train_loss 113.359070,Time used 0.007998s\n",
      "batch 5690, train_loss 109.626930,Time used 0.009998s\n",
      "batch 5691, train_loss 150.531281,Time used 0.007040s\n",
      "batch 5692, train_loss 118.119843,Time used 0.009000s\n",
      "batch 5693, train_loss 121.070595,Time used 0.007966s\n",
      "batch 5694, train_loss 122.213188,Time used 0.007999s\n",
      "batch 5695, train_loss 117.268837,Time used 0.007004s\n",
      "batch 5696, train_loss 132.572662,Time used 0.007998s\n",
      "batch 5697, train_loss 112.012970,Time used 0.010999s\n",
      "batch 5698, train_loss 119.183640,Time used 0.007002s\n",
      "batch 5699, train_loss 122.843491,Time used 0.010999s\n",
      "batch 5700, train_loss 138.646500,Time used 0.009998s\n",
      "***************************test_batch 5700, test_rmse_loss 12.606780,test_mae_loss 4.829014,test_mape_loss 67.166917,Time used 0.033005s\n",
      "batch 5701, train_loss 95.065826,Time used 0.007000s\n",
      "batch 5702, train_loss 120.971344,Time used 0.006996s\n",
      "batch 5703, train_loss 76.329094,Time used 0.008003s\n",
      "batch 5704, train_loss 139.018417,Time used 0.008000s\n",
      "batch 5705, train_loss 114.257111,Time used 0.007000s\n",
      "batch 5706, train_loss 103.966805,Time used 0.010000s\n",
      "batch 5707, train_loss 129.584885,Time used 0.007002s\n",
      "batch 5708, train_loss 134.496384,Time used 0.009999s\n",
      "batch 5709, train_loss 124.206741,Time used 0.009002s\n",
      "batch 5710, train_loss 114.069450,Time used 0.010997s\n",
      "batch 5711, train_loss 121.010239,Time used 0.007002s\n",
      "batch 5712, train_loss 148.169250,Time used 0.006998s\n",
      "batch 5713, train_loss 139.264511,Time used 0.010000s\n",
      "batch 5714, train_loss 135.088745,Time used 0.010996s\n",
      "batch 5715, train_loss 142.674149,Time used 0.008004s\n",
      "batch 5716, train_loss 91.197678,Time used 0.007999s\n",
      "batch 5717, train_loss 112.709709,Time used 0.006998s\n",
      "batch 5718, train_loss 124.522491,Time used 0.006999s\n",
      "batch 5719, train_loss 112.669479,Time used 0.007001s\n",
      "batch 5720, train_loss 121.300140,Time used 0.008003s\n",
      "batch 5721, train_loss 89.040749,Time used 0.009998s\n",
      "batch 5722, train_loss 105.993340,Time used 0.011033s\n",
      "batch 5723, train_loss 135.081238,Time used 0.007000s\n",
      "batch 5724, train_loss 148.782700,Time used 0.007000s\n",
      "batch 5725, train_loss 107.299873,Time used 0.007995s\n",
      "batch 5726, train_loss 95.915451,Time used 0.007002s\n",
      "batch 5727, train_loss 108.696823,Time used 0.006965s\n",
      "batch 5728, train_loss 113.196457,Time used 0.009000s\n",
      "batch 5729, train_loss 117.086571,Time used 0.007998s\n",
      "batch 5730, train_loss 145.467499,Time used 0.010003s\n",
      "batch 5731, train_loss 130.276703,Time used 0.006998s\n",
      "batch 5732, train_loss 141.912125,Time used 0.010000s\n",
      "batch 5733, train_loss 111.513741,Time used 0.011002s\n",
      "batch 5734, train_loss 115.372200,Time used 0.010996s\n",
      "batch 5735, train_loss 130.756760,Time used 0.011000s\n",
      "batch 5736, train_loss 111.036835,Time used 0.011000s\n",
      "batch 5737, train_loss 101.910553,Time used 0.009999s\n",
      "batch 5738, train_loss 160.621277,Time used 0.007000s\n",
      "batch 5739, train_loss 90.236557,Time used 0.009000s\n",
      "batch 5740, train_loss 123.811943,Time used 0.006999s\n",
      "batch 5741, train_loss 119.985497,Time used 0.008000s\n",
      "batch 5742, train_loss 138.375046,Time used 0.007001s\n",
      "batch 5743, train_loss 99.956001,Time used 0.008000s\n",
      "batch 5744, train_loss 93.142090,Time used 0.007999s\n",
      "batch 5745, train_loss 100.004517,Time used 0.007000s\n",
      "batch 5746, train_loss 115.915291,Time used 0.007000s\n",
      "batch 5747, train_loss 104.985474,Time used 0.008002s\n",
      "batch 5748, train_loss 126.408752,Time used 0.011002s\n",
      "batch 5749, train_loss 105.938728,Time used 0.007995s\n",
      "batch 5750, train_loss 149.832306,Time used 0.007000s\n",
      "batch 5751, train_loss 137.220261,Time used 0.007002s\n",
      "batch 5752, train_loss 107.022430,Time used 0.011003s\n",
      "batch 5753, train_loss 139.044159,Time used 0.010997s\n",
      "batch 5754, train_loss 121.639526,Time used 0.010001s\n",
      "batch 5755, train_loss 96.736237,Time used 0.011003s\n",
      "batch 5756, train_loss 120.011574,Time used 0.008997s\n",
      "batch 5757, train_loss 109.429314,Time used 0.010001s\n",
      "batch 5758, train_loss 158.529495,Time used 0.011002s\n",
      "batch 5759, train_loss 138.925491,Time used 0.009007s\n",
      "batch 5760, train_loss 117.029877,Time used 0.010999s\n",
      "batch 5761, train_loss 128.078430,Time used 0.010998s\n",
      "batch 5762, train_loss 120.516861,Time used 0.010000s\n",
      "batch 5763, train_loss 131.047882,Time used 0.010003s\n",
      "batch 5764, train_loss 140.569992,Time used 0.009998s\n",
      "batch 5765, train_loss 118.716072,Time used 0.010999s\n",
      "batch 5766, train_loss 111.806679,Time used 0.012003s\n",
      "batch 5767, train_loss 143.609009,Time used 0.010001s\n",
      "batch 5768, train_loss 102.369812,Time used 0.009002s\n",
      "batch 5769, train_loss 124.916115,Time used 0.008002s\n",
      "batch 5770, train_loss 81.104538,Time used 0.007998s\n",
      "batch 5771, train_loss 119.208183,Time used 0.007000s\n",
      "batch 5772, train_loss 116.432259,Time used 0.007999s\n",
      "batch 5773, train_loss 105.546082,Time used 0.007000s\n",
      "batch 5774, train_loss 112.885399,Time used 0.008002s\n",
      "batch 5775, train_loss 124.450203,Time used 0.006001s\n",
      "batch 5776, train_loss 150.128586,Time used 0.007003s\n",
      "batch 5777, train_loss 97.815323,Time used 0.007001s\n",
      "batch 5778, train_loss 115.976639,Time used 0.010001s\n",
      "batch 5779, train_loss 146.955017,Time used 0.007999s\n",
      "batch 5780, train_loss 132.778320,Time used 0.007000s\n",
      "batch 5781, train_loss 124.226051,Time used 0.006998s\n",
      "batch 5782, train_loss 105.320435,Time used 0.008002s\n",
      "batch 5783, train_loss 111.011688,Time used 0.007000s\n",
      "batch 5784, train_loss 100.630775,Time used 0.007002s\n",
      "batch 5785, train_loss 110.063408,Time used 0.005999s\n",
      "batch 5786, train_loss 122.881119,Time used 0.011004s\n",
      "batch 5787, train_loss 122.153168,Time used 0.008998s\n",
      "batch 5788, train_loss 109.422462,Time used 0.008000s\n",
      "batch 5789, train_loss 119.308464,Time used 0.009003s\n",
      "batch 5790, train_loss 145.580444,Time used 0.009997s\n",
      "batch 5791, train_loss 137.732773,Time used 0.011002s\n",
      "batch 5792, train_loss 151.078873,Time used 0.010998s\n",
      "batch 5793, train_loss 100.751450,Time used 0.008000s\n",
      "batch 5794, train_loss 126.609528,Time used 0.010000s\n",
      "batch 5795, train_loss 104.728477,Time used 0.007002s\n",
      "batch 5796, train_loss 120.517838,Time used 0.007999s\n",
      "batch 5797, train_loss 113.660934,Time used 0.007000s\n",
      "batch 5798, train_loss 114.553261,Time used 0.010000s\n",
      "batch 5799, train_loss 128.282394,Time used 0.007002s\n",
      "batch 5800, train_loss 88.361351,Time used 0.008000s\n",
      "***************************test_batch 5800, test_rmse_loss 12.513640,test_mae_loss 4.803908,test_mape_loss 67.615824,Time used 0.033999s\n",
      "batch 5801, train_loss 143.697830,Time used 0.008000s\n",
      "batch 5802, train_loss 98.465042,Time used 0.006999s\n",
      "batch 5803, train_loss 119.171257,Time used 0.009002s\n",
      "batch 5804, train_loss 108.549873,Time used 0.006999s\n",
      "batch 5805, train_loss 142.885849,Time used 0.007998s\n",
      "batch 5806, train_loss 124.937996,Time used 0.007999s\n",
      "batch 5807, train_loss 89.179680,Time used 0.009001s\n",
      "batch 5808, train_loss 113.941193,Time used 0.008002s\n",
      "batch 5809, train_loss 119.471344,Time used 0.010998s\n",
      "batch 5810, train_loss 112.539490,Time used 0.010002s\n",
      "batch 5811, train_loss 129.441055,Time used 0.009998s\n",
      "batch 5812, train_loss 89.415550,Time used 0.007004s\n",
      "batch 5813, train_loss 134.297882,Time used 0.008997s\n",
      "batch 5814, train_loss 165.967270,Time used 0.009998s\n",
      "batch 5815, train_loss 113.547058,Time used 0.010002s\n",
      "batch 5816, train_loss 157.226044,Time used 0.009000s\n",
      "batch 5817, train_loss 118.300591,Time used 0.008000s\n",
      "batch 5818, train_loss 104.262962,Time used 0.016999s\n",
      "batch 5819, train_loss 103.002960,Time used 0.011002s\n",
      "batch 5820, train_loss 123.733139,Time used 0.011000s\n",
      "batch 5821, train_loss 105.765480,Time used 0.011000s\n",
      "batch 5822, train_loss 80.157463,Time used 0.010000s\n",
      "batch 5823, train_loss 134.122711,Time used 0.011001s\n",
      "batch 5824, train_loss 80.039459,Time used 0.008000s\n",
      "batch 5825, train_loss 118.963539,Time used 0.007001s\n",
      "batch 5826, train_loss 79.801216,Time used 0.009993s\n",
      "batch 5827, train_loss 130.382462,Time used 0.009998s\n",
      "batch 5828, train_loss 151.538300,Time used 0.010000s\n",
      "batch 5829, train_loss 71.818298,Time used 0.010000s\n",
      "batch 5830, train_loss 134.828522,Time used 0.009003s\n",
      "batch 5831, train_loss 168.405975,Time used 0.007996s\n",
      "batch 5832, train_loss 119.648018,Time used 0.007000s\n",
      "batch 5833, train_loss 120.215515,Time used 0.006999s\n",
      "batch 5834, train_loss 124.176132,Time used 0.008999s\n",
      "batch 5835, train_loss 101.988899,Time used 0.007002s\n",
      "batch 5836, train_loss 146.656296,Time used 0.009000s\n",
      "batch 5837, train_loss 107.914543,Time used 0.011001s\n",
      "batch 5838, train_loss 90.151459,Time used 0.011000s\n",
      "batch 5839, train_loss 167.018860,Time used 0.012002s\n",
      "batch 5840, train_loss 104.731300,Time used 0.010001s\n",
      "batch 5841, train_loss 108.845268,Time used 0.013001s\n",
      "batch 5842, train_loss 111.906357,Time used 0.012000s\n",
      "batch 5843, train_loss 141.063110,Time used 0.011996s\n",
      "batch 5844, train_loss 101.706894,Time used 0.008011s\n",
      "batch 5845, train_loss 109.045242,Time used 0.007002s\n",
      "batch 5846, train_loss 105.342903,Time used 0.007998s\n",
      "batch 5847, train_loss 106.454414,Time used 0.010999s\n",
      "batch 5848, train_loss 128.336182,Time used 0.010999s\n",
      "batch 5849, train_loss 123.503258,Time used 0.012001s\n",
      "batch 5850, train_loss 128.449554,Time used 0.007998s\n",
      "batch 5851, train_loss 112.414360,Time used 0.008000s\n",
      "batch 5852, train_loss 109.801903,Time used 0.010002s\n",
      "batch 5853, train_loss 133.169907,Time used 0.014001s\n",
      "batch 5854, train_loss 90.117355,Time used 0.011000s\n",
      "batch 5855, train_loss 168.711487,Time used 0.010998s\n",
      "batch 5856, train_loss 93.864388,Time used 0.008004s\n",
      "batch 5857, train_loss 162.994064,Time used 0.007000s\n",
      "batch 5858, train_loss 117.733459,Time used 0.006001s\n",
      "batch 5859, train_loss 141.485336,Time used 0.008998s\n",
      "batch 5860, train_loss 120.649521,Time used 0.011003s\n",
      "batch 5861, train_loss 107.321396,Time used 0.010001s\n",
      "batch 5862, train_loss 101.796432,Time used 0.009000s\n",
      "batch 5863, train_loss 106.822243,Time used 0.007998s\n",
      "batch 5864, train_loss 98.994873,Time used 0.008002s\n",
      "batch 5865, train_loss 120.873093,Time used 0.007002s\n",
      "batch 5866, train_loss 121.186432,Time used 0.011001s\n",
      "batch 5867, train_loss 109.196732,Time used 0.008001s\n",
      "batch 5868, train_loss 109.701035,Time used 0.008002s\n",
      "batch 5869, train_loss 156.268005,Time used 0.006997s\n",
      "batch 5870, train_loss 129.112106,Time used 0.010002s\n",
      "batch 5871, train_loss 122.580032,Time used 0.007998s\n",
      "batch 5872, train_loss 118.353096,Time used 0.008000s\n",
      "batch 5873, train_loss 121.395943,Time used 0.008003s\n",
      "batch 5874, train_loss 94.067497,Time used 0.007000s\n",
      "batch 5875, train_loss 101.407578,Time used 0.006998s\n",
      "batch 5876, train_loss 104.669960,Time used 0.008003s\n",
      "batch 5877, train_loss 117.593445,Time used 0.007999s\n",
      "batch 5878, train_loss 134.897751,Time used 0.008996s\n",
      "batch 5879, train_loss 102.637978,Time used 0.008003s\n",
      "batch 5880, train_loss 104.348312,Time used 0.006999s\n",
      "batch 5881, train_loss 118.101234,Time used 0.010998s\n",
      "batch 5882, train_loss 113.751289,Time used 0.008003s\n",
      "batch 5883, train_loss 126.935707,Time used 0.006999s\n",
      "batch 5884, train_loss 127.311417,Time used 0.007998s\n",
      "batch 5885, train_loss 163.583755,Time used 0.007000s\n",
      "batch 5886, train_loss 113.709206,Time used 0.008002s\n",
      "batch 5887, train_loss 119.435135,Time used 0.008997s\n",
      "batch 5888, train_loss 103.763802,Time used 0.009000s\n",
      "batch 5889, train_loss 147.982498,Time used 0.009001s\n",
      "batch 5890, train_loss 98.706871,Time used 0.009000s\n",
      "batch 5891, train_loss 107.423004,Time used 0.008009s\n",
      "batch 5892, train_loss 105.846054,Time used 0.007029s\n",
      "batch 5893, train_loss 112.960365,Time used 0.006971s\n",
      "batch 5894, train_loss 134.831238,Time used 0.010001s\n",
      "batch 5895, train_loss 122.743286,Time used 0.007000s\n",
      "batch 5896, train_loss 104.264618,Time used 0.007999s\n",
      "batch 5897, train_loss 106.398903,Time used 0.007003s\n",
      "batch 5898, train_loss 129.748276,Time used 0.007032s\n",
      "batch 5899, train_loss 90.811203,Time used 0.006965s\n",
      "batch 5900, train_loss 113.223602,Time used 0.006963s\n",
      "***************************test_batch 5900, test_rmse_loss 12.427235,test_mae_loss 4.772424,test_mape_loss 67.238021,Time used 0.032998s\n",
      "batch 5901, train_loss 100.404236,Time used 0.009005s\n",
      "batch 5902, train_loss 111.127975,Time used 0.007002s\n",
      "batch 5903, train_loss 121.409058,Time used 0.006998s\n",
      "batch 5904, train_loss 122.511040,Time used 0.011998s\n",
      "batch 5905, train_loss 119.371857,Time used 0.009995s\n",
      "batch 5906, train_loss 126.257133,Time used 0.007996s\n",
      "batch 5907, train_loss 131.047516,Time used 0.008002s\n",
      "batch 5908, train_loss 152.412933,Time used 0.008002s\n",
      "batch 5909, train_loss 137.526535,Time used 0.006998s\n",
      "batch 5910, train_loss 148.498352,Time used 0.009000s\n",
      "batch 5911, train_loss 106.587082,Time used 0.009998s\n",
      "batch 5912, train_loss 112.489891,Time used 0.010003s\n",
      "batch 5913, train_loss 106.637398,Time used 0.011001s\n",
      "batch 5914, train_loss 109.634041,Time used 0.008003s\n",
      "batch 5915, train_loss 111.028389,Time used 0.007999s\n",
      "batch 5916, train_loss 97.716545,Time used 0.010002s\n",
      "batch 5917, train_loss 80.883842,Time used 0.007999s\n",
      "batch 5918, train_loss 129.984528,Time used 0.014002s\n",
      "batch 5919, train_loss 100.161919,Time used 0.011996s\n",
      "batch 5920, train_loss 134.913345,Time used 0.012003s\n",
      "batch 5921, train_loss 103.507736,Time used 0.009001s\n",
      "batch 5922, train_loss 126.126282,Time used 0.010000s\n",
      "batch 5923, train_loss 104.023445,Time used 0.006999s\n",
      "batch 5924, train_loss 133.156311,Time used 0.014004s\n",
      "batch 5925, train_loss 110.987091,Time used 0.010000s\n",
      "batch 5926, train_loss 118.321213,Time used 0.011001s\n",
      "batch 5927, train_loss 104.533287,Time used 0.010000s\n",
      "batch 5928, train_loss 100.521820,Time used 0.011002s\n",
      "batch 5929, train_loss 114.694359,Time used 0.011001s\n",
      "batch 5930, train_loss 139.375626,Time used 0.009998s\n",
      "batch 5931, train_loss 118.885117,Time used 0.011003s\n",
      "batch 5932, train_loss 121.634903,Time used 0.010998s\n",
      "batch 5933, train_loss 70.833603,Time used 0.010999s\n",
      "batch 5934, train_loss 139.199203,Time used 0.010004s\n",
      "batch 5935, train_loss 127.330360,Time used 0.008998s\n",
      "batch 5936, train_loss 139.691422,Time used 0.012000s\n",
      "batch 5937, train_loss 131.193741,Time used 0.011001s\n",
      "batch 5938, train_loss 100.795776,Time used 0.011998s\n",
      "batch 5939, train_loss 96.897995,Time used 0.010001s\n",
      "batch 5940, train_loss 128.154297,Time used 0.013998s\n",
      "batch 5941, train_loss 94.752548,Time used 0.012000s\n",
      "batch 5942, train_loss 97.676346,Time used 0.014002s\n",
      "batch 5943, train_loss 105.759453,Time used 0.010998s\n",
      "batch 5944, train_loss 105.159424,Time used 0.011002s\n",
      "batch 5945, train_loss 129.398499,Time used 0.013002s\n",
      "batch 5946, train_loss 122.059906,Time used 0.016000s\n",
      "batch 5947, train_loss 109.904129,Time used 0.015000s\n",
      "batch 5948, train_loss 105.786774,Time used 0.024999s\n",
      "batch 5949, train_loss 128.689575,Time used 0.014001s\n",
      "batch 5950, train_loss 125.404251,Time used 0.022002s\n",
      "batch 5951, train_loss 127.175270,Time used 0.013999s\n",
      "batch 5952, train_loss 116.640129,Time used 0.014001s\n",
      "batch 5953, train_loss 89.795471,Time used 0.012002s\n",
      "batch 5954, train_loss 116.242760,Time used 0.011993s\n",
      "batch 5955, train_loss 103.998337,Time used 0.012000s\n",
      "batch 5956, train_loss 123.680565,Time used 0.011004s\n",
      "batch 5957, train_loss 94.670273,Time used 0.011002s\n",
      "batch 5958, train_loss 113.928131,Time used 0.013001s\n",
      "batch 5959, train_loss 113.934364,Time used 0.012002s\n",
      "batch 5960, train_loss 127.082726,Time used 0.013999s\n",
      "batch 5961, train_loss 136.703705,Time used 0.017001s\n",
      "batch 5962, train_loss 140.604172,Time used 0.012999s\n",
      "batch 5963, train_loss 128.501602,Time used 0.012002s\n",
      "batch 5964, train_loss 142.322662,Time used 0.012999s\n",
      "batch 5965, train_loss 110.041954,Time used 0.011998s\n",
      "batch 5966, train_loss 103.458961,Time used 0.009002s\n",
      "batch 5967, train_loss 142.613983,Time used 0.010000s\n",
      "batch 5968, train_loss 119.879181,Time used 0.013000s\n",
      "batch 5969, train_loss 87.323792,Time used 0.007998s\n",
      "batch 5970, train_loss 85.964790,Time used 0.015001s\n",
      "batch 5971, train_loss 98.548035,Time used 0.018000s\n",
      "batch 5972, train_loss 158.359924,Time used 0.011999s\n",
      "batch 5973, train_loss 93.432083,Time used 0.012000s\n",
      "batch 5974, train_loss 119.048843,Time used 0.012003s\n",
      "batch 5975, train_loss 123.079964,Time used 0.012999s\n",
      "batch 5976, train_loss 114.127556,Time used 0.011999s\n",
      "batch 5977, train_loss 120.537689,Time used 0.013000s\n",
      "batch 5978, train_loss 129.386398,Time used 0.014000s\n",
      "batch 5979, train_loss 84.202690,Time used 0.013000s\n",
      "batch 5980, train_loss 102.591698,Time used 0.010999s\n",
      "batch 5981, train_loss 123.181053,Time used 0.014002s\n",
      "batch 5982, train_loss 116.179855,Time used 0.013997s\n",
      "batch 5983, train_loss 102.498459,Time used 0.016000s\n",
      "batch 5984, train_loss 113.718376,Time used 0.013000s\n",
      "batch 5985, train_loss 158.259933,Time used 0.012001s\n",
      "batch 5986, train_loss 97.665733,Time used 0.013999s\n",
      "batch 5987, train_loss 117.927788,Time used 0.017001s\n",
      "batch 5988, train_loss 132.175171,Time used 0.021997s\n",
      "batch 5989, train_loss 132.048203,Time used 0.020004s\n",
      "batch 5990, train_loss 122.240479,Time used 0.012002s\n",
      "batch 5991, train_loss 119.830971,Time used 0.014998s\n",
      "batch 5992, train_loss 119.678856,Time used 0.027000s\n",
      "batch 5993, train_loss 86.929390,Time used 0.024003s\n",
      "batch 5994, train_loss 103.144943,Time used 0.014998s\n",
      "batch 5995, train_loss 133.472626,Time used 0.013000s\n",
      "batch 5996, train_loss 97.535645,Time used 0.012999s\n",
      "batch 5997, train_loss 128.814545,Time used 0.014003s\n",
      "batch 5998, train_loss 138.970367,Time used 0.012998s\n",
      "batch 5999, train_loss 109.124283,Time used 0.013001s\n",
      "batch 6000, train_loss 86.663330,Time used 0.010999s\n",
      "***************************test_batch 6000, test_rmse_loss 12.340008,test_mae_loss 4.745036,test_mape_loss 67.335689,Time used 0.046001s\n",
      "batch 6001, train_loss 119.222733,Time used 0.013998s\n",
      "batch 6002, train_loss 103.318748,Time used 0.010998s\n",
      "batch 6003, train_loss 87.615662,Time used 0.013003s\n",
      "batch 6004, train_loss 107.519287,Time used 0.011998s\n",
      "batch 6005, train_loss 98.183975,Time used 0.012004s\n",
      "batch 6006, train_loss 146.546631,Time used 0.009995s\n",
      "batch 6007, train_loss 114.690903,Time used 0.011001s\n",
      "batch 6008, train_loss 106.801910,Time used 0.008001s\n",
      "batch 6009, train_loss 106.445381,Time used 0.008000s\n",
      "batch 6010, train_loss 165.159821,Time used 0.008004s\n",
      "batch 6011, train_loss 152.235306,Time used 0.007000s\n",
      "batch 6012, train_loss 125.436157,Time used 0.008999s\n",
      "batch 6013, train_loss 161.585999,Time used 0.012001s\n",
      "batch 6014, train_loss 118.055679,Time used 0.011998s\n",
      "batch 6015, train_loss 92.467751,Time used 0.009004s\n",
      "batch 6016, train_loss 122.090919,Time used 0.011998s\n",
      "batch 6017, train_loss 98.491623,Time used 0.008000s\n",
      "batch 6018, train_loss 86.463005,Time used 0.009001s\n",
      "batch 6019, train_loss 99.171593,Time used 0.012000s\n",
      "batch 6020, train_loss 100.571510,Time used 0.012002s\n",
      "batch 6021, train_loss 97.183212,Time used 0.011000s\n",
      "batch 6022, train_loss 117.528152,Time used 0.007999s\n",
      "batch 6023, train_loss 122.401131,Time used 0.010998s\n",
      "batch 6024, train_loss 119.261658,Time used 0.009002s\n",
      "batch 6025, train_loss 114.091644,Time used 0.009000s\n",
      "batch 6026, train_loss 94.448326,Time used 0.010999s\n",
      "batch 6027, train_loss 80.594955,Time used 0.012003s\n",
      "batch 6028, train_loss 107.432976,Time used 0.010999s\n",
      "batch 6029, train_loss 129.697418,Time used 0.010001s\n",
      "batch 6030, train_loss 124.392143,Time used 0.007999s\n",
      "batch 6031, train_loss 96.556938,Time used 0.011000s\n",
      "batch 6032, train_loss 136.451813,Time used 0.010001s\n",
      "batch 6033, train_loss 137.218826,Time used 0.007998s\n",
      "batch 6034, train_loss 120.177513,Time used 0.009001s\n",
      "batch 6035, train_loss 102.534546,Time used 0.009000s\n",
      "batch 6036, train_loss 109.272072,Time used 0.010000s\n",
      "batch 6037, train_loss 97.970940,Time used 0.008000s\n",
      "batch 6038, train_loss 113.750839,Time used 0.013001s\n",
      "batch 6039, train_loss 85.102051,Time used 0.008997s\n",
      "batch 6040, train_loss 114.931213,Time used 0.007003s\n",
      "batch 6041, train_loss 119.833015,Time used 0.009996s\n",
      "batch 6042, train_loss 122.562698,Time used 0.007002s\n",
      "batch 6043, train_loss 96.939529,Time used 0.007003s\n",
      "batch 6044, train_loss 101.992851,Time used 0.008999s\n",
      "batch 6045, train_loss 152.990158,Time used 0.008000s\n",
      "batch 6046, train_loss 118.038773,Time used 0.007001s\n",
      "batch 6047, train_loss 139.191437,Time used 0.009000s\n",
      "batch 6048, train_loss 143.516830,Time used 0.010000s\n",
      "batch 6049, train_loss 113.289124,Time used 0.007999s\n",
      "batch 6050, train_loss 101.653809,Time used 0.007000s\n",
      "batch 6051, train_loss 117.772202,Time used 0.008000s\n",
      "batch 6052, train_loss 100.476295,Time used 0.006999s\n",
      "batch 6053, train_loss 119.011749,Time used 0.008002s\n",
      "batch 6054, train_loss 159.818588,Time used 0.010998s\n",
      "batch 6055, train_loss 94.545593,Time used 0.008001s\n",
      "batch 6056, train_loss 84.512787,Time used 0.006999s\n",
      "batch 6057, train_loss 105.523071,Time used 0.009998s\n",
      "batch 6058, train_loss 83.318283,Time used 0.011001s\n",
      "batch 6059, train_loss 147.380203,Time used 0.008002s\n",
      "batch 6060, train_loss 92.576225,Time used 0.009002s\n",
      "batch 6061, train_loss 127.751434,Time used 0.006999s\n",
      "batch 6062, train_loss 132.605927,Time used 0.008998s\n",
      "batch 6063, train_loss 135.151764,Time used 0.007002s\n",
      "batch 6064, train_loss 101.333084,Time used 0.008000s\n",
      "batch 6065, train_loss 98.418449,Time used 0.009002s\n",
      "batch 6066, train_loss 109.376518,Time used 0.007999s\n",
      "batch 6067, train_loss 114.564156,Time used 0.008000s\n",
      "batch 6068, train_loss 122.603462,Time used 0.007999s\n",
      "batch 6069, train_loss 111.786369,Time used 0.008000s\n",
      "batch 6070, train_loss 137.279694,Time used 0.010997s\n",
      "batch 6071, train_loss 101.361382,Time used 0.012001s\n",
      "batch 6072, train_loss 138.120758,Time used 0.012001s\n",
      "batch 6073, train_loss 84.893990,Time used 0.011997s\n",
      "batch 6074, train_loss 107.407272,Time used 0.008004s\n",
      "batch 6075, train_loss 134.866959,Time used 0.007997s\n",
      "batch 6076, train_loss 87.786491,Time used 0.007000s\n",
      "batch 6077, train_loss 101.558525,Time used 0.008001s\n",
      "batch 6078, train_loss 158.260803,Time used 0.008998s\n",
      "batch 6079, train_loss 137.613586,Time used 0.007000s\n",
      "batch 6080, train_loss 126.342491,Time used 0.012003s\n",
      "batch 6081, train_loss 124.560860,Time used 0.011001s\n",
      "batch 6082, train_loss 86.890320,Time used 0.008999s\n",
      "batch 6083, train_loss 116.257217,Time used 0.008998s\n",
      "batch 6084, train_loss 97.828941,Time used 0.011000s\n",
      "batch 6085, train_loss 127.194412,Time used 0.007002s\n",
      "batch 6086, train_loss 114.337082,Time used 0.007998s\n",
      "batch 6087, train_loss 94.401886,Time used 0.011001s\n",
      "batch 6088, train_loss 92.070709,Time used 0.010000s\n",
      "batch 6089, train_loss 123.958984,Time used 0.008000s\n",
      "batch 6090, train_loss 129.227707,Time used 0.007999s\n",
      "batch 6091, train_loss 131.102325,Time used 0.010002s\n",
      "batch 6092, train_loss 136.802979,Time used 0.011001s\n",
      "batch 6093, train_loss 86.961609,Time used 0.007998s\n",
      "batch 6094, train_loss 112.653114,Time used 0.007001s\n",
      "batch 6095, train_loss 129.059677,Time used 0.008998s\n",
      "batch 6096, train_loss 97.076019,Time used 0.009000s\n",
      "batch 6097, train_loss 104.594383,Time used 0.006999s\n",
      "batch 6098, train_loss 83.269958,Time used 0.010999s\n",
      "batch 6099, train_loss 118.652122,Time used 0.008004s\n",
      "batch 6100, train_loss 125.023514,Time used 0.008998s\n",
      "***************************test_batch 6100, test_rmse_loss 12.257217,test_mae_loss 4.714482,test_mape_loss 66.997146,Time used 0.037000s\n",
      "batch 6101, train_loss 106.695541,Time used 0.010999s\n",
      "batch 6102, train_loss 108.141502,Time used 0.010000s\n",
      "batch 6103, train_loss 118.902565,Time used 0.010999s\n",
      "batch 6104, train_loss 115.583633,Time used 0.010001s\n",
      "batch 6105, train_loss 126.561043,Time used 0.008001s\n",
      "batch 6106, train_loss 145.465607,Time used 0.010999s\n",
      "batch 6107, train_loss 114.171684,Time used 0.008998s\n",
      "batch 6108, train_loss 119.573753,Time used 0.007999s\n",
      "batch 6109, train_loss 115.788361,Time used 0.008001s\n",
      "batch 6110, train_loss 92.225327,Time used 0.007000s\n",
      "batch 6111, train_loss 117.015366,Time used 0.008999s\n",
      "batch 6112, train_loss 140.609619,Time used 0.007000s\n",
      "batch 6113, train_loss 90.102837,Time used 0.007001s\n",
      "batch 6114, train_loss 106.990242,Time used 0.007000s\n",
      "batch 6115, train_loss 142.601807,Time used 0.008001s\n",
      "batch 6116, train_loss 111.551064,Time used 0.008000s\n",
      "batch 6117, train_loss 99.943390,Time used 0.009001s\n",
      "batch 6118, train_loss 81.558037,Time used 0.008996s\n",
      "batch 6119, train_loss 117.903023,Time used 0.009004s\n",
      "batch 6120, train_loss 128.099411,Time used 0.008001s\n",
      "batch 6121, train_loss 143.752243,Time used 0.009002s\n",
      "batch 6122, train_loss 108.931366,Time used 0.008001s\n",
      "batch 6123, train_loss 108.348640,Time used 0.009999s\n",
      "batch 6124, train_loss 95.707230,Time used 0.011001s\n",
      "batch 6125, train_loss 125.605904,Time used 0.006998s\n",
      "batch 6126, train_loss 77.127327,Time used 0.008001s\n",
      "batch 6127, train_loss 120.050598,Time used 0.008002s\n",
      "batch 6128, train_loss 135.504303,Time used 0.007998s\n",
      "batch 6129, train_loss 95.934494,Time used 0.010001s\n",
      "batch 6130, train_loss 110.440514,Time used 0.007999s\n",
      "batch 6131, train_loss 128.594452,Time used 0.007001s\n",
      "batch 6132, train_loss 107.108070,Time used 0.011999s\n",
      "batch 6133, train_loss 99.797478,Time used 0.008999s\n",
      "batch 6134, train_loss 99.779518,Time used 0.009003s\n",
      "batch 6135, train_loss 157.268188,Time used 0.007998s\n",
      "batch 6136, train_loss 169.414780,Time used 0.006998s\n",
      "batch 6137, train_loss 100.957451,Time used 0.010001s\n",
      "batch 6138, train_loss 106.839478,Time used 0.011999s\n",
      "batch 6139, train_loss 103.823982,Time used 0.008001s\n",
      "batch 6140, train_loss 101.655663,Time used 0.011002s\n",
      "batch 6141, train_loss 84.733994,Time used 0.009997s\n",
      "batch 6142, train_loss 148.676712,Time used 0.010002s\n",
      "batch 6143, train_loss 96.501472,Time used 0.010002s\n",
      "batch 6144, train_loss 93.830124,Time used 0.011001s\n",
      "batch 6145, train_loss 150.708878,Time used 0.012001s\n",
      "batch 6146, train_loss 108.690819,Time used 0.008000s\n",
      "batch 6147, train_loss 128.341141,Time used 0.009000s\n",
      "batch 6148, train_loss 146.252167,Time used 0.007999s\n",
      "batch 6149, train_loss 95.882835,Time used 0.009001s\n",
      "batch 6150, train_loss 86.559753,Time used 0.010000s\n",
      "batch 6151, train_loss 114.949623,Time used 0.009007s\n",
      "batch 6152, train_loss 129.783844,Time used 0.006993s\n",
      "batch 6153, train_loss 92.080650,Time used 0.006999s\n",
      "batch 6154, train_loss 91.216553,Time used 0.008000s\n",
      "batch 6155, train_loss 119.725861,Time used 0.007000s\n",
      "batch 6156, train_loss 100.268600,Time used 0.008000s\n",
      "batch 6157, train_loss 138.942749,Time used 0.010010s\n",
      "batch 6158, train_loss 138.962646,Time used 0.007991s\n",
      "batch 6159, train_loss 102.522110,Time used 0.009003s\n",
      "batch 6160, train_loss 134.613556,Time used 0.007997s\n",
      "batch 6161, train_loss 102.887268,Time used 0.010998s\n",
      "batch 6162, train_loss 96.989906,Time used 0.010003s\n",
      "batch 6163, train_loss 109.931252,Time used 0.011000s\n",
      "batch 6164, train_loss 93.716255,Time used 0.008998s\n",
      "batch 6165, train_loss 96.789848,Time used 0.007002s\n",
      "batch 6166, train_loss 103.656281,Time used 0.010036s\n",
      "batch 6167, train_loss 110.600609,Time used 0.007963s\n",
      "batch 6168, train_loss 118.015846,Time used 0.011003s\n",
      "batch 6169, train_loss 109.696136,Time used 0.014000s\n",
      "batch 6170, train_loss 126.422592,Time used 0.012000s\n",
      "batch 6171, train_loss 133.706329,Time used 0.012998s\n",
      "batch 6172, train_loss 120.961601,Time used 0.010002s\n",
      "batch 6173, train_loss 105.729927,Time used 0.012002s\n",
      "batch 6174, train_loss 85.233284,Time used 0.011997s\n",
      "batch 6175, train_loss 145.337494,Time used 0.008001s\n",
      "batch 6176, train_loss 114.117462,Time used 0.009000s\n",
      "batch 6177, train_loss 100.114182,Time used 0.008001s\n",
      "batch 6178, train_loss 127.950005,Time used 0.007997s\n",
      "batch 6179, train_loss 116.311226,Time used 0.009002s\n",
      "batch 6180, train_loss 133.210571,Time used 0.011002s\n",
      "batch 6181, train_loss 102.853058,Time used 0.012000s\n",
      "batch 6182, train_loss 138.407837,Time used 0.011001s\n",
      "batch 6183, train_loss 120.278343,Time used 0.007998s\n",
      "batch 6184, train_loss 129.347961,Time used 0.007001s\n",
      "batch 6185, train_loss 68.921402,Time used 0.009999s\n",
      "batch 6186, train_loss 86.734055,Time used 0.009001s\n",
      "batch 6187, train_loss 119.638275,Time used 0.009001s\n",
      "batch 6188, train_loss 99.004417,Time used 0.008000s\n",
      "batch 6189, train_loss 112.769165,Time used 0.009001s\n",
      "batch 6190, train_loss 97.665207,Time used 0.010002s\n",
      "batch 6191, train_loss 92.576012,Time used 0.010998s\n",
      "batch 6192, train_loss 115.849274,Time used 0.009999s\n",
      "batch 6193, train_loss 94.314888,Time used 0.008000s\n",
      "batch 6194, train_loss 119.551346,Time used 0.007002s\n",
      "batch 6195, train_loss 108.427956,Time used 0.007004s\n",
      "batch 6196, train_loss 120.830383,Time used 0.006999s\n",
      "batch 6197, train_loss 121.355453,Time used 0.008000s\n",
      "batch 6198, train_loss 110.824554,Time used 0.008000s\n",
      "batch 6199, train_loss 101.153419,Time used 0.009040s\n",
      "batch 6200, train_loss 104.744072,Time used 0.009998s\n",
      "***************************test_batch 6200, test_rmse_loss 12.171534,test_mae_loss 4.689395,test_mape_loss 67.153403,Time used 0.032001s\n",
      "batch 6201, train_loss 133.016144,Time used 0.009999s\n",
      "batch 6202, train_loss 143.665558,Time used 0.010001s\n",
      "batch 6203, train_loss 93.277977,Time used 0.010024s\n",
      "batch 6204, train_loss 117.334579,Time used 0.009975s\n",
      "batch 6205, train_loss 107.361023,Time used 0.009003s\n",
      "batch 6206, train_loss 98.594215,Time used 0.008000s\n",
      "batch 6207, train_loss 97.958359,Time used 0.009041s\n",
      "batch 6208, train_loss 131.375366,Time used 0.007955s\n",
      "batch 6209, train_loss 120.643059,Time used 0.007001s\n",
      "batch 6210, train_loss 121.093491,Time used 0.006999s\n",
      "batch 6211, train_loss 137.737061,Time used 0.007002s\n",
      "batch 6212, train_loss 99.119759,Time used 0.008002s\n",
      "batch 6213, train_loss 102.674759,Time used 0.006999s\n",
      "batch 6214, train_loss 89.712662,Time used 0.008001s\n",
      "batch 6215, train_loss 109.402542,Time used 0.007999s\n",
      "batch 6216, train_loss 109.288704,Time used 0.007001s\n",
      "batch 6217, train_loss 123.969131,Time used 0.006964s\n",
      "batch 6218, train_loss 152.150497,Time used 0.010002s\n",
      "batch 6219, train_loss 118.454514,Time used 0.010000s\n",
      "batch 6220, train_loss 86.213257,Time used 0.006997s\n",
      "batch 6221, train_loss 114.468216,Time used 0.007000s\n",
      "batch 6222, train_loss 89.452591,Time used 0.009001s\n",
      "batch 6223, train_loss 98.728058,Time used 0.007998s\n",
      "batch 6224, train_loss 125.780510,Time used 0.008002s\n",
      "batch 6225, train_loss 103.672348,Time used 0.007997s\n",
      "batch 6226, train_loss 95.789841,Time used 0.013001s\n",
      "batch 6227, train_loss 118.947075,Time used 0.008997s\n",
      "batch 6228, train_loss 139.803726,Time used 0.008001s\n",
      "batch 6229, train_loss 92.681595,Time used 0.011999s\n",
      "batch 6230, train_loss 99.764847,Time used 0.010001s\n",
      "batch 6231, train_loss 111.453873,Time used 0.008999s\n",
      "batch 6232, train_loss 107.828842,Time used 0.010002s\n",
      "batch 6233, train_loss 91.386459,Time used 0.006999s\n",
      "batch 6234, train_loss 137.730331,Time used 0.006999s\n",
      "batch 6235, train_loss 102.985596,Time used 0.009000s\n",
      "batch 6236, train_loss 135.614288,Time used 0.008002s\n",
      "batch 6237, train_loss 109.537842,Time used 0.009005s\n",
      "batch 6238, train_loss 99.844429,Time used 0.010993s\n",
      "batch 6239, train_loss 120.808006,Time used 0.010002s\n",
      "batch 6240, train_loss 107.296333,Time used 0.008000s\n",
      "batch 6241, train_loss 90.921402,Time used 0.011999s\n",
      "batch 6242, train_loss 78.203583,Time used 0.008000s\n",
      "batch 6243, train_loss 84.789307,Time used 0.009999s\n",
      "batch 6244, train_loss 122.724503,Time used 0.008998s\n",
      "batch 6245, train_loss 139.208084,Time used 0.007000s\n",
      "batch 6246, train_loss 137.938171,Time used 0.010003s\n",
      "batch 6247, train_loss 97.777214,Time used 0.011000s\n",
      "batch 6248, train_loss 142.016342,Time used 0.008001s\n",
      "batch 6249, train_loss 137.508835,Time used 0.008001s\n",
      "batch 6250, train_loss 119.529411,Time used 0.008999s\n",
      "batch 6251, train_loss 105.110306,Time used 0.010003s\n",
      "batch 6252, train_loss 147.125046,Time used 0.008998s\n",
      "batch 6253, train_loss 115.602562,Time used 0.010998s\n",
      "batch 6254, train_loss 64.898293,Time used 0.008001s\n",
      "batch 6255, train_loss 110.220779,Time used 0.009000s\n",
      "batch 6256, train_loss 115.637619,Time used 0.008000s\n",
      "batch 6257, train_loss 106.755676,Time used 0.008000s\n",
      "batch 6258, train_loss 113.310532,Time used 0.009002s\n",
      "batch 6259, train_loss 115.949463,Time used 0.007999s\n",
      "batch 6260, train_loss 99.134277,Time used 0.010000s\n",
      "batch 6261, train_loss 101.191689,Time used 0.009002s\n",
      "batch 6262, train_loss 144.921249,Time used 0.008000s\n",
      "batch 6263, train_loss 105.878624,Time used 0.010998s\n",
      "batch 6264, train_loss 77.721741,Time used 0.008002s\n",
      "batch 6265, train_loss 122.257858,Time used 0.012001s\n",
      "batch 6266, train_loss 97.758476,Time used 0.014999s\n",
      "batch 6267, train_loss 134.687012,Time used 0.011002s\n",
      "batch 6268, train_loss 110.572777,Time used 0.007997s\n",
      "batch 6269, train_loss 112.001556,Time used 0.008002s\n",
      "batch 6270, train_loss 87.854271,Time used 0.009001s\n",
      "batch 6271, train_loss 85.697662,Time used 0.008000s\n",
      "batch 6272, train_loss 136.527985,Time used 0.011000s\n",
      "batch 6273, train_loss 96.280548,Time used 0.012003s\n",
      "batch 6274, train_loss 120.701324,Time used 0.011000s\n",
      "batch 6275, train_loss 109.250458,Time used 0.011998s\n",
      "batch 6276, train_loss 125.771675,Time used 0.007999s\n",
      "batch 6277, train_loss 88.819939,Time used 0.007001s\n",
      "batch 6278, train_loss 139.996506,Time used 0.008000s\n",
      "batch 6279, train_loss 112.139946,Time used 0.010001s\n",
      "batch 6280, train_loss 116.664940,Time used 0.009002s\n",
      "batch 6281, train_loss 108.375565,Time used 0.011996s\n",
      "batch 6282, train_loss 119.039612,Time used 0.012001s\n",
      "batch 6283, train_loss 109.985275,Time used 0.013999s\n",
      "batch 6284, train_loss 89.779366,Time used 0.011002s\n",
      "batch 6285, train_loss 122.193230,Time used 0.007004s\n",
      "batch 6286, train_loss 91.019638,Time used 0.008000s\n",
      "batch 6287, train_loss 112.759369,Time used 0.007001s\n",
      "batch 6288, train_loss 116.611198,Time used 0.008000s\n",
      "batch 6289, train_loss 129.588928,Time used 0.007000s\n",
      "batch 6290, train_loss 107.137260,Time used 0.007002s\n",
      "batch 6291, train_loss 113.090790,Time used 0.007999s\n",
      "batch 6292, train_loss 92.921936,Time used 0.008003s\n",
      "batch 6293, train_loss 133.439102,Time used 0.007999s\n",
      "batch 6294, train_loss 96.558014,Time used 0.009999s\n",
      "batch 6295, train_loss 133.337372,Time used 0.007999s\n",
      "batch 6296, train_loss 122.863930,Time used 0.007001s\n",
      "batch 6297, train_loss 100.619278,Time used 0.007000s\n",
      "batch 6298, train_loss 125.423134,Time used 0.007000s\n",
      "batch 6299, train_loss 141.974350,Time used 0.007998s\n",
      "batch 6300, train_loss 85.437828,Time used 0.010034s\n",
      "***************************test_batch 6300, test_rmse_loss 12.091682,test_mae_loss 4.659040,test_mape_loss 66.666117,Time used 0.033965s\n",
      "batch 6301, train_loss 86.919594,Time used 0.008001s\n",
      "batch 6302, train_loss 101.550079,Time used 0.007998s\n",
      "batch 6303, train_loss 73.445412,Time used 0.008004s\n",
      "batch 6304, train_loss 92.637253,Time used 0.008999s\n",
      "batch 6305, train_loss 102.670158,Time used 0.011032s\n",
      "batch 6306, train_loss 110.600288,Time used 0.007037s\n",
      "batch 6307, train_loss 91.476067,Time used 0.006998s\n",
      "batch 6308, train_loss 160.324127,Time used 0.006967s\n",
      "batch 6309, train_loss 111.554459,Time used 0.008999s\n",
      "batch 6310, train_loss 135.180161,Time used 0.008998s\n",
      "batch 6311, train_loss 121.968071,Time used 0.011003s\n",
      "batch 6312, train_loss 85.821152,Time used 0.011003s\n",
      "batch 6313, train_loss 104.511185,Time used 0.008001s\n",
      "batch 6314, train_loss 111.701309,Time used 0.012998s\n",
      "batch 6315, train_loss 94.919579,Time used 0.009000s\n",
      "batch 6316, train_loss 99.725296,Time used 0.008000s\n",
      "batch 6317, train_loss 85.007500,Time used 0.008002s\n",
      "batch 6318, train_loss 98.622581,Time used 0.007999s\n",
      "batch 6319, train_loss 118.146263,Time used 0.010998s\n",
      "batch 6320, train_loss 101.280632,Time used 0.011000s\n",
      "batch 6321, train_loss 91.519630,Time used 0.010002s\n",
      "batch 6322, train_loss 152.608643,Time used 0.008000s\n",
      "batch 6323, train_loss 111.165710,Time used 0.010036s\n",
      "batch 6324, train_loss 122.803993,Time used 0.008961s\n",
      "batch 6325, train_loss 105.656181,Time used 0.010002s\n",
      "batch 6326, train_loss 105.905952,Time used 0.009998s\n",
      "batch 6327, train_loss 88.483528,Time used 0.008998s\n",
      "batch 6328, train_loss 97.580963,Time used 0.012001s\n",
      "batch 6329, train_loss 106.851967,Time used 0.009001s\n",
      "batch 6330, train_loss 98.721497,Time used 0.006999s\n",
      "batch 6331, train_loss 122.321182,Time used 0.008002s\n",
      "batch 6332, train_loss 131.480988,Time used 0.009002s\n",
      "batch 6333, train_loss 135.781525,Time used 0.010997s\n",
      "batch 6334, train_loss 95.710014,Time used 0.010001s\n",
      "batch 6335, train_loss 127.761162,Time used 0.007996s\n",
      "batch 6336, train_loss 141.725861,Time used 0.007000s\n",
      "batch 6337, train_loss 120.340858,Time used 0.009000s\n",
      "batch 6338, train_loss 141.926132,Time used 0.011000s\n",
      "batch 6339, train_loss 118.806641,Time used 0.010000s\n",
      "batch 6340, train_loss 102.216850,Time used 0.010001s\n",
      "batch 6341, train_loss 133.160904,Time used 0.008999s\n",
      "batch 6342, train_loss 89.488174,Time used 0.011002s\n",
      "batch 6343, train_loss 85.183029,Time used 0.012000s\n",
      "batch 6344, train_loss 117.980476,Time used 0.011998s\n",
      "batch 6345, train_loss 116.549232,Time used 0.007000s\n",
      "batch 6346, train_loss 135.344482,Time used 0.007000s\n",
      "batch 6347, train_loss 111.877945,Time used 0.007000s\n",
      "batch 6348, train_loss 114.898827,Time used 0.008000s\n",
      "batch 6349, train_loss 97.973289,Time used 0.007999s\n",
      "batch 6350, train_loss 97.740173,Time used 0.007000s\n",
      "batch 6351, train_loss 123.346077,Time used 0.008002s\n",
      "batch 6352, train_loss 95.300224,Time used 0.007000s\n",
      "batch 6353, train_loss 129.393494,Time used 0.008000s\n",
      "batch 6354, train_loss 115.376396,Time used 0.008000s\n",
      "batch 6355, train_loss 103.942917,Time used 0.009999s\n",
      "batch 6356, train_loss 111.050201,Time used 0.008001s\n",
      "batch 6357, train_loss 83.281921,Time used 0.006998s\n",
      "batch 6358, train_loss 98.493172,Time used 0.007002s\n",
      "batch 6359, train_loss 115.149544,Time used 0.007000s\n",
      "batch 6360, train_loss 79.921104,Time used 0.008000s\n",
      "batch 6361, train_loss 131.078445,Time used 0.010998s\n",
      "batch 6362, train_loss 111.720657,Time used 0.010003s\n",
      "batch 6363, train_loss 104.395958,Time used 0.009000s\n",
      "batch 6364, train_loss 96.959549,Time used 0.010000s\n",
      "batch 6365, train_loss 92.518486,Time used 0.010003s\n",
      "batch 6366, train_loss 104.065392,Time used 0.011997s\n",
      "batch 6367, train_loss 110.801468,Time used 0.011000s\n",
      "batch 6368, train_loss 126.564003,Time used 0.010000s\n",
      "batch 6369, train_loss 116.382751,Time used 0.010000s\n",
      "batch 6370, train_loss 116.994270,Time used 0.008999s\n",
      "batch 6371, train_loss 127.026115,Time used 0.008001s\n",
      "batch 6372, train_loss 112.699951,Time used 0.011999s\n",
      "batch 6373, train_loss 141.622787,Time used 0.009002s\n",
      "batch 6374, train_loss 71.870453,Time used 0.008001s\n",
      "batch 6375, train_loss 122.742683,Time used 0.010999s\n",
      "batch 6376, train_loss 97.930359,Time used 0.011998s\n",
      "batch 6377, train_loss 114.535652,Time used 0.010000s\n",
      "batch 6378, train_loss 87.487381,Time used 0.010001s\n",
      "batch 6379, train_loss 101.399185,Time used 0.007999s\n",
      "batch 6380, train_loss 110.709076,Time used 0.009004s\n",
      "batch 6381, train_loss 100.235008,Time used 0.007998s\n",
      "batch 6382, train_loss 117.673073,Time used 0.009001s\n",
      "batch 6383, train_loss 99.423775,Time used 0.012001s\n",
      "batch 6384, train_loss 114.280655,Time used 0.009999s\n",
      "batch 6385, train_loss 113.695351,Time used 0.012000s\n",
      "batch 6386, train_loss 129.349152,Time used 0.008998s\n",
      "batch 6387, train_loss 120.623169,Time used 0.007999s\n",
      "batch 6388, train_loss 69.431984,Time used 0.007000s\n",
      "batch 6389, train_loss 84.528275,Time used 0.010002s\n",
      "batch 6390, train_loss 116.338417,Time used 0.008000s\n",
      "batch 6391, train_loss 107.590118,Time used 0.008000s\n",
      "batch 6392, train_loss 112.861427,Time used 0.010998s\n",
      "batch 6393, train_loss 98.194435,Time used 0.010001s\n",
      "batch 6394, train_loss 100.249069,Time used 0.011002s\n",
      "batch 6395, train_loss 104.574867,Time used 0.009000s\n",
      "batch 6396, train_loss 105.705910,Time used 0.009997s\n",
      "batch 6397, train_loss 122.374786,Time used 0.007998s\n",
      "batch 6398, train_loss 104.608925,Time used 0.009995s\n",
      "batch 6399, train_loss 107.790146,Time used 0.008000s\n",
      "batch 6400, train_loss 107.363640,Time used 0.010000s\n",
      "***************************test_batch 6400, test_rmse_loss 12.007406,test_mae_loss 4.636443,test_mape_loss 67.019000,Time used 0.040001s\n",
      "batch 6401, train_loss 132.118881,Time used 0.012001s\n",
      "batch 6402, train_loss 94.426056,Time used 0.006999s\n",
      "batch 6403, train_loss 134.711075,Time used 0.007999s\n",
      "batch 6404, train_loss 112.571564,Time used 0.008000s\n",
      "batch 6405, train_loss 108.737068,Time used 0.008001s\n",
      "batch 6406, train_loss 113.070007,Time used 0.006999s\n",
      "batch 6407, train_loss 126.447762,Time used 0.007002s\n",
      "batch 6408, train_loss 94.245926,Time used 0.006998s\n",
      "batch 6409, train_loss 116.043266,Time used 0.008009s\n",
      "batch 6410, train_loss 115.833481,Time used 0.007992s\n",
      "batch 6411, train_loss 107.305916,Time used 0.010000s\n",
      "batch 6412, train_loss 104.966774,Time used 0.006999s\n",
      "batch 6413, train_loss 87.644814,Time used 0.011002s\n",
      "batch 6414, train_loss 101.557030,Time used 0.008001s\n",
      "batch 6415, train_loss 97.832993,Time used 0.007998s\n",
      "batch 6416, train_loss 142.259964,Time used 0.008003s\n",
      "batch 6417, train_loss 125.714874,Time used 0.008997s\n",
      "batch 6418, train_loss 117.469879,Time used 0.008036s\n",
      "batch 6419, train_loss 120.958786,Time used 0.007962s\n",
      "batch 6420, train_loss 97.030556,Time used 0.010003s\n",
      "batch 6421, train_loss 104.347435,Time used 0.010999s\n",
      "batch 6422, train_loss 100.394394,Time used 0.007999s\n",
      "batch 6423, train_loss 108.159660,Time used 0.007002s\n",
      "batch 6424, train_loss 110.054543,Time used 0.010000s\n",
      "batch 6425, train_loss 98.073837,Time used 0.008997s\n",
      "batch 6426, train_loss 123.975540,Time used 0.011007s\n",
      "batch 6427, train_loss 102.743790,Time used 0.006994s\n",
      "batch 6428, train_loss 120.803162,Time used 0.008000s\n",
      "batch 6429, train_loss 117.130676,Time used 0.007999s\n",
      "batch 6430, train_loss 102.298935,Time used 0.007997s\n",
      "batch 6431, train_loss 101.896576,Time used 0.007000s\n",
      "batch 6432, train_loss 88.293816,Time used 0.008001s\n",
      "batch 6433, train_loss 121.067719,Time used 0.011000s\n",
      "batch 6434, train_loss 116.954399,Time used 0.008000s\n",
      "batch 6435, train_loss 107.565697,Time used 0.007998s\n",
      "batch 6436, train_loss 116.617081,Time used 0.007001s\n",
      "batch 6437, train_loss 129.458862,Time used 0.008000s\n",
      "batch 6438, train_loss 108.263298,Time used 0.010001s\n",
      "batch 6439, train_loss 88.912422,Time used 0.008000s\n",
      "batch 6440, train_loss 101.977592,Time used 0.008003s\n",
      "batch 6441, train_loss 107.585373,Time used 0.009001s\n",
      "batch 6442, train_loss 122.101379,Time used 0.010001s\n",
      "batch 6443, train_loss 114.193779,Time used 0.008000s\n",
      "batch 6444, train_loss 103.620323,Time used 0.010000s\n",
      "batch 6445, train_loss 107.924873,Time used 0.011001s\n",
      "batch 6446, train_loss 78.053909,Time used 0.009001s\n",
      "batch 6447, train_loss 102.738319,Time used 0.010997s\n",
      "batch 6448, train_loss 118.347115,Time used 0.008001s\n",
      "batch 6449, train_loss 101.208038,Time used 0.009998s\n",
      "batch 6450, train_loss 121.811363,Time used 0.011001s\n",
      "batch 6451, train_loss 91.017509,Time used 0.007999s\n",
      "batch 6452, train_loss 84.347176,Time used 0.007002s\n",
      "batch 6453, train_loss 135.906326,Time used 0.007000s\n",
      "batch 6454, train_loss 91.923134,Time used 0.008999s\n",
      "batch 6455, train_loss 121.199577,Time used 0.006998s\n",
      "batch 6456, train_loss 112.370041,Time used 0.009005s\n",
      "batch 6457, train_loss 110.087097,Time used 0.008999s\n",
      "batch 6458, train_loss 130.185593,Time used 0.008002s\n",
      "batch 6459, train_loss 94.593544,Time used 0.010998s\n",
      "batch 6460, train_loss 100.759995,Time used 0.010999s\n",
      "batch 6461, train_loss 113.320869,Time used 0.008999s\n",
      "batch 6462, train_loss 106.139610,Time used 0.011002s\n",
      "batch 6463, train_loss 84.617737,Time used 0.009000s\n",
      "batch 6464, train_loss 72.404869,Time used 0.011001s\n",
      "batch 6465, train_loss 115.576302,Time used 0.008999s\n",
      "batch 6466, train_loss 104.196236,Time used 0.010000s\n",
      "batch 6467, train_loss 104.018829,Time used 0.011001s\n",
      "batch 6468, train_loss 79.273872,Time used 0.009000s\n",
      "batch 6469, train_loss 111.831764,Time used 0.009999s\n",
      "batch 6470, train_loss 132.672470,Time used 0.008000s\n",
      "batch 6471, train_loss 115.177757,Time used 0.009999s\n",
      "batch 6472, train_loss 91.190689,Time used 0.010006s\n",
      "batch 6473, train_loss 108.579315,Time used 0.009996s\n",
      "batch 6474, train_loss 117.310577,Time used 0.012999s\n",
      "batch 6475, train_loss 120.237473,Time used 0.011001s\n",
      "batch 6476, train_loss 140.348572,Time used 0.008001s\n",
      "batch 6477, train_loss 138.891464,Time used 0.009999s\n",
      "batch 6478, train_loss 120.877853,Time used 0.010000s\n",
      "batch 6479, train_loss 107.926224,Time used 0.009000s\n",
      "batch 6480, train_loss 74.822884,Time used 0.010001s\n",
      "batch 6481, train_loss 103.318748,Time used 0.010000s\n",
      "batch 6482, train_loss 97.657410,Time used 0.013002s\n",
      "batch 6483, train_loss 98.308586,Time used 0.014000s\n",
      "batch 6484, train_loss 104.548355,Time used 0.006999s\n",
      "batch 6485, train_loss 84.500542,Time used 0.008999s\n",
      "batch 6486, train_loss 115.517685,Time used 0.007001s\n",
      "batch 6487, train_loss 132.001266,Time used 0.007999s\n",
      "batch 6488, train_loss 73.183846,Time used 0.009005s\n",
      "batch 6489, train_loss 88.342102,Time used 0.007999s\n",
      "batch 6490, train_loss 96.125565,Time used 0.009995s\n",
      "batch 6491, train_loss 117.734673,Time used 0.007000s\n",
      "batch 6492, train_loss 104.732201,Time used 0.007001s\n",
      "batch 6493, train_loss 111.080475,Time used 0.010001s\n",
      "batch 6494, train_loss 127.485550,Time used 0.008004s\n",
      "batch 6495, train_loss 103.792557,Time used 0.006997s\n",
      "batch 6496, train_loss 121.609833,Time used 0.007001s\n",
      "batch 6497, train_loss 138.404724,Time used 0.007999s\n",
      "batch 6498, train_loss 110.329315,Time used 0.008001s\n",
      "batch 6499, train_loss 125.879074,Time used 0.007997s\n",
      "batch 6500, train_loss 113.169373,Time used 0.010002s\n",
      "***************************test_batch 6500, test_rmse_loss 11.928362,test_mae_loss 4.608571,test_mape_loss 66.685505,Time used 0.029999s\n",
      "batch 6501, train_loss 132.621765,Time used 0.009001s\n",
      "batch 6502, train_loss 97.535385,Time used 0.008000s\n",
      "batch 6503, train_loss 80.351936,Time used 0.008012s\n",
      "batch 6504, train_loss 109.908203,Time used 0.006997s\n",
      "batch 6505, train_loss 125.555489,Time used 0.008002s\n",
      "batch 6506, train_loss 85.654724,Time used 0.007998s\n",
      "batch 6507, train_loss 106.659966,Time used 0.006998s\n",
      "batch 6508, train_loss 138.617157,Time used 0.008002s\n",
      "batch 6509, train_loss 121.991440,Time used 0.009998s\n",
      "batch 6510, train_loss 102.178886,Time used 0.007001s\n",
      "batch 6511, train_loss 86.202972,Time used 0.007001s\n",
      "batch 6512, train_loss 92.560219,Time used 0.006999s\n",
      "batch 6513, train_loss 129.338715,Time used 0.011002s\n",
      "batch 6514, train_loss 83.442451,Time used 0.010999s\n",
      "batch 6515, train_loss 127.861374,Time used 0.007002s\n",
      "batch 6516, train_loss 111.380608,Time used 0.009000s\n",
      "batch 6517, train_loss 86.470406,Time used 0.008000s\n",
      "batch 6518, train_loss 102.490433,Time used 0.008999s\n",
      "batch 6519, train_loss 99.286766,Time used 0.010000s\n",
      "batch 6520, train_loss 122.792030,Time used 0.007999s\n",
      "batch 6521, train_loss 89.458244,Time used 0.008998s\n",
      "batch 6522, train_loss 106.189346,Time used 0.012001s\n",
      "batch 6523, train_loss 126.350624,Time used 0.010000s\n",
      "batch 6524, train_loss 100.981064,Time used 0.009009s\n",
      "batch 6525, train_loss 108.510559,Time used 0.010992s\n",
      "batch 6526, train_loss 111.415871,Time used 0.011001s\n",
      "batch 6527, train_loss 114.359161,Time used 0.008998s\n",
      "batch 6528, train_loss 99.395706,Time used 0.008000s\n",
      "batch 6529, train_loss 106.456161,Time used 0.010999s\n",
      "batch 6530, train_loss 144.080826,Time used 0.007001s\n",
      "batch 6531, train_loss 140.328705,Time used 0.007998s\n",
      "batch 6532, train_loss 122.105225,Time used 0.007003s\n",
      "batch 6533, train_loss 108.674355,Time used 0.007997s\n",
      "batch 6534, train_loss 101.607803,Time used 0.010001s\n",
      "batch 6535, train_loss 102.622307,Time used 0.008003s\n",
      "batch 6536, train_loss 120.998589,Time used 0.007998s\n",
      "batch 6537, train_loss 106.548233,Time used 0.007000s\n",
      "batch 6538, train_loss 93.854965,Time used 0.007999s\n",
      "batch 6539, train_loss 123.005371,Time used 0.008002s\n",
      "batch 6540, train_loss 99.919350,Time used 0.006999s\n",
      "batch 6541, train_loss 98.439362,Time used 0.008001s\n",
      "batch 6542, train_loss 98.450249,Time used 0.008999s\n",
      "batch 6543, train_loss 117.898872,Time used 0.010998s\n",
      "batch 6544, train_loss 84.036339,Time used 0.012001s\n",
      "batch 6545, train_loss 93.027397,Time used 0.012001s\n",
      "batch 6546, train_loss 97.733612,Time used 0.010000s\n",
      "batch 6547, train_loss 99.123955,Time used 0.008998s\n",
      "batch 6548, train_loss 74.720573,Time used 0.010999s\n",
      "batch 6549, train_loss 89.044846,Time used 0.011000s\n",
      "batch 6550, train_loss 113.237328,Time used 0.007001s\n",
      "batch 6551, train_loss 96.526192,Time used 0.008000s\n",
      "batch 6552, train_loss 139.900955,Time used 0.006999s\n",
      "batch 6553, train_loss 130.501068,Time used 0.009999s\n",
      "batch 6554, train_loss 131.092178,Time used 0.008000s\n",
      "batch 6555, train_loss 116.626038,Time used 0.008002s\n",
      "batch 6556, train_loss 97.091591,Time used 0.007002s\n",
      "batch 6557, train_loss 111.295174,Time used 0.010997s\n",
      "batch 6558, train_loss 124.867966,Time used 0.011001s\n",
      "batch 6559, train_loss 68.643105,Time used 0.012002s\n",
      "batch 6560, train_loss 97.094101,Time used 0.009007s\n",
      "batch 6561, train_loss 135.940338,Time used 0.011993s\n",
      "batch 6562, train_loss 74.820526,Time used 0.012002s\n",
      "batch 6563, train_loss 113.684647,Time used 0.010997s\n",
      "batch 6564, train_loss 118.304131,Time used 0.011004s\n",
      "batch 6565, train_loss 128.907227,Time used 0.012001s\n",
      "batch 6566, train_loss 97.596985,Time used 0.012002s\n",
      "batch 6567, train_loss 107.626427,Time used 0.009999s\n",
      "batch 6568, train_loss 84.174210,Time used 0.011001s\n",
      "batch 6569, train_loss 115.812805,Time used 0.010002s\n",
      "batch 6570, train_loss 100.816582,Time used 0.009998s\n",
      "batch 6571, train_loss 126.932106,Time used 0.010002s\n",
      "batch 6572, train_loss 104.351067,Time used 0.012001s\n",
      "batch 6573, train_loss 106.043983,Time used 0.012002s\n",
      "batch 6574, train_loss 88.124603,Time used 0.012002s\n",
      "batch 6575, train_loss 90.264999,Time used 0.013999s\n",
      "batch 6576, train_loss 91.599487,Time used 0.011998s\n",
      "batch 6577, train_loss 85.962700,Time used 0.011998s\n",
      "batch 6578, train_loss 128.802353,Time used 0.011003s\n",
      "batch 6579, train_loss 99.479866,Time used 0.010999s\n",
      "batch 6580, train_loss 99.415688,Time used 0.023003s\n",
      "batch 6581, train_loss 134.047775,Time used 0.018002s\n",
      "batch 6582, train_loss 109.097069,Time used 0.026000s\n",
      "batch 6583, train_loss 114.628174,Time used 0.013001s\n",
      "batch 6584, train_loss 125.876930,Time used 0.016000s\n",
      "batch 6585, train_loss 92.916069,Time used 0.012000s\n",
      "batch 6586, train_loss 113.234398,Time used 0.016001s\n",
      "batch 6587, train_loss 88.439415,Time used 0.019997s\n",
      "batch 6588, train_loss 89.354309,Time used 0.014002s\n",
      "batch 6589, train_loss 108.101471,Time used 0.012000s\n",
      "batch 6590, train_loss 102.456718,Time used 0.012001s\n",
      "batch 6591, train_loss 115.144897,Time used 0.012999s\n",
      "batch 6592, train_loss 85.974930,Time used 0.013999s\n",
      "batch 6593, train_loss 72.257202,Time used 0.012001s\n",
      "batch 6594, train_loss 104.223320,Time used 0.013000s\n",
      "batch 6595, train_loss 134.758545,Time used 0.013999s\n",
      "batch 6596, train_loss 87.664520,Time used 0.011000s\n",
      "batch 6597, train_loss 136.475037,Time used 0.011000s\n",
      "batch 6598, train_loss 108.356178,Time used 0.012001s\n",
      "batch 6599, train_loss 98.878410,Time used 0.011999s\n",
      "batch 6600, train_loss 119.430481,Time used 0.009000s\n",
      "***************************test_batch 6600, test_rmse_loss 11.851456,test_mae_loss 4.581147,test_mape_loss 66.365250,Time used 0.044999s\n",
      "batch 6601, train_loss 97.781502,Time used 0.013001s\n",
      "batch 6602, train_loss 113.087852,Time used 0.010002s\n",
      "batch 6603, train_loss 103.458878,Time used 0.009999s\n",
      "batch 6604, train_loss 84.028404,Time used 0.011998s\n",
      "batch 6605, train_loss 113.805107,Time used 0.012000s\n",
      "batch 6606, train_loss 112.458603,Time used 0.012001s\n",
      "batch 6607, train_loss 75.380455,Time used 0.012999s\n",
      "batch 6608, train_loss 122.419479,Time used 0.008002s\n",
      "batch 6609, train_loss 107.646713,Time used 0.010999s\n",
      "batch 6610, train_loss 115.713715,Time used 0.011003s\n",
      "batch 6611, train_loss 92.046127,Time used 0.008000s\n",
      "batch 6612, train_loss 96.370872,Time used 0.012001s\n",
      "batch 6613, train_loss 149.257217,Time used 0.010000s\n",
      "batch 6614, train_loss 134.570908,Time used 0.010999s\n",
      "batch 6615, train_loss 92.221222,Time used 0.010000s\n",
      "batch 6616, train_loss 133.692413,Time used 0.007994s\n",
      "batch 6617, train_loss 94.513206,Time used 0.011002s\n",
      "batch 6618, train_loss 95.622673,Time used 0.011003s\n",
      "batch 6619, train_loss 95.168327,Time used 0.010000s\n",
      "batch 6620, train_loss 101.745224,Time used 0.011000s\n",
      "batch 6621, train_loss 97.100204,Time used 0.008001s\n",
      "batch 6622, train_loss 91.146767,Time used 0.008000s\n",
      "batch 6623, train_loss 136.141739,Time used 0.009998s\n",
      "batch 6624, train_loss 90.117325,Time used 0.010000s\n",
      "batch 6625, train_loss 106.844505,Time used 0.006998s\n",
      "batch 6626, train_loss 127.292839,Time used 0.009002s\n",
      "batch 6627, train_loss 103.626305,Time used 0.011998s\n",
      "batch 6628, train_loss 85.432083,Time used 0.011002s\n",
      "batch 6629, train_loss 92.563507,Time used 0.010001s\n",
      "batch 6630, train_loss 88.975838,Time used 0.008002s\n",
      "batch 6631, train_loss 136.359528,Time used 0.008998s\n",
      "batch 6632, train_loss 135.411957,Time used 0.007998s\n",
      "batch 6633, train_loss 150.179413,Time used 0.011001s\n",
      "batch 6634, train_loss 125.104660,Time used 0.011000s\n",
      "batch 6635, train_loss 80.730362,Time used 0.009999s\n",
      "batch 6636, train_loss 114.625069,Time used 0.009999s\n",
      "batch 6637, train_loss 115.656464,Time used 0.009999s\n",
      "batch 6638, train_loss 109.409988,Time used 0.007001s\n",
      "batch 6639, train_loss 87.252602,Time used 0.008000s\n",
      "batch 6640, train_loss 136.033920,Time used 0.009000s\n",
      "batch 6641, train_loss 107.590759,Time used 0.009002s\n",
      "batch 6642, train_loss 80.431801,Time used 0.011000s\n",
      "batch 6643, train_loss 84.577209,Time used 0.011998s\n",
      "batch 6644, train_loss 81.028183,Time used 0.010000s\n",
      "batch 6645, train_loss 94.517860,Time used 0.011000s\n",
      "batch 6646, train_loss 89.934837,Time used 0.010998s\n",
      "batch 6647, train_loss 102.194572,Time used 0.007001s\n",
      "batch 6648, train_loss 101.979370,Time used 0.007000s\n",
      "batch 6649, train_loss 92.750061,Time used 0.008000s\n",
      "batch 6650, train_loss 110.745209,Time used 0.008999s\n",
      "batch 6651, train_loss 96.994011,Time used 0.011000s\n",
      "batch 6652, train_loss 99.173462,Time used 0.006999s\n",
      "batch 6653, train_loss 122.405380,Time used 0.008004s\n",
      "batch 6654, train_loss 137.553452,Time used 0.007997s\n",
      "batch 6655, train_loss 98.545067,Time used 0.011001s\n",
      "batch 6656, train_loss 92.803963,Time used 0.011000s\n",
      "batch 6657, train_loss 110.949249,Time used 0.008001s\n",
      "batch 6658, train_loss 94.034782,Time used 0.009001s\n",
      "batch 6659, train_loss 117.751511,Time used 0.007999s\n",
      "batch 6660, train_loss 84.145065,Time used 0.009002s\n",
      "batch 6661, train_loss 114.183449,Time used 0.009996s\n",
      "batch 6662, train_loss 106.350586,Time used 0.013001s\n",
      "batch 6663, train_loss 95.785789,Time used 0.009001s\n",
      "batch 6664, train_loss 131.854752,Time used 0.008000s\n",
      "batch 6665, train_loss 112.988274,Time used 0.008001s\n",
      "batch 6666, train_loss 104.430771,Time used 0.007999s\n",
      "batch 6667, train_loss 109.527351,Time used 0.010002s\n",
      "batch 6668, train_loss 97.511337,Time used 0.007999s\n",
      "batch 6669, train_loss 121.596481,Time used 0.012000s\n",
      "batch 6670, train_loss 104.214920,Time used 0.011000s\n",
      "batch 6671, train_loss 95.308647,Time used 0.007999s\n",
      "batch 6672, train_loss 77.171021,Time used 0.007998s\n",
      "batch 6673, train_loss 123.118477,Time used 0.010998s\n",
      "batch 6674, train_loss 99.421936,Time used 0.008006s\n",
      "batch 6675, train_loss 113.966454,Time used 0.011997s\n",
      "batch 6676, train_loss 103.403702,Time used 0.011999s\n",
      "batch 6677, train_loss 108.317314,Time used 0.009999s\n",
      "batch 6678, train_loss 104.261726,Time used 0.011001s\n",
      "batch 6679, train_loss 91.111961,Time used 0.011999s\n",
      "batch 6680, train_loss 111.680443,Time used 0.009004s\n",
      "batch 6681, train_loss 110.623528,Time used 0.010000s\n",
      "batch 6682, train_loss 103.181015,Time used 0.011001s\n",
      "batch 6683, train_loss 132.641205,Time used 0.011001s\n",
      "batch 6684, train_loss 95.503914,Time used 0.008999s\n",
      "batch 6685, train_loss 91.593102,Time used 0.011003s\n",
      "batch 6686, train_loss 79.739693,Time used 0.009001s\n",
      "batch 6687, train_loss 93.904564,Time used 0.010000s\n",
      "batch 6688, train_loss 88.112816,Time used 0.009001s\n",
      "batch 6689, train_loss 106.736183,Time used 0.007997s\n",
      "batch 6690, train_loss 106.825775,Time used 0.008003s\n",
      "batch 6691, train_loss 124.286491,Time used 0.009999s\n",
      "batch 6692, train_loss 116.530006,Time used 0.010001s\n",
      "batch 6693, train_loss 82.698128,Time used 0.011998s\n",
      "batch 6694, train_loss 132.946381,Time used 0.009001s\n",
      "batch 6695, train_loss 99.356613,Time used 0.007999s\n",
      "batch 6696, train_loss 101.660538,Time used 0.011001s\n",
      "batch 6697, train_loss 108.499306,Time used 0.008000s\n",
      "batch 6698, train_loss 138.732727,Time used 0.009001s\n",
      "batch 6699, train_loss 110.852295,Time used 0.009002s\n",
      "batch 6700, train_loss 112.836693,Time used 0.007999s\n",
      "***************************test_batch 6700, test_rmse_loss 11.775223,test_mae_loss 4.556717,test_mape_loss 66.290154,Time used 0.036998s\n",
      "batch 6701, train_loss 82.818405,Time used 0.012001s\n",
      "batch 6702, train_loss 100.162682,Time used 0.011000s\n",
      "batch 6703, train_loss 97.603233,Time used 0.011999s\n",
      "batch 6704, train_loss 93.100739,Time used 0.007998s\n",
      "batch 6705, train_loss 114.388283,Time used 0.009000s\n",
      "batch 6706, train_loss 105.920288,Time used 0.011000s\n",
      "batch 6707, train_loss 100.418869,Time used 0.011002s\n",
      "batch 6708, train_loss 97.763718,Time used 0.009998s\n",
      "batch 6709, train_loss 120.939972,Time used 0.009003s\n",
      "batch 6710, train_loss 139.398697,Time used 0.007997s\n",
      "batch 6711, train_loss 103.588722,Time used 0.010003s\n",
      "batch 6712, train_loss 70.322556,Time used 0.011997s\n",
      "batch 6713, train_loss 106.563225,Time used 0.008003s\n",
      "batch 6714, train_loss 100.365578,Time used 0.007999s\n",
      "batch 6715, train_loss 98.105042,Time used 0.013000s\n",
      "batch 6716, train_loss 115.438538,Time used 0.010005s\n",
      "batch 6717, train_loss 85.133583,Time used 0.010999s\n",
      "batch 6718, train_loss 110.623611,Time used 0.010997s\n",
      "batch 6719, train_loss 110.518845,Time used 0.012000s\n",
      "batch 6720, train_loss 88.737976,Time used 0.009001s\n",
      "batch 6721, train_loss 103.307205,Time used 0.012002s\n",
      "batch 6722, train_loss 138.487640,Time used 0.010990s\n",
      "batch 6723, train_loss 127.741035,Time used 0.010998s\n",
      "batch 6724, train_loss 97.771614,Time used 0.009000s\n",
      "batch 6725, train_loss 117.780273,Time used 0.008000s\n",
      "batch 6726, train_loss 117.431000,Time used 0.007999s\n",
      "batch 6727, train_loss 93.874985,Time used 0.009000s\n",
      "batch 6728, train_loss 122.768211,Time used 0.010999s\n",
      "batch 6729, train_loss 121.197227,Time used 0.010999s\n",
      "batch 6730, train_loss 108.349548,Time used 0.009000s\n",
      "batch 6731, train_loss 76.925949,Time used 0.011002s\n",
      "batch 6732, train_loss 100.794357,Time used 0.009998s\n",
      "batch 6733, train_loss 78.991570,Time used 0.007999s\n",
      "batch 6734, train_loss 109.922112,Time used 0.009001s\n",
      "batch 6735, train_loss 85.588539,Time used 0.008998s\n",
      "batch 6736, train_loss 112.655334,Time used 0.007999s\n",
      "batch 6737, train_loss 116.405136,Time used 0.008003s\n",
      "batch 6738, train_loss 117.976425,Time used 0.008997s\n",
      "batch 6739, train_loss 92.372360,Time used 0.010002s\n",
      "batch 6740, train_loss 86.692032,Time used 0.009999s\n",
      "batch 6741, train_loss 100.458389,Time used 0.010001s\n",
      "batch 6742, train_loss 102.525368,Time used 0.011000s\n",
      "batch 6743, train_loss 79.696678,Time used 0.006999s\n",
      "batch 6744, train_loss 95.497765,Time used 0.011000s\n",
      "batch 6745, train_loss 101.524986,Time used 0.009001s\n",
      "batch 6746, train_loss 86.995689,Time used 0.008997s\n",
      "batch 6747, train_loss 107.690834,Time used 0.009000s\n",
      "batch 6748, train_loss 91.834015,Time used 0.010046s\n",
      "batch 6749, train_loss 96.471741,Time used 0.008955s\n",
      "batch 6750, train_loss 79.025528,Time used 0.008000s\n",
      "batch 6751, train_loss 111.532059,Time used 0.008998s\n",
      "batch 6752, train_loss 125.831635,Time used 0.011003s\n",
      "batch 6753, train_loss 93.181198,Time used 0.009999s\n",
      "batch 6754, train_loss 89.581421,Time used 0.010999s\n",
      "batch 6755, train_loss 105.924713,Time used 0.010000s\n",
      "batch 6756, train_loss 111.909737,Time used 0.013999s\n",
      "batch 6757, train_loss 87.061996,Time used 0.012006s\n",
      "batch 6758, train_loss 81.786385,Time used 0.009995s\n",
      "batch 6759, train_loss 125.315231,Time used 0.009998s\n",
      "batch 6760, train_loss 114.698364,Time used 0.012001s\n",
      "batch 6761, train_loss 115.472084,Time used 0.007999s\n",
      "batch 6762, train_loss 133.963028,Time used 0.010001s\n",
      "batch 6763, train_loss 112.694778,Time used 0.011001s\n",
      "batch 6764, train_loss 111.802254,Time used 0.009000s\n",
      "batch 6765, train_loss 101.167801,Time used 0.009001s\n",
      "batch 6766, train_loss 114.688538,Time used 0.010000s\n",
      "batch 6767, train_loss 97.180534,Time used 0.008997s\n",
      "batch 6768, train_loss 100.036903,Time used 0.007998s\n",
      "batch 6769, train_loss 94.760620,Time used 0.011000s\n",
      "batch 6770, train_loss 89.204330,Time used 0.007998s\n",
      "batch 6771, train_loss 117.314148,Time used 0.007000s\n",
      "batch 6772, train_loss 107.377563,Time used 0.008000s\n",
      "batch 6773, train_loss 94.677643,Time used 0.007000s\n",
      "batch 6774, train_loss 109.328682,Time used 0.009004s\n",
      "batch 6775, train_loss 95.660858,Time used 0.009998s\n",
      "batch 6776, train_loss 86.185799,Time used 0.007998s\n",
      "batch 6777, train_loss 134.117371,Time used 0.007001s\n",
      "batch 6778, train_loss 80.083817,Time used 0.011001s\n",
      "batch 6779, train_loss 102.531761,Time used 0.009002s\n",
      "batch 6780, train_loss 87.603165,Time used 0.010998s\n",
      "batch 6781, train_loss 82.495758,Time used 0.012002s\n",
      "batch 6782, train_loss 126.625839,Time used 0.012000s\n",
      "batch 6783, train_loss 99.227386,Time used 0.011001s\n",
      "batch 6784, train_loss 110.583717,Time used 0.011999s\n",
      "batch 6785, train_loss 107.846535,Time used 0.011000s\n",
      "batch 6786, train_loss 103.529503,Time used 0.012001s\n",
      "batch 6787, train_loss 88.629433,Time used 0.009000s\n",
      "batch 6788, train_loss 108.112816,Time used 0.008002s\n",
      "batch 6789, train_loss 109.373032,Time used 0.011998s\n",
      "batch 6790, train_loss 119.750565,Time used 0.008998s\n",
      "batch 6791, train_loss 123.005302,Time used 0.011002s\n",
      "batch 6792, train_loss 111.774269,Time used 0.015000s\n",
      "batch 6793, train_loss 142.992355,Time used 0.008000s\n",
      "batch 6794, train_loss 89.465424,Time used 0.009000s\n",
      "batch 6795, train_loss 118.562569,Time used 0.009008s\n",
      "batch 6796, train_loss 89.539825,Time used 0.011992s\n",
      "batch 6797, train_loss 82.209656,Time used 0.009001s\n",
      "batch 6798, train_loss 112.656746,Time used 0.011999s\n",
      "batch 6799, train_loss 108.695740,Time used 0.008000s\n",
      "batch 6800, train_loss 145.618286,Time used 0.008002s\n",
      "***************************test_batch 6800, test_rmse_loss 11.696956,test_mae_loss 4.535232,test_mape_loss 66.560346,Time used 0.045998s\n",
      "batch 6801, train_loss 117.952652,Time used 0.012000s\n",
      "batch 6802, train_loss 98.760513,Time used 0.011000s\n",
      "batch 6803, train_loss 88.765427,Time used 0.007001s\n",
      "batch 6804, train_loss 113.791710,Time used 0.006999s\n",
      "batch 6805, train_loss 105.612846,Time used 0.008000s\n",
      "batch 6806, train_loss 99.049919,Time used 0.010999s\n",
      "batch 6807, train_loss 93.801277,Time used 0.008999s\n",
      "batch 6808, train_loss 84.057220,Time used 0.008002s\n",
      "batch 6809, train_loss 91.836220,Time used 0.007998s\n",
      "batch 6810, train_loss 118.269951,Time used 0.006999s\n",
      "batch 6811, train_loss 83.768394,Time used 0.007000s\n",
      "batch 6812, train_loss 105.387703,Time used 0.007002s\n",
      "batch 6813, train_loss 101.779533,Time used 0.008000s\n",
      "batch 6814, train_loss 81.677696,Time used 0.007000s\n",
      "batch 6815, train_loss 104.645874,Time used 0.008001s\n",
      "batch 6816, train_loss 102.950912,Time used 0.006999s\n",
      "batch 6817, train_loss 91.754509,Time used 0.010999s\n",
      "batch 6818, train_loss 102.557915,Time used 0.007999s\n",
      "batch 6819, train_loss 120.934662,Time used 0.010000s\n",
      "batch 6820, train_loss 100.261368,Time used 0.008001s\n",
      "batch 6821, train_loss 140.094315,Time used 0.011001s\n",
      "batch 6822, train_loss 110.465164,Time used 0.008000s\n",
      "batch 6823, train_loss 94.549652,Time used 0.008997s\n",
      "batch 6824, train_loss 137.875717,Time used 0.007999s\n",
      "batch 6825, train_loss 78.386444,Time used 0.007002s\n",
      "batch 6826, train_loss 141.422043,Time used 0.007001s\n",
      "batch 6827, train_loss 83.062134,Time used 0.008001s\n",
      "batch 6828, train_loss 111.720253,Time used 0.008001s\n",
      "batch 6829, train_loss 85.862762,Time used 0.009999s\n",
      "batch 6830, train_loss 122.446861,Time used 0.006999s\n",
      "batch 6831, train_loss 84.239639,Time used 0.007000s\n",
      "batch 6832, train_loss 85.237045,Time used 0.008000s\n",
      "batch 6833, train_loss 104.944969,Time used 0.008999s\n",
      "batch 6834, train_loss 70.402397,Time used 0.007001s\n",
      "batch 6835, train_loss 67.998825,Time used 0.009001s\n",
      "batch 6836, train_loss 116.569695,Time used 0.010000s\n",
      "batch 6837, train_loss 111.330299,Time used 0.007001s\n",
      "batch 6838, train_loss 100.128166,Time used 0.006999s\n",
      "batch 6839, train_loss 98.190689,Time used 0.008001s\n",
      "batch 6840, train_loss 113.863861,Time used 0.006998s\n",
      "batch 6841, train_loss 107.763252,Time used 0.007999s\n",
      "batch 6842, train_loss 120.674629,Time used 0.007999s\n",
      "batch 6843, train_loss 102.451721,Time used 0.011002s\n",
      "batch 6844, train_loss 103.162338,Time used 0.009998s\n",
      "batch 6845, train_loss 83.054794,Time used 0.009999s\n",
      "batch 6846, train_loss 108.117096,Time used 0.011002s\n",
      "batch 6847, train_loss 108.580681,Time used 0.011997s\n",
      "batch 6848, train_loss 89.779457,Time used 0.008999s\n",
      "batch 6849, train_loss 89.513168,Time used 0.010001s\n",
      "batch 6850, train_loss 100.167068,Time used 0.008000s\n",
      "batch 6851, train_loss 108.879143,Time used 0.011000s\n",
      "batch 6852, train_loss 99.720200,Time used 0.011001s\n",
      "batch 6853, train_loss 92.025223,Time used 0.013997s\n",
      "batch 6854, train_loss 72.929260,Time used 0.008000s\n",
      "batch 6855, train_loss 123.683380,Time used 0.008000s\n",
      "batch 6856, train_loss 100.635696,Time used 0.008997s\n",
      "batch 6857, train_loss 160.666092,Time used 0.008003s\n",
      "batch 6858, train_loss 90.820244,Time used 0.007001s\n",
      "batch 6859, train_loss 94.850243,Time used 0.008000s\n",
      "batch 6860, train_loss 95.348557,Time used 0.010998s\n",
      "batch 6861, train_loss 90.015099,Time used 0.008000s\n",
      "batch 6862, train_loss 87.112190,Time used 0.007998s\n",
      "batch 6863, train_loss 104.113037,Time used 0.009002s\n",
      "batch 6864, train_loss 133.262283,Time used 0.011003s\n",
      "batch 6865, train_loss 84.696579,Time used 0.007999s\n",
      "batch 6866, train_loss 96.312088,Time used 0.008002s\n",
      "batch 6867, train_loss 115.724815,Time used 0.007999s\n",
      "batch 6868, train_loss 96.498352,Time used 0.011000s\n",
      "batch 6869, train_loss 103.634834,Time used 0.009001s\n",
      "batch 6870, train_loss 82.254684,Time used 0.007000s\n",
      "batch 6871, train_loss 106.869423,Time used 0.008000s\n",
      "batch 6872, train_loss 98.098488,Time used 0.006999s\n",
      "batch 6873, train_loss 98.211281,Time used 0.008002s\n",
      "batch 6874, train_loss 90.525650,Time used 0.006999s\n",
      "batch 6875, train_loss 76.319595,Time used 0.007000s\n",
      "batch 6876, train_loss 95.828651,Time used 0.007000s\n",
      "batch 6877, train_loss 159.302017,Time used 0.010037s\n",
      "batch 6878, train_loss 91.657860,Time used 0.008965s\n",
      "batch 6879, train_loss 109.537079,Time used 0.010000s\n",
      "batch 6880, train_loss 111.198662,Time used 0.009999s\n",
      "batch 6881, train_loss 101.003990,Time used 0.006999s\n",
      "batch 6882, train_loss 105.860931,Time used 0.007000s\n",
      "batch 6883, train_loss 124.706337,Time used 0.008000s\n",
      "batch 6884, train_loss 113.931015,Time used 0.008002s\n",
      "batch 6885, train_loss 99.131622,Time used 0.006997s\n",
      "batch 6886, train_loss 107.964096,Time used 0.007998s\n",
      "batch 6887, train_loss 87.173012,Time used 0.010000s\n",
      "batch 6888, train_loss 101.802292,Time used 0.009999s\n",
      "batch 6889, train_loss 99.562202,Time used 0.010003s\n",
      "batch 6890, train_loss 109.426773,Time used 0.012000s\n",
      "batch 6891, train_loss 101.819557,Time used 0.009998s\n",
      "batch 6892, train_loss 66.220619,Time used 0.008001s\n",
      "batch 6893, train_loss 120.021675,Time used 0.009999s\n",
      "batch 6894, train_loss 94.754112,Time used 0.007000s\n",
      "batch 6895, train_loss 95.198608,Time used 0.009001s\n",
      "batch 6896, train_loss 108.206467,Time used 0.009999s\n",
      "batch 6897, train_loss 102.542526,Time used 0.012999s\n",
      "batch 6898, train_loss 100.172981,Time used 0.009001s\n",
      "batch 6899, train_loss 92.992981,Time used 0.009001s\n",
      "batch 6900, train_loss 82.073761,Time used 0.009002s\n",
      "***************************test_batch 6900, test_rmse_loss 11.625038,test_mae_loss 4.506672,test_mape_loss 65.956304,Time used 0.032999s\n",
      "batch 6901, train_loss 114.553375,Time used 0.008000s\n",
      "batch 6902, train_loss 124.928040,Time used 0.008001s\n",
      "batch 6903, train_loss 122.678452,Time used 0.010002s\n",
      "batch 6904, train_loss 91.697548,Time used 0.010000s\n",
      "batch 6905, train_loss 82.626160,Time used 0.011000s\n",
      "batch 6906, train_loss 94.879845,Time used 0.011003s\n",
      "batch 6907, train_loss 105.410583,Time used 0.007998s\n",
      "batch 6908, train_loss 92.536812,Time used 0.009001s\n",
      "batch 6909, train_loss 142.634735,Time used 0.007999s\n",
      "batch 6910, train_loss 102.877640,Time used 0.010999s\n",
      "batch 6911, train_loss 88.772240,Time used 0.008000s\n",
      "batch 6912, train_loss 114.400757,Time used 0.008000s\n",
      "batch 6913, train_loss 88.920601,Time used 0.007000s\n",
      "batch 6914, train_loss 138.729599,Time used 0.012000s\n",
      "batch 6915, train_loss 77.341576,Time used 0.010000s\n",
      "batch 6916, train_loss 107.681335,Time used 0.007000s\n",
      "batch 6917, train_loss 102.405396,Time used 0.008000s\n",
      "batch 6918, train_loss 98.725067,Time used 0.007003s\n",
      "batch 6919, train_loss 96.520714,Time used 0.008001s\n",
      "batch 6920, train_loss 81.586090,Time used 0.007001s\n",
      "batch 6921, train_loss 142.882355,Time used 0.006999s\n",
      "batch 6922, train_loss 122.050713,Time used 0.007998s\n",
      "batch 6923, train_loss 112.351540,Time used 0.010003s\n",
      "batch 6924, train_loss 98.225052,Time used 0.008001s\n",
      "batch 6925, train_loss 94.276978,Time used 0.008003s\n",
      "batch 6926, train_loss 117.711143,Time used 0.007999s\n",
      "batch 6927, train_loss 101.994324,Time used 0.007998s\n",
      "batch 6928, train_loss 96.247536,Time used 0.009000s\n",
      "batch 6929, train_loss 105.980125,Time used 0.009007s\n",
      "batch 6930, train_loss 105.970650,Time used 0.007994s\n",
      "batch 6931, train_loss 81.858421,Time used 0.008002s\n",
      "batch 6932, train_loss 111.567894,Time used 0.006997s\n",
      "batch 6933, train_loss 92.618889,Time used 0.010999s\n",
      "batch 6934, train_loss 105.791153,Time used 0.007003s\n",
      "batch 6935, train_loss 68.578468,Time used 0.007999s\n",
      "batch 6936, train_loss 92.609116,Time used 0.006999s\n",
      "batch 6937, train_loss 113.914711,Time used 0.007995s\n",
      "batch 6938, train_loss 123.029915,Time used 0.008001s\n",
      "batch 6939, train_loss 94.688782,Time used 0.009035s\n",
      "batch 6940, train_loss 112.327316,Time used 0.008964s\n",
      "batch 6941, train_loss 100.103836,Time used 0.008037s\n",
      "batch 6942, train_loss 88.392670,Time used 0.009964s\n",
      "batch 6943, train_loss 107.425720,Time used 0.007002s\n",
      "batch 6944, train_loss 105.473167,Time used 0.010998s\n",
      "batch 6945, train_loss 111.445969,Time used 0.009004s\n",
      "batch 6946, train_loss 115.423630,Time used 0.009995s\n",
      "batch 6947, train_loss 104.815987,Time used 0.008001s\n",
      "batch 6948, train_loss 117.770882,Time used 0.008000s\n",
      "batch 6949, train_loss 75.553818,Time used 0.008001s\n",
      "batch 6950, train_loss 107.593269,Time used 0.010998s\n",
      "batch 6951, train_loss 131.554169,Time used 0.011038s\n",
      "batch 6952, train_loss 96.677147,Time used 0.007005s\n",
      "batch 6953, train_loss 117.120461,Time used 0.008959s\n",
      "batch 6954, train_loss 87.271988,Time used 0.008997s\n",
      "batch 6955, train_loss 85.948578,Time used 0.007001s\n",
      "batch 6956, train_loss 79.119247,Time used 0.007001s\n",
      "batch 6957, train_loss 81.072365,Time used 0.010000s\n",
      "batch 6958, train_loss 115.886375,Time used 0.012002s\n",
      "batch 6959, train_loss 70.648430,Time used 0.011998s\n",
      "batch 6960, train_loss 91.708740,Time used 0.011002s\n",
      "batch 6961, train_loss 77.876938,Time used 0.009001s\n",
      "batch 6962, train_loss 88.588783,Time used 0.008001s\n",
      "batch 6963, train_loss 107.232994,Time used 0.006997s\n",
      "batch 6964, train_loss 107.241104,Time used 0.009001s\n",
      "batch 6965, train_loss 126.482574,Time used 0.011999s\n",
      "batch 6966, train_loss 71.398331,Time used 0.008000s\n",
      "batch 6967, train_loss 117.306999,Time used 0.007001s\n",
      "batch 6968, train_loss 111.408897,Time used 0.007000s\n",
      "batch 6969, train_loss 88.379982,Time used 0.006998s\n",
      "batch 6970, train_loss 86.281731,Time used 0.007002s\n",
      "batch 6971, train_loss 111.586533,Time used 0.007000s\n",
      "batch 6972, train_loss 106.721405,Time used 0.010000s\n",
      "batch 6973, train_loss 94.935516,Time used 0.008000s\n",
      "batch 6974, train_loss 110.429146,Time used 0.007001s\n",
      "batch 6975, train_loss 107.413589,Time used 0.007999s\n",
      "batch 6976, train_loss 92.223328,Time used 0.006999s\n",
      "batch 6977, train_loss 112.890762,Time used 0.009004s\n",
      "batch 6978, train_loss 115.024780,Time used 0.008034s\n",
      "batch 6979, train_loss 114.077080,Time used 0.007965s\n",
      "batch 6980, train_loss 88.094818,Time used 0.007035s\n",
      "batch 6981, train_loss 95.274025,Time used 0.008007s\n",
      "batch 6982, train_loss 83.786781,Time used 0.006958s\n",
      "batch 6983, train_loss 86.097389,Time used 0.006999s\n",
      "batch 6984, train_loss 127.945763,Time used 0.008002s\n",
      "batch 6985, train_loss 92.627403,Time used 0.009995s\n",
      "batch 6986, train_loss 76.200676,Time used 0.011003s\n",
      "batch 6987, train_loss 92.962662,Time used 0.013999s\n",
      "batch 6988, train_loss 136.401825,Time used 0.011997s\n",
      "batch 6989, train_loss 90.692696,Time used 0.012007s\n",
      "batch 6990, train_loss 114.916542,Time used 0.012992s\n",
      "batch 6991, train_loss 104.447990,Time used 0.009002s\n",
      "batch 6992, train_loss 104.910995,Time used 0.008996s\n",
      "batch 6993, train_loss 77.619446,Time used 0.008000s\n",
      "batch 6994, train_loss 104.125031,Time used 0.009001s\n",
      "batch 6995, train_loss 105.682701,Time used 0.007001s\n",
      "batch 6996, train_loss 99.997231,Time used 0.007000s\n",
      "batch 6997, train_loss 93.597717,Time used 0.007000s\n",
      "batch 6998, train_loss 105.461502,Time used 0.011000s\n",
      "batch 6999, train_loss 100.400375,Time used 0.008001s\n",
      "batch 7000, train_loss 78.638443,Time used 0.011000s\n",
      "***************************test_batch 7000, test_rmse_loss 11.551872,test_mae_loss 4.484591,test_mape_loss 65.949645,Time used 0.043004s\n",
      "batch 7001, train_loss 87.463623,Time used 0.008000s\n",
      "batch 7002, train_loss 137.684708,Time used 0.011999s\n",
      "batch 7003, train_loss 107.506081,Time used 0.012005s\n",
      "batch 7004, train_loss 118.396721,Time used 0.011000s\n",
      "batch 7005, train_loss 95.915977,Time used 0.011997s\n",
      "batch 7006, train_loss 99.273300,Time used 0.011002s\n",
      "batch 7007, train_loss 110.602272,Time used 0.007999s\n",
      "batch 7008, train_loss 83.886208,Time used 0.008996s\n",
      "batch 7009, train_loss 104.121605,Time used 0.011035s\n",
      "batch 7010, train_loss 130.421310,Time used 0.007000s\n",
      "batch 7011, train_loss 96.337662,Time used 0.007971s\n",
      "batch 7012, train_loss 116.948822,Time used 0.008996s\n",
      "batch 7013, train_loss 98.910973,Time used 0.011033s\n",
      "batch 7014, train_loss 98.505890,Time used 0.006965s\n",
      "batch 7015, train_loss 117.833504,Time used 0.009001s\n",
      "batch 7016, train_loss 108.018539,Time used 0.008005s\n",
      "batch 7017, train_loss 76.800026,Time used 0.007998s\n",
      "batch 7018, train_loss 96.874466,Time used 0.007031s\n",
      "batch 7019, train_loss 82.122986,Time used 0.009964s\n",
      "batch 7020, train_loss 87.870766,Time used 0.008034s\n",
      "batch 7021, train_loss 81.087738,Time used 0.007967s\n",
      "batch 7022, train_loss 121.480728,Time used 0.008000s\n",
      "batch 7023, train_loss 90.216255,Time used 0.007998s\n",
      "batch 7024, train_loss 123.631706,Time used 0.010000s\n",
      "batch 7025, train_loss 112.208000,Time used 0.011039s\n",
      "batch 7026, train_loss 66.107193,Time used 0.006998s\n",
      "batch 7027, train_loss 120.418549,Time used 0.007000s\n",
      "batch 7028, train_loss 92.551788,Time used 0.008001s\n",
      "batch 7029, train_loss 89.840050,Time used 0.007000s\n",
      "batch 7030, train_loss 102.612816,Time used 0.007001s\n",
      "batch 7031, train_loss 103.031998,Time used 0.006999s\n",
      "batch 7032, train_loss 94.648804,Time used 0.009002s\n",
      "batch 7033, train_loss 102.222435,Time used 0.007000s\n",
      "batch 7034, train_loss 75.786163,Time used 0.007000s\n",
      "batch 7035, train_loss 85.114403,Time used 0.007001s\n",
      "batch 7036, train_loss 100.034172,Time used 0.006999s\n",
      "batch 7037, train_loss 115.695930,Time used 0.008998s\n",
      "batch 7038, train_loss 119.472115,Time used 0.009000s\n",
      "batch 7039, train_loss 111.649902,Time used 0.008002s\n",
      "batch 7040, train_loss 76.024986,Time used 0.006999s\n",
      "batch 7041, train_loss 81.081039,Time used 0.008000s\n",
      "batch 7042, train_loss 73.108025,Time used 0.008000s\n",
      "batch 7043, train_loss 106.172356,Time used 0.009999s\n",
      "batch 7044, train_loss 122.160637,Time used 0.007003s\n",
      "batch 7045, train_loss 89.860085,Time used 0.007999s\n",
      "batch 7046, train_loss 118.145958,Time used 0.009002s\n",
      "batch 7047, train_loss 91.671791,Time used 0.009998s\n",
      "batch 7048, train_loss 104.466797,Time used 0.008000s\n",
      "batch 7049, train_loss 117.592888,Time used 0.008000s\n",
      "batch 7050, train_loss 127.766228,Time used 0.007999s\n",
      "batch 7051, train_loss 120.790810,Time used 0.007000s\n",
      "batch 7052, train_loss 76.676643,Time used 0.008004s\n",
      "batch 7053, train_loss 95.697296,Time used 0.010999s\n",
      "batch 7054, train_loss 90.740753,Time used 0.008998s\n",
      "batch 7055, train_loss 104.756485,Time used 0.008000s\n",
      "batch 7056, train_loss 98.487366,Time used 0.008000s\n",
      "batch 7057, train_loss 105.076935,Time used 0.008999s\n",
      "batch 7058, train_loss 98.025291,Time used 0.011001s\n",
      "batch 7059, train_loss 105.726303,Time used 0.010001s\n",
      "batch 7060, train_loss 67.976326,Time used 0.011998s\n",
      "batch 7061, train_loss 106.457840,Time used 0.011998s\n",
      "batch 7062, train_loss 79.356316,Time used 0.007999s\n",
      "batch 7063, train_loss 110.638695,Time used 0.011003s\n",
      "batch 7064, train_loss 102.888405,Time used 0.011000s\n",
      "batch 7065, train_loss 105.478928,Time used 0.011000s\n",
      "batch 7066, train_loss 105.273796,Time used 0.009000s\n",
      "batch 7067, train_loss 96.184685,Time used 0.008997s\n",
      "batch 7068, train_loss 96.038261,Time used 0.008001s\n",
      "batch 7069, train_loss 94.688675,Time used 0.008001s\n",
      "batch 7070, train_loss 123.410942,Time used 0.011000s\n",
      "batch 7071, train_loss 65.714218,Time used 0.009001s\n",
      "batch 7072, train_loss 110.607658,Time used 0.006999s\n",
      "batch 7073, train_loss 88.092796,Time used 0.011000s\n",
      "batch 7074, train_loss 87.315697,Time used 0.010998s\n",
      "batch 7075, train_loss 98.242058,Time used 0.011003s\n",
      "batch 7076, train_loss 97.018112,Time used 0.009999s\n",
      "batch 7077, train_loss 107.471130,Time used 0.010000s\n",
      "batch 7078, train_loss 89.598587,Time used 0.008000s\n",
      "batch 7079, train_loss 105.101906,Time used 0.010998s\n",
      "batch 7080, train_loss 153.436752,Time used 0.010002s\n",
      "batch 7081, train_loss 87.864944,Time used 0.007998s\n",
      "batch 7082, train_loss 83.728157,Time used 0.007001s\n",
      "batch 7083, train_loss 98.590584,Time used 0.007999s\n",
      "batch 7084, train_loss 116.372154,Time used 0.008001s\n",
      "batch 7085, train_loss 87.735352,Time used 0.008998s\n",
      "batch 7086, train_loss 106.886154,Time used 0.011001s\n",
      "batch 7087, train_loss 98.110298,Time used 0.007998s\n",
      "batch 7088, train_loss 110.710258,Time used 0.007000s\n",
      "batch 7089, train_loss 107.687248,Time used 0.008002s\n",
      "batch 7090, train_loss 81.882156,Time used 0.007000s\n",
      "batch 7091, train_loss 92.143478,Time used 0.008000s\n",
      "batch 7092, train_loss 81.749290,Time used 0.007001s\n",
      "batch 7093, train_loss 116.024727,Time used 0.007999s\n",
      "batch 7094, train_loss 96.862862,Time used 0.006999s\n",
      "batch 7095, train_loss 116.376381,Time used 0.007000s\n",
      "batch 7096, train_loss 112.567520,Time used 0.008001s\n",
      "batch 7097, train_loss 98.261459,Time used 0.008001s\n",
      "batch 7098, train_loss 107.772797,Time used 0.007000s\n",
      "batch 7099, train_loss 108.438095,Time used 0.008001s\n",
      "batch 7100, train_loss 91.311150,Time used 0.007998s\n",
      "***************************test_batch 7100, test_rmse_loss 11.477350,test_mae_loss 4.464014,test_mape_loss 66.133948,Time used 0.035000s\n",
      "batch 7101, train_loss 108.569344,Time used 0.009002s\n",
      "batch 7102, train_loss 91.468529,Time used 0.010000s\n",
      "batch 7103, train_loss 83.956093,Time used 0.008000s\n",
      "batch 7104, train_loss 105.636749,Time used 0.007998s\n",
      "batch 7105, train_loss 86.603012,Time used 0.010000s\n",
      "batch 7106, train_loss 94.136078,Time used 0.007997s\n",
      "batch 7107, train_loss 88.802055,Time used 0.008001s\n",
      "batch 7108, train_loss 66.184906,Time used 0.009001s\n",
      "batch 7109, train_loss 86.505882,Time used 0.012001s\n",
      "batch 7110, train_loss 94.828445,Time used 0.010996s\n",
      "batch 7111, train_loss 78.895607,Time used 0.009001s\n",
      "batch 7112, train_loss 109.585350,Time used 0.008000s\n",
      "batch 7113, train_loss 93.927925,Time used 0.007001s\n",
      "batch 7114, train_loss 95.971123,Time used 0.012001s\n",
      "batch 7115, train_loss 97.910904,Time used 0.010000s\n",
      "batch 7116, train_loss 95.229362,Time used 0.011998s\n",
      "batch 7117, train_loss 92.564590,Time used 0.010999s\n",
      "batch 7118, train_loss 95.118614,Time used 0.010000s\n",
      "batch 7119, train_loss 116.505653,Time used 0.010004s\n",
      "batch 7120, train_loss 122.072052,Time used 0.010000s\n",
      "batch 7121, train_loss 133.578308,Time used 0.010005s\n",
      "batch 7122, train_loss 104.143494,Time used 0.011001s\n",
      "batch 7123, train_loss 93.885963,Time used 0.008999s\n",
      "batch 7124, train_loss 96.386063,Time used 0.011001s\n",
      "batch 7125, train_loss 139.073532,Time used 0.011001s\n",
      "batch 7126, train_loss 85.865639,Time used 0.008000s\n",
      "batch 7127, train_loss 106.123444,Time used 0.011000s\n",
      "batch 7128, train_loss 109.555351,Time used 0.006999s\n",
      "batch 7129, train_loss 98.013863,Time used 0.008000s\n",
      "batch 7130, train_loss 97.295609,Time used 0.012004s\n",
      "batch 7131, train_loss 90.087227,Time used 0.013999s\n",
      "batch 7132, train_loss 106.622200,Time used 0.013001s\n",
      "batch 7133, train_loss 84.211334,Time used 0.013000s\n",
      "batch 7134, train_loss 105.354485,Time used 0.013000s\n",
      "batch 7135, train_loss 64.956406,Time used 0.009998s\n",
      "batch 7136, train_loss 110.251610,Time used 0.011003s\n",
      "batch 7137, train_loss 89.251732,Time used 0.017999s\n",
      "batch 7138, train_loss 111.767250,Time used 0.060002s\n",
      "batch 7139, train_loss 95.444008,Time used 0.028997s\n",
      "batch 7140, train_loss 93.960945,Time used 0.028001s\n",
      "batch 7141, train_loss 118.591446,Time used 0.017002s\n",
      "batch 7142, train_loss 121.725769,Time used 0.027000s\n",
      "batch 7143, train_loss 86.913849,Time used 0.015997s\n",
      "batch 7144, train_loss 120.610245,Time used 0.015001s\n",
      "batch 7145, train_loss 92.570381,Time used 0.021998s\n",
      "batch 7146, train_loss 104.646996,Time used 0.014998s\n",
      "batch 7147, train_loss 96.342728,Time used 0.013000s\n",
      "batch 7148, train_loss 109.170204,Time used 0.016998s\n",
      "batch 7149, train_loss 89.214035,Time used 0.013000s\n",
      "batch 7150, train_loss 77.242584,Time used 0.014998s\n",
      "batch 7151, train_loss 120.113647,Time used 0.014002s\n",
      "batch 7152, train_loss 91.200073,Time used 0.014999s\n",
      "batch 7153, train_loss 68.801155,Time used 0.015003s\n",
      "batch 7154, train_loss 118.854691,Time used 0.025001s\n",
      "batch 7155, train_loss 92.081467,Time used 0.012996s\n",
      "batch 7156, train_loss 107.360718,Time used 0.011001s\n",
      "batch 7157, train_loss 93.491844,Time used 0.012000s\n",
      "batch 7158, train_loss 67.702316,Time used 0.012000s\n",
      "batch 7159, train_loss 100.553520,Time used 0.012995s\n",
      "batch 7160, train_loss 105.313278,Time used 0.013001s\n",
      "batch 7161, train_loss 90.449921,Time used 0.014998s\n",
      "batch 7162, train_loss 86.194008,Time used 0.013001s\n",
      "batch 7163, train_loss 112.870911,Time used 0.010000s\n",
      "batch 7164, train_loss 119.890686,Time used 0.013998s\n",
      "batch 7165, train_loss 84.047066,Time used 0.015001s\n",
      "batch 7166, train_loss 98.753380,Time used 0.013999s\n",
      "batch 7167, train_loss 95.590500,Time used 0.018002s\n",
      "batch 7168, train_loss 120.403191,Time used 0.017000s\n",
      "batch 7169, train_loss 99.290192,Time used 0.020001s\n",
      "batch 7170, train_loss 106.009529,Time used 0.010998s\n",
      "batch 7171, train_loss 90.109879,Time used 0.012999s\n",
      "batch 7172, train_loss 131.485077,Time used 0.013002s\n",
      "batch 7173, train_loss 90.372551,Time used 0.012001s\n",
      "batch 7174, train_loss 97.312958,Time used 0.012998s\n",
      "batch 7175, train_loss 98.136032,Time used 0.012002s\n",
      "batch 7176, train_loss 93.379433,Time used 0.011998s\n",
      "batch 7177, train_loss 116.820023,Time used 0.009998s\n",
      "batch 7178, train_loss 79.380249,Time used 0.010999s\n",
      "batch 7179, train_loss 97.589828,Time used 0.012005s\n",
      "batch 7180, train_loss 98.853294,Time used 0.011998s\n",
      "batch 7181, train_loss 100.975662,Time used 0.011003s\n",
      "batch 7182, train_loss 87.770218,Time used 0.012997s\n",
      "batch 7183, train_loss 79.536888,Time used 0.009997s\n",
      "batch 7184, train_loss 90.197723,Time used 0.011998s\n",
      "batch 7185, train_loss 57.530411,Time used 0.012002s\n",
      "batch 7186, train_loss 95.678665,Time used 0.008001s\n",
      "batch 7187, train_loss 103.396790,Time used 0.008999s\n",
      "batch 7188, train_loss 85.159790,Time used 0.007998s\n",
      "batch 7189, train_loss 90.565018,Time used 0.011001s\n",
      "batch 7190, train_loss 116.062897,Time used 0.012001s\n",
      "batch 7191, train_loss 79.459518,Time used 0.014997s\n",
      "batch 7192, train_loss 128.713638,Time used 0.011002s\n",
      "batch 7193, train_loss 90.772133,Time used 0.012996s\n",
      "batch 7194, train_loss 111.830894,Time used 0.014005s\n",
      "batch 7195, train_loss 140.214706,Time used 0.015999s\n",
      "batch 7196, train_loss 117.574821,Time used 0.012999s\n",
      "batch 7197, train_loss 117.388702,Time used 0.019000s\n",
      "batch 7198, train_loss 116.382874,Time used 0.011997s\n",
      "batch 7199, train_loss 85.800339,Time used 0.012000s\n",
      "batch 7200, train_loss 72.713875,Time used 0.011002s\n",
      "***************************test_batch 7200, test_rmse_loss 11.407581,test_mae_loss 4.438710,test_mape_loss 65.792149,Time used 0.049001s\n",
      "batch 7201, train_loss 101.630325,Time used 0.012004s\n",
      "batch 7202, train_loss 99.759995,Time used 0.010998s\n",
      "batch 7203, train_loss 96.733185,Time used 0.011999s\n",
      "batch 7204, train_loss 100.773727,Time used 0.008001s\n",
      "batch 7205, train_loss 85.683060,Time used 0.010999s\n",
      "batch 7206, train_loss 104.999619,Time used 0.010998s\n",
      "batch 7207, train_loss 124.230537,Time used 0.009999s\n",
      "batch 7208, train_loss 92.354340,Time used 0.012002s\n",
      "batch 7209, train_loss 95.386841,Time used 0.014001s\n",
      "batch 7210, train_loss 83.700676,Time used 0.013000s\n",
      "batch 7211, train_loss 78.914986,Time used 0.010000s\n",
      "batch 7212, train_loss 88.636253,Time used 0.010000s\n",
      "batch 7213, train_loss 95.622849,Time used 0.011999s\n",
      "batch 7214, train_loss 109.308617,Time used 0.020002s\n",
      "batch 7215, train_loss 85.327682,Time used 0.012997s\n",
      "batch 7216, train_loss 119.167908,Time used 0.012001s\n",
      "batch 7217, train_loss 101.975464,Time used 0.012001s\n",
      "batch 7218, train_loss 107.553307,Time used 0.013001s\n",
      "batch 7219, train_loss 104.220978,Time used 0.011998s\n",
      "batch 7220, train_loss 93.525650,Time used 0.011000s\n",
      "batch 7221, train_loss 110.019699,Time used 0.012000s\n",
      "batch 7222, train_loss 65.761406,Time used 0.011000s\n",
      "batch 7223, train_loss 103.959068,Time used 0.012002s\n",
      "batch 7224, train_loss 105.394180,Time used 0.012002s\n",
      "batch 7225, train_loss 95.760902,Time used 0.012001s\n",
      "batch 7226, train_loss 72.467819,Time used 0.012000s\n",
      "batch 7227, train_loss 87.882202,Time used 0.012000s\n",
      "batch 7228, train_loss 99.841553,Time used 0.012998s\n",
      "batch 7229, train_loss 112.761368,Time used 0.012002s\n",
      "batch 7230, train_loss 68.763252,Time used 0.011998s\n",
      "batch 7231, train_loss 92.985794,Time used 0.011000s\n",
      "batch 7232, train_loss 97.856941,Time used 0.013002s\n",
      "batch 7233, train_loss 115.294716,Time used 0.012999s\n",
      "batch 7234, train_loss 89.071556,Time used 0.012001s\n",
      "batch 7235, train_loss 102.254341,Time used 0.011997s\n",
      "batch 7236, train_loss 118.398796,Time used 0.011002s\n",
      "batch 7237, train_loss 81.124146,Time used 0.012001s\n",
      "batch 7238, train_loss 71.339760,Time used 0.013000s\n",
      "batch 7239, train_loss 90.957047,Time used 0.010000s\n",
      "batch 7240, train_loss 106.625259,Time used 0.009003s\n",
      "batch 7241, train_loss 121.737236,Time used 0.009998s\n",
      "batch 7242, train_loss 100.540108,Time used 0.009000s\n",
      "batch 7243, train_loss 119.201340,Time used 0.009999s\n",
      "batch 7244, train_loss 104.950890,Time used 0.008999s\n",
      "batch 7245, train_loss 101.878334,Time used 0.010998s\n",
      "batch 7246, train_loss 100.296997,Time used 0.010003s\n",
      "batch 7247, train_loss 101.814827,Time used 0.007999s\n",
      "batch 7248, train_loss 93.264740,Time used 0.008000s\n",
      "batch 7249, train_loss 98.575806,Time used 0.009000s\n",
      "batch 7250, train_loss 77.378647,Time used 0.008001s\n",
      "batch 7251, train_loss 80.223656,Time used 0.012000s\n",
      "batch 7252, train_loss 99.865013,Time used 0.011001s\n",
      "batch 7253, train_loss 84.325500,Time used 0.012003s\n",
      "batch 7254, train_loss 98.227257,Time used 0.011000s\n",
      "batch 7255, train_loss 125.562721,Time used 0.011000s\n",
      "batch 7256, train_loss 87.877121,Time used 0.013999s\n",
      "batch 7257, train_loss 93.797165,Time used 0.026999s\n",
      "batch 7258, train_loss 91.750000,Time used 0.024994s\n",
      "batch 7259, train_loss 80.172958,Time used 0.037998s\n",
      "batch 7260, train_loss 97.433807,Time used 0.020000s\n",
      "batch 7261, train_loss 86.508194,Time used 0.016000s\n",
      "batch 7262, train_loss 98.800354,Time used 0.013998s\n",
      "batch 7263, train_loss 100.297119,Time used 0.016002s\n",
      "batch 7264, train_loss 88.072083,Time used 0.014999s\n",
      "batch 7265, train_loss 122.508148,Time used 0.012999s\n",
      "batch 7266, train_loss 94.867607,Time used 0.013001s\n",
      "batch 7267, train_loss 114.866798,Time used 0.008001s\n",
      "batch 7268, train_loss 92.070396,Time used 0.012002s\n",
      "batch 7269, train_loss 111.711945,Time used 0.014003s\n",
      "batch 7270, train_loss 108.947754,Time used 0.018000s\n",
      "batch 7271, train_loss 105.020340,Time used 0.011998s\n",
      "batch 7272, train_loss 101.366211,Time used 0.011000s\n",
      "batch 7273, train_loss 115.259689,Time used 0.013005s\n",
      "batch 7274, train_loss 92.070862,Time used 0.011995s\n",
      "batch 7275, train_loss 106.539711,Time used 0.012997s\n",
      "batch 7276, train_loss 78.237823,Time used 0.012003s\n",
      "batch 7277, train_loss 104.105087,Time used 0.013002s\n",
      "batch 7278, train_loss 104.666115,Time used 0.009998s\n",
      "batch 7279, train_loss 112.473183,Time used 0.011003s\n",
      "batch 7280, train_loss 84.008171,Time used 0.011997s\n",
      "batch 7281, train_loss 96.897606,Time used 0.012002s\n",
      "batch 7282, train_loss 82.133476,Time used 0.012001s\n",
      "batch 7283, train_loss 82.520973,Time used 0.009999s\n",
      "batch 7284, train_loss 95.537704,Time used 0.012002s\n",
      "batch 7285, train_loss 124.093704,Time used 0.011998s\n",
      "batch 7286, train_loss 65.542244,Time used 0.009001s\n",
      "batch 7287, train_loss 94.321419,Time used 0.007001s\n",
      "batch 7288, train_loss 103.281143,Time used 0.010998s\n",
      "batch 7289, train_loss 82.418953,Time used 0.010001s\n",
      "batch 7290, train_loss 111.666862,Time used 0.014999s\n",
      "batch 7291, train_loss 105.066017,Time used 0.009999s\n",
      "batch 7292, train_loss 90.179939,Time used 0.010998s\n",
      "batch 7293, train_loss 97.772591,Time used 0.012002s\n",
      "batch 7294, train_loss 119.607658,Time used 0.008002s\n",
      "batch 7295, train_loss 88.095734,Time used 0.011997s\n",
      "batch 7296, train_loss 96.442749,Time used 0.006999s\n",
      "batch 7297, train_loss 85.969025,Time used 0.010999s\n",
      "batch 7298, train_loss 118.996727,Time used 0.007000s\n",
      "batch 7299, train_loss 103.554108,Time used 0.008999s\n",
      "batch 7300, train_loss 90.036331,Time used 0.006999s\n",
      "***************************test_batch 7300, test_rmse_loss 11.338049,test_mae_loss 4.415921,test_mape_loss 65.572130,Time used 0.040000s\n",
      "batch 7301, train_loss 86.487717,Time used 0.006999s\n",
      "batch 7302, train_loss 94.343109,Time used 0.009039s\n",
      "batch 7303, train_loss 72.444916,Time used 0.007004s\n",
      "batch 7304, train_loss 88.258629,Time used 0.007957s\n",
      "batch 7305, train_loss 113.875534,Time used 0.010038s\n",
      "batch 7306, train_loss 102.771858,Time used 0.008964s\n",
      "batch 7307, train_loss 86.570824,Time used 0.010004s\n",
      "batch 7308, train_loss 77.997086,Time used 0.008999s\n",
      "batch 7309, train_loss 135.978073,Time used 0.010001s\n",
      "batch 7310, train_loss 104.952034,Time used 0.009003s\n",
      "batch 7311, train_loss 91.107445,Time used 0.010998s\n",
      "batch 7312, train_loss 118.895653,Time used 0.008002s\n",
      "batch 7313, train_loss 73.279381,Time used 0.006998s\n",
      "batch 7314, train_loss 109.714783,Time used 0.008003s\n",
      "batch 7315, train_loss 105.561440,Time used 0.007001s\n",
      "batch 7316, train_loss 107.436516,Time used 0.006995s\n",
      "batch 7317, train_loss 89.271873,Time used 0.007999s\n",
      "batch 7318, train_loss 91.620789,Time used 0.008003s\n",
      "batch 7319, train_loss 114.219200,Time used 0.007999s\n",
      "batch 7320, train_loss 61.268654,Time used 0.006999s\n",
      "batch 7321, train_loss 122.654839,Time used 0.008001s\n",
      "batch 7322, train_loss 98.850769,Time used 0.007999s\n",
      "batch 7323, train_loss 81.608337,Time used 0.008002s\n",
      "batch 7324, train_loss 94.308128,Time used 0.007998s\n",
      "batch 7325, train_loss 86.267311,Time used 0.009002s\n",
      "batch 7326, train_loss 94.552124,Time used 0.007999s\n",
      "batch 7327, train_loss 125.668022,Time used 0.009000s\n",
      "batch 7328, train_loss 100.364403,Time used 0.010002s\n",
      "batch 7329, train_loss 98.328201,Time used 0.009996s\n",
      "batch 7330, train_loss 88.150208,Time used 0.007002s\n",
      "batch 7331, train_loss 87.434837,Time used 0.008002s\n",
      "batch 7332, train_loss 86.962761,Time used 0.008998s\n",
      "batch 7333, train_loss 118.298035,Time used 0.008001s\n",
      "batch 7334, train_loss 115.174286,Time used 0.009001s\n",
      "batch 7335, train_loss 107.375710,Time used 0.008998s\n",
      "batch 7336, train_loss 74.932358,Time used 0.007000s\n",
      "batch 7337, train_loss 67.664886,Time used 0.007001s\n",
      "batch 7338, train_loss 97.149979,Time used 0.006998s\n",
      "batch 7339, train_loss 90.350960,Time used 0.011037s\n",
      "batch 7340, train_loss 114.853828,Time used 0.007967s\n",
      "batch 7341, train_loss 98.261185,Time used 0.006996s\n",
      "batch 7342, train_loss 105.618591,Time used 0.008035s\n",
      "batch 7343, train_loss 84.499489,Time used 0.005999s\n",
      "batch 7344, train_loss 79.092712,Time used 0.007963s\n",
      "batch 7345, train_loss 85.039162,Time used 0.011001s\n",
      "batch 7346, train_loss 93.689301,Time used 0.009998s\n",
      "batch 7347, train_loss 138.534958,Time used 0.011000s\n",
      "batch 7348, train_loss 86.410660,Time used 0.010002s\n",
      "batch 7349, train_loss 111.505035,Time used 0.011040s\n",
      "batch 7350, train_loss 93.453049,Time used 0.010993s\n",
      "batch 7351, train_loss 83.448341,Time used 0.009966s\n",
      "batch 7352, train_loss 100.072723,Time used 0.009999s\n",
      "batch 7353, train_loss 104.913223,Time used 0.007000s\n",
      "batch 7354, train_loss 116.699760,Time used 0.009000s\n",
      "batch 7355, train_loss 88.006172,Time used 0.011000s\n",
      "batch 7356, train_loss 93.631439,Time used 0.008000s\n",
      "batch 7357, train_loss 99.057671,Time used 0.007000s\n",
      "batch 7358, train_loss 85.221947,Time used 0.008001s\n",
      "batch 7359, train_loss 85.101440,Time used 0.007999s\n",
      "batch 7360, train_loss 98.056450,Time used 0.008002s\n",
      "batch 7361, train_loss 98.228210,Time used 0.007001s\n",
      "batch 7362, train_loss 83.258827,Time used 0.008001s\n",
      "batch 7363, train_loss 96.316185,Time used 0.008999s\n",
      "batch 7364, train_loss 104.544098,Time used 0.007999s\n",
      "batch 7365, train_loss 96.886765,Time used 0.007001s\n",
      "batch 7366, train_loss 107.389526,Time used 0.008002s\n",
      "batch 7367, train_loss 91.931389,Time used 0.006998s\n",
      "batch 7368, train_loss 69.761024,Time used 0.007999s\n",
      "batch 7369, train_loss 102.512070,Time used 0.011002s\n",
      "batch 7370, train_loss 86.421890,Time used 0.010998s\n",
      "batch 7371, train_loss 86.677895,Time used 0.008002s\n",
      "batch 7372, train_loss 82.106705,Time used 0.010999s\n",
      "batch 7373, train_loss 90.433884,Time used 0.007999s\n",
      "batch 7374, train_loss 77.673714,Time used 0.007001s\n",
      "batch 7375, train_loss 81.807388,Time used 0.010000s\n",
      "batch 7376, train_loss 103.499023,Time used 0.006999s\n",
      "batch 7377, train_loss 112.100471,Time used 0.007001s\n",
      "batch 7378, train_loss 111.887901,Time used 0.008001s\n",
      "batch 7379, train_loss 115.237267,Time used 0.008002s\n",
      "batch 7380, train_loss 94.342155,Time used 0.007999s\n",
      "batch 7381, train_loss 87.953148,Time used 0.010035s\n",
      "batch 7382, train_loss 85.497169,Time used 0.010001s\n",
      "batch 7383, train_loss 94.328194,Time used 0.006963s\n",
      "batch 7384, train_loss 96.903984,Time used 0.011005s\n",
      "batch 7385, train_loss 109.914169,Time used 0.006998s\n",
      "batch 7386, train_loss 104.777893,Time used 0.010000s\n",
      "batch 7387, train_loss 70.572327,Time used 0.007000s\n",
      "batch 7388, train_loss 133.484985,Time used 0.008997s\n",
      "batch 7389, train_loss 76.050827,Time used 0.008998s\n",
      "batch 7390, train_loss 94.362022,Time used 0.010003s\n",
      "batch 7391, train_loss 95.341156,Time used 0.008000s\n",
      "batch 7392, train_loss 111.923080,Time used 0.006999s\n",
      "batch 7393, train_loss 113.054588,Time used 0.007999s\n",
      "batch 7394, train_loss 103.439079,Time used 0.013001s\n",
      "batch 7395, train_loss 93.199562,Time used 0.010996s\n",
      "batch 7396, train_loss 90.082008,Time used 0.010004s\n",
      "batch 7397, train_loss 107.395493,Time used 0.008996s\n",
      "batch 7398, train_loss 80.802040,Time used 0.008001s\n",
      "batch 7399, train_loss 112.562286,Time used 0.007999s\n",
      "batch 7400, train_loss 119.586205,Time used 0.007000s\n",
      "***************************test_batch 7400, test_rmse_loss 11.270159,test_mae_loss 4.392779,test_mape_loss 65.281993,Time used 0.028001s\n",
      "batch 7401, train_loss 79.953110,Time used 0.012001s\n",
      "batch 7402, train_loss 72.806686,Time used 0.011998s\n",
      "batch 7403, train_loss 77.771881,Time used 0.007000s\n",
      "batch 7404, train_loss 92.195976,Time used 0.009001s\n",
      "batch 7405, train_loss 75.194183,Time used 0.007000s\n",
      "batch 7406, train_loss 114.758064,Time used 0.008001s\n",
      "batch 7407, train_loss 72.049530,Time used 0.007000s\n",
      "batch 7408, train_loss 94.021637,Time used 0.016999s\n",
      "batch 7409, train_loss 99.239494,Time used 0.009000s\n",
      "batch 7410, train_loss 86.329582,Time used 0.007999s\n",
      "batch 7411, train_loss 108.709457,Time used 0.009000s\n",
      "batch 7412, train_loss 107.245232,Time used 0.009002s\n",
      "batch 7413, train_loss 99.506416,Time used 0.012001s\n",
      "batch 7414, train_loss 119.371895,Time used 0.008997s\n",
      "batch 7415, train_loss 85.230362,Time used 0.011002s\n",
      "batch 7416, train_loss 93.735008,Time used 0.008000s\n",
      "batch 7417, train_loss 113.026390,Time used 0.008999s\n",
      "batch 7418, train_loss 98.382088,Time used 0.007001s\n",
      "batch 7419, train_loss 101.500984,Time used 0.008002s\n",
      "batch 7420, train_loss 87.204811,Time used 0.007998s\n",
      "batch 7421, train_loss 118.191025,Time used 0.008002s\n",
      "batch 7422, train_loss 88.719795,Time used 0.007999s\n",
      "batch 7423, train_loss 72.205887,Time used 0.006999s\n",
      "batch 7424, train_loss 104.890434,Time used 0.008002s\n",
      "batch 7425, train_loss 115.380272,Time used 0.011000s\n",
      "batch 7426, train_loss 119.458252,Time used 0.011000s\n",
      "batch 7427, train_loss 104.589798,Time used 0.008001s\n",
      "batch 7428, train_loss 82.418991,Time used 0.011000s\n",
      "batch 7429, train_loss 78.470634,Time used 0.007999s\n",
      "batch 7430, train_loss 98.155533,Time used 0.009001s\n",
      "batch 7431, train_loss 96.549126,Time used 0.009997s\n",
      "batch 7432, train_loss 69.748871,Time used 0.007001s\n",
      "batch 7433, train_loss 95.918869,Time used 0.008000s\n",
      "batch 7434, train_loss 105.157936,Time used 0.007999s\n",
      "batch 7435, train_loss 68.014435,Time used 0.009002s\n",
      "batch 7436, train_loss 108.751656,Time used 0.007000s\n",
      "batch 7437, train_loss 87.876602,Time used 0.007000s\n",
      "batch 7438, train_loss 86.039680,Time used 0.007001s\n",
      "batch 7439, train_loss 98.023720,Time used 0.007998s\n",
      "batch 7440, train_loss 92.925842,Time used 0.007000s\n",
      "batch 7441, train_loss 101.491158,Time used 0.007002s\n",
      "batch 7442, train_loss 112.873878,Time used 0.008001s\n",
      "batch 7443, train_loss 102.187851,Time used 0.008000s\n",
      "batch 7444, train_loss 102.906525,Time used 0.006996s\n",
      "batch 7445, train_loss 109.554115,Time used 0.007003s\n",
      "batch 7446, train_loss 90.108429,Time used 0.012001s\n",
      "batch 7447, train_loss 95.195679,Time used 0.007001s\n",
      "batch 7448, train_loss 88.459694,Time used 0.009998s\n",
      "batch 7449, train_loss 82.807701,Time used 0.010002s\n",
      "batch 7450, train_loss 106.802460,Time used 0.009000s\n",
      "batch 7451, train_loss 92.035881,Time used 0.009998s\n",
      "batch 7452, train_loss 93.369370,Time used 0.011001s\n",
      "batch 7453, train_loss 97.595329,Time used 0.007997s\n",
      "batch 7454, train_loss 107.148445,Time used 0.007002s\n",
      "batch 7455, train_loss 71.010788,Time used 0.007999s\n",
      "batch 7456, train_loss 105.649864,Time used 0.007000s\n",
      "batch 7457, train_loss 96.062187,Time used 0.007001s\n",
      "batch 7458, train_loss 100.174881,Time used 0.006999s\n",
      "batch 7459, train_loss 83.849403,Time used 0.007002s\n",
      "batch 7460, train_loss 80.811424,Time used 0.011001s\n",
      "batch 7461, train_loss 80.895828,Time used 0.010000s\n",
      "batch 7462, train_loss 81.033760,Time used 0.006999s\n",
      "batch 7463, train_loss 117.456032,Time used 0.008003s\n",
      "batch 7464, train_loss 85.058617,Time used 0.008999s\n",
      "batch 7465, train_loss 102.586639,Time used 0.008002s\n",
      "batch 7466, train_loss 91.337814,Time used 0.006999s\n",
      "batch 7467, train_loss 76.483566,Time used 0.008000s\n",
      "batch 7468, train_loss 73.194336,Time used 0.008001s\n",
      "batch 7469, train_loss 91.683830,Time used 0.007999s\n",
      "batch 7470, train_loss 90.527687,Time used 0.008001s\n",
      "batch 7471, train_loss 111.274582,Time used 0.010999s\n",
      "batch 7472, train_loss 99.855042,Time used 0.011002s\n",
      "batch 7473, train_loss 103.524658,Time used 0.011000s\n",
      "batch 7474, train_loss 99.245003,Time used 0.010996s\n",
      "batch 7475, train_loss 109.331947,Time used 0.009002s\n",
      "batch 7476, train_loss 84.221214,Time used 0.006999s\n",
      "batch 7477, train_loss 119.177231,Time used 0.008002s\n",
      "batch 7478, train_loss 107.215355,Time used 0.006999s\n",
      "batch 7479, train_loss 85.110924,Time used 0.007999s\n",
      "batch 7480, train_loss 84.500900,Time used 0.005999s\n",
      "batch 7481, train_loss 80.964592,Time used 0.007000s\n",
      "batch 7482, train_loss 86.090675,Time used 0.007000s\n",
      "batch 7483, train_loss 73.019356,Time used 0.007000s\n",
      "batch 7484, train_loss 105.874886,Time used 0.008000s\n",
      "batch 7485, train_loss 94.280876,Time used 0.006999s\n",
      "batch 7486, train_loss 104.815979,Time used 0.011000s\n",
      "batch 7487, train_loss 110.333702,Time used 0.010000s\n",
      "batch 7488, train_loss 93.370529,Time used 0.008002s\n",
      "batch 7489, train_loss 84.427925,Time used 0.006999s\n",
      "batch 7490, train_loss 107.735168,Time used 0.008000s\n",
      "batch 7491, train_loss 55.778587,Time used 0.010998s\n",
      "batch 7492, train_loss 100.713326,Time used 0.009002s\n",
      "batch 7493, train_loss 79.966179,Time used 0.007999s\n",
      "batch 7494, train_loss 97.052589,Time used 0.009998s\n",
      "batch 7495, train_loss 92.261765,Time used 0.008003s\n",
      "batch 7496, train_loss 90.234543,Time used 0.007999s\n",
      "batch 7497, train_loss 89.658707,Time used 0.007999s\n",
      "batch 7498, train_loss 81.989861,Time used 0.008000s\n",
      "batch 7499, train_loss 92.541321,Time used 0.009000s\n",
      "batch 7500, train_loss 100.102730,Time used 0.007001s\n",
      "***************************test_batch 7500, test_rmse_loss 11.201112,test_mae_loss 4.372291,test_mape_loss 65.395494,Time used 0.032999s\n",
      "batch 7501, train_loss 115.259842,Time used 0.011000s\n",
      "batch 7502, train_loss 93.143150,Time used 0.010999s\n",
      "batch 7503, train_loss 102.216927,Time used 0.010999s\n",
      "batch 7504, train_loss 90.147430,Time used 0.008003s\n",
      "batch 7505, train_loss 114.237915,Time used 0.008000s\n",
      "batch 7506, train_loss 80.197121,Time used 0.008998s\n",
      "batch 7507, train_loss 72.249855,Time used 0.008001s\n",
      "batch 7508, train_loss 114.937363,Time used 0.010999s\n",
      "batch 7509, train_loss 104.058052,Time used 0.011003s\n",
      "batch 7510, train_loss 97.954323,Time used 0.011036s\n",
      "batch 7511, train_loss 105.376724,Time used 0.006998s\n",
      "batch 7512, train_loss 109.798973,Time used 0.007999s\n",
      "batch 7513, train_loss 87.491829,Time used 0.011005s\n",
      "batch 7514, train_loss 107.993538,Time used 0.009000s\n",
      "batch 7515, train_loss 92.641205,Time used 0.010995s\n",
      "batch 7516, train_loss 124.097923,Time used 0.007002s\n",
      "batch 7517, train_loss 84.852219,Time used 0.008001s\n",
      "batch 7518, train_loss 73.065834,Time used 0.007035s\n",
      "batch 7519, train_loss 92.791069,Time used 0.007963s\n",
      "batch 7520, train_loss 94.653328,Time used 0.007000s\n",
      "batch 7521, train_loss 97.633163,Time used 0.008002s\n",
      "batch 7522, train_loss 88.141594,Time used 0.006999s\n",
      "batch 7523, train_loss 107.515800,Time used 0.011001s\n",
      "batch 7524, train_loss 92.566887,Time used 0.006999s\n",
      "batch 7525, train_loss 91.652687,Time used 0.007000s\n",
      "batch 7526, train_loss 80.220482,Time used 0.007000s\n",
      "batch 7527, train_loss 90.486366,Time used 0.008000s\n",
      "batch 7528, train_loss 106.535141,Time used 0.006999s\n",
      "batch 7529, train_loss 105.593834,Time used 0.008002s\n",
      "batch 7530, train_loss 109.872719,Time used 0.006999s\n",
      "batch 7531, train_loss 70.348854,Time used 0.008002s\n",
      "batch 7532, train_loss 103.658287,Time used 0.007997s\n",
      "batch 7533, train_loss 91.993996,Time used 0.011000s\n",
      "batch 7534, train_loss 73.050270,Time used 0.010001s\n",
      "batch 7535, train_loss 108.979881,Time used 0.006999s\n",
      "batch 7536, train_loss 88.868439,Time used 0.011000s\n",
      "batch 7537, train_loss 102.610497,Time used 0.010996s\n",
      "batch 7538, train_loss 62.858265,Time used 0.009002s\n",
      "batch 7539, train_loss 99.927467,Time used 0.011999s\n",
      "batch 7540, train_loss 104.073006,Time used 0.008002s\n",
      "batch 7541, train_loss 92.426605,Time used 0.008001s\n",
      "batch 7542, train_loss 88.199066,Time used 0.006997s\n",
      "batch 7543, train_loss 80.966232,Time used 0.009001s\n",
      "batch 7544, train_loss 79.781059,Time used 0.008000s\n",
      "batch 7545, train_loss 97.128265,Time used 0.007000s\n",
      "batch 7546, train_loss 92.602493,Time used 0.007002s\n",
      "batch 7547, train_loss 105.334602,Time used 0.007999s\n",
      "batch 7548, train_loss 99.757141,Time used 0.008001s\n",
      "batch 7549, train_loss 77.723839,Time used 0.009003s\n",
      "batch 7550, train_loss 74.004692,Time used 0.010997s\n",
      "batch 7551, train_loss 118.512970,Time used 0.009999s\n",
      "batch 7552, train_loss 92.860046,Time used 0.006999s\n",
      "batch 7553, train_loss 98.779243,Time used 0.010998s\n",
      "batch 7554, train_loss 98.398018,Time used 0.009967s\n",
      "batch 7555, train_loss 96.408333,Time used 0.011000s\n",
      "batch 7556, train_loss 95.397209,Time used 0.008036s\n",
      "batch 7557, train_loss 95.801819,Time used 0.006994s\n",
      "batch 7558, train_loss 102.174026,Time used 0.007966s\n",
      "batch 7559, train_loss 113.390488,Time used 0.008996s\n",
      "batch 7560, train_loss 88.743637,Time used 0.009001s\n",
      "batch 7561, train_loss 95.461510,Time used 0.010983s\n",
      "batch 7562, train_loss 116.888580,Time used 0.007967s\n",
      "batch 7563, train_loss 79.855141,Time used 0.007998s\n",
      "batch 7564, train_loss 107.489761,Time used 0.010999s\n",
      "batch 7565, train_loss 79.651855,Time used 0.011000s\n",
      "batch 7566, train_loss 88.981049,Time used 0.008006s\n",
      "batch 7567, train_loss 85.711548,Time used 0.007994s\n",
      "batch 7568, train_loss 72.875023,Time used 0.007004s\n",
      "batch 7569, train_loss 69.875977,Time used 0.008999s\n",
      "batch 7570, train_loss 79.507729,Time used 0.007999s\n",
      "batch 7571, train_loss 90.020058,Time used 0.010000s\n",
      "batch 7572, train_loss 91.200111,Time used 0.006999s\n",
      "batch 7573, train_loss 72.149673,Time used 0.008001s\n",
      "batch 7574, train_loss 114.211868,Time used 0.006994s\n",
      "batch 7575, train_loss 83.253578,Time used 0.010993s\n",
      "batch 7576, train_loss 91.575897,Time used 0.008998s\n",
      "batch 7577, train_loss 106.515755,Time used 0.007004s\n",
      "batch 7578, train_loss 102.235001,Time used 0.007999s\n",
      "batch 7579, train_loss 96.908348,Time used 0.006996s\n",
      "batch 7580, train_loss 107.840889,Time used 0.007003s\n",
      "batch 7581, train_loss 92.015007,Time used 0.010999s\n",
      "batch 7582, train_loss 114.442268,Time used 0.009004s\n",
      "batch 7583, train_loss 105.989037,Time used 0.006999s\n",
      "batch 7584, train_loss 107.573944,Time used 0.007998s\n",
      "batch 7585, train_loss 85.725563,Time used 0.008999s\n",
      "batch 7586, train_loss 120.769592,Time used 0.009001s\n",
      "batch 7587, train_loss 84.855843,Time used 0.007999s\n",
      "batch 7588, train_loss 84.369896,Time used 0.008000s\n",
      "batch 7589, train_loss 105.931717,Time used 0.011001s\n",
      "batch 7590, train_loss 89.268890,Time used 0.009000s\n",
      "batch 7591, train_loss 80.473495,Time used 0.008034s\n",
      "batch 7592, train_loss 84.048019,Time used 0.009967s\n",
      "batch 7593, train_loss 86.022812,Time used 0.008000s\n",
      "batch 7594, train_loss 97.346756,Time used 0.007999s\n",
      "batch 7595, train_loss 87.702950,Time used 0.007038s\n",
      "batch 7596, train_loss 115.687294,Time used 0.007962s\n",
      "batch 7597, train_loss 102.636986,Time used 0.008000s\n",
      "batch 7598, train_loss 77.897903,Time used 0.011001s\n",
      "batch 7599, train_loss 104.709343,Time used 0.012034s\n",
      "batch 7600, train_loss 74.801590,Time used 0.006964s\n",
      "***************************test_batch 7600, test_rmse_loss 11.137553,test_mae_loss 4.349225,test_mape_loss 65.038241,Time used 0.031001s\n",
      "batch 7601, train_loss 84.298187,Time used 0.007003s\n",
      "batch 7602, train_loss 106.321419,Time used 0.007999s\n",
      "batch 7603, train_loss 109.178436,Time used 0.009999s\n",
      "batch 7604, train_loss 112.329796,Time used 0.013000s\n",
      "batch 7605, train_loss 86.887657,Time used 0.008004s\n",
      "batch 7606, train_loss 76.525742,Time used 0.007997s\n",
      "batch 7607, train_loss 109.543800,Time used 0.007000s\n",
      "batch 7608, train_loss 77.227158,Time used 0.009002s\n",
      "batch 7609, train_loss 99.051620,Time used 0.008995s\n",
      "batch 7610, train_loss 88.483444,Time used 0.010001s\n",
      "batch 7611, train_loss 112.050224,Time used 0.008002s\n",
      "batch 7612, train_loss 93.628174,Time used 0.009996s\n",
      "batch 7613, train_loss 94.688301,Time used 0.011002s\n",
      "batch 7614, train_loss 88.351509,Time used 0.007999s\n",
      "batch 7615, train_loss 90.572441,Time used 0.008002s\n",
      "batch 7616, train_loss 112.026741,Time used 0.006999s\n",
      "batch 7617, train_loss 90.333397,Time used 0.007000s\n",
      "batch 7618, train_loss 107.301117,Time used 0.011002s\n",
      "batch 7619, train_loss 70.824722,Time used 0.010998s\n",
      "batch 7620, train_loss 110.021477,Time used 0.008001s\n",
      "batch 7621, train_loss 99.242455,Time used 0.011000s\n",
      "batch 7622, train_loss 76.652199,Time used 0.007002s\n",
      "batch 7623, train_loss 91.249458,Time used 0.009001s\n",
      "batch 7624, train_loss 65.757248,Time used 0.010996s\n",
      "batch 7625, train_loss 101.467186,Time used 0.009004s\n",
      "batch 7626, train_loss 70.986206,Time used 0.010997s\n",
      "batch 7627, train_loss 88.232208,Time used 0.009002s\n",
      "batch 7628, train_loss 89.381462,Time used 0.011000s\n",
      "batch 7629, train_loss 105.640152,Time used 0.010998s\n",
      "batch 7630, train_loss 87.095100,Time used 0.011002s\n",
      "batch 7631, train_loss 107.475471,Time used 0.009998s\n",
      "batch 7632, train_loss 98.375565,Time used 0.010998s\n",
      "batch 7633, train_loss 96.900352,Time used 0.011003s\n",
      "batch 7634, train_loss 94.106735,Time used 0.009998s\n",
      "batch 7635, train_loss 91.677895,Time used 0.007000s\n",
      "batch 7636, train_loss 101.249535,Time used 0.010999s\n",
      "batch 7637, train_loss 92.083588,Time used 0.008011s\n",
      "batch 7638, train_loss 84.739662,Time used 0.010991s\n",
      "batch 7639, train_loss 99.209396,Time used 0.011001s\n",
      "batch 7640, train_loss 127.304504,Time used 0.010999s\n",
      "batch 7641, train_loss 84.659027,Time used 0.007001s\n",
      "batch 7642, train_loss 85.955917,Time used 0.007999s\n",
      "batch 7643, train_loss 92.997612,Time used 0.007998s\n",
      "batch 7644, train_loss 103.214989,Time used 0.008002s\n",
      "batch 7645, train_loss 92.443748,Time used 0.007999s\n",
      "batch 7646, train_loss 58.260105,Time used 0.007001s\n",
      "batch 7647, train_loss 101.133766,Time used 0.006998s\n",
      "batch 7648, train_loss 116.273247,Time used 0.008004s\n",
      "batch 7649, train_loss 83.344315,Time used 0.007999s\n",
      "batch 7650, train_loss 78.812080,Time used 0.006999s\n",
      "batch 7651, train_loss 104.398331,Time used 0.007001s\n",
      "batch 7652, train_loss 104.006294,Time used 0.010998s\n",
      "batch 7653, train_loss 93.083359,Time used 0.011001s\n",
      "batch 7654, train_loss 93.700493,Time used 0.010001s\n",
      "batch 7655, train_loss 76.748238,Time used 0.008999s\n",
      "batch 7656, train_loss 75.223267,Time used 0.008000s\n",
      "batch 7657, train_loss 104.340431,Time used 0.008999s\n",
      "batch 7658, train_loss 107.870811,Time used 0.007003s\n",
      "batch 7659, train_loss 76.955421,Time used 0.006998s\n",
      "batch 7660, train_loss 83.329651,Time used 0.007999s\n",
      "batch 7661, train_loss 84.913399,Time used 0.010000s\n",
      "batch 7662, train_loss 96.023247,Time used 0.010002s\n",
      "batch 7663, train_loss 99.989128,Time used 0.007998s\n",
      "batch 7664, train_loss 84.246521,Time used 0.006999s\n",
      "batch 7665, train_loss 67.585579,Time used 0.008004s\n",
      "batch 7666, train_loss 95.922516,Time used 0.006999s\n",
      "batch 7667, train_loss 105.322594,Time used 0.009000s\n",
      "batch 7668, train_loss 100.598389,Time used 0.010999s\n",
      "batch 7669, train_loss 91.345238,Time used 0.010002s\n",
      "batch 7670, train_loss 74.405052,Time used 0.009997s\n",
      "batch 7671, train_loss 98.230850,Time used 0.008000s\n",
      "batch 7672, train_loss 91.657303,Time used 0.008001s\n",
      "batch 7673, train_loss 97.301773,Time used 0.007002s\n",
      "batch 7674, train_loss 76.906075,Time used 0.011998s\n",
      "batch 7675, train_loss 95.972214,Time used 0.011006s\n",
      "batch 7676, train_loss 75.064697,Time used 0.007997s\n",
      "batch 7677, train_loss 103.540520,Time used 0.006999s\n",
      "batch 7678, train_loss 102.144180,Time used 0.006999s\n",
      "batch 7679, train_loss 98.557678,Time used 0.007001s\n",
      "batch 7680, train_loss 114.444572,Time used 0.007001s\n",
      "batch 7681, train_loss 91.879166,Time used 0.010997s\n",
      "batch 7682, train_loss 113.682976,Time used 0.008003s\n",
      "batch 7683, train_loss 89.848442,Time used 0.007000s\n",
      "batch 7684, train_loss 93.455521,Time used 0.008000s\n",
      "batch 7685, train_loss 76.354263,Time used 0.011998s\n",
      "batch 7686, train_loss 64.866135,Time used 0.008004s\n",
      "batch 7687, train_loss 88.110268,Time used 0.006998s\n",
      "batch 7688, train_loss 94.764626,Time used 0.007995s\n",
      "batch 7689, train_loss 113.430359,Time used 0.007001s\n",
      "batch 7690, train_loss 84.804283,Time used 0.008006s\n",
      "batch 7691, train_loss 85.422768,Time used 0.007003s\n",
      "batch 7692, train_loss 95.133972,Time used 0.006999s\n",
      "batch 7693, train_loss 117.739418,Time used 0.008000s\n",
      "batch 7694, train_loss 86.160561,Time used 0.009999s\n",
      "batch 7695, train_loss 92.462509,Time used 0.011002s\n",
      "batch 7696, train_loss 109.046364,Time used 0.010998s\n",
      "batch 7697, train_loss 89.119003,Time used 0.011001s\n",
      "batch 7698, train_loss 81.848557,Time used 0.009001s\n",
      "batch 7699, train_loss 84.894783,Time used 0.013000s\n",
      "batch 7700, train_loss 72.733978,Time used 0.009997s\n",
      "***************************test_batch 7700, test_rmse_loss 11.070662,test_mae_loss 4.328740,test_mape_loss 64.943826,Time used 0.034001s\n",
      "batch 7701, train_loss 88.487534,Time used 0.007999s\n",
      "batch 7702, train_loss 114.400856,Time used 0.007999s\n",
      "batch 7703, train_loss 81.290619,Time used 0.010003s\n",
      "batch 7704, train_loss 110.203323,Time used 0.008999s\n",
      "batch 7705, train_loss 109.522362,Time used 0.009000s\n",
      "batch 7706, train_loss 100.788620,Time used 0.010998s\n",
      "batch 7707, train_loss 79.512115,Time used 0.010003s\n",
      "batch 7708, train_loss 71.148087,Time used 0.008000s\n",
      "batch 7709, train_loss 109.174362,Time used 0.008000s\n",
      "batch 7710, train_loss 98.193405,Time used 0.009998s\n",
      "batch 7711, train_loss 102.913544,Time used 0.011001s\n",
      "batch 7712, train_loss 96.771690,Time used 0.011001s\n",
      "batch 7713, train_loss 100.359688,Time used 0.008998s\n",
      "batch 7714, train_loss 102.786911,Time used 0.008001s\n",
      "batch 7715, train_loss 99.019783,Time used 0.008000s\n",
      "batch 7716, train_loss 91.457787,Time used 0.009001s\n",
      "batch 7717, train_loss 94.788887,Time used 0.011999s\n",
      "batch 7718, train_loss 109.636536,Time used 0.011999s\n",
      "batch 7719, train_loss 73.548584,Time used 0.012002s\n",
      "batch 7720, train_loss 66.969826,Time used 0.014003s\n",
      "batch 7721, train_loss 85.000160,Time used 0.009995s\n",
      "batch 7722, train_loss 112.400055,Time used 0.012002s\n",
      "batch 7723, train_loss 93.917793,Time used 0.053001s\n",
      "batch 7724, train_loss 92.255394,Time used 0.133003s\n",
      "batch 7725, train_loss 86.129181,Time used 0.034000s\n",
      "batch 7726, train_loss 75.980431,Time used 0.034999s\n",
      "batch 7727, train_loss 87.211884,Time used 0.055000s\n",
      "batch 7728, train_loss 72.879272,Time used 0.020999s\n",
      "batch 7729, train_loss 101.734993,Time used 0.021999s\n",
      "batch 7730, train_loss 87.431923,Time used 0.041999s\n",
      "batch 7731, train_loss 112.282402,Time used 0.022998s\n",
      "batch 7732, train_loss 121.681984,Time used 0.029010s\n",
      "batch 7733, train_loss 89.954712,Time used 0.023996s\n",
      "batch 7734, train_loss 89.720360,Time used 0.303000s\n",
      "batch 7735, train_loss 87.582809,Time used 0.180000s\n",
      "batch 7736, train_loss 80.065125,Time used 0.044997s\n",
      "batch 7737, train_loss 93.289314,Time used 0.011999s\n",
      "batch 7738, train_loss 102.267624,Time used 0.013003s\n",
      "batch 7739, train_loss 78.598640,Time used 0.011003s\n",
      "batch 7740, train_loss 95.832184,Time used 0.018999s\n",
      "batch 7741, train_loss 111.320084,Time used 0.021999s\n",
      "batch 7742, train_loss 99.721962,Time used 0.015999s\n",
      "batch 7743, train_loss 74.476631,Time used 0.013008s\n",
      "batch 7744, train_loss 94.354057,Time used 0.015994s\n",
      "batch 7745, train_loss 106.533546,Time used 0.013001s\n",
      "batch 7746, train_loss 76.190056,Time used 0.012000s\n",
      "batch 7747, train_loss 92.142860,Time used 0.010998s\n",
      "batch 7748, train_loss 86.751945,Time used 0.010003s\n",
      "batch 7749, train_loss 76.747879,Time used 0.011000s\n",
      "batch 7750, train_loss 82.766945,Time used 0.014009s\n",
      "batch 7751, train_loss 95.542114,Time used 0.013992s\n",
      "batch 7752, train_loss 68.904800,Time used 0.016001s\n",
      "batch 7753, train_loss 84.067055,Time used 0.021000s\n",
      "batch 7754, train_loss 95.946060,Time used 0.026001s\n",
      "batch 7755, train_loss 88.546295,Time used 0.022000s\n",
      "batch 7756, train_loss 75.854958,Time used 0.028002s\n",
      "batch 7757, train_loss 90.264526,Time used 0.046999s\n",
      "batch 7758, train_loss 93.930450,Time used 0.062996s\n",
      "batch 7759, train_loss 79.569984,Time used 0.018000s\n",
      "batch 7760, train_loss 91.410614,Time used 0.029002s\n",
      "batch 7761, train_loss 84.500496,Time used 0.017001s\n",
      "batch 7762, train_loss 97.399376,Time used 0.033002s\n",
      "batch 7763, train_loss 98.377678,Time used 0.019995s\n",
      "batch 7764, train_loss 116.627075,Time used 0.015002s\n",
      "batch 7765, train_loss 104.418434,Time used 0.015002s\n",
      "batch 7766, train_loss 84.362358,Time used 0.013995s\n",
      "batch 7767, train_loss 87.925804,Time used 0.014021s\n",
      "batch 7768, train_loss 106.152977,Time used 0.012982s\n",
      "batch 7769, train_loss 91.954536,Time used 0.012997s\n",
      "batch 7770, train_loss 82.922073,Time used 0.015000s\n",
      "batch 7771, train_loss 67.317001,Time used 0.015000s\n",
      "batch 7772, train_loss 89.302322,Time used 0.017000s\n",
      "batch 7773, train_loss 103.543228,Time used 0.013996s\n",
      "batch 7774, train_loss 84.319138,Time used 0.012006s\n",
      "batch 7775, train_loss 99.770645,Time used 0.022003s\n",
      "batch 7776, train_loss 102.253975,Time used 0.012997s\n",
      "batch 7777, train_loss 86.488495,Time used 0.008997s\n",
      "batch 7778, train_loss 71.765488,Time used 0.009003s\n",
      "batch 7779, train_loss 102.028236,Time used 0.013999s\n",
      "batch 7780, train_loss 58.723118,Time used 0.012996s\n",
      "batch 7781, train_loss 76.069595,Time used 0.009004s\n",
      "batch 7782, train_loss 92.975632,Time used 0.008001s\n",
      "batch 7783, train_loss 64.265930,Time used 0.008000s\n",
      "batch 7784, train_loss 86.062111,Time used 0.009002s\n",
      "batch 7785, train_loss 87.042702,Time used 0.011002s\n",
      "batch 7786, train_loss 108.067162,Time used 0.010998s\n",
      "batch 7787, train_loss 85.199387,Time used 0.010000s\n",
      "batch 7788, train_loss 91.859535,Time used 0.007000s\n",
      "batch 7789, train_loss 111.245033,Time used 0.006999s\n",
      "batch 7790, train_loss 77.796402,Time used 0.008000s\n",
      "batch 7791, train_loss 113.026215,Time used 0.008001s\n",
      "batch 7792, train_loss 97.700188,Time used 0.007001s\n",
      "batch 7793, train_loss 106.263733,Time used 0.007998s\n",
      "batch 7794, train_loss 116.043762,Time used 0.008001s\n",
      "batch 7795, train_loss 97.593567,Time used 0.007001s\n",
      "batch 7796, train_loss 98.717018,Time used 0.008000s\n",
      "batch 7797, train_loss 82.842003,Time used 0.008001s\n",
      "batch 7798, train_loss 99.081917,Time used 0.008002s\n",
      "batch 7799, train_loss 82.297249,Time used 0.008997s\n",
      "batch 7800, train_loss 101.440071,Time used 0.010003s\n",
      "***************************test_batch 7800, test_rmse_loss 11.005029,test_mae_loss 4.306125,test_mape_loss 64.745214,Time used 0.033996s\n",
      "batch 7801, train_loss 88.462151,Time used 0.010004s\n",
      "batch 7802, train_loss 92.147789,Time used 0.007998s\n",
      "batch 7803, train_loss 80.247604,Time used 0.010997s\n",
      "batch 7804, train_loss 100.335846,Time used 0.007999s\n",
      "batch 7805, train_loss 96.264542,Time used 0.010003s\n",
      "batch 7806, train_loss 103.368370,Time used 0.008996s\n",
      "batch 7807, train_loss 112.250488,Time used 0.007002s\n",
      "batch 7808, train_loss 100.270256,Time used 0.007000s\n",
      "batch 7809, train_loss 59.252022,Time used 0.008000s\n",
      "batch 7810, train_loss 80.427422,Time used 0.008002s\n",
      "batch 7811, train_loss 73.851723,Time used 0.007997s\n",
      "batch 7812, train_loss 78.195465,Time used 0.007001s\n",
      "batch 7813, train_loss 96.945412,Time used 0.007996s\n",
      "batch 7814, train_loss 102.031097,Time used 0.006999s\n",
      "batch 7815, train_loss 119.846138,Time used 0.008000s\n",
      "batch 7816, train_loss 112.351509,Time used 0.008000s\n",
      "batch 7817, train_loss 112.247231,Time used 0.006999s\n",
      "batch 7818, train_loss 63.498455,Time used 0.010000s\n",
      "batch 7819, train_loss 90.523727,Time used 0.011002s\n",
      "batch 7820, train_loss 109.507011,Time used 0.009997s\n",
      "batch 7821, train_loss 49.092003,Time used 0.009001s\n",
      "batch 7822, train_loss 95.496796,Time used 0.009999s\n",
      "batch 7823, train_loss 82.594048,Time used 0.006999s\n",
      "batch 7824, train_loss 88.739899,Time used 0.011001s\n",
      "batch 7825, train_loss 89.946999,Time used 0.010998s\n",
      "batch 7826, train_loss 90.532303,Time used 0.009000s\n",
      "batch 7827, train_loss 93.354858,Time used 0.006998s\n",
      "batch 7828, train_loss 87.714661,Time used 0.007998s\n",
      "batch 7829, train_loss 71.080780,Time used 0.007002s\n",
      "batch 7830, train_loss 100.525032,Time used 0.006999s\n",
      "batch 7831, train_loss 87.098473,Time used 0.007001s\n",
      "batch 7832, train_loss 71.077271,Time used 0.007034s\n",
      "batch 7833, train_loss 111.824471,Time used 0.008963s\n",
      "batch 7834, train_loss 97.168159,Time used 0.011041s\n",
      "batch 7835, train_loss 79.357742,Time used 0.006960s\n",
      "batch 7836, train_loss 101.332863,Time used 0.007998s\n",
      "batch 7837, train_loss 79.967926,Time used 0.007000s\n",
      "batch 7838, train_loss 74.372017,Time used 0.007000s\n",
      "batch 7839, train_loss 86.373268,Time used 0.009001s\n",
      "batch 7840, train_loss 81.626595,Time used 0.011002s\n",
      "batch 7841, train_loss 95.830063,Time used 0.009999s\n",
      "batch 7842, train_loss 115.198303,Time used 0.007997s\n",
      "batch 7843, train_loss 93.773727,Time used 0.011000s\n",
      "batch 7844, train_loss 81.792206,Time used 0.012002s\n",
      "batch 7845, train_loss 81.522820,Time used 0.012034s\n",
      "batch 7846, train_loss 111.453682,Time used 0.008967s\n",
      "batch 7847, train_loss 87.922791,Time used 0.007998s\n",
      "batch 7848, train_loss 111.658958,Time used 0.008001s\n",
      "batch 7849, train_loss 88.587517,Time used 0.008001s\n",
      "batch 7850, train_loss 81.093956,Time used 0.006999s\n",
      "batch 7851, train_loss 76.159088,Time used 0.009000s\n",
      "batch 7852, train_loss 98.520546,Time used 0.006999s\n",
      "batch 7853, train_loss 88.800995,Time used 0.007001s\n",
      "batch 7854, train_loss 85.076408,Time used 0.009000s\n",
      "batch 7855, train_loss 98.034454,Time used 0.010000s\n",
      "batch 7856, train_loss 88.053635,Time used 0.009999s\n",
      "batch 7857, train_loss 77.808701,Time used 0.007000s\n",
      "batch 7858, train_loss 81.761482,Time used 0.007001s\n",
      "batch 7859, train_loss 111.645966,Time used 0.009001s\n",
      "batch 7860, train_loss 96.844193,Time used 0.010999s\n",
      "batch 7861, train_loss 85.749046,Time used 0.010001s\n",
      "batch 7862, train_loss 71.595375,Time used 0.011000s\n",
      "batch 7863, train_loss 86.964714,Time used 0.009002s\n",
      "batch 7864, train_loss 73.657593,Time used 0.009999s\n",
      "batch 7865, train_loss 89.354164,Time used 0.008998s\n",
      "batch 7866, train_loss 106.557297,Time used 0.007000s\n",
      "batch 7867, train_loss 87.248207,Time used 0.012000s\n",
      "batch 7868, train_loss 86.577995,Time used 0.011000s\n",
      "batch 7869, train_loss 106.672066,Time used 0.011000s\n",
      "batch 7870, train_loss 107.258156,Time used 0.007004s\n",
      "batch 7871, train_loss 104.910126,Time used 0.011997s\n",
      "batch 7872, train_loss 97.091324,Time used 0.010002s\n",
      "batch 7873, train_loss 91.976303,Time used 0.007992s\n",
      "batch 7874, train_loss 84.881493,Time used 0.009001s\n",
      "batch 7875, train_loss 71.450752,Time used 0.007001s\n",
      "batch 7876, train_loss 108.520195,Time used 0.007000s\n",
      "batch 7877, train_loss 103.296906,Time used 0.008000s\n",
      "batch 7878, train_loss 104.477036,Time used 0.007999s\n",
      "batch 7879, train_loss 88.641937,Time used 0.007001s\n",
      "batch 7880, train_loss 81.287498,Time used 0.010002s\n",
      "batch 7881, train_loss 82.640541,Time used 0.007999s\n",
      "batch 7882, train_loss 77.755943,Time used 0.011999s\n",
      "batch 7883, train_loss 101.146072,Time used 0.014001s\n",
      "batch 7884, train_loss 80.255852,Time used 0.007999s\n",
      "batch 7885, train_loss 90.114395,Time used 0.007999s\n",
      "batch 7886, train_loss 75.215729,Time used 0.006999s\n",
      "batch 7887, train_loss 86.158325,Time used 0.006996s\n",
      "batch 7888, train_loss 84.636238,Time used 0.008001s\n",
      "batch 7889, train_loss 94.724304,Time used 0.007001s\n",
      "batch 7890, train_loss 85.619385,Time used 0.007998s\n",
      "batch 7891, train_loss 105.091316,Time used 0.007000s\n",
      "batch 7892, train_loss 102.568336,Time used 0.006999s\n",
      "batch 7893, train_loss 93.141304,Time used 0.007001s\n",
      "batch 7894, train_loss 76.562447,Time used 0.007000s\n",
      "batch 7895, train_loss 105.992340,Time used 0.007001s\n",
      "batch 7896, train_loss 93.393936,Time used 0.006999s\n",
      "batch 7897, train_loss 115.306641,Time used 0.010003s\n",
      "batch 7898, train_loss 93.941414,Time used 0.007033s\n",
      "batch 7899, train_loss 84.093567,Time used 0.007965s\n",
      "batch 7900, train_loss 106.133995,Time used 0.006998s\n",
      "***************************test_batch 7900, test_rmse_loss 10.943424,test_mae_loss 4.281927,test_mape_loss 64.267230,Time used 0.035002s\n",
      "batch 7901, train_loss 93.702591,Time used 0.009998s\n",
      "batch 7902, train_loss 103.586578,Time used 0.009009s\n",
      "batch 7903, train_loss 102.609825,Time used 0.009993s\n",
      "batch 7904, train_loss 96.853401,Time used 0.007999s\n",
      "batch 7905, train_loss 78.697838,Time used 0.007000s\n",
      "batch 7906, train_loss 100.991997,Time used 0.010000s\n",
      "batch 7907, train_loss 63.951077,Time used 0.009002s\n",
      "batch 7908, train_loss 65.515396,Time used 0.006999s\n",
      "batch 7909, train_loss 106.467590,Time used 0.007001s\n",
      "batch 7910, train_loss 88.769539,Time used 0.007000s\n",
      "batch 7911, train_loss 93.222137,Time used 0.006999s\n",
      "batch 7912, train_loss 76.161552,Time used 0.010002s\n",
      "batch 7913, train_loss 87.200500,Time used 0.008002s\n",
      "batch 7914, train_loss 88.456047,Time used 0.007000s\n",
      "batch 7915, train_loss 91.388031,Time used 0.007001s\n",
      "batch 7916, train_loss 71.365227,Time used 0.008999s\n",
      "batch 7917, train_loss 98.597176,Time used 0.008001s\n",
      "batch 7918, train_loss 86.377449,Time used 0.007000s\n",
      "batch 7919, train_loss 79.923584,Time used 0.007000s\n",
      "batch 7920, train_loss 90.094200,Time used 0.008000s\n",
      "batch 7921, train_loss 90.405197,Time used 0.008001s\n",
      "batch 7922, train_loss 85.191772,Time used 0.006999s\n",
      "batch 7923, train_loss 111.432083,Time used 0.007999s\n",
      "batch 7924, train_loss 96.629990,Time used 0.009000s\n",
      "batch 7925, train_loss 81.594978,Time used 0.006963s\n",
      "batch 7926, train_loss 83.804504,Time used 0.007998s\n",
      "batch 7927, train_loss 114.229568,Time used 0.011004s\n",
      "batch 7928, train_loss 87.316978,Time used 0.008034s\n",
      "batch 7929, train_loss 84.015297,Time used 0.006963s\n",
      "batch 7930, train_loss 88.899155,Time used 0.009001s\n",
      "batch 7931, train_loss 96.030151,Time used 0.010999s\n",
      "batch 7932, train_loss 87.835167,Time used 0.011001s\n",
      "batch 7933, train_loss 99.677437,Time used 0.011032s\n",
      "batch 7934, train_loss 70.084457,Time used 0.008967s\n",
      "batch 7935, train_loss 87.544502,Time used 0.009002s\n",
      "batch 7936, train_loss 73.699654,Time used 0.008034s\n",
      "batch 7937, train_loss 90.320366,Time used 0.010963s\n",
      "batch 7938, train_loss 76.906540,Time used 0.009040s\n",
      "batch 7939, train_loss 83.072121,Time used 0.006998s\n",
      "batch 7940, train_loss 112.165039,Time used 0.009002s\n",
      "batch 7941, train_loss 76.543335,Time used 0.008999s\n",
      "batch 7942, train_loss 78.647537,Time used 0.007998s\n",
      "batch 7943, train_loss 92.717575,Time used 0.007001s\n",
      "batch 7944, train_loss 109.422646,Time used 0.008000s\n",
      "batch 7945, train_loss 90.383080,Time used 0.009001s\n",
      "batch 7946, train_loss 86.239342,Time used 0.008000s\n",
      "batch 7947, train_loss 99.815575,Time used 0.010006s\n",
      "batch 7948, train_loss 100.426369,Time used 0.007999s\n",
      "batch 7949, train_loss 109.058662,Time used 0.008999s\n",
      "batch 7950, train_loss 88.895370,Time used 0.007044s\n",
      "batch 7951, train_loss 110.928673,Time used 0.011993s\n",
      "batch 7952, train_loss 87.974449,Time used 0.008970s\n",
      "batch 7953, train_loss 92.591721,Time used 0.007993s\n",
      "batch 7954, train_loss 64.165962,Time used 0.007999s\n",
      "batch 7955, train_loss 82.600204,Time used 0.007000s\n",
      "batch 7956, train_loss 87.049225,Time used 0.007004s\n",
      "batch 7957, train_loss 85.203781,Time used 0.007037s\n",
      "batch 7958, train_loss 99.065521,Time used 0.007963s\n",
      "batch 7959, train_loss 105.019478,Time used 0.010000s\n",
      "batch 7960, train_loss 81.535004,Time used 0.008002s\n",
      "batch 7961, train_loss 123.903618,Time used 0.010996s\n",
      "batch 7962, train_loss 87.133026,Time used 0.007001s\n",
      "batch 7963, train_loss 94.873650,Time used 0.009003s\n",
      "batch 7964, train_loss 72.432510,Time used 0.009997s\n",
      "batch 7965, train_loss 71.772247,Time used 0.007002s\n",
      "batch 7966, train_loss 71.377495,Time used 0.010000s\n",
      "batch 7967, train_loss 80.118538,Time used 0.011000s\n",
      "batch 7968, train_loss 78.387619,Time used 0.009001s\n",
      "batch 7969, train_loss 102.026840,Time used 0.009000s\n",
      "batch 7970, train_loss 104.897202,Time used 0.011002s\n",
      "batch 7971, train_loss 103.316154,Time used 0.007997s\n",
      "batch 7972, train_loss 81.166794,Time used 0.007001s\n",
      "batch 7973, train_loss 80.150894,Time used 0.007999s\n",
      "batch 7974, train_loss 78.321655,Time used 0.007001s\n",
      "batch 7975, train_loss 70.929062,Time used 0.007999s\n",
      "batch 7976, train_loss 82.932236,Time used 0.007001s\n",
      "batch 7977, train_loss 78.800323,Time used 0.007000s\n",
      "batch 7978, train_loss 92.785004,Time used 0.006997s\n",
      "batch 7979, train_loss 76.514717,Time used 0.010004s\n",
      "batch 7980, train_loss 84.355736,Time used 0.020000s\n",
      "batch 7981, train_loss 85.990494,Time used 0.017999s\n",
      "batch 7982, train_loss 113.346764,Time used 0.012002s\n",
      "batch 7983, train_loss 112.614693,Time used 0.011000s\n",
      "batch 7984, train_loss 90.364082,Time used 0.010997s\n",
      "batch 7985, train_loss 69.182571,Time used 0.012000s\n",
      "batch 7986, train_loss 110.838783,Time used 0.012000s\n",
      "batch 7987, train_loss 73.464745,Time used 0.012004s\n",
      "batch 7988, train_loss 91.187363,Time used 0.013998s\n",
      "batch 7989, train_loss 95.511780,Time used 0.009001s\n",
      "batch 7990, train_loss 77.799911,Time used 0.008000s\n",
      "batch 7991, train_loss 96.242950,Time used 0.009000s\n",
      "batch 7992, train_loss 92.681160,Time used 0.008997s\n",
      "batch 7993, train_loss 85.065392,Time used 0.006999s\n",
      "batch 7994, train_loss 97.386215,Time used 0.009001s\n",
      "batch 7995, train_loss 85.213020,Time used 0.007001s\n",
      "batch 7996, train_loss 85.299583,Time used 0.006999s\n",
      "batch 7997, train_loss 95.202881,Time used 0.008999s\n",
      "batch 7998, train_loss 73.077881,Time used 0.009998s\n",
      "batch 7999, train_loss 80.348526,Time used 0.008001s\n",
      "batch 8000, train_loss 89.036865,Time used 0.009005s\n",
      "***************************test_batch 8000, test_rmse_loss 10.879671,test_mae_loss 4.262854,test_mape_loss 64.354898,Time used 0.036996s\n",
      "batch 8001, train_loss 84.787292,Time used 0.014001s\n",
      "batch 8002, train_loss 102.624794,Time used 0.010999s\n",
      "batch 8003, train_loss 94.503365,Time used 0.012001s\n",
      "batch 8004, train_loss 95.107613,Time used 0.014002s\n",
      "batch 8005, train_loss 71.123795,Time used 0.013002s\n",
      "batch 8006, train_loss 82.081947,Time used 0.016001s\n",
      "batch 8007, train_loss 85.665031,Time used 0.012997s\n",
      "batch 8008, train_loss 84.366615,Time used 0.013000s\n",
      "batch 8009, train_loss 100.997093,Time used 0.013000s\n",
      "batch 8010, train_loss 82.854706,Time used 0.014002s\n",
      "batch 8011, train_loss 89.887573,Time used 0.011997s\n",
      "batch 8012, train_loss 101.560783,Time used 0.008000s\n",
      "batch 8013, train_loss 90.658699,Time used 0.010998s\n",
      "batch 8014, train_loss 93.290558,Time used 0.009003s\n",
      "batch 8015, train_loss 82.168686,Time used 0.008000s\n",
      "batch 8016, train_loss 107.820633,Time used 0.008008s\n",
      "batch 8017, train_loss 108.207657,Time used 0.012009s\n",
      "batch 8018, train_loss 97.656212,Time used 0.009990s\n",
      "batch 8019, train_loss 94.331734,Time used 0.010000s\n",
      "batch 8020, train_loss 83.424324,Time used 0.007999s\n",
      "batch 8021, train_loss 95.864105,Time used 0.008000s\n",
      "batch 8022, train_loss 78.593376,Time used 0.013002s\n",
      "batch 8023, train_loss 99.351067,Time used 0.007997s\n",
      "batch 8024, train_loss 88.960243,Time used 0.009004s\n",
      "batch 8025, train_loss 88.281044,Time used 0.007997s\n",
      "batch 8026, train_loss 115.493286,Time used 0.010000s\n",
      "batch 8027, train_loss 80.160545,Time used 0.009001s\n",
      "batch 8028, train_loss 90.479782,Time used 0.011997s\n",
      "batch 8029, train_loss 104.922348,Time used 0.009002s\n",
      "batch 8030, train_loss 91.509277,Time used 0.008000s\n",
      "batch 8031, train_loss 91.431305,Time used 0.010000s\n",
      "batch 8032, train_loss 85.473305,Time used 0.006997s\n",
      "batch 8033, train_loss 87.119705,Time used 0.010003s\n",
      "batch 8034, train_loss 85.500725,Time used 0.010000s\n",
      "batch 8035, train_loss 68.559914,Time used 0.009000s\n",
      "batch 8036, train_loss 86.563080,Time used 0.010001s\n",
      "batch 8037, train_loss 72.794426,Time used 0.008000s\n",
      "batch 8038, train_loss 78.368797,Time used 0.009999s\n",
      "batch 8039, train_loss 88.630905,Time used 0.008002s\n",
      "batch 8040, train_loss 71.161896,Time used 0.008001s\n",
      "batch 8041, train_loss 108.458733,Time used 0.011001s\n",
      "batch 8042, train_loss 87.813866,Time used 0.008000s\n",
      "batch 8043, train_loss 85.818382,Time used 0.008000s\n",
      "batch 8044, train_loss 105.952293,Time used 0.008000s\n",
      "batch 8045, train_loss 87.089607,Time used 0.008000s\n",
      "batch 8046, train_loss 97.119637,Time used 0.007000s\n",
      "batch 8047, train_loss 89.905655,Time used 0.009036s\n",
      "batch 8048, train_loss 83.583130,Time used 0.009965s\n",
      "batch 8049, train_loss 82.980202,Time used 0.007003s\n",
      "batch 8050, train_loss 75.628395,Time used 0.008000s\n",
      "batch 8051, train_loss 82.954262,Time used 0.010998s\n",
      "batch 8052, train_loss 76.424026,Time used 0.010997s\n",
      "batch 8053, train_loss 75.403198,Time used 0.010000s\n",
      "batch 8054, train_loss 79.418526,Time used 0.010999s\n",
      "batch 8055, train_loss 91.883934,Time used 0.008005s\n",
      "batch 8056, train_loss 111.834984,Time used 0.008998s\n",
      "batch 8057, train_loss 73.678635,Time used 0.007001s\n",
      "batch 8058, train_loss 74.433525,Time used 0.008034s\n",
      "batch 8059, train_loss 95.425339,Time used 0.007972s\n",
      "batch 8060, train_loss 96.424370,Time used 0.009993s\n",
      "batch 8061, train_loss 81.189148,Time used 0.009002s\n",
      "batch 8062, train_loss 111.354607,Time used 0.009000s\n",
      "batch 8063, train_loss 66.954323,Time used 0.009002s\n",
      "batch 8064, train_loss 106.451317,Time used 0.007001s\n",
      "batch 8065, train_loss 96.503578,Time used 0.006996s\n",
      "batch 8066, train_loss 76.831795,Time used 0.010002s\n",
      "batch 8067, train_loss 81.531563,Time used 0.008998s\n",
      "batch 8068, train_loss 56.662834,Time used 0.009001s\n",
      "batch 8069, train_loss 84.292175,Time used 0.007001s\n",
      "batch 8070, train_loss 78.790802,Time used 0.007000s\n",
      "batch 8071, train_loss 109.158669,Time used 0.012007s\n",
      "batch 8072, train_loss 75.275177,Time used 0.008001s\n",
      "batch 8073, train_loss 92.207794,Time used 0.010000s\n",
      "batch 8074, train_loss 98.421066,Time used 0.008999s\n",
      "batch 8075, train_loss 107.680183,Time used 0.011000s\n",
      "batch 8076, train_loss 82.216995,Time used 0.010001s\n",
      "batch 8077, train_loss 116.119072,Time used 0.009999s\n",
      "batch 8078, train_loss 70.215958,Time used 0.009004s\n",
      "batch 8079, train_loss 81.898750,Time used 0.006999s\n",
      "batch 8080, train_loss 101.326111,Time used 0.008001s\n",
      "batch 8081, train_loss 108.940811,Time used 0.007998s\n",
      "batch 8082, train_loss 76.279503,Time used 0.008004s\n",
      "batch 8083, train_loss 70.622887,Time used 0.008997s\n",
      "batch 8084, train_loss 97.647369,Time used 0.014001s\n",
      "batch 8085, train_loss 110.911224,Time used 0.008000s\n",
      "batch 8086, train_loss 87.976288,Time used 0.008000s\n",
      "batch 8087, train_loss 71.163338,Time used 0.008000s\n",
      "batch 8088, train_loss 89.000534,Time used 0.008000s\n",
      "batch 8089, train_loss 94.909363,Time used 0.010000s\n",
      "batch 8090, train_loss 83.882317,Time used 0.008001s\n",
      "batch 8091, train_loss 96.014015,Time used 0.008002s\n",
      "batch 8092, train_loss 69.232780,Time used 0.011999s\n",
      "batch 8093, train_loss 91.248024,Time used 0.012000s\n",
      "batch 8094, train_loss 85.080704,Time used 0.010002s\n",
      "batch 8095, train_loss 96.393227,Time used 0.007998s\n",
      "batch 8096, train_loss 98.059586,Time used 0.010002s\n",
      "batch 8097, train_loss 102.085030,Time used 0.010003s\n",
      "batch 8098, train_loss 90.921738,Time used 0.007997s\n",
      "batch 8099, train_loss 76.490189,Time used 0.009000s\n",
      "batch 8100, train_loss 78.562782,Time used 0.009000s\n",
      "***************************test_batch 8100, test_rmse_loss 10.818818,test_mae_loss 4.239331,test_mape_loss 63.851197,Time used 0.033999s\n",
      "batch 8101, train_loss 93.719574,Time used 0.012001s\n",
      "batch 8102, train_loss 81.703690,Time used 0.008000s\n",
      "batch 8103, train_loss 68.721313,Time used 0.007000s\n",
      "batch 8104, train_loss 90.036201,Time used 0.008001s\n",
      "batch 8105, train_loss 113.589470,Time used 0.010998s\n",
      "batch 8106, train_loss 81.906662,Time used 0.009001s\n",
      "batch 8107, train_loss 74.318268,Time used 0.006999s\n",
      "batch 8108, train_loss 75.795105,Time used 0.008000s\n",
      "batch 8109, train_loss 97.561951,Time used 0.006999s\n",
      "batch 8110, train_loss 104.660698,Time used 0.010002s\n",
      "batch 8111, train_loss 66.092499,Time used 0.006999s\n",
      "batch 8112, train_loss 105.589890,Time used 0.010000s\n",
      "batch 8113, train_loss 106.270271,Time used 0.008001s\n",
      "batch 8114, train_loss 74.885841,Time used 0.008999s\n",
      "batch 8115, train_loss 95.925224,Time used 0.007999s\n",
      "batch 8116, train_loss 98.850754,Time used 0.009001s\n",
      "batch 8117, train_loss 82.821350,Time used 0.011001s\n",
      "batch 8118, train_loss 85.135277,Time used 0.008003s\n",
      "batch 8119, train_loss 80.092377,Time used 0.006996s\n",
      "batch 8120, train_loss 90.685265,Time used 0.008039s\n",
      "batch 8121, train_loss 110.176109,Time used 0.007998s\n",
      "batch 8122, train_loss 84.568222,Time used 0.007000s\n",
      "batch 8123, train_loss 82.168503,Time used 0.007969s\n",
      "batch 8124, train_loss 73.892326,Time used 0.007000s\n",
      "batch 8125, train_loss 92.807144,Time used 0.010998s\n",
      "batch 8126, train_loss 88.648964,Time used 0.008002s\n",
      "batch 8127, train_loss 97.585609,Time used 0.010997s\n",
      "batch 8128, train_loss 86.062073,Time used 0.011002s\n",
      "batch 8129, train_loss 86.954796,Time used 0.008000s\n",
      "batch 8130, train_loss 95.978333,Time used 0.008035s\n",
      "batch 8131, train_loss 87.310295,Time used 0.006998s\n",
      "batch 8132, train_loss 110.208069,Time used 0.008967s\n",
      "batch 8133, train_loss 83.856926,Time used 0.008998s\n",
      "batch 8134, train_loss 77.858871,Time used 0.010000s\n",
      "batch 8135, train_loss 53.728848,Time used 0.007002s\n",
      "batch 8136, train_loss 83.506889,Time used 0.009997s\n",
      "batch 8137, train_loss 110.706451,Time used 0.012032s\n",
      "batch 8138, train_loss 80.892731,Time used 0.007967s\n",
      "batch 8139, train_loss 102.211479,Time used 0.011000s\n",
      "batch 8140, train_loss 89.900620,Time used 0.009002s\n",
      "batch 8141, train_loss 78.237152,Time used 0.010998s\n",
      "batch 8142, train_loss 65.667290,Time used 0.010000s\n",
      "batch 8143, train_loss 79.947701,Time used 0.009999s\n",
      "batch 8144, train_loss 96.271172,Time used 0.008001s\n",
      "batch 8145, train_loss 104.873199,Time used 0.011998s\n",
      "batch 8146, train_loss 88.583000,Time used 0.010999s\n",
      "batch 8147, train_loss 82.906242,Time used 0.008000s\n",
      "batch 8148, train_loss 91.930672,Time used 0.007002s\n",
      "batch 8149, train_loss 113.343880,Time used 0.011001s\n",
      "batch 8150, train_loss 75.856430,Time used 0.006998s\n",
      "batch 8151, train_loss 93.401634,Time used 0.007001s\n",
      "batch 8152, train_loss 75.334198,Time used 0.007000s\n",
      "batch 8153, train_loss 78.619156,Time used 0.008002s\n",
      "batch 8154, train_loss 107.503334,Time used 0.007001s\n",
      "batch 8155, train_loss 77.130829,Time used 0.006999s\n",
      "batch 8156, train_loss 95.390778,Time used 0.010000s\n",
      "batch 8157, train_loss 66.300743,Time used 0.009999s\n",
      "batch 8158, train_loss 93.543465,Time used 0.008002s\n",
      "batch 8159, train_loss 78.780724,Time used 0.013000s\n",
      "batch 8160, train_loss 76.771828,Time used 0.010035s\n",
      "batch 8161, train_loss 96.087563,Time used 0.010966s\n",
      "batch 8162, train_loss 76.472565,Time used 0.008035s\n",
      "batch 8163, train_loss 86.521828,Time used 0.007001s\n",
      "batch 8164, train_loss 114.554070,Time used 0.008964s\n",
      "batch 8165, train_loss 104.469063,Time used 0.011003s\n",
      "batch 8166, train_loss 109.235329,Time used 0.012032s\n",
      "batch 8167, train_loss 78.476036,Time used 0.008964s\n",
      "batch 8168, train_loss 80.734138,Time used 0.009001s\n",
      "batch 8169, train_loss 110.826874,Time used 0.009001s\n",
      "batch 8170, train_loss 102.395340,Time used 0.009000s\n",
      "batch 8171, train_loss 76.495338,Time used 0.009000s\n",
      "batch 8172, train_loss 77.263458,Time used 0.007998s\n",
      "batch 8173, train_loss 75.570831,Time used 0.011038s\n",
      "batch 8174, train_loss 85.686508,Time used 0.008963s\n",
      "batch 8175, train_loss 74.328896,Time used 0.011999s\n",
      "batch 8176, train_loss 69.637222,Time used 0.011000s\n",
      "batch 8177, train_loss 84.561081,Time used 0.012033s\n",
      "batch 8178, train_loss 111.500443,Time used 0.009001s\n",
      "batch 8179, train_loss 75.559975,Time used 0.008001s\n",
      "batch 8180, train_loss 88.667862,Time used 0.008961s\n",
      "batch 8181, train_loss 86.829079,Time used 0.007001s\n",
      "batch 8182, train_loss 77.708542,Time used 0.007999s\n",
      "batch 8183, train_loss 81.849747,Time used 0.007002s\n",
      "batch 8184, train_loss 72.621117,Time used 0.010001s\n",
      "batch 8185, train_loss 65.469276,Time used 0.008965s\n",
      "batch 8186, train_loss 97.703270,Time used 0.009003s\n",
      "batch 8187, train_loss 82.691437,Time used 0.008999s\n",
      "batch 8188, train_loss 74.081520,Time used 0.009002s\n",
      "batch 8189, train_loss 105.536385,Time used 0.007996s\n",
      "batch 8190, train_loss 95.934082,Time used 0.009004s\n",
      "batch 8191, train_loss 114.373344,Time used 0.009997s\n",
      "batch 8192, train_loss 82.797363,Time used 0.008001s\n",
      "batch 8193, train_loss 65.781586,Time used 0.010002s\n",
      "batch 8194, train_loss 101.974983,Time used 0.014000s\n",
      "batch 8195, train_loss 83.276016,Time used 0.012001s\n",
      "batch 8196, train_loss 76.637505,Time used 0.012000s\n",
      "batch 8197, train_loss 75.807831,Time used 0.011001s\n",
      "batch 8198, train_loss 83.093689,Time used 0.009000s\n",
      "batch 8199, train_loss 89.309288,Time used 0.012001s\n",
      "batch 8200, train_loss 85.805305,Time used 0.012003s\n",
      "***************************test_batch 8200, test_rmse_loss 10.756640,test_mae_loss 4.221685,test_mape_loss 63.910397,Time used 0.063999s\n",
      "batch 8201, train_loss 92.936386,Time used 0.014520s\n",
      "batch 8202, train_loss 103.680840,Time used 0.012516s\n",
      "batch 8203, train_loss 88.921669,Time used 0.012642s\n",
      "batch 8204, train_loss 85.761368,Time used 0.008998s\n",
      "batch 8205, train_loss 83.964645,Time used 0.012001s\n",
      "batch 8206, train_loss 64.243813,Time used 0.013000s\n",
      "batch 8207, train_loss 72.024963,Time used 0.013003s\n",
      "batch 8208, train_loss 122.536766,Time used 0.011996s\n",
      "batch 8209, train_loss 73.888626,Time used 0.012010s\n",
      "batch 8210, train_loss 76.172180,Time used 0.008990s\n",
      "batch 8211, train_loss 116.305168,Time used 0.011999s\n",
      "batch 8212, train_loss 75.624481,Time used 0.009006s\n",
      "batch 8213, train_loss 127.980812,Time used 0.008994s\n",
      "batch 8214, train_loss 70.342262,Time used 0.011003s\n",
      "batch 8215, train_loss 77.568756,Time used 0.012003s\n",
      "batch 8216, train_loss 61.867630,Time used 0.011999s\n",
      "batch 8217, train_loss 81.123177,Time used 0.011999s\n",
      "batch 8218, train_loss 96.490685,Time used 0.009001s\n",
      "batch 8219, train_loss 68.431686,Time used 0.009001s\n",
      "batch 8220, train_loss 81.653465,Time used 0.011002s\n",
      "batch 8221, train_loss 101.767143,Time used 0.009000s\n",
      "batch 8222, train_loss 84.091927,Time used 0.008000s\n",
      "batch 8223, train_loss 96.659492,Time used 0.007999s\n",
      "batch 8224, train_loss 85.012054,Time used 0.009998s\n",
      "batch 8225, train_loss 81.080841,Time used 0.009003s\n",
      "batch 8226, train_loss 90.225243,Time used 0.010997s\n",
      "batch 8227, train_loss 83.273804,Time used 0.009002s\n",
      "batch 8228, train_loss 105.666733,Time used 0.007998s\n",
      "batch 8229, train_loss 77.376137,Time used 0.008002s\n",
      "batch 8230, train_loss 76.828468,Time used 0.006999s\n",
      "batch 8231, train_loss 101.378403,Time used 0.007002s\n",
      "batch 8232, train_loss 96.792709,Time used 0.007002s\n",
      "batch 8233, train_loss 75.764549,Time used 0.007000s\n",
      "batch 8234, train_loss 83.850212,Time used 0.008002s\n",
      "batch 8235, train_loss 94.095604,Time used 0.007998s\n",
      "batch 8236, train_loss 66.686859,Time used 0.006999s\n",
      "batch 8237, train_loss 96.979462,Time used 0.006990s\n",
      "batch 8238, train_loss 67.654129,Time used 0.008000s\n",
      "batch 8239, train_loss 102.036415,Time used 0.008000s\n",
      "batch 8240, train_loss 111.660843,Time used 0.008001s\n",
      "batch 8241, train_loss 64.650360,Time used 0.012001s\n",
      "batch 8242, train_loss 97.106186,Time used 0.011999s\n",
      "batch 8243, train_loss 89.834618,Time used 0.015001s\n",
      "batch 8244, train_loss 114.099380,Time used 0.010000s\n",
      "batch 8245, train_loss 72.720459,Time used 0.009995s\n",
      "batch 8246, train_loss 90.238495,Time used 0.012002s\n",
      "batch 8247, train_loss 96.168091,Time used 0.010999s\n",
      "batch 8248, train_loss 73.927589,Time used 0.008000s\n",
      "batch 8249, train_loss 87.713158,Time used 0.012000s\n",
      "batch 8250, train_loss 84.953186,Time used 0.009999s\n",
      "batch 8251, train_loss 90.388016,Time used 0.013001s\n",
      "batch 8252, train_loss 72.058876,Time used 0.011999s\n",
      "batch 8253, train_loss 68.377632,Time used 0.008002s\n",
      "batch 8254, train_loss 114.802460,Time used 0.012000s\n",
      "batch 8255, train_loss 92.201744,Time used 0.011000s\n",
      "batch 8256, train_loss 73.346146,Time used 0.009001s\n",
      "batch 8257, train_loss 77.603935,Time used 0.008003s\n",
      "batch 8258, train_loss 116.562775,Time used 0.010999s\n",
      "batch 8259, train_loss 105.510422,Time used 0.010000s\n",
      "batch 8260, train_loss 87.668510,Time used 0.009002s\n",
      "batch 8261, train_loss 105.293091,Time used 0.012001s\n",
      "batch 8262, train_loss 69.571152,Time used 0.010004s\n",
      "batch 8263, train_loss 89.359680,Time used 0.010995s\n",
      "batch 8264, train_loss 67.869476,Time used 0.009003s\n",
      "batch 8265, train_loss 85.642456,Time used 0.006999s\n",
      "batch 8266, train_loss 60.592556,Time used 0.010997s\n",
      "batch 8267, train_loss 96.580086,Time used 0.008001s\n",
      "batch 8268, train_loss 96.976814,Time used 0.008000s\n",
      "batch 8269, train_loss 91.612778,Time used 0.008999s\n",
      "batch 8270, train_loss 81.479942,Time used 0.011002s\n",
      "batch 8271, train_loss 106.983978,Time used 0.011997s\n",
      "batch 8272, train_loss 95.513893,Time used 0.011000s\n",
      "batch 8273, train_loss 59.958576,Time used 0.008000s\n",
      "batch 8274, train_loss 89.683563,Time used 0.010001s\n",
      "batch 8275, train_loss 81.968346,Time used 0.011999s\n",
      "batch 8276, train_loss 95.904922,Time used 0.010999s\n",
      "batch 8277, train_loss 93.168922,Time used 0.008001s\n",
      "batch 8278, train_loss 54.183361,Time used 0.011002s\n",
      "batch 8279, train_loss 76.012680,Time used 0.008000s\n",
      "batch 8280, train_loss 90.402702,Time used 0.008000s\n",
      "batch 8281, train_loss 100.489456,Time used 0.009002s\n",
      "batch 8282, train_loss 76.422821,Time used 0.010999s\n",
      "batch 8283, train_loss 61.189655,Time used 0.010002s\n",
      "batch 8284, train_loss 94.896446,Time used 0.007998s\n",
      "batch 8285, train_loss 92.249565,Time used 0.008000s\n",
      "batch 8286, train_loss 76.216057,Time used 0.008003s\n",
      "batch 8287, train_loss 92.001976,Time used 0.008997s\n",
      "batch 8288, train_loss 78.175125,Time used 0.006999s\n",
      "batch 8289, train_loss 69.204842,Time used 0.010000s\n",
      "batch 8290, train_loss 77.437950,Time used 0.008000s\n",
      "batch 8291, train_loss 110.786659,Time used 0.009001s\n",
      "batch 8292, train_loss 75.063965,Time used 0.007998s\n",
      "batch 8293, train_loss 80.745300,Time used 0.008002s\n",
      "batch 8294, train_loss 101.482079,Time used 0.006999s\n",
      "batch 8295, train_loss 72.830177,Time used 0.010004s\n",
      "batch 8296, train_loss 98.472664,Time used 0.007998s\n",
      "batch 8297, train_loss 107.963097,Time used 0.008996s\n",
      "batch 8298, train_loss 80.235062,Time used 0.006999s\n",
      "batch 8299, train_loss 90.747620,Time used 0.011001s\n",
      "batch 8300, train_loss 90.803436,Time used 0.012001s\n",
      "***************************test_batch 8300, test_rmse_loss 10.696871,test_mae_loss 4.200734,test_mape_loss 63.725861,Time used 0.044000s\n",
      "batch 8301, train_loss 97.024704,Time used 0.009000s\n",
      "batch 8302, train_loss 87.099998,Time used 0.008000s\n",
      "batch 8303, train_loss 83.559807,Time used 0.007999s\n",
      "batch 8304, train_loss 74.880363,Time used 0.008998s\n",
      "batch 8305, train_loss 86.415421,Time used 0.009998s\n",
      "batch 8306, train_loss 64.417915,Time used 0.007999s\n",
      "batch 8307, train_loss 85.969269,Time used 0.009000s\n",
      "batch 8308, train_loss 77.245369,Time used 0.010001s\n",
      "batch 8309, train_loss 99.635567,Time used 0.007000s\n",
      "batch 8310, train_loss 70.527321,Time used 0.009001s\n",
      "batch 8311, train_loss 113.107834,Time used 0.011000s\n",
      "batch 8312, train_loss 92.475182,Time used 0.007000s\n",
      "batch 8313, train_loss 108.297523,Time used 0.009003s\n",
      "batch 8314, train_loss 85.879333,Time used 0.010997s\n",
      "batch 8315, train_loss 72.316673,Time used 0.010002s\n",
      "batch 8316, train_loss 84.774719,Time used 0.006999s\n",
      "batch 8317, train_loss 73.769806,Time used 0.008001s\n",
      "batch 8318, train_loss 73.082184,Time used 0.011003s\n",
      "batch 8319, train_loss 90.677010,Time used 0.008999s\n",
      "batch 8320, train_loss 102.093529,Time used 0.011000s\n",
      "batch 8321, train_loss 78.537361,Time used 0.011000s\n",
      "batch 8322, train_loss 93.188660,Time used 0.008000s\n",
      "batch 8323, train_loss 101.107292,Time used 0.006997s\n",
      "batch 8324, train_loss 90.859848,Time used 0.008000s\n",
      "batch 8325, train_loss 94.742073,Time used 0.007001s\n",
      "batch 8326, train_loss 64.261253,Time used 0.008000s\n",
      "batch 8327, train_loss 75.525024,Time used 0.009999s\n",
      "batch 8328, train_loss 86.015320,Time used 0.011003s\n",
      "batch 8329, train_loss 75.799164,Time used 0.007997s\n",
      "batch 8330, train_loss 120.343369,Time used 0.011000s\n",
      "batch 8331, train_loss 109.055710,Time used 0.010039s\n",
      "batch 8332, train_loss 78.917824,Time used 0.007000s\n",
      "batch 8333, train_loss 85.014076,Time used 0.008997s\n",
      "batch 8334, train_loss 73.174438,Time used 0.007999s\n",
      "batch 8335, train_loss 90.130676,Time used 0.008000s\n",
      "batch 8336, train_loss 94.428467,Time used 0.007000s\n",
      "batch 8337, train_loss 64.089394,Time used 0.008007s\n",
      "batch 8338, train_loss 99.395180,Time used 0.009019s\n",
      "batch 8339, train_loss 74.869530,Time used 0.009999s\n",
      "batch 8340, train_loss 96.861000,Time used 0.007001s\n",
      "batch 8341, train_loss 97.951607,Time used 0.010999s\n",
      "batch 8342, train_loss 70.402596,Time used 0.010000s\n",
      "batch 8343, train_loss 83.574043,Time used 0.012001s\n",
      "batch 8344, train_loss 76.673073,Time used 0.011999s\n",
      "batch 8345, train_loss 82.699043,Time used 0.007001s\n",
      "batch 8346, train_loss 72.704842,Time used 0.007002s\n",
      "batch 8347, train_loss 67.478180,Time used 0.009997s\n",
      "batch 8348, train_loss 92.886963,Time used 0.007002s\n",
      "batch 8349, train_loss 100.171379,Time used 0.008001s\n",
      "batch 8350, train_loss 83.738983,Time used 0.007001s\n",
      "batch 8351, train_loss 92.146332,Time used 0.006999s\n",
      "batch 8352, train_loss 76.457779,Time used 0.008002s\n",
      "batch 8353, train_loss 105.789818,Time used 0.010002s\n",
      "batch 8354, train_loss 101.464973,Time used 0.007999s\n",
      "batch 8355, train_loss 77.010567,Time used 0.007004s\n",
      "batch 8356, train_loss 92.489265,Time used 0.008999s\n",
      "batch 8357, train_loss 90.170448,Time used 0.008999s\n",
      "batch 8358, train_loss 65.308685,Time used 0.006999s\n",
      "batch 8359, train_loss 68.585381,Time used 0.008002s\n",
      "batch 8360, train_loss 80.079803,Time used 0.007998s\n",
      "batch 8361, train_loss 103.538254,Time used 0.009001s\n",
      "batch 8362, train_loss 74.776627,Time used 0.011002s\n",
      "batch 8363, train_loss 92.177193,Time used 0.006996s\n",
      "batch 8364, train_loss 86.411797,Time used 0.008000s\n",
      "batch 8365, train_loss 80.995590,Time used 0.011001s\n",
      "batch 8366, train_loss 88.790787,Time used 0.012000s\n",
      "batch 8367, train_loss 103.058662,Time used 0.007002s\n",
      "batch 8368, train_loss 98.427780,Time used 0.010997s\n",
      "batch 8369, train_loss 77.055984,Time used 0.008000s\n",
      "batch 8370, train_loss 79.406403,Time used 0.010000s\n",
      "batch 8371, train_loss 79.070892,Time used 0.008000s\n",
      "batch 8372, train_loss 95.355499,Time used 0.007000s\n",
      "batch 8373, train_loss 88.648056,Time used 0.009002s\n",
      "batch 8374, train_loss 92.503563,Time used 0.012000s\n",
      "batch 8375, train_loss 60.606277,Time used 0.008000s\n",
      "batch 8376, train_loss 71.618782,Time used 0.008999s\n",
      "batch 8377, train_loss 96.330612,Time used 0.008003s\n",
      "batch 8378, train_loss 92.629082,Time used 0.007998s\n",
      "batch 8379, train_loss 81.060349,Time used 0.009000s\n",
      "batch 8380, train_loss 79.861839,Time used 0.010999s\n",
      "batch 8381, train_loss 77.411362,Time used 0.010999s\n",
      "batch 8382, train_loss 112.431602,Time used 0.009000s\n",
      "batch 8383, train_loss 80.081497,Time used 0.008003s\n",
      "batch 8384, train_loss 80.765923,Time used 0.009999s\n",
      "batch 8385, train_loss 70.921616,Time used 0.011999s\n",
      "batch 8386, train_loss 85.419334,Time used 0.012999s\n",
      "batch 8387, train_loss 90.066544,Time used 0.008999s\n",
      "batch 8388, train_loss 73.506004,Time used 0.008000s\n",
      "batch 8389, train_loss 83.449806,Time used 0.007002s\n",
      "batch 8390, train_loss 98.210037,Time used 0.008000s\n",
      "batch 8391, train_loss 81.587563,Time used 0.006999s\n",
      "batch 8392, train_loss 83.378174,Time used 0.008000s\n",
      "batch 8393, train_loss 97.428505,Time used 0.008000s\n",
      "batch 8394, train_loss 100.490944,Time used 0.006999s\n",
      "batch 8395, train_loss 96.993576,Time used 0.007001s\n",
      "batch 8396, train_loss 86.042656,Time used 0.006999s\n",
      "batch 8397, train_loss 81.464005,Time used 0.008000s\n",
      "batch 8398, train_loss 70.665131,Time used 0.007001s\n",
      "batch 8399, train_loss 69.183678,Time used 0.011002s\n",
      "batch 8400, train_loss 78.723839,Time used 0.008999s\n",
      "***************************test_batch 8400, test_rmse_loss 10.639258,test_mae_loss 4.179320,test_mape_loss 63.358971,Time used 0.033999s\n",
      "batch 8401, train_loss 109.843559,Time used 0.013000s\n",
      "batch 8402, train_loss 91.714188,Time used 0.010002s\n",
      "batch 8403, train_loss 80.560608,Time used 0.012998s\n",
      "batch 8404, train_loss 89.971375,Time used 0.098003s\n",
      "batch 8405, train_loss 116.739944,Time used 0.236997s\n",
      "batch 8406, train_loss 77.908394,Time used 0.169002s\n",
      "batch 8407, train_loss 89.756020,Time used 0.320000s\n",
      "batch 8408, train_loss 66.178589,Time used 0.040001s\n",
      "batch 8409, train_loss 69.099777,Time used 0.243003s\n",
      "batch 8410, train_loss 109.126640,Time used 0.043525s\n",
      "batch 8411, train_loss 55.074127,Time used 0.048999s\n",
      "batch 8412, train_loss 87.277206,Time used 0.021001s\n",
      "batch 8413, train_loss 77.892868,Time used 0.011992s\n",
      "batch 8414, train_loss 77.825119,Time used 0.014001s\n",
      "batch 8415, train_loss 112.122292,Time used 0.014006s\n",
      "batch 8416, train_loss 76.770699,Time used 0.043000s\n",
      "batch 8417, train_loss 103.501213,Time used 0.015004s\n",
      "batch 8418, train_loss 78.082344,Time used 0.011997s\n",
      "batch 8419, train_loss 73.043739,Time used 0.010998s\n",
      "batch 8420, train_loss 81.743004,Time used 0.010003s\n",
      "batch 8421, train_loss 84.254562,Time used 0.010998s\n",
      "batch 8422, train_loss 92.435989,Time used 0.011000s\n",
      "batch 8423, train_loss 70.195267,Time used 0.012999s\n",
      "batch 8424, train_loss 71.166725,Time used 0.010002s\n",
      "batch 8425, train_loss 78.871292,Time used 0.012002s\n",
      "batch 8426, train_loss 83.413498,Time used 0.012000s\n",
      "batch 8427, train_loss 78.505951,Time used 0.009999s\n",
      "batch 8428, train_loss 96.208115,Time used 0.008002s\n",
      "batch 8429, train_loss 68.017563,Time used 0.010999s\n",
      "batch 8430, train_loss 74.517502,Time used 0.010001s\n",
      "batch 8431, train_loss 71.185448,Time used 0.010998s\n",
      "batch 8432, train_loss 102.398575,Time used 0.011001s\n",
      "batch 8433, train_loss 97.286644,Time used 0.011999s\n",
      "batch 8434, train_loss 60.536499,Time used 0.008002s\n",
      "batch 8435, train_loss 95.261810,Time used 0.009999s\n",
      "batch 8436, train_loss 111.780235,Time used 0.011000s\n",
      "batch 8437, train_loss 91.161789,Time used 0.011002s\n",
      "batch 8438, train_loss 89.254776,Time used 0.011996s\n",
      "batch 8439, train_loss 67.021790,Time used 0.010005s\n",
      "batch 8440, train_loss 84.276726,Time used 0.008999s\n",
      "batch 8441, train_loss 86.841484,Time used 0.012000s\n",
      "batch 8442, train_loss 86.008873,Time used 0.011999s\n",
      "batch 8443, train_loss 88.698463,Time used 0.008000s\n",
      "batch 8444, train_loss 96.668991,Time used 0.011000s\n",
      "batch 8445, train_loss 47.043289,Time used 0.008012s\n",
      "batch 8446, train_loss 81.407867,Time used 0.008000s\n",
      "batch 8447, train_loss 99.254883,Time used 0.009997s\n",
      "batch 8448, train_loss 102.522964,Time used 0.008001s\n",
      "batch 8449, train_loss 87.588570,Time used 0.010998s\n",
      "batch 8450, train_loss 59.258808,Time used 0.009002s\n",
      "batch 8451, train_loss 87.604759,Time used 0.011000s\n",
      "batch 8452, train_loss 94.777313,Time used 0.008001s\n",
      "batch 8453, train_loss 66.484352,Time used 0.008007s\n",
      "batch 8454, train_loss 88.674973,Time used 0.007993s\n",
      "batch 8455, train_loss 80.091965,Time used 0.011001s\n",
      "batch 8456, train_loss 108.644165,Time used 0.009998s\n",
      "batch 8457, train_loss 84.204720,Time used 0.008999s\n",
      "batch 8458, train_loss 77.766403,Time used 0.010001s\n",
      "batch 8459, train_loss 80.751823,Time used 0.007999s\n",
      "batch 8460, train_loss 94.359703,Time used 0.011001s\n",
      "batch 8461, train_loss 102.423965,Time used 0.010999s\n",
      "batch 8462, train_loss 89.164093,Time used 0.012002s\n",
      "batch 8463, train_loss 92.541504,Time used 0.011997s\n",
      "batch 8464, train_loss 59.119862,Time used 0.010001s\n",
      "batch 8465, train_loss 78.586403,Time used 0.009000s\n",
      "batch 8466, train_loss 75.723427,Time used 0.007000s\n",
      "batch 8467, train_loss 103.459679,Time used 0.011001s\n",
      "batch 8468, train_loss 71.800949,Time used 0.008001s\n",
      "batch 8469, train_loss 101.642593,Time used 0.007998s\n",
      "batch 8470, train_loss 76.974380,Time used 0.008004s\n",
      "batch 8471, train_loss 79.462456,Time used 0.007998s\n",
      "batch 8472, train_loss 91.132187,Time used 0.008002s\n",
      "batch 8473, train_loss 94.908760,Time used 0.010998s\n",
      "batch 8474, train_loss 100.007317,Time used 0.010001s\n",
      "batch 8475, train_loss 90.716423,Time used 0.009999s\n",
      "batch 8476, train_loss 90.346649,Time used 0.007002s\n",
      "batch 8477, train_loss 84.969452,Time used 0.011002s\n",
      "batch 8478, train_loss 89.380920,Time used 0.008999s\n",
      "batch 8479, train_loss 94.066261,Time used 0.010001s\n",
      "batch 8480, train_loss 81.083702,Time used 0.009997s\n",
      "batch 8481, train_loss 75.439484,Time used 0.010001s\n",
      "batch 8482, train_loss 73.441780,Time used 0.008999s\n",
      "batch 8483, train_loss 66.090683,Time used 0.008002s\n",
      "batch 8484, train_loss 91.707886,Time used 0.011000s\n",
      "batch 8485, train_loss 72.580223,Time used 0.008002s\n",
      "batch 8486, train_loss 70.314980,Time used 0.010999s\n",
      "batch 8487, train_loss 69.846924,Time used 0.007997s\n",
      "batch 8488, train_loss 70.856369,Time used 0.008001s\n",
      "batch 8489, train_loss 96.509995,Time used 0.008000s\n",
      "batch 8490, train_loss 98.051796,Time used 0.006999s\n",
      "batch 8491, train_loss 80.718689,Time used 0.008001s\n",
      "batch 8492, train_loss 81.962326,Time used 0.008000s\n",
      "batch 8493, train_loss 103.035500,Time used 0.009999s\n",
      "batch 8494, train_loss 78.102509,Time used 0.009999s\n",
      "batch 8495, train_loss 69.294930,Time used 0.011001s\n",
      "batch 8496, train_loss 104.000023,Time used 0.009000s\n",
      "batch 8497, train_loss 87.427094,Time used 0.008002s\n",
      "batch 8498, train_loss 79.068825,Time used 0.008000s\n",
      "batch 8499, train_loss 86.957596,Time used 0.007000s\n",
      "batch 8500, train_loss 65.319664,Time used 0.007999s\n",
      "***************************test_batch 8500, test_rmse_loss 10.581502,test_mae_loss 4.159072,test_mape_loss 63.184685,Time used 0.034001s\n",
      "batch 8501, train_loss 86.645256,Time used 0.007999s\n",
      "batch 8502, train_loss 80.410416,Time used 0.008001s\n",
      "batch 8503, train_loss 89.701302,Time used 0.006999s\n",
      "batch 8504, train_loss 61.405895,Time used 0.008999s\n",
      "batch 8505, train_loss 77.269882,Time used 0.010000s\n",
      "batch 8506, train_loss 102.560326,Time used 0.008004s\n",
      "batch 8507, train_loss 62.825195,Time used 0.007998s\n",
      "batch 8508, train_loss 83.671478,Time used 0.008002s\n",
      "batch 8509, train_loss 77.656090,Time used 0.007998s\n",
      "batch 8510, train_loss 86.543030,Time used 0.008000s\n",
      "batch 8511, train_loss 114.851204,Time used 0.010000s\n",
      "batch 8512, train_loss 82.867004,Time used 0.009001s\n",
      "batch 8513, train_loss 91.982704,Time used 0.010001s\n",
      "batch 8514, train_loss 69.787971,Time used 0.008001s\n",
      "batch 8515, train_loss 97.799561,Time used 0.010997s\n",
      "batch 8516, train_loss 73.874886,Time used 0.011001s\n",
      "batch 8517, train_loss 81.118599,Time used 0.006999s\n",
      "batch 8518, train_loss 97.278496,Time used 0.010036s\n",
      "batch 8519, train_loss 107.240753,Time used 0.007966s\n",
      "batch 8520, train_loss 76.792000,Time used 0.006998s\n",
      "batch 8521, train_loss 61.806583,Time used 0.007001s\n",
      "batch 8522, train_loss 67.816605,Time used 0.006998s\n",
      "batch 8523, train_loss 72.255653,Time used 0.007000s\n",
      "batch 8524, train_loss 86.728470,Time used 0.010000s\n",
      "batch 8525, train_loss 90.056427,Time used 0.007999s\n",
      "batch 8526, train_loss 81.720345,Time used 0.010000s\n",
      "batch 8527, train_loss 125.504639,Time used 0.008001s\n",
      "batch 8528, train_loss 112.246941,Time used 0.008000s\n",
      "batch 8529, train_loss 91.348351,Time used 0.007000s\n",
      "batch 8530, train_loss 87.565628,Time used 0.007999s\n",
      "batch 8531, train_loss 92.124702,Time used 0.007001s\n",
      "batch 8532, train_loss 86.987236,Time used 0.009999s\n",
      "batch 8533, train_loss 74.879448,Time used 0.007999s\n",
      "batch 8534, train_loss 61.573444,Time used 0.008002s\n",
      "batch 8535, train_loss 88.506386,Time used 0.007001s\n",
      "batch 8536, train_loss 62.577438,Time used 0.009998s\n",
      "batch 8537, train_loss 82.307938,Time used 0.011001s\n",
      "batch 8538, train_loss 84.673630,Time used 0.008999s\n",
      "batch 8539, train_loss 61.297226,Time used 0.008003s\n",
      "batch 8540, train_loss 69.940155,Time used 0.006997s\n",
      "batch 8541, train_loss 91.011711,Time used 0.008002s\n",
      "batch 8542, train_loss 102.375961,Time used 0.006999s\n",
      "batch 8543, train_loss 90.771393,Time used 0.007002s\n",
      "batch 8544, train_loss 90.249146,Time used 0.007997s\n",
      "batch 8545, train_loss 80.120262,Time used 0.007999s\n",
      "batch 8546, train_loss 85.148933,Time used 0.007001s\n",
      "batch 8547, train_loss 79.409370,Time used 0.007004s\n",
      "batch 8548, train_loss 88.949051,Time used 0.008997s\n",
      "batch 8549, train_loss 83.973343,Time used 0.010003s\n",
      "batch 8550, train_loss 88.724586,Time used 0.009000s\n",
      "batch 8551, train_loss 82.161598,Time used 0.009996s\n",
      "batch 8552, train_loss 63.024063,Time used 0.011002s\n",
      "batch 8553, train_loss 77.196274,Time used 0.009004s\n",
      "batch 8554, train_loss 70.841484,Time used 0.007993s\n",
      "batch 8555, train_loss 90.653526,Time used 0.010005s\n",
      "batch 8556, train_loss 89.078056,Time used 0.009033s\n",
      "batch 8557, train_loss 91.898987,Time used 0.009002s\n",
      "batch 8558, train_loss 75.048523,Time used 0.007999s\n",
      "batch 8559, train_loss 107.876862,Time used 0.006963s\n",
      "batch 8560, train_loss 79.973030,Time used 0.006999s\n",
      "batch 8561, train_loss 110.936630,Time used 0.007004s\n",
      "batch 8562, train_loss 101.223412,Time used 0.007999s\n",
      "batch 8563, train_loss 82.486748,Time used 0.008000s\n",
      "batch 8564, train_loss 68.421906,Time used 0.007002s\n",
      "batch 8565, train_loss 77.407471,Time used 0.006998s\n",
      "batch 8566, train_loss 81.235619,Time used 0.008035s\n",
      "batch 8567, train_loss 83.739632,Time used 0.006961s\n",
      "batch 8568, train_loss 70.776985,Time used 0.008003s\n",
      "batch 8569, train_loss 110.962769,Time used 0.007997s\n",
      "batch 8570, train_loss 95.269333,Time used 0.010034s\n",
      "batch 8571, train_loss 93.465515,Time used 0.006963s\n",
      "batch 8572, train_loss 90.686386,Time used 0.008998s\n",
      "batch 8573, train_loss 69.013000,Time used 0.006037s\n",
      "batch 8574, train_loss 56.032192,Time used 0.007963s\n",
      "batch 8575, train_loss 99.887672,Time used 0.007000s\n",
      "batch 8576, train_loss 74.729813,Time used 0.008038s\n",
      "batch 8577, train_loss 92.505257,Time used 0.007963s\n",
      "batch 8578, train_loss 78.640450,Time used 0.011001s\n",
      "batch 8579, train_loss 109.570213,Time used 0.011001s\n",
      "batch 8580, train_loss 67.134880,Time used 0.010001s\n",
      "batch 8581, train_loss 80.445862,Time used 0.008001s\n",
      "batch 8582, train_loss 84.805779,Time used 0.007998s\n",
      "batch 8583, train_loss 91.427856,Time used 0.009001s\n",
      "batch 8584, train_loss 64.912125,Time used 0.011002s\n",
      "batch 8585, train_loss 77.054314,Time used 0.006999s\n",
      "batch 8586, train_loss 95.535027,Time used 0.008001s\n",
      "batch 8587, train_loss 91.731331,Time used 0.007000s\n",
      "batch 8588, train_loss 69.559296,Time used 0.008000s\n",
      "batch 8589, train_loss 65.717857,Time used 0.008000s\n",
      "batch 8590, train_loss 83.147575,Time used 0.008000s\n",
      "batch 8591, train_loss 64.833099,Time used 0.009999s\n",
      "batch 8592, train_loss 99.245720,Time used 0.008000s\n",
      "batch 8593, train_loss 86.305054,Time used 0.007004s\n",
      "batch 8594, train_loss 83.345665,Time used 0.007996s\n",
      "batch 8595, train_loss 84.611046,Time used 0.008005s\n",
      "batch 8596, train_loss 95.451492,Time used 0.011996s\n",
      "batch 8597, train_loss 105.777954,Time used 0.008003s\n",
      "batch 8598, train_loss 66.298264,Time used 0.009999s\n",
      "batch 8599, train_loss 82.946648,Time used 0.008003s\n",
      "batch 8600, train_loss 92.299934,Time used 0.008000s\n",
      "***************************test_batch 8600, test_rmse_loss 10.522868,test_mae_loss 4.141613,test_mape_loss 63.227867,Time used 0.033998s\n",
      "batch 8601, train_loss 57.684891,Time used 0.011001s\n",
      "batch 8602, train_loss 81.928528,Time used 0.011001s\n",
      "batch 8603, train_loss 83.379036,Time used 0.006999s\n",
      "batch 8604, train_loss 81.345055,Time used 0.008000s\n",
      "batch 8605, train_loss 84.089241,Time used 0.009999s\n",
      "batch 8606, train_loss 62.229210,Time used 0.007001s\n",
      "batch 8607, train_loss 80.016953,Time used 0.008999s\n",
      "batch 8608, train_loss 66.263130,Time used 0.007001s\n",
      "batch 8609, train_loss 110.181335,Time used 0.008038s\n",
      "batch 8610, train_loss 82.972404,Time used 0.007998s\n",
      "batch 8611, train_loss 76.977066,Time used 0.008966s\n",
      "batch 8612, train_loss 94.853279,Time used 0.008999s\n",
      "batch 8613, train_loss 99.023903,Time used 0.006999s\n",
      "batch 8614, train_loss 82.066437,Time used 0.007002s\n",
      "batch 8615, train_loss 67.301544,Time used 0.009044s\n",
      "batch 8616, train_loss 93.436958,Time used 0.006990s\n",
      "batch 8617, train_loss 83.813103,Time used 0.009004s\n",
      "batch 8618, train_loss 81.950134,Time used 0.012001s\n",
      "batch 8619, train_loss 85.322403,Time used 0.010996s\n",
      "batch 8620, train_loss 85.379814,Time used 0.008005s\n",
      "batch 8621, train_loss 67.916214,Time used 0.008994s\n",
      "batch 8622, train_loss 76.429054,Time used 0.011040s\n",
      "batch 8623, train_loss 82.859352,Time used 0.007962s\n",
      "batch 8624, train_loss 95.159363,Time used 0.008016s\n",
      "batch 8625, train_loss 68.220139,Time used 0.006965s\n",
      "batch 8626, train_loss 75.295670,Time used 0.008000s\n",
      "batch 8627, train_loss 75.333794,Time used 0.012000s\n",
      "batch 8628, train_loss 103.239906,Time used 0.009006s\n",
      "batch 8629, train_loss 74.737671,Time used 0.009000s\n",
      "batch 8630, train_loss 68.517731,Time used 0.008031s\n",
      "batch 8631, train_loss 84.558449,Time used 0.011000s\n",
      "batch 8632, train_loss 100.119621,Time used 0.009967s\n",
      "batch 8633, train_loss 74.784630,Time used 0.008996s\n",
      "batch 8634, train_loss 89.240807,Time used 0.009000s\n",
      "batch 8635, train_loss 101.913597,Time used 0.007999s\n",
      "batch 8636, train_loss 71.828171,Time used 0.010005s\n",
      "batch 8637, train_loss 90.292862,Time used 0.011000s\n",
      "batch 8638, train_loss 97.456894,Time used 0.007997s\n",
      "batch 8639, train_loss 74.302002,Time used 0.009000s\n",
      "batch 8640, train_loss 86.490379,Time used 0.009000s\n",
      "batch 8641, train_loss 58.305847,Time used 0.008002s\n",
      "batch 8642, train_loss 64.915405,Time used 0.007999s\n",
      "batch 8643, train_loss 103.748924,Time used 0.006999s\n",
      "batch 8644, train_loss 54.518970,Time used 0.011000s\n",
      "batch 8645, train_loss 100.254738,Time used 0.008004s\n",
      "batch 8646, train_loss 94.258278,Time used 0.006997s\n",
      "batch 8647, train_loss 95.524559,Time used 0.010999s\n",
      "batch 8648, train_loss 82.392632,Time used 0.008002s\n",
      "batch 8649, train_loss 77.599014,Time used 0.011001s\n",
      "batch 8650, train_loss 76.987244,Time used 0.007998s\n",
      "batch 8651, train_loss 102.729668,Time used 0.010000s\n",
      "batch 8652, train_loss 86.170395,Time used 0.007002s\n",
      "batch 8653, train_loss 88.414429,Time used 0.009000s\n",
      "batch 8654, train_loss 67.159088,Time used 0.007000s\n",
      "batch 8655, train_loss 95.083794,Time used 0.011000s\n",
      "batch 8656, train_loss 81.919312,Time used 0.008001s\n",
      "batch 8657, train_loss 100.645882,Time used 0.010999s\n",
      "batch 8658, train_loss 83.705826,Time used 0.014001s\n",
      "batch 8659, train_loss 75.530426,Time used 0.009998s\n",
      "batch 8660, train_loss 75.112862,Time used 0.011999s\n",
      "batch 8661, train_loss 60.533031,Time used 0.009999s\n",
      "batch 8662, train_loss 90.254532,Time used 0.010000s\n",
      "batch 8663, train_loss 90.984100,Time used 0.007001s\n",
      "batch 8664, train_loss 83.041298,Time used 0.007001s\n",
      "batch 8665, train_loss 64.646156,Time used 0.010000s\n",
      "batch 8666, train_loss 87.699219,Time used 0.007999s\n",
      "batch 8667, train_loss 84.487961,Time used 0.008003s\n",
      "batch 8668, train_loss 83.161491,Time used 0.007033s\n",
      "batch 8669, train_loss 89.965103,Time used 0.006967s\n",
      "batch 8670, train_loss 87.678001,Time used 0.010037s\n",
      "batch 8671, train_loss 94.372955,Time used 0.008961s\n",
      "batch 8672, train_loss 80.447823,Time used 0.008004s\n",
      "batch 8673, train_loss 93.181519,Time used 0.006999s\n",
      "batch 8674, train_loss 73.037384,Time used 0.008031s\n",
      "batch 8675, train_loss 73.004150,Time used 0.007000s\n",
      "batch 8676, train_loss 82.841385,Time used 0.007000s\n",
      "batch 8677, train_loss 89.011475,Time used 0.006999s\n",
      "batch 8678, train_loss 95.648476,Time used 0.007996s\n",
      "batch 8679, train_loss 81.128021,Time used 0.008964s\n",
      "batch 8680, train_loss 115.422218,Time used 0.008000s\n",
      "batch 8681, train_loss 85.862228,Time used 0.006999s\n",
      "batch 8682, train_loss 67.940620,Time used 0.020001s\n",
      "batch 8683, train_loss 82.649460,Time used 0.010002s\n",
      "batch 8684, train_loss 60.034199,Time used 0.008002s\n",
      "batch 8685, train_loss 62.882946,Time used 0.008034s\n",
      "batch 8686, train_loss 87.596619,Time used 0.007002s\n",
      "batch 8687, train_loss 71.873871,Time used 0.006963s\n",
      "batch 8688, train_loss 90.472633,Time used 0.008001s\n",
      "batch 8689, train_loss 87.515450,Time used 0.009001s\n",
      "batch 8690, train_loss 81.932983,Time used 0.006999s\n",
      "batch 8691, train_loss 84.554703,Time used 0.008001s\n",
      "batch 8692, train_loss 57.447472,Time used 0.007000s\n",
      "batch 8693, train_loss 85.110138,Time used 0.008000s\n",
      "batch 8694, train_loss 98.310730,Time used 0.009998s\n",
      "batch 8695, train_loss 91.012344,Time used 0.011000s\n",
      "batch 8696, train_loss 81.082817,Time used 0.008002s\n",
      "batch 8697, train_loss 69.349594,Time used 0.009999s\n",
      "batch 8698, train_loss 101.278809,Time used 0.007004s\n",
      "batch 8699, train_loss 67.004547,Time used 0.007998s\n",
      "batch 8700, train_loss 68.036095,Time used 0.011001s\n",
      "***************************test_batch 8700, test_rmse_loss 10.472077,test_mae_loss 4.117005,test_mape_loss 62.457561,Time used 0.042998s\n",
      "batch 8701, train_loss 85.962540,Time used 0.010001s\n",
      "batch 8702, train_loss 107.271889,Time used 0.007000s\n",
      "batch 8703, train_loss 81.394730,Time used 0.008002s\n",
      "batch 8704, train_loss 57.532253,Time used 0.006999s\n",
      "batch 8705, train_loss 73.769104,Time used 0.008002s\n",
      "batch 8706, train_loss 83.111259,Time used 0.006997s\n",
      "batch 8707, train_loss 71.344612,Time used 0.007000s\n",
      "batch 8708, train_loss 72.527664,Time used 0.008002s\n",
      "batch 8709, train_loss 77.399803,Time used 0.007001s\n",
      "batch 8710, train_loss 111.496353,Time used 0.010996s\n",
      "batch 8711, train_loss 95.872322,Time used 0.011003s\n",
      "batch 8712, train_loss 89.709175,Time used 0.010998s\n",
      "batch 8713, train_loss 82.580971,Time used 0.008000s\n",
      "batch 8714, train_loss 99.324875,Time used 0.009999s\n",
      "batch 8715, train_loss 90.692917,Time used 0.008000s\n",
      "batch 8716, train_loss 82.505150,Time used 0.007998s\n",
      "batch 8717, train_loss 110.673172,Time used 0.008002s\n",
      "batch 8718, train_loss 86.557426,Time used 0.008000s\n",
      "batch 8719, train_loss 75.403992,Time used 0.009999s\n",
      "batch 8720, train_loss 56.684647,Time used 0.011001s\n",
      "batch 8721, train_loss 76.489441,Time used 0.008000s\n",
      "batch 8722, train_loss 59.964874,Time used 0.007999s\n",
      "batch 8723, train_loss 74.788216,Time used 0.007001s\n",
      "batch 8724, train_loss 95.010956,Time used 0.006999s\n",
      "batch 8725, train_loss 70.850510,Time used 0.010999s\n",
      "batch 8726, train_loss 89.562607,Time used 0.007999s\n",
      "batch 8727, train_loss 93.830971,Time used 0.008003s\n",
      "batch 8728, train_loss 76.741943,Time used 0.011001s\n",
      "batch 8729, train_loss 85.284592,Time used 0.007999s\n",
      "batch 8730, train_loss 83.434746,Time used 0.011000s\n",
      "batch 8731, train_loss 76.798302,Time used 0.008000s\n",
      "batch 8732, train_loss 88.550034,Time used 0.007999s\n",
      "batch 8733, train_loss 62.847610,Time used 0.009999s\n",
      "batch 8734, train_loss 80.502007,Time used 0.009003s\n",
      "batch 8735, train_loss 95.967804,Time used 0.008999s\n",
      "batch 8736, train_loss 79.674339,Time used 0.010999s\n",
      "batch 8737, train_loss 74.678558,Time used 0.009997s\n",
      "batch 8738, train_loss 73.071236,Time used 0.011000s\n",
      "batch 8739, train_loss 79.492432,Time used 0.009000s\n",
      "batch 8740, train_loss 71.166359,Time used 0.010998s\n",
      "batch 8741, train_loss 83.042938,Time used 0.013000s\n",
      "batch 8742, train_loss 72.771194,Time used 0.011004s\n",
      "batch 8743, train_loss 79.942093,Time used 0.007997s\n",
      "batch 8744, train_loss 89.725960,Time used 0.008002s\n",
      "batch 8745, train_loss 72.613976,Time used 0.009000s\n",
      "batch 8746, train_loss 71.776115,Time used 0.008002s\n",
      "batch 8747, train_loss 84.749260,Time used 0.006999s\n",
      "batch 8748, train_loss 76.536514,Time used 0.007001s\n",
      "batch 8749, train_loss 108.370354,Time used 0.009000s\n",
      "batch 8750, train_loss 100.469521,Time used 0.007001s\n",
      "batch 8751, train_loss 89.958168,Time used 0.007999s\n",
      "batch 8752, train_loss 85.268921,Time used 0.008003s\n",
      "batch 8753, train_loss 90.103546,Time used 0.008999s\n",
      "batch 8754, train_loss 64.833870,Time used 0.007002s\n",
      "batch 8755, train_loss 86.531487,Time used 0.007998s\n",
      "batch 8756, train_loss 89.629448,Time used 0.008003s\n",
      "batch 8757, train_loss 75.765518,Time used 0.009997s\n",
      "batch 8758, train_loss 73.094856,Time used 0.010000s\n",
      "batch 8759, train_loss 86.722008,Time used 0.012002s\n",
      "batch 8760, train_loss 89.716133,Time used 0.012000s\n",
      "batch 8761, train_loss 72.506386,Time used 0.011000s\n",
      "batch 8762, train_loss 89.837891,Time used 0.008003s\n",
      "batch 8763, train_loss 89.154030,Time used 0.011997s\n",
      "batch 8764, train_loss 77.150833,Time used 0.011002s\n",
      "batch 8765, train_loss 66.391563,Time used 0.006997s\n",
      "batch 8766, train_loss 75.281250,Time used 0.010000s\n",
      "batch 8767, train_loss 89.506775,Time used 0.007002s\n",
      "batch 8768, train_loss 78.682762,Time used 0.010000s\n",
      "batch 8769, train_loss 79.690292,Time used 0.006999s\n",
      "batch 8770, train_loss 90.056633,Time used 0.011000s\n",
      "batch 8771, train_loss 78.865959,Time used 0.009000s\n",
      "batch 8772, train_loss 79.551140,Time used 0.007005s\n",
      "batch 8773, train_loss 100.621124,Time used 0.007998s\n",
      "batch 8774, train_loss 76.246117,Time used 0.008002s\n",
      "batch 8775, train_loss 75.886528,Time used 0.008001s\n",
      "batch 8776, train_loss 75.115646,Time used 0.010997s\n",
      "batch 8777, train_loss 79.387177,Time used 0.010003s\n",
      "batch 8778, train_loss 64.370224,Time used 0.008000s\n",
      "batch 8779, train_loss 81.109406,Time used 0.008001s\n",
      "batch 8780, train_loss 71.162010,Time used 0.006998s\n",
      "batch 8781, train_loss 100.103371,Time used 0.008998s\n",
      "batch 8782, train_loss 93.534805,Time used 0.008003s\n",
      "batch 8783, train_loss 78.517845,Time used 0.007999s\n",
      "batch 8784, train_loss 103.056084,Time used 0.009998s\n",
      "batch 8785, train_loss 78.387291,Time used 0.008000s\n",
      "batch 8786, train_loss 104.453377,Time used 0.007999s\n",
      "batch 8787, train_loss 91.484337,Time used 0.008001s\n",
      "batch 8788, train_loss 86.393829,Time used 0.008967s\n",
      "batch 8789, train_loss 73.730415,Time used 0.008046s\n",
      "batch 8790, train_loss 81.315804,Time used 0.010955s\n",
      "batch 8791, train_loss 80.144363,Time used 0.009000s\n",
      "batch 8792, train_loss 85.223701,Time used 0.007995s\n",
      "batch 8793, train_loss 81.412598,Time used 0.007999s\n",
      "batch 8794, train_loss 84.644615,Time used 0.006999s\n",
      "batch 8795, train_loss 62.741932,Time used 0.012001s\n",
      "batch 8796, train_loss 86.956680,Time used 0.010999s\n",
      "batch 8797, train_loss 78.187576,Time used 0.009003s\n",
      "batch 8798, train_loss 91.980698,Time used 0.007000s\n",
      "batch 8799, train_loss 109.162094,Time used 0.011998s\n",
      "batch 8800, train_loss 81.332504,Time used 0.012002s\n",
      "***************************test_batch 8800, test_rmse_loss 10.414009,test_mae_loss 4.101390,test_mape_loss 62.575672,Time used 0.043000s\n",
      "batch 8801, train_loss 70.102737,Time used 0.009002s\n",
      "batch 8802, train_loss 72.453842,Time used 0.007998s\n",
      "batch 8803, train_loss 93.359543,Time used 0.007002s\n",
      "batch 8804, train_loss 69.807281,Time used 0.008004s\n",
      "batch 8805, train_loss 62.433693,Time used 0.010993s\n",
      "batch 8806, train_loss 71.323387,Time used 0.009000s\n",
      "batch 8807, train_loss 93.355530,Time used 0.009001s\n",
      "batch 8808, train_loss 68.629082,Time used 0.009001s\n",
      "batch 8809, train_loss 99.842377,Time used 0.009002s\n",
      "batch 8810, train_loss 84.871246,Time used 0.007999s\n",
      "batch 8811, train_loss 70.298515,Time used 0.010998s\n",
      "batch 8812, train_loss 93.049583,Time used 0.012001s\n",
      "batch 8813, train_loss 66.581703,Time used 0.008000s\n",
      "batch 8814, train_loss 78.511566,Time used 0.009000s\n",
      "batch 8815, train_loss 83.008080,Time used 0.008000s\n",
      "batch 8816, train_loss 72.634628,Time used 0.012002s\n",
      "batch 8817, train_loss 88.907562,Time used 0.009001s\n",
      "batch 8818, train_loss 65.223885,Time used 0.008999s\n",
      "batch 8819, train_loss 82.245125,Time used 0.012000s\n",
      "batch 8820, train_loss 82.126503,Time used 0.009000s\n",
      "batch 8821, train_loss 69.013412,Time used 0.012005s\n",
      "batch 8822, train_loss 95.556709,Time used 0.007995s\n",
      "batch 8823, train_loss 91.661697,Time used 0.012999s\n",
      "batch 8824, train_loss 69.615532,Time used 0.009005s\n",
      "batch 8825, train_loss 89.352539,Time used 0.008996s\n",
      "batch 8826, train_loss 80.634750,Time used 0.009000s\n",
      "batch 8827, train_loss 79.437668,Time used 0.008000s\n",
      "batch 8828, train_loss 85.760941,Time used 0.009000s\n",
      "batch 8829, train_loss 85.296440,Time used 0.006999s\n",
      "batch 8830, train_loss 101.594894,Time used 0.009002s\n",
      "batch 8831, train_loss 66.240128,Time used 0.011001s\n",
      "batch 8832, train_loss 72.737244,Time used 0.009000s\n",
      "batch 8833, train_loss 94.387276,Time used 0.009001s\n",
      "batch 8834, train_loss 62.432125,Time used 0.008998s\n",
      "batch 8835, train_loss 82.722649,Time used 0.008001s\n",
      "batch 8836, train_loss 86.006668,Time used 0.009000s\n",
      "batch 8837, train_loss 98.660728,Time used 0.009998s\n",
      "batch 8838, train_loss 100.346954,Time used 0.011000s\n",
      "batch 8839, train_loss 74.627548,Time used 0.007006s\n",
      "batch 8840, train_loss 85.206268,Time used 0.006999s\n",
      "batch 8841, train_loss 70.171745,Time used 0.008001s\n",
      "batch 8842, train_loss 67.995506,Time used 0.008001s\n",
      "batch 8843, train_loss 93.297668,Time used 0.008012s\n",
      "batch 8844, train_loss 87.304749,Time used 0.007986s\n",
      "batch 8845, train_loss 65.851822,Time used 0.011000s\n",
      "batch 8846, train_loss 78.331596,Time used 0.012006s\n",
      "batch 8847, train_loss 67.461601,Time used 0.006995s\n",
      "batch 8848, train_loss 79.401108,Time used 0.010001s\n",
      "batch 8849, train_loss 63.835304,Time used 0.012003s\n",
      "batch 8850, train_loss 84.998009,Time used 0.011996s\n",
      "batch 8851, train_loss 76.232582,Time used 0.011017s\n",
      "batch 8852, train_loss 98.417366,Time used 0.011996s\n",
      "batch 8853, train_loss 93.875671,Time used 0.009001s\n",
      "batch 8854, train_loss 95.480881,Time used 0.009000s\n",
      "batch 8855, train_loss 71.689354,Time used 0.009001s\n",
      "batch 8856, train_loss 70.546730,Time used 0.009001s\n",
      "batch 8857, train_loss 79.734863,Time used 0.013000s\n",
      "batch 8858, train_loss 61.307293,Time used 0.009002s\n",
      "batch 8859, train_loss 88.046387,Time used 0.010998s\n",
      "batch 8860, train_loss 84.907524,Time used 0.009999s\n",
      "batch 8861, train_loss 74.733177,Time used 0.008003s\n",
      "batch 8862, train_loss 62.690788,Time used 0.007998s\n",
      "batch 8863, train_loss 86.753990,Time used 0.007000s\n",
      "batch 8864, train_loss 79.213219,Time used 0.008001s\n",
      "batch 8865, train_loss 73.762718,Time used 0.007999s\n",
      "batch 8866, train_loss 90.834457,Time used 0.008002s\n",
      "batch 8867, train_loss 109.814018,Time used 0.011034s\n",
      "batch 8868, train_loss 81.340652,Time used 0.008962s\n",
      "batch 8869, train_loss 90.703590,Time used 0.010002s\n",
      "batch 8870, train_loss 86.055092,Time used 0.008000s\n",
      "batch 8871, train_loss 87.822495,Time used 0.008000s\n",
      "batch 8872, train_loss 80.862221,Time used 0.009002s\n",
      "batch 8873, train_loss 87.038086,Time used 0.010001s\n",
      "batch 8874, train_loss 69.244652,Time used 0.010998s\n",
      "batch 8875, train_loss 78.229881,Time used 0.011998s\n",
      "batch 8876, train_loss 75.342300,Time used 0.011003s\n",
      "batch 8877, train_loss 73.236137,Time used 0.009001s\n",
      "batch 8878, train_loss 81.766991,Time used 0.006999s\n",
      "batch 8879, train_loss 71.207024,Time used 0.007998s\n",
      "batch 8880, train_loss 90.443039,Time used 0.006999s\n",
      "batch 8881, train_loss 82.497154,Time used 0.010996s\n",
      "batch 8882, train_loss 80.660736,Time used 0.008001s\n",
      "batch 8883, train_loss 79.882133,Time used 0.007001s\n",
      "batch 8884, train_loss 72.192436,Time used 0.008000s\n",
      "batch 8885, train_loss 64.747276,Time used 0.006999s\n",
      "batch 8886, train_loss 66.625153,Time used 0.008998s\n",
      "batch 8887, train_loss 123.871231,Time used 0.007000s\n",
      "batch 8888, train_loss 96.255859,Time used 0.008003s\n",
      "batch 8889, train_loss 96.999931,Time used 0.006999s\n",
      "batch 8890, train_loss 67.941040,Time used 0.006999s\n",
      "batch 8891, train_loss 82.912270,Time used 0.010001s\n",
      "batch 8892, train_loss 54.239578,Time used 0.007999s\n",
      "batch 8893, train_loss 68.528618,Time used 0.010000s\n",
      "batch 8894, train_loss 59.905479,Time used 0.011001s\n",
      "batch 8895, train_loss 78.670792,Time used 0.008997s\n",
      "batch 8896, train_loss 90.439003,Time used 0.008002s\n",
      "batch 8897, train_loss 83.363716,Time used 0.006999s\n",
      "batch 8898, train_loss 94.345032,Time used 0.007002s\n",
      "batch 8899, train_loss 76.485252,Time used 0.006997s\n",
      "batch 8900, train_loss 90.813080,Time used 0.006999s\n",
      "***************************test_batch 8900, test_rmse_loss 10.358948,test_mae_loss 4.082390,test_mape_loss 62.308906,Time used 0.028001s\n",
      "batch 8901, train_loss 100.924614,Time used 0.007037s\n",
      "batch 8902, train_loss 73.834595,Time used 0.008963s\n",
      "batch 8903, train_loss 82.810028,Time used 0.006999s\n",
      "batch 8904, train_loss 70.715065,Time used 0.008001s\n",
      "batch 8905, train_loss 88.449448,Time used 0.008005s\n",
      "batch 8906, train_loss 92.915230,Time used 0.006999s\n",
      "batch 8907, train_loss 75.229935,Time used 0.008000s\n",
      "batch 8908, train_loss 85.440781,Time used 0.006998s\n",
      "batch 8909, train_loss 68.199867,Time used 0.008999s\n",
      "batch 8910, train_loss 74.981148,Time used 0.007001s\n",
      "batch 8911, train_loss 110.719360,Time used 0.008001s\n",
      "batch 8912, train_loss 77.479103,Time used 0.009999s\n",
      "batch 8913, train_loss 83.627335,Time used 0.008001s\n",
      "batch 8914, train_loss 70.284874,Time used 0.009001s\n",
      "batch 8915, train_loss 87.298813,Time used 0.007999s\n",
      "batch 8916, train_loss 98.122627,Time used 0.009001s\n",
      "batch 8917, train_loss 88.426376,Time used 0.007999s\n",
      "batch 8918, train_loss 76.698898,Time used 0.008001s\n",
      "batch 8919, train_loss 93.740295,Time used 0.006999s\n",
      "batch 8920, train_loss 94.057129,Time used 0.008002s\n",
      "batch 8921, train_loss 82.385353,Time used 0.007000s\n",
      "batch 8922, train_loss 74.468620,Time used 0.008001s\n",
      "batch 8923, train_loss 60.916237,Time used 0.009000s\n",
      "batch 8924, train_loss 54.477909,Time used 0.007998s\n",
      "batch 8925, train_loss 62.899696,Time used 0.008001s\n",
      "batch 8926, train_loss 66.372650,Time used 0.008000s\n",
      "batch 8927, train_loss 75.607620,Time used 0.009000s\n",
      "batch 8928, train_loss 92.581757,Time used 0.008998s\n",
      "batch 8929, train_loss 76.704079,Time used 0.008999s\n",
      "batch 8930, train_loss 94.170769,Time used 0.011000s\n",
      "batch 8931, train_loss 70.393547,Time used 0.007001s\n",
      "batch 8932, train_loss 71.972061,Time used 0.011002s\n",
      "batch 8933, train_loss 93.398071,Time used 0.014997s\n",
      "batch 8934, train_loss 86.724251,Time used 0.014002s\n",
      "batch 8935, train_loss 89.440796,Time used 0.013519s\n",
      "batch 8936, train_loss 87.271393,Time used 0.016998s\n",
      "batch 8937, train_loss 74.376305,Time used 0.013534s\n",
      "batch 8938, train_loss 79.140228,Time used 0.013002s\n",
      "batch 8939, train_loss 97.342400,Time used 0.009010s\n",
      "batch 8940, train_loss 76.908806,Time used 0.010993s\n",
      "batch 8941, train_loss 74.715340,Time used 0.011000s\n",
      "batch 8942, train_loss 92.456985,Time used 0.009999s\n",
      "batch 8943, train_loss 79.301277,Time used 0.008999s\n",
      "batch 8944, train_loss 64.443932,Time used 0.010000s\n",
      "batch 8945, train_loss 87.999374,Time used 0.009998s\n",
      "batch 8946, train_loss 67.969559,Time used 0.010999s\n",
      "batch 8947, train_loss 89.623856,Time used 0.011003s\n",
      "batch 8948, train_loss 82.153358,Time used 0.009001s\n",
      "batch 8949, train_loss 67.804817,Time used 0.009998s\n",
      "batch 8950, train_loss 81.699776,Time used 0.012005s\n",
      "batch 8951, train_loss 73.691322,Time used 0.012996s\n",
      "batch 8952, train_loss 69.914177,Time used 0.011000s\n",
      "batch 8953, train_loss 77.106705,Time used 0.011997s\n",
      "batch 8954, train_loss 86.745674,Time used 0.010003s\n",
      "batch 8955, train_loss 64.645363,Time used 0.012001s\n",
      "batch 8956, train_loss 71.201714,Time used 0.011997s\n",
      "batch 8957, train_loss 85.844231,Time used 0.012999s\n",
      "batch 8958, train_loss 66.589355,Time used 0.010999s\n",
      "batch 8959, train_loss 74.323471,Time used 0.008000s\n",
      "batch 8960, train_loss 74.399788,Time used 0.008999s\n",
      "batch 8961, train_loss 72.458733,Time used 0.010000s\n",
      "batch 8962, train_loss 80.571022,Time used 0.010998s\n",
      "batch 8963, train_loss 59.373039,Time used 0.009000s\n",
      "batch 8964, train_loss 71.813766,Time used 0.010000s\n",
      "batch 8965, train_loss 66.514763,Time used 0.009000s\n",
      "batch 8966, train_loss 93.464706,Time used 0.010001s\n",
      "batch 8967, train_loss 85.962807,Time used 0.010997s\n",
      "batch 8968, train_loss 68.521469,Time used 0.010998s\n",
      "batch 8969, train_loss 89.301277,Time used 0.012000s\n",
      "batch 8970, train_loss 99.754829,Time used 0.011999s\n",
      "batch 8971, train_loss 62.768578,Time used 0.012001s\n",
      "batch 8972, train_loss 80.753258,Time used 0.008001s\n",
      "batch 8973, train_loss 102.445847,Time used 0.009001s\n",
      "batch 8974, train_loss 103.977074,Time used 0.007000s\n",
      "batch 8975, train_loss 80.514816,Time used 0.008000s\n",
      "batch 8976, train_loss 107.128952,Time used 0.009000s\n",
      "batch 8977, train_loss 80.700493,Time used 0.010000s\n",
      "batch 8978, train_loss 85.621056,Time used 0.008001s\n",
      "batch 8979, train_loss 70.849495,Time used 0.008001s\n",
      "batch 8980, train_loss 79.179977,Time used 0.009999s\n",
      "batch 8981, train_loss 91.786896,Time used 0.009999s\n",
      "batch 8982, train_loss 73.018242,Time used 0.010001s\n",
      "batch 8983, train_loss 100.521179,Time used 0.007999s\n",
      "batch 8984, train_loss 69.591850,Time used 0.009002s\n",
      "batch 8985, train_loss 89.076881,Time used 0.006999s\n",
      "batch 8986, train_loss 90.339935,Time used 0.009002s\n",
      "batch 8987, train_loss 67.234604,Time used 0.013999s\n",
      "batch 8988, train_loss 69.039253,Time used 0.007000s\n",
      "batch 8989, train_loss 78.724564,Time used 0.009000s\n",
      "batch 8990, train_loss 97.075249,Time used 0.008001s\n",
      "batch 8991, train_loss 84.352684,Time used 0.009997s\n",
      "batch 8992, train_loss 98.171654,Time used 0.007002s\n",
      "batch 8993, train_loss 68.319939,Time used 0.009000s\n",
      "batch 8994, train_loss 76.428429,Time used 0.011001s\n",
      "batch 8995, train_loss 88.684105,Time used 0.008000s\n",
      "batch 8996, train_loss 75.490921,Time used 0.006999s\n",
      "batch 8997, train_loss 62.960907,Time used 0.009000s\n",
      "batch 8998, train_loss 95.079582,Time used 0.008000s\n",
      "batch 8999, train_loss 62.786594,Time used 0.011001s\n",
      "batch 9000, train_loss 64.865196,Time used 0.007000s\n",
      "***************************test_batch 9000, test_rmse_loss 10.306169,test_mae_loss 4.062170,test_mape_loss 61.998030,Time used 0.038999s\n",
      "batch 9001, train_loss 90.109840,Time used 0.011998s\n",
      "batch 9002, train_loss 62.578991,Time used 0.010998s\n",
      "batch 9003, train_loss 57.029762,Time used 0.010001s\n",
      "batch 9004, train_loss 84.577736,Time used 0.010999s\n",
      "batch 9005, train_loss 89.140701,Time used 0.011002s\n",
      "batch 9006, train_loss 60.868992,Time used 0.012001s\n",
      "batch 9007, train_loss 88.104065,Time used 0.011001s\n",
      "batch 9008, train_loss 91.596794,Time used 0.010000s\n",
      "batch 9009, train_loss 98.274765,Time used 0.012001s\n",
      "batch 9010, train_loss 70.093628,Time used 0.011998s\n",
      "batch 9011, train_loss 89.913109,Time used 0.011002s\n",
      "batch 9012, train_loss 73.921082,Time used 0.009001s\n",
      "batch 9013, train_loss 81.806244,Time used 0.012002s\n",
      "batch 9014, train_loss 89.218819,Time used 0.011998s\n",
      "batch 9015, train_loss 75.974701,Time used 0.013002s\n",
      "batch 9016, train_loss 68.800163,Time used 0.015001s\n",
      "batch 9017, train_loss 94.991455,Time used 0.010999s\n",
      "batch 9018, train_loss 56.868275,Time used 0.010999s\n",
      "batch 9019, train_loss 96.078300,Time used 0.011002s\n",
      "batch 9020, train_loss 90.559914,Time used 0.013002s\n",
      "batch 9021, train_loss 81.904068,Time used 0.013997s\n",
      "batch 9022, train_loss 75.929230,Time used 0.012999s\n",
      "batch 9023, train_loss 75.741333,Time used 0.014002s\n",
      "batch 9024, train_loss 71.699844,Time used 0.012999s\n",
      "batch 9025, train_loss 100.739822,Time used 0.014000s\n",
      "batch 9026, train_loss 72.666794,Time used 0.015001s\n",
      "batch 9027, train_loss 51.985550,Time used 0.013001s\n",
      "batch 9028, train_loss 71.758911,Time used 0.010998s\n",
      "batch 9029, train_loss 75.591171,Time used 0.011999s\n",
      "batch 9030, train_loss 61.925751,Time used 0.009999s\n",
      "batch 9031, train_loss 73.701286,Time used 0.009001s\n",
      "batch 9032, train_loss 97.218666,Time used 0.010998s\n",
      "batch 9033, train_loss 81.103508,Time used 0.010002s\n",
      "batch 9034, train_loss 77.936836,Time used 0.011999s\n",
      "batch 9035, train_loss 90.329109,Time used 0.012003s\n",
      "batch 9036, train_loss 67.256439,Time used 0.011998s\n",
      "batch 9037, train_loss 77.572540,Time used 0.011000s\n",
      "batch 9038, train_loss 91.635384,Time used 0.013999s\n",
      "batch 9039, train_loss 91.006470,Time used 0.011000s\n",
      "batch 9040, train_loss 80.861366,Time used 0.014003s\n",
      "batch 9041, train_loss 78.851364,Time used 0.018997s\n",
      "batch 9042, train_loss 63.597435,Time used 0.012001s\n",
      "batch 9043, train_loss 87.836380,Time used 0.010999s\n",
      "batch 9044, train_loss 86.170456,Time used 0.009000s\n",
      "batch 9045, train_loss 96.468201,Time used 0.007999s\n",
      "batch 9046, train_loss 78.105545,Time used 0.008001s\n",
      "batch 9047, train_loss 78.227966,Time used 0.008001s\n",
      "batch 9048, train_loss 78.615578,Time used 0.009999s\n",
      "batch 9049, train_loss 74.779404,Time used 0.010003s\n",
      "batch 9050, train_loss 68.916885,Time used 0.010998s\n",
      "batch 9051, train_loss 55.565887,Time used 0.012004s\n",
      "batch 9052, train_loss 59.007484,Time used 0.008996s\n",
      "batch 9053, train_loss 84.306892,Time used 0.008001s\n",
      "batch 9054, train_loss 66.861076,Time used 0.010998s\n",
      "batch 9055, train_loss 87.251907,Time used 0.011000s\n",
      "batch 9056, train_loss 97.783760,Time used 0.011000s\n",
      "batch 9057, train_loss 79.771561,Time used 0.007999s\n",
      "batch 9058, train_loss 67.482208,Time used 0.008000s\n",
      "batch 9059, train_loss 108.313301,Time used 0.008999s\n",
      "batch 9060, train_loss 92.677017,Time used 0.011003s\n",
      "batch 9061, train_loss 71.722076,Time used 0.008999s\n",
      "batch 9062, train_loss 75.916092,Time used 0.010998s\n",
      "batch 9063, train_loss 83.648201,Time used 0.010002s\n",
      "batch 9064, train_loss 89.693329,Time used 0.011000s\n",
      "batch 9065, train_loss 79.858345,Time used 0.010001s\n",
      "batch 9066, train_loss 61.670792,Time used 0.011991s\n",
      "batch 9067, train_loss 72.039162,Time used 0.009999s\n",
      "batch 9068, train_loss 105.898346,Time used 0.011000s\n",
      "batch 9069, train_loss 98.700645,Time used 0.012001s\n",
      "batch 9070, train_loss 81.947136,Time used 0.009002s\n",
      "batch 9071, train_loss 74.450386,Time used 0.011998s\n",
      "batch 9072, train_loss 67.456276,Time used 0.009999s\n",
      "batch 9073, train_loss 82.438530,Time used 0.010999s\n",
      "batch 9074, train_loss 70.762207,Time used 0.008999s\n",
      "batch 9075, train_loss 72.836014,Time used 0.008999s\n",
      "batch 9076, train_loss 75.577164,Time used 0.008000s\n",
      "batch 9077, train_loss 70.155182,Time used 0.006999s\n",
      "batch 9078, train_loss 80.203606,Time used 0.008002s\n",
      "batch 9079, train_loss 64.899948,Time used 0.006999s\n",
      "batch 9080, train_loss 100.762817,Time used 0.008002s\n",
      "batch 9081, train_loss 92.870148,Time used 0.006999s\n",
      "batch 9082, train_loss 97.646843,Time used 0.008000s\n",
      "batch 9083, train_loss 69.936989,Time used 0.008000s\n",
      "batch 9084, train_loss 85.312813,Time used 0.006999s\n",
      "batch 9085, train_loss 90.611259,Time used 0.008000s\n",
      "batch 9086, train_loss 70.685699,Time used 0.007999s\n",
      "batch 9087, train_loss 84.712318,Time used 0.011002s\n",
      "batch 9088, train_loss 102.049103,Time used 0.012001s\n",
      "batch 9089, train_loss 61.122467,Time used 0.007000s\n",
      "batch 9090, train_loss 81.750046,Time used 0.007998s\n",
      "batch 9091, train_loss 66.278137,Time used 0.006999s\n",
      "batch 9092, train_loss 65.810966,Time used 0.010002s\n",
      "batch 9093, train_loss 59.222973,Time used 0.010999s\n",
      "batch 9094, train_loss 89.263405,Time used 0.011000s\n",
      "batch 9095, train_loss 76.732361,Time used 0.010002s\n",
      "batch 9096, train_loss 90.509827,Time used 0.008001s\n",
      "batch 9097, train_loss 79.177734,Time used 0.007997s\n",
      "batch 9098, train_loss 76.902176,Time used 0.008008s\n",
      "batch 9099, train_loss 71.294403,Time used 0.007000s\n",
      "batch 9100, train_loss 68.692528,Time used 0.007000s\n",
      "***************************test_batch 9100, test_rmse_loss 10.251358,test_mae_loss 4.047202,test_mape_loss 62.028286,Time used 0.029000s\n",
      "batch 9101, train_loss 76.321503,Time used 0.010998s\n",
      "batch 9102, train_loss 87.761452,Time used 0.008001s\n",
      "batch 9103, train_loss 93.134369,Time used 0.010001s\n",
      "batch 9104, train_loss 83.699226,Time used 0.006999s\n",
      "batch 9105, train_loss 77.986946,Time used 0.008999s\n",
      "batch 9106, train_loss 70.469643,Time used 0.009001s\n",
      "batch 9107, train_loss 85.573433,Time used 0.007999s\n",
      "batch 9108, train_loss 64.456055,Time used 0.007000s\n",
      "batch 9109, train_loss 80.379532,Time used 0.007001s\n",
      "batch 9110, train_loss 78.035210,Time used 0.007000s\n",
      "batch 9111, train_loss 91.619476,Time used 0.009000s\n",
      "batch 9112, train_loss 74.202469,Time used 0.008000s\n",
      "batch 9113, train_loss 78.642776,Time used 0.008002s\n",
      "batch 9114, train_loss 71.078819,Time used 0.009001s\n",
      "batch 9115, train_loss 78.979820,Time used 0.007998s\n",
      "batch 9116, train_loss 80.175316,Time used 0.013993s\n",
      "batch 9117, train_loss 85.842133,Time used 0.010003s\n",
      "batch 9118, train_loss 70.718445,Time used 0.013996s\n",
      "batch 9119, train_loss 92.492264,Time used 0.011999s\n",
      "batch 9120, train_loss 79.452209,Time used 0.012998s\n",
      "batch 9121, train_loss 84.554146,Time used 0.009000s\n",
      "batch 9122, train_loss 77.630447,Time used 0.009001s\n",
      "batch 9123, train_loss 76.705307,Time used 0.012999s\n",
      "batch 9124, train_loss 84.341019,Time used 0.011998s\n",
      "batch 9125, train_loss 94.944824,Time used 0.011001s\n",
      "batch 9126, train_loss 84.614212,Time used 0.012002s\n",
      "batch 9127, train_loss 61.450172,Time used 0.010996s\n",
      "batch 9128, train_loss 85.802757,Time used 0.013001s\n",
      "batch 9129, train_loss 69.549568,Time used 0.010004s\n",
      "batch 9130, train_loss 70.427490,Time used 0.008995s\n",
      "batch 9131, train_loss 102.741745,Time used 0.011999s\n",
      "batch 9132, train_loss 70.935524,Time used 0.008001s\n",
      "batch 9133, train_loss 71.700241,Time used 0.010002s\n",
      "batch 9134, train_loss 86.820419,Time used 0.007998s\n",
      "batch 9135, train_loss 106.547806,Time used 0.008999s\n",
      "batch 9136, train_loss 91.388237,Time used 0.012007s\n",
      "batch 9137, train_loss 73.806847,Time used 0.010993s\n",
      "batch 9138, train_loss 85.664062,Time used 0.013002s\n",
      "batch 9139, train_loss 82.274323,Time used 0.009000s\n",
      "batch 9140, train_loss 63.347900,Time used 0.007998s\n",
      "batch 9141, train_loss 65.587936,Time used 0.006986s\n",
      "batch 9142, train_loss 64.951965,Time used 0.010000s\n",
      "batch 9143, train_loss 72.332741,Time used 0.011999s\n",
      "batch 9144, train_loss 63.732353,Time used 0.012001s\n",
      "batch 9145, train_loss 70.430275,Time used 0.012001s\n",
      "batch 9146, train_loss 86.823296,Time used 0.011000s\n",
      "batch 9147, train_loss 70.187775,Time used 0.008000s\n",
      "batch 9148, train_loss 69.901031,Time used 0.008998s\n",
      "batch 9149, train_loss 85.746964,Time used 0.008000s\n",
      "batch 9150, train_loss 92.593842,Time used 0.008001s\n",
      "batch 9151, train_loss 74.798874,Time used 0.007001s\n",
      "batch 9152, train_loss 79.181335,Time used 0.010999s\n",
      "batch 9153, train_loss 76.851089,Time used 0.008002s\n",
      "batch 9154, train_loss 68.198639,Time used 0.006999s\n",
      "batch 9155, train_loss 91.319756,Time used 0.008002s\n",
      "batch 9156, train_loss 73.272400,Time used 0.007001s\n",
      "batch 9157, train_loss 87.657074,Time used 0.007998s\n",
      "batch 9158, train_loss 79.238945,Time used 0.007998s\n",
      "batch 9159, train_loss 61.088127,Time used 0.008000s\n",
      "batch 9160, train_loss 66.017715,Time used 0.008006s\n",
      "batch 9161, train_loss 59.399670,Time used 0.006996s\n",
      "batch 9162, train_loss 84.276749,Time used 0.007998s\n",
      "batch 9163, train_loss 75.491386,Time used 0.007004s\n",
      "batch 9164, train_loss 99.196823,Time used 0.008000s\n",
      "batch 9165, train_loss 85.612457,Time used 0.010001s\n",
      "batch 9166, train_loss 89.679688,Time used 0.006997s\n",
      "batch 9167, train_loss 92.980713,Time used 0.007999s\n",
      "batch 9168, train_loss 67.389297,Time used 0.012002s\n",
      "batch 9169, train_loss 77.360268,Time used 0.009999s\n",
      "batch 9170, train_loss 107.847206,Time used 0.009999s\n",
      "batch 9171, train_loss 67.298447,Time used 0.007999s\n",
      "batch 9172, train_loss 78.068329,Time used 0.008002s\n",
      "batch 9173, train_loss 64.964783,Time used 0.007000s\n",
      "batch 9174, train_loss 115.622292,Time used 0.011999s\n",
      "batch 9175, train_loss 83.328186,Time used 0.011000s\n",
      "batch 9176, train_loss 85.204948,Time used 0.010996s\n",
      "batch 9177, train_loss 75.888725,Time used 0.009001s\n",
      "batch 9178, train_loss 69.896591,Time used 0.008997s\n",
      "batch 9179, train_loss 84.114029,Time used 0.009001s\n",
      "batch 9180, train_loss 82.228424,Time used 0.008000s\n",
      "batch 9181, train_loss 67.585587,Time used 0.011000s\n",
      "batch 9182, train_loss 79.127831,Time used 0.008003s\n",
      "batch 9183, train_loss 74.085403,Time used 0.007999s\n",
      "batch 9184, train_loss 68.466576,Time used 0.008000s\n",
      "batch 9185, train_loss 66.939262,Time used 0.010001s\n",
      "batch 9186, train_loss 66.614738,Time used 0.008997s\n",
      "batch 9187, train_loss 73.865005,Time used 0.009001s\n",
      "batch 9188, train_loss 77.648361,Time used 0.008999s\n",
      "batch 9189, train_loss 82.664909,Time used 0.011001s\n",
      "batch 9190, train_loss 86.923187,Time used 0.011998s\n",
      "batch 9191, train_loss 71.480881,Time used 0.009002s\n",
      "batch 9192, train_loss 76.146332,Time used 0.006999s\n",
      "batch 9193, train_loss 78.588058,Time used 0.008000s\n",
      "batch 9194, train_loss 78.312386,Time used 0.008999s\n",
      "batch 9195, train_loss 81.886719,Time used 0.007001s\n",
      "batch 9196, train_loss 68.301620,Time used 0.008000s\n",
      "batch 9197, train_loss 92.450142,Time used 0.007001s\n",
      "batch 9198, train_loss 94.725769,Time used 0.009999s\n",
      "batch 9199, train_loss 89.647301,Time used 0.009000s\n",
      "batch 9200, train_loss 69.371223,Time used 0.010001s\n",
      "***************************test_batch 9200, test_rmse_loss 10.205529,test_mae_loss 4.024741,test_mape_loss 61.352324,Time used 0.036000s\n",
      "batch 9201, train_loss 63.975941,Time used 0.009997s\n",
      "batch 9202, train_loss 100.890533,Time used 0.008003s\n",
      "batch 9203, train_loss 78.119957,Time used 0.008997s\n",
      "batch 9204, train_loss 87.801620,Time used 0.010000s\n",
      "batch 9205, train_loss 82.197968,Time used 0.008001s\n",
      "batch 9206, train_loss 69.162987,Time used 0.006997s\n",
      "batch 9207, train_loss 66.804764,Time used 0.007000s\n",
      "batch 9208, train_loss 67.173973,Time used 0.008000s\n",
      "batch 9209, train_loss 91.694817,Time used 0.007001s\n",
      "batch 9210, train_loss 78.994995,Time used 0.010002s\n",
      "batch 9211, train_loss 71.301231,Time used 0.006998s\n",
      "batch 9212, train_loss 69.922646,Time used 0.016001s\n",
      "batch 9213, train_loss 80.544266,Time used 0.012000s\n",
      "batch 9214, train_loss 65.440712,Time used 0.010999s\n",
      "batch 9215, train_loss 79.269417,Time used 0.007000s\n",
      "batch 9216, train_loss 72.041283,Time used 0.008999s\n",
      "batch 9217, train_loss 69.127502,Time used 0.010002s\n",
      "batch 9218, train_loss 64.807091,Time used 0.007000s\n",
      "batch 9219, train_loss 70.582268,Time used 0.010996s\n",
      "batch 9220, train_loss 76.213661,Time used 0.008005s\n",
      "batch 9221, train_loss 110.195114,Time used 0.007000s\n",
      "batch 9222, train_loss 79.205307,Time used 0.009001s\n",
      "batch 9223, train_loss 52.212875,Time used 0.010999s\n",
      "batch 9224, train_loss 86.757736,Time used 0.008000s\n",
      "batch 9225, train_loss 85.245529,Time used 0.008000s\n",
      "batch 9226, train_loss 72.774231,Time used 0.007999s\n",
      "batch 9227, train_loss 68.816956,Time used 0.007000s\n",
      "batch 9228, train_loss 66.623337,Time used 0.007002s\n",
      "batch 9229, train_loss 85.892235,Time used 0.008000s\n",
      "batch 9230, train_loss 96.834831,Time used 0.009001s\n",
      "batch 9231, train_loss 84.817490,Time used 0.008000s\n",
      "batch 9232, train_loss 58.022995,Time used 0.009999s\n",
      "batch 9233, train_loss 84.429939,Time used 0.006999s\n",
      "batch 9234, train_loss 85.581703,Time used 0.006999s\n",
      "batch 9235, train_loss 61.851810,Time used 0.010004s\n",
      "batch 9236, train_loss 107.504852,Time used 0.010997s\n",
      "batch 9237, train_loss 89.209785,Time used 0.010999s\n",
      "batch 9238, train_loss 73.049316,Time used 0.009002s\n",
      "batch 9239, train_loss 64.919571,Time used 0.013999s\n",
      "batch 9240, train_loss 79.516708,Time used 0.008003s\n",
      "batch 9241, train_loss 91.473457,Time used 0.009003s\n",
      "batch 9242, train_loss 69.098038,Time used 0.011999s\n",
      "batch 9243, train_loss 100.341484,Time used 0.011001s\n",
      "batch 9244, train_loss 82.391296,Time used 0.010000s\n",
      "batch 9245, train_loss 77.873528,Time used 0.008999s\n",
      "batch 9246, train_loss 73.896431,Time used 0.008000s\n",
      "batch 9247, train_loss 75.012894,Time used 0.007000s\n",
      "batch 9248, train_loss 87.995644,Time used 0.008001s\n",
      "batch 9249, train_loss 73.512947,Time used 0.008998s\n",
      "batch 9250, train_loss 52.493958,Time used 0.008000s\n",
      "batch 9251, train_loss 70.742683,Time used 0.007000s\n",
      "batch 9252, train_loss 83.648796,Time used 0.009003s\n",
      "batch 9253, train_loss 65.025986,Time used 0.006998s\n",
      "batch 9254, train_loss 77.304665,Time used 0.010003s\n",
      "batch 9255, train_loss 100.958824,Time used 0.009999s\n",
      "batch 9256, train_loss 81.998573,Time used 0.007999s\n",
      "batch 9257, train_loss 79.486809,Time used 0.007010s\n",
      "batch 9258, train_loss 70.549973,Time used 0.007988s\n",
      "batch 9259, train_loss 82.644646,Time used 0.010004s\n",
      "batch 9260, train_loss 76.425636,Time used 0.009999s\n",
      "batch 9261, train_loss 61.514912,Time used 0.009004s\n",
      "batch 9262, train_loss 74.139717,Time used 0.008997s\n",
      "batch 9263, train_loss 93.361794,Time used 0.013999s\n",
      "batch 9264, train_loss 67.507370,Time used 0.011001s\n",
      "batch 9265, train_loss 67.297585,Time used 0.008004s\n",
      "batch 9266, train_loss 82.572647,Time used 0.008994s\n",
      "batch 9267, train_loss 78.429085,Time used 0.010999s\n",
      "batch 9268, train_loss 84.617119,Time used 0.007002s\n",
      "batch 9269, train_loss 90.916176,Time used 0.007000s\n",
      "batch 9270, train_loss 65.741867,Time used 0.007000s\n",
      "batch 9271, train_loss 68.629646,Time used 0.007000s\n",
      "batch 9272, train_loss 82.517479,Time used 0.006000s\n",
      "batch 9273, train_loss 76.862129,Time used 0.007003s\n",
      "batch 9274, train_loss 76.647705,Time used 0.007999s\n",
      "batch 9275, train_loss 67.479744,Time used 0.008999s\n",
      "batch 9276, train_loss 70.745819,Time used 0.007002s\n",
      "batch 9277, train_loss 79.063103,Time used 0.009999s\n",
      "batch 9278, train_loss 93.165756,Time used 0.018000s\n",
      "batch 9279, train_loss 76.064026,Time used 0.010001s\n",
      "batch 9280, train_loss 93.315529,Time used 0.009001s\n",
      "batch 9281, train_loss 100.976067,Time used 0.006997s\n",
      "batch 9282, train_loss 86.810669,Time used 0.007999s\n",
      "batch 9283, train_loss 64.335037,Time used 0.010000s\n",
      "batch 9284, train_loss 69.537987,Time used 0.007999s\n",
      "batch 9285, train_loss 79.617966,Time used 0.007999s\n",
      "batch 9286, train_loss 78.670471,Time used 0.008001s\n",
      "batch 9287, train_loss 55.101715,Time used 0.008000s\n",
      "batch 9288, train_loss 76.070305,Time used 0.007998s\n",
      "batch 9289, train_loss 67.532623,Time used 0.006997s\n",
      "batch 9290, train_loss 64.556343,Time used 0.007002s\n",
      "batch 9291, train_loss 75.438492,Time used 0.008000s\n",
      "batch 9292, train_loss 62.164646,Time used 0.006999s\n",
      "batch 9293, train_loss 78.526726,Time used 0.007000s\n",
      "batch 9294, train_loss 74.002167,Time used 0.007999s\n",
      "batch 9295, train_loss 75.475464,Time used 0.009001s\n",
      "batch 9296, train_loss 84.385826,Time used 0.007000s\n",
      "batch 9297, train_loss 62.945782,Time used 0.007000s\n",
      "batch 9298, train_loss 83.746010,Time used 0.008002s\n",
      "batch 9299, train_loss 95.978500,Time used 0.007998s\n",
      "batch 9300, train_loss 77.410858,Time used 0.011000s\n",
      "***************************test_batch 9300, test_rmse_loss 10.151467,test_mae_loss 4.009145,test_mape_loss 61.325585,Time used 0.041002s\n",
      "batch 9301, train_loss 95.999413,Time used 0.007998s\n",
      "batch 9302, train_loss 58.148426,Time used 0.007999s\n",
      "batch 9303, train_loss 96.782341,Time used 0.007000s\n",
      "batch 9304, train_loss 81.445869,Time used 0.009000s\n",
      "batch 9305, train_loss 91.221245,Time used 0.011000s\n",
      "batch 9306, train_loss 73.502388,Time used 0.010999s\n",
      "batch 9307, train_loss 68.297920,Time used 0.010002s\n",
      "batch 9308, train_loss 81.520302,Time used 0.011001s\n",
      "batch 9309, train_loss 80.554527,Time used 0.010999s\n",
      "batch 9310, train_loss 79.021294,Time used 0.008999s\n",
      "batch 9311, train_loss 82.098381,Time used 0.010000s\n",
      "batch 9312, train_loss 69.822487,Time used 0.007003s\n",
      "batch 9313, train_loss 67.592857,Time used 0.006999s\n",
      "batch 9314, train_loss 75.655632,Time used 0.008998s\n",
      "batch 9315, train_loss 55.031361,Time used 0.009003s\n",
      "batch 9316, train_loss 87.205360,Time used 0.008999s\n",
      "batch 9317, train_loss 74.515678,Time used 0.009001s\n",
      "batch 9318, train_loss 87.683693,Time used 0.011000s\n",
      "batch 9319, train_loss 60.106472,Time used 0.008998s\n",
      "batch 9320, train_loss 89.466347,Time used 0.011005s\n",
      "batch 9321, train_loss 77.869423,Time used 0.010999s\n",
      "batch 9322, train_loss 66.348518,Time used 0.011001s\n",
      "batch 9323, train_loss 75.444298,Time used 0.011998s\n",
      "batch 9324, train_loss 91.858612,Time used 0.012000s\n",
      "batch 9325, train_loss 99.028610,Time used 0.009004s\n",
      "batch 9326, train_loss 88.563728,Time used 0.008996s\n",
      "batch 9327, train_loss 72.092484,Time used 0.009002s\n",
      "batch 9328, train_loss 84.857552,Time used 0.012001s\n",
      "batch 9329, train_loss 69.815689,Time used 0.007993s\n",
      "batch 9330, train_loss 81.256912,Time used 0.008001s\n",
      "batch 9331, train_loss 103.947807,Time used 0.008999s\n",
      "batch 9332, train_loss 69.936279,Time used 0.008001s\n",
      "batch 9333, train_loss 73.048027,Time used 0.007001s\n",
      "batch 9334, train_loss 63.819302,Time used 0.010000s\n",
      "batch 9335, train_loss 73.969391,Time used 0.007000s\n",
      "batch 9336, train_loss 66.875092,Time used 0.011998s\n",
      "batch 9337, train_loss 72.942017,Time used 0.007000s\n",
      "batch 9338, train_loss 68.192818,Time used 0.012000s\n",
      "batch 9339, train_loss 69.819466,Time used 0.011999s\n",
      "batch 9340, train_loss 71.921593,Time used 0.007000s\n",
      "batch 9341, train_loss 74.988869,Time used 0.006999s\n",
      "batch 9342, train_loss 63.343262,Time used 0.006999s\n",
      "batch 9343, train_loss 87.134972,Time used 0.009000s\n",
      "batch 9344, train_loss 67.397713,Time used 0.010000s\n",
      "batch 9345, train_loss 81.730270,Time used 0.008001s\n",
      "batch 9346, train_loss 76.597900,Time used 0.010000s\n",
      "batch 9347, train_loss 75.710754,Time used 0.007998s\n",
      "batch 9348, train_loss 74.751884,Time used 0.009003s\n",
      "batch 9349, train_loss 67.718605,Time used 0.011998s\n",
      "batch 9350, train_loss 74.321510,Time used 0.008001s\n",
      "batch 9351, train_loss 67.970924,Time used 0.008002s\n",
      "batch 9352, train_loss 83.130241,Time used 0.007995s\n",
      "batch 9353, train_loss 73.221443,Time used 0.007999s\n",
      "batch 9354, train_loss 92.123520,Time used 0.010000s\n",
      "batch 9355, train_loss 98.574081,Time used 0.010004s\n",
      "batch 9356, train_loss 67.416435,Time used 0.010001s\n",
      "batch 9357, train_loss 77.084015,Time used 0.011001s\n",
      "batch 9358, train_loss 95.744484,Time used 0.010000s\n",
      "batch 9359, train_loss 87.851227,Time used 0.007000s\n",
      "batch 9360, train_loss 82.349396,Time used 0.010001s\n",
      "batch 9361, train_loss 93.767250,Time used 0.009998s\n",
      "batch 9362, train_loss 69.422508,Time used 0.006999s\n",
      "batch 9363, train_loss 99.720871,Time used 0.007001s\n",
      "batch 9364, train_loss 100.288635,Time used 0.007999s\n",
      "batch 9365, train_loss 67.015930,Time used 0.006999s\n",
      "batch 9366, train_loss 78.652016,Time used 0.007001s\n",
      "batch 9367, train_loss 68.481133,Time used 0.008001s\n",
      "batch 9368, train_loss 78.028633,Time used 0.006999s\n",
      "batch 9369, train_loss 66.744972,Time used 0.010000s\n",
      "batch 9370, train_loss 53.328114,Time used 0.010002s\n",
      "batch 9371, train_loss 78.953789,Time used 0.007001s\n",
      "batch 9372, train_loss 83.015533,Time used 0.007000s\n",
      "batch 9373, train_loss 66.609978,Time used 0.007036s\n",
      "batch 9374, train_loss 64.050514,Time used 0.008000s\n",
      "batch 9375, train_loss 79.905563,Time used 0.006963s\n",
      "batch 9376, train_loss 82.296539,Time used 0.006999s\n",
      "batch 9377, train_loss 86.597084,Time used 0.008003s\n",
      "batch 9378, train_loss 103.092972,Time used 0.006999s\n",
      "batch 9379, train_loss 70.286903,Time used 0.009999s\n",
      "batch 9380, train_loss 75.929924,Time used 0.010001s\n",
      "batch 9381, train_loss 78.496391,Time used 0.007000s\n",
      "batch 9382, train_loss 79.514175,Time used 0.007001s\n",
      "batch 9383, train_loss 49.467201,Time used 0.008002s\n",
      "batch 9384, train_loss 73.892303,Time used 0.009998s\n",
      "batch 9385, train_loss 70.940651,Time used 0.009998s\n",
      "batch 9386, train_loss 66.829811,Time used 0.007000s\n",
      "batch 9387, train_loss 73.923019,Time used 0.007001s\n",
      "batch 9388, train_loss 40.762363,Time used 0.007001s\n",
      "batch 9389, train_loss 71.886574,Time used 0.007998s\n",
      "batch 9390, train_loss 84.627357,Time used 0.009001s\n",
      "batch 9391, train_loss 75.660713,Time used 0.007999s\n",
      "batch 9392, train_loss 83.504311,Time used 0.008000s\n",
      "batch 9393, train_loss 70.339157,Time used 0.008000s\n",
      "batch 9394, train_loss 71.284897,Time used 0.008000s\n",
      "batch 9395, train_loss 79.407524,Time used 0.009999s\n",
      "batch 9396, train_loss 93.939568,Time used 0.009003s\n",
      "batch 9397, train_loss 65.094437,Time used 0.007000s\n",
      "batch 9398, train_loss 105.742592,Time used 0.009002s\n",
      "batch 9399, train_loss 75.797318,Time used 0.009999s\n",
      "batch 9400, train_loss 69.425461,Time used 0.010002s\n",
      "***************************test_batch 9400, test_rmse_loss 10.099947,test_mae_loss 3.995403,test_mape_loss 61.427231,Time used 0.045996s\n",
      "batch 9401, train_loss 76.300713,Time used 0.012003s\n",
      "batch 9402, train_loss 87.945297,Time used 0.011001s\n",
      "batch 9403, train_loss 77.020767,Time used 0.012000s\n",
      "batch 9404, train_loss 84.258659,Time used 0.011001s\n",
      "batch 9405, train_loss 70.040428,Time used 0.013004s\n",
      "batch 9406, train_loss 90.875641,Time used 0.011998s\n",
      "batch 9407, train_loss 66.727058,Time used 0.015999s\n",
      "batch 9408, train_loss 91.288445,Time used 0.020002s\n",
      "batch 9409, train_loss 67.550598,Time used 0.016999s\n",
      "batch 9410, train_loss 75.430191,Time used 0.019006s\n",
      "batch 9411, train_loss 81.412506,Time used 0.020010s\n",
      "batch 9412, train_loss 60.633499,Time used 0.015000s\n",
      "batch 9413, train_loss 91.239548,Time used 0.024000s\n",
      "batch 9414, train_loss 78.318016,Time used 0.015002s\n",
      "batch 9415, train_loss 69.147400,Time used 0.013002s\n",
      "batch 9416, train_loss 87.526848,Time used 0.013999s\n",
      "batch 9417, train_loss 67.157532,Time used 0.007998s\n",
      "batch 9418, train_loss 80.943794,Time used 0.010002s\n",
      "batch 9419, train_loss 79.829399,Time used 0.009000s\n",
      "batch 9420, train_loss 69.923019,Time used 0.012998s\n",
      "batch 9421, train_loss 81.914017,Time used 0.014002s\n",
      "batch 9422, train_loss 106.897858,Time used 0.013009s\n",
      "batch 9423, train_loss 80.117500,Time used 0.012990s\n",
      "batch 9424, train_loss 86.437187,Time used 0.015001s\n",
      "batch 9425, train_loss 83.534836,Time used 0.017999s\n",
      "batch 9426, train_loss 75.008080,Time used 0.012001s\n",
      "batch 9427, train_loss 76.461243,Time used 0.022001s\n",
      "batch 9428, train_loss 61.014515,Time used 0.014000s\n",
      "batch 9429, train_loss 62.312279,Time used 0.012001s\n",
      "batch 9430, train_loss 61.243874,Time used 0.013000s\n",
      "batch 9431, train_loss 77.490814,Time used 0.010998s\n",
      "batch 9432, train_loss 77.402626,Time used 0.014002s\n",
      "batch 9433, train_loss 63.245468,Time used 0.010001s\n",
      "batch 9434, train_loss 77.788551,Time used 0.010999s\n",
      "batch 9435, train_loss 66.193993,Time used 0.011004s\n",
      "batch 9436, train_loss 94.818657,Time used 0.011000s\n",
      "batch 9437, train_loss 91.267418,Time used 0.013000s\n",
      "batch 9438, train_loss 62.823559,Time used 0.009999s\n",
      "batch 9439, train_loss 56.297382,Time used 0.011000s\n",
      "batch 9440, train_loss 55.863792,Time used 0.008000s\n",
      "batch 9441, train_loss 92.105545,Time used 0.011001s\n",
      "batch 9442, train_loss 88.265694,Time used 0.010999s\n",
      "batch 9443, train_loss 66.090042,Time used 0.007999s\n",
      "batch 9444, train_loss 105.495544,Time used 0.008004s\n",
      "batch 9445, train_loss 84.564156,Time used 0.007998s\n",
      "batch 9446, train_loss 65.022804,Time used 0.010001s\n",
      "batch 9447, train_loss 81.867386,Time used 0.007999s\n",
      "batch 9448, train_loss 56.654636,Time used 0.009001s\n",
      "batch 9449, train_loss 72.007240,Time used 0.007999s\n",
      "batch 9450, train_loss 82.999146,Time used 0.008001s\n",
      "batch 9451, train_loss 90.149193,Time used 0.011999s\n",
      "batch 9452, train_loss 93.795258,Time used 0.011999s\n",
      "batch 9453, train_loss 83.056419,Time used 0.011002s\n",
      "batch 9454, train_loss 80.858391,Time used 0.010000s\n",
      "batch 9455, train_loss 64.040291,Time used 0.011001s\n",
      "batch 9456, train_loss 58.667500,Time used 0.010998s\n",
      "batch 9457, train_loss 63.680676,Time used 0.010999s\n",
      "batch 9458, train_loss 71.514511,Time used 0.012002s\n",
      "batch 9459, train_loss 91.520882,Time used 0.009002s\n",
      "batch 9460, train_loss 65.783318,Time used 0.008997s\n",
      "batch 9461, train_loss 77.198883,Time used 0.007999s\n",
      "batch 9462, train_loss 63.572788,Time used 0.009000s\n",
      "batch 9463, train_loss 70.537041,Time used 0.008001s\n",
      "batch 9464, train_loss 72.326797,Time used 0.008000s\n",
      "batch 9465, train_loss 73.631493,Time used 0.008999s\n",
      "batch 9466, train_loss 77.106148,Time used 0.009000s\n",
      "batch 9467, train_loss 97.505035,Time used 0.006999s\n",
      "batch 9468, train_loss 80.386902,Time used 0.011001s\n",
      "batch 9469, train_loss 74.537773,Time used 0.010003s\n",
      "batch 9470, train_loss 56.529522,Time used 0.011997s\n",
      "batch 9471, train_loss 61.024666,Time used 0.008001s\n",
      "batch 9472, train_loss 86.274727,Time used 0.008000s\n",
      "batch 9473, train_loss 95.196365,Time used 0.009998s\n",
      "batch 9474, train_loss 67.551674,Time used 0.008003s\n",
      "batch 9475, train_loss 72.153778,Time used 0.006999s\n",
      "batch 9476, train_loss 61.190647,Time used 0.008996s\n",
      "batch 9477, train_loss 90.204857,Time used 0.008001s\n",
      "batch 9478, train_loss 97.595001,Time used 0.012000s\n",
      "batch 9479, train_loss 82.736000,Time used 0.011006s\n",
      "batch 9480, train_loss 80.709351,Time used 0.007998s\n",
      "batch 9481, train_loss 75.417740,Time used 0.010003s\n",
      "batch 9482, train_loss 92.115883,Time used 0.011996s\n",
      "batch 9483, train_loss 81.312759,Time used 0.011004s\n",
      "batch 9484, train_loss 80.986069,Time used 0.010996s\n",
      "batch 9485, train_loss 92.792152,Time used 0.011003s\n",
      "batch 9486, train_loss 55.227116,Time used 0.012000s\n",
      "batch 9487, train_loss 75.882050,Time used 0.009000s\n",
      "batch 9488, train_loss 72.579033,Time used 0.010001s\n",
      "batch 9489, train_loss 67.790001,Time used 0.011999s\n",
      "batch 9490, train_loss 88.105431,Time used 0.009998s\n",
      "batch 9491, train_loss 103.551460,Time used 0.009001s\n",
      "batch 9492, train_loss 73.276497,Time used 0.008001s\n",
      "batch 9493, train_loss 84.998917,Time used 0.012001s\n",
      "batch 9494, train_loss 100.371315,Time used 0.010998s\n",
      "batch 9495, train_loss 55.976929,Time used 0.010001s\n",
      "batch 9496, train_loss 68.804474,Time used 0.008998s\n",
      "batch 9497, train_loss 68.215736,Time used 0.008001s\n",
      "batch 9498, train_loss 82.428062,Time used 0.011001s\n",
      "batch 9499, train_loss 66.063469,Time used 0.009001s\n",
      "batch 9500, train_loss 60.390587,Time used 0.011997s\n",
      "***************************test_batch 9500, test_rmse_loss 10.049721,test_mae_loss 3.980240,test_mape_loss 61.395370,Time used 0.036000s\n",
      "batch 9501, train_loss 86.641434,Time used 0.008001s\n",
      "batch 9502, train_loss 63.687580,Time used 0.006999s\n",
      "batch 9503, train_loss 55.982700,Time used 0.009002s\n",
      "batch 9504, train_loss 73.442253,Time used 0.008000s\n",
      "batch 9505, train_loss 88.642723,Time used 0.010991s\n",
      "batch 9506, train_loss 87.106812,Time used 0.009000s\n",
      "batch 9507, train_loss 64.997498,Time used 0.011002s\n",
      "batch 9508, train_loss 85.988495,Time used 0.010002s\n",
      "batch 9509, train_loss 84.554573,Time used 0.009000s\n",
      "batch 9510, train_loss 62.512299,Time used 0.010002s\n",
      "batch 9511, train_loss 88.920311,Time used 0.010000s\n",
      "batch 9512, train_loss 74.181839,Time used 0.012001s\n",
      "batch 9513, train_loss 62.739758,Time used 0.010000s\n",
      "batch 9514, train_loss 88.642708,Time used 0.011000s\n",
      "batch 9515, train_loss 71.149826,Time used 0.011000s\n",
      "batch 9516, train_loss 62.694233,Time used 0.011000s\n",
      "batch 9517, train_loss 86.535744,Time used 0.007997s\n",
      "batch 9518, train_loss 85.305504,Time used 0.009002s\n",
      "batch 9519, train_loss 73.919365,Time used 0.011002s\n",
      "batch 9520, train_loss 88.871429,Time used 0.010999s\n",
      "batch 9521, train_loss 71.357124,Time used 0.010001s\n",
      "batch 9522, train_loss 87.450851,Time used 0.008000s\n",
      "batch 9523, train_loss 52.757385,Time used 0.010002s\n",
      "batch 9524, train_loss 81.464706,Time used 0.012000s\n",
      "batch 9525, train_loss 59.989975,Time used 0.007000s\n",
      "batch 9526, train_loss 60.173561,Time used 0.007999s\n",
      "batch 9527, train_loss 73.325539,Time used 0.009000s\n",
      "batch 9528, train_loss 78.650757,Time used 0.010003s\n",
      "batch 9529, train_loss 64.523033,Time used 0.011999s\n",
      "batch 9530, train_loss 73.993988,Time used 0.012002s\n",
      "batch 9531, train_loss 87.099716,Time used 0.011998s\n",
      "batch 9532, train_loss 67.390411,Time used 0.011003s\n",
      "batch 9533, train_loss 66.986374,Time used 0.009004s\n",
      "batch 9534, train_loss 74.837868,Time used 0.008997s\n",
      "batch 9535, train_loss 75.237831,Time used 0.011001s\n",
      "batch 9536, train_loss 81.725998,Time used 0.011999s\n",
      "batch 9537, train_loss 85.338226,Time used 0.012002s\n",
      "batch 9538, train_loss 73.770393,Time used 0.011000s\n",
      "batch 9539, train_loss 78.433418,Time used 0.011000s\n",
      "batch 9540, train_loss 76.005020,Time used 0.008997s\n",
      "batch 9541, train_loss 73.856384,Time used 0.008000s\n",
      "batch 9542, train_loss 73.962425,Time used 0.011003s\n",
      "batch 9543, train_loss 67.077126,Time used 0.010001s\n",
      "batch 9544, train_loss 77.466782,Time used 0.009000s\n",
      "batch 9545, train_loss 62.015076,Time used 0.011998s\n",
      "batch 9546, train_loss 72.133049,Time used 0.013999s\n",
      "batch 9547, train_loss 89.231674,Time used 0.014003s\n",
      "batch 9548, train_loss 76.588478,Time used 0.012998s\n",
      "batch 9549, train_loss 63.238907,Time used 0.012999s\n",
      "batch 9550, train_loss 93.862595,Time used 0.012000s\n",
      "batch 9551, train_loss 86.722839,Time used 0.019000s\n",
      "batch 9552, train_loss 76.151161,Time used 0.012000s\n",
      "batch 9553, train_loss 54.265587,Time used 0.012000s\n",
      "batch 9554, train_loss 47.766701,Time used 0.012003s\n",
      "batch 9555, train_loss 58.243076,Time used 0.012999s\n",
      "batch 9556, train_loss 82.199524,Time used 0.012999s\n",
      "batch 9557, train_loss 60.445633,Time used 0.013001s\n",
      "batch 9558, train_loss 81.026131,Time used 0.013999s\n",
      "batch 9559, train_loss 55.666981,Time used 0.031000s\n",
      "batch 9560, train_loss 69.148682,Time used 0.012997s\n",
      "batch 9561, train_loss 89.408752,Time used 0.016999s\n",
      "batch 9562, train_loss 71.434242,Time used 0.014001s\n",
      "batch 9563, train_loss 82.524345,Time used 0.015000s\n",
      "batch 9564, train_loss 95.058586,Time used 0.016999s\n",
      "batch 9565, train_loss 81.374039,Time used 0.016999s\n",
      "batch 9566, train_loss 84.024750,Time used 0.017002s\n",
      "batch 9567, train_loss 66.297516,Time used 0.021999s\n",
      "batch 9568, train_loss 80.556564,Time used 0.015000s\n",
      "batch 9569, train_loss 83.985062,Time used 0.013002s\n",
      "batch 9570, train_loss 90.716362,Time used 0.011996s\n",
      "batch 9571, train_loss 84.965416,Time used 0.011003s\n",
      "batch 9572, train_loss 86.317871,Time used 0.010001s\n",
      "batch 9573, train_loss 67.253090,Time used 0.010998s\n",
      "batch 9574, train_loss 86.266388,Time used 0.011001s\n",
      "batch 9575, train_loss 92.847115,Time used 0.012000s\n",
      "batch 9576, train_loss 61.189896,Time used 0.013001s\n",
      "batch 9577, train_loss 69.273071,Time used 0.023001s\n",
      "batch 9578, train_loss 70.233131,Time used 0.013999s\n",
      "batch 9579, train_loss 79.988739,Time used 0.014001s\n",
      "batch 9580, train_loss 80.292168,Time used 0.014003s\n",
      "batch 9581, train_loss 63.095200,Time used 0.011997s\n",
      "batch 9582, train_loss 76.934975,Time used 0.011000s\n",
      "batch 9583, train_loss 93.142242,Time used 0.008999s\n",
      "batch 9584, train_loss 77.886452,Time used 0.012001s\n",
      "batch 9585, train_loss 80.441750,Time used 0.016004s\n",
      "batch 9586, train_loss 62.306816,Time used 0.012998s\n",
      "batch 9587, train_loss 89.372299,Time used 0.013001s\n",
      "batch 9588, train_loss 68.905373,Time used 0.013000s\n",
      "batch 9589, train_loss 91.824005,Time used 0.013999s\n",
      "batch 9590, train_loss 70.445732,Time used 0.013002s\n",
      "batch 9591, train_loss 56.701221,Time used 0.020997s\n",
      "batch 9592, train_loss 73.930992,Time used 0.014999s\n",
      "batch 9593, train_loss 68.678047,Time used 0.012002s\n",
      "batch 9594, train_loss 61.773605,Time used 0.012999s\n",
      "batch 9595, train_loss 108.554054,Time used 0.008999s\n",
      "batch 9596, train_loss 77.103928,Time used 0.012000s\n",
      "batch 9597, train_loss 69.023567,Time used 0.014002s\n",
      "batch 9598, train_loss 66.793640,Time used 0.010999s\n",
      "batch 9599, train_loss 82.792786,Time used 0.011001s\n",
      "batch 9600, train_loss 69.646652,Time used 0.012001s\n",
      "***************************test_batch 9600, test_rmse_loss 10.000999,test_mae_loss 3.964995,test_mape_loss 61.330719,Time used 0.045997s\n",
      "batch 9601, train_loss 73.464813,Time used 0.015000s\n",
      "batch 9602, train_loss 71.430969,Time used 0.016000s\n",
      "batch 9603, train_loss 102.988029,Time used 0.026999s\n",
      "batch 9604, train_loss 51.397011,Time used 0.013999s\n",
      "batch 9605, train_loss 79.853584,Time used 0.012999s\n",
      "batch 9606, train_loss 71.647461,Time used 0.013000s\n",
      "batch 9607, train_loss 71.211166,Time used 0.012999s\n",
      "batch 9608, train_loss 90.312103,Time used 0.012002s\n",
      "batch 9609, train_loss 82.216942,Time used 0.008002s\n",
      "batch 9610, train_loss 76.011185,Time used 0.012000s\n",
      "batch 9611, train_loss 73.335022,Time used 0.011998s\n",
      "batch 9612, train_loss 84.716118,Time used 0.012001s\n",
      "batch 9613, train_loss 77.314461,Time used 0.011998s\n",
      "batch 9614, train_loss 59.246613,Time used 0.012004s\n",
      "batch 9615, train_loss 64.506851,Time used 0.017999s\n",
      "batch 9616, train_loss 70.050987,Time used 0.016000s\n",
      "batch 9617, train_loss 75.783142,Time used 0.011999s\n",
      "batch 9618, train_loss 71.357590,Time used 0.012004s\n",
      "batch 9619, train_loss 72.943802,Time used 0.010998s\n",
      "batch 9620, train_loss 86.856277,Time used 0.011000s\n",
      "batch 9621, train_loss 82.314468,Time used 0.008998s\n",
      "batch 9622, train_loss 61.702583,Time used 0.008002s\n",
      "batch 9623, train_loss 81.321342,Time used 0.009998s\n",
      "batch 9624, train_loss 73.076767,Time used 0.011000s\n",
      "batch 9625, train_loss 79.768105,Time used 0.011001s\n",
      "batch 9626, train_loss 69.870224,Time used 0.015001s\n",
      "batch 9627, train_loss 80.905914,Time used 0.011999s\n",
      "batch 9628, train_loss 87.645950,Time used 0.013002s\n",
      "batch 9629, train_loss 86.378113,Time used 0.011000s\n",
      "batch 9630, train_loss 64.919937,Time used 0.011001s\n",
      "batch 9631, train_loss 85.533020,Time used 0.016999s\n",
      "batch 9632, train_loss 47.542168,Time used 0.016000s\n",
      "batch 9633, train_loss 74.897491,Time used 0.014000s\n",
      "batch 9634, train_loss 80.940369,Time used 0.012001s\n",
      "batch 9635, train_loss 61.357384,Time used 0.013001s\n",
      "batch 9636, train_loss 74.257690,Time used 0.010999s\n",
      "batch 9637, train_loss 89.394012,Time used 0.013001s\n",
      "batch 9638, train_loss 80.208427,Time used 0.011007s\n",
      "batch 9639, train_loss 74.809090,Time used 0.013996s\n",
      "batch 9640, train_loss 79.185005,Time used 0.013001s\n",
      "batch 9641, train_loss 60.842255,Time used 0.015000s\n",
      "batch 9642, train_loss 72.160553,Time used 0.013998s\n",
      "batch 9643, train_loss 88.152496,Time used 0.014001s\n",
      "batch 9644, train_loss 70.965607,Time used 0.014999s\n",
      "batch 9645, train_loss 71.874260,Time used 0.013000s\n",
      "batch 9646, train_loss 75.563919,Time used 0.012000s\n",
      "batch 9647, train_loss 58.980011,Time used 0.014000s\n",
      "batch 9648, train_loss 85.449875,Time used 0.025002s\n",
      "batch 9649, train_loss 80.572029,Time used 0.011998s\n",
      "batch 9650, train_loss 65.536652,Time used 0.013003s\n",
      "batch 9651, train_loss 77.499229,Time used 0.011000s\n",
      "batch 9652, train_loss 82.348404,Time used 0.011001s\n",
      "batch 9653, train_loss 84.716743,Time used 0.013001s\n",
      "batch 9654, train_loss 93.354988,Time used 0.013007s\n",
      "batch 9655, train_loss 78.781120,Time used 0.012993s\n",
      "batch 9656, train_loss 60.132133,Time used 0.012999s\n",
      "batch 9657, train_loss 72.303345,Time used 0.011999s\n",
      "batch 9658, train_loss 69.988945,Time used 0.012001s\n",
      "batch 9659, train_loss 54.909328,Time used 0.011000s\n",
      "batch 9660, train_loss 68.403122,Time used 0.022001s\n",
      "batch 9661, train_loss 75.143089,Time used 0.013001s\n",
      "batch 9662, train_loss 68.852242,Time used 0.011998s\n",
      "batch 9663, train_loss 88.017075,Time used 0.011999s\n",
      "batch 9664, train_loss 78.618469,Time used 0.012000s\n",
      "batch 9665, train_loss 78.183273,Time used 0.010000s\n",
      "batch 9666, train_loss 76.099113,Time used 0.011000s\n",
      "batch 9667, train_loss 71.602989,Time used 0.011002s\n",
      "batch 9668, train_loss 80.516548,Time used 0.009000s\n",
      "batch 9669, train_loss 74.882195,Time used 0.012999s\n",
      "batch 9670, train_loss 73.425751,Time used 0.011999s\n",
      "batch 9671, train_loss 64.811951,Time used 0.010000s\n",
      "batch 9672, train_loss 78.605301,Time used 0.011001s\n",
      "batch 9673, train_loss 82.763641,Time used 0.012000s\n",
      "batch 9674, train_loss 79.755371,Time used 0.011999s\n",
      "batch 9675, train_loss 68.653404,Time used 0.012999s\n",
      "batch 9676, train_loss 65.903572,Time used 0.012000s\n",
      "batch 9677, train_loss 63.807598,Time used 0.009000s\n",
      "batch 9678, train_loss 82.635902,Time used 0.011000s\n",
      "batch 9679, train_loss 62.506016,Time used 0.011005s\n",
      "batch 9680, train_loss 82.171715,Time used 0.010999s\n",
      "batch 9681, train_loss 70.749748,Time used 0.012001s\n",
      "batch 9682, train_loss 84.103165,Time used 0.011000s\n",
      "batch 9683, train_loss 66.304047,Time used 0.012001s\n",
      "batch 9684, train_loss 88.524200,Time used 0.010996s\n",
      "batch 9685, train_loss 75.050507,Time used 0.011001s\n",
      "batch 9686, train_loss 73.731216,Time used 0.010999s\n",
      "batch 9687, train_loss 72.847702,Time used 0.012001s\n",
      "batch 9688, train_loss 98.466255,Time used 0.013000s\n",
      "batch 9689, train_loss 65.650490,Time used 0.012002s\n",
      "batch 9690, train_loss 85.747963,Time used 0.020004s\n",
      "batch 9691, train_loss 73.137314,Time used 0.020000s\n",
      "batch 9692, train_loss 70.542244,Time used 0.011000s\n",
      "batch 9693, train_loss 70.407532,Time used 0.012000s\n",
      "batch 9694, train_loss 68.939110,Time used 0.012000s\n",
      "batch 9695, train_loss 68.161865,Time used 0.013000s\n",
      "batch 9696, train_loss 72.427025,Time used 0.012000s\n",
      "batch 9697, train_loss 67.250374,Time used 0.011001s\n",
      "batch 9698, train_loss 87.182861,Time used 0.012001s\n",
      "batch 9699, train_loss 62.017864,Time used 0.009998s\n",
      "batch 9700, train_loss 89.123589,Time used 0.010001s\n",
      "***************************test_batch 9700, test_rmse_loss 9.957578,test_mae_loss 3.943071,test_mape_loss 60.536206,Time used 0.046001s\n",
      "batch 9701, train_loss 78.213593,Time used 0.012001s\n",
      "batch 9702, train_loss 76.408821,Time used 0.009999s\n",
      "batch 9703, train_loss 86.652939,Time used 0.011999s\n",
      "batch 9704, train_loss 72.742485,Time used 0.012000s\n",
      "batch 9705, train_loss 86.640823,Time used 0.010998s\n",
      "batch 9706, train_loss 67.876228,Time used 0.008000s\n",
      "batch 9707, train_loss 90.743401,Time used 0.008002s\n",
      "batch 9708, train_loss 91.987068,Time used 0.008000s\n",
      "batch 9709, train_loss 79.650414,Time used 0.010999s\n",
      "batch 9710, train_loss 70.206543,Time used 0.010000s\n",
      "batch 9711, train_loss 61.752014,Time used 0.010999s\n",
      "batch 9712, train_loss 69.890503,Time used 0.008001s\n",
      "batch 9713, train_loss 79.590668,Time used 0.007001s\n",
      "batch 9714, train_loss 74.784653,Time used 0.008002s\n",
      "batch 9715, train_loss 51.233940,Time used 0.011999s\n",
      "batch 9716, train_loss 87.289169,Time used 0.008001s\n",
      "batch 9717, train_loss 59.508724,Time used 0.009999s\n",
      "batch 9718, train_loss 60.691067,Time used 0.008001s\n",
      "batch 9719, train_loss 57.826618,Time used 0.011000s\n",
      "batch 9720, train_loss 80.439461,Time used 0.011003s\n",
      "batch 9721, train_loss 81.005058,Time used 0.011997s\n",
      "batch 9722, train_loss 57.446686,Time used 0.012002s\n",
      "batch 9723, train_loss 66.694038,Time used 0.009997s\n",
      "batch 9724, train_loss 76.728310,Time used 0.012000s\n",
      "batch 9725, train_loss 66.911880,Time used 0.008000s\n",
      "batch 9726, train_loss 69.787140,Time used 0.010000s\n",
      "batch 9727, train_loss 76.827179,Time used 0.008000s\n",
      "batch 9728, train_loss 65.963516,Time used 0.011000s\n",
      "batch 9729, train_loss 58.187515,Time used 0.011001s\n",
      "batch 9730, train_loss 90.841972,Time used 0.012999s\n",
      "batch 9731, train_loss 66.878059,Time used 0.012002s\n",
      "batch 9732, train_loss 62.653389,Time used 0.010999s\n",
      "batch 9733, train_loss 75.704803,Time used 0.012001s\n",
      "batch 9734, train_loss 89.238968,Time used 0.009999s\n",
      "batch 9735, train_loss 93.319389,Time used 0.010998s\n",
      "batch 9736, train_loss 92.700905,Time used 0.011003s\n",
      "batch 9737, train_loss 100.968147,Time used 0.015999s\n",
      "batch 9738, train_loss 78.679428,Time used 0.024001s\n",
      "batch 9739, train_loss 71.052643,Time used 0.020000s\n",
      "batch 9740, train_loss 96.792061,Time used 0.011999s\n",
      "batch 9741, train_loss 60.263714,Time used 0.010999s\n",
      "batch 9742, train_loss 61.332695,Time used 0.010998s\n",
      "batch 9743, train_loss 60.381596,Time used 0.010999s\n",
      "batch 9744, train_loss 63.984573,Time used 0.011001s\n",
      "batch 9745, train_loss 74.317169,Time used 0.010999s\n",
      "batch 9746, train_loss 56.200302,Time used 0.010002s\n",
      "batch 9747, train_loss 85.047813,Time used 0.012998s\n",
      "batch 9748, train_loss 48.019535,Time used 0.010000s\n",
      "batch 9749, train_loss 80.110329,Time used 0.011998s\n",
      "batch 9750, train_loss 78.076981,Time used 0.010999s\n",
      "batch 9751, train_loss 96.562759,Time used 0.011002s\n",
      "batch 9752, train_loss 71.056709,Time used 0.010998s\n",
      "batch 9753, train_loss 63.612213,Time used 0.008000s\n",
      "batch 9754, train_loss 74.274727,Time used 0.012002s\n",
      "batch 9755, train_loss 61.746933,Time used 0.011999s\n",
      "batch 9756, train_loss 76.097313,Time used 0.007999s\n",
      "batch 9757, train_loss 67.785309,Time used 0.010001s\n",
      "batch 9758, train_loss 80.388397,Time used 0.011000s\n",
      "batch 9759, train_loss 82.147827,Time used 0.010999s\n",
      "batch 9760, train_loss 81.169907,Time used 0.008002s\n",
      "batch 9761, train_loss 55.804314,Time used 0.007999s\n",
      "batch 9762, train_loss 80.984711,Time used 0.007001s\n",
      "batch 9763, train_loss 72.092293,Time used 0.007000s\n",
      "batch 9764, train_loss 72.621010,Time used 0.009000s\n",
      "batch 9765, train_loss 66.757462,Time used 0.009001s\n",
      "batch 9766, train_loss 99.521301,Time used 0.014000s\n",
      "batch 9767, train_loss 79.635231,Time used 0.009999s\n",
      "batch 9768, train_loss 77.202713,Time used 0.009999s\n",
      "batch 9769, train_loss 77.569824,Time used 0.011999s\n",
      "batch 9770, train_loss 63.465919,Time used 0.010001s\n",
      "batch 9771, train_loss 61.576252,Time used 0.010003s\n",
      "batch 9772, train_loss 77.969444,Time used 0.011003s\n",
      "batch 9773, train_loss 73.612595,Time used 0.012001s\n",
      "batch 9774, train_loss 70.803596,Time used 0.019998s\n",
      "batch 9775, train_loss 77.578903,Time used 0.014000s\n",
      "batch 9776, train_loss 84.041214,Time used 0.012002s\n",
      "batch 9777, train_loss 73.172791,Time used 0.012998s\n",
      "batch 9778, train_loss 92.691254,Time used 0.012999s\n",
      "batch 9779, train_loss 70.165810,Time used 0.012000s\n",
      "batch 9780, train_loss 88.730797,Time used 0.011997s\n",
      "batch 9781, train_loss 65.536041,Time used 0.014001s\n",
      "batch 9782, train_loss 68.495758,Time used 0.012000s\n",
      "batch 9783, train_loss 78.846725,Time used 0.012003s\n",
      "batch 9784, train_loss 75.789795,Time used 0.011997s\n",
      "batch 9785, train_loss 72.954033,Time used 0.012004s\n",
      "batch 9786, train_loss 67.253815,Time used 0.011001s\n",
      "batch 9787, train_loss 88.003868,Time used 0.013999s\n",
      "batch 9788, train_loss 64.260262,Time used 0.026000s\n",
      "batch 9789, train_loss 75.474648,Time used 0.013999s\n",
      "batch 9790, train_loss 56.771046,Time used 0.013000s\n",
      "batch 9791, train_loss 74.881432,Time used 0.009999s\n",
      "batch 9792, train_loss 77.417717,Time used 0.009994s\n",
      "batch 9793, train_loss 62.999302,Time used 0.008998s\n",
      "batch 9794, train_loss 90.903831,Time used 0.009001s\n",
      "batch 9795, train_loss 71.135872,Time used 0.009000s\n",
      "batch 9796, train_loss 78.237770,Time used 0.011001s\n",
      "batch 9797, train_loss 68.541908,Time used 0.011000s\n",
      "batch 9798, train_loss 57.922092,Time used 0.013998s\n",
      "batch 9799, train_loss 74.244171,Time used 0.014002s\n",
      "batch 9800, train_loss 79.891975,Time used 0.024001s\n",
      "***************************test_batch 9800, test_rmse_loss 9.907276,test_mae_loss 3.930377,test_mape_loss 60.720595,Time used 0.053000s\n",
      "batch 9801, train_loss 61.215359,Time used 0.008000s\n",
      "batch 9802, train_loss 88.107063,Time used 0.008998s\n",
      "batch 9803, train_loss 88.509308,Time used 0.007999s\n",
      "batch 9804, train_loss 53.174065,Time used 0.009001s\n",
      "batch 9805, train_loss 82.789131,Time used 0.008000s\n",
      "batch 9806, train_loss 71.370880,Time used 0.010000s\n",
      "batch 9807, train_loss 75.772522,Time used 0.015002s\n",
      "batch 9808, train_loss 82.502945,Time used 0.013000s\n",
      "batch 9809, train_loss 55.297516,Time used 0.011998s\n",
      "batch 9810, train_loss 78.601677,Time used 0.012999s\n",
      "batch 9811, train_loss 92.041061,Time used 0.012001s\n",
      "batch 9812, train_loss 82.523521,Time used 0.010999s\n",
      "batch 9813, train_loss 59.182659,Time used 0.012000s\n",
      "batch 9814, train_loss 75.527496,Time used 0.013003s\n",
      "batch 9815, train_loss 77.042580,Time used 0.011000s\n",
      "batch 9816, train_loss 65.052544,Time used 0.009000s\n",
      "batch 9817, train_loss 81.498802,Time used 0.014999s\n",
      "batch 9818, train_loss 83.872696,Time used 0.012999s\n",
      "batch 9819, train_loss 79.595192,Time used 0.012002s\n",
      "batch 9820, train_loss 72.705566,Time used 0.010999s\n",
      "batch 9821, train_loss 60.910091,Time used 0.011001s\n",
      "batch 9822, train_loss 57.324558,Time used 0.010999s\n",
      "batch 9823, train_loss 75.071930,Time used 0.012002s\n",
      "batch 9824, train_loss 77.284309,Time used 0.010998s\n",
      "batch 9825, train_loss 92.404442,Time used 0.011003s\n",
      "batch 9826, train_loss 68.210510,Time used 0.012998s\n",
      "batch 9827, train_loss 67.307915,Time used 0.013999s\n",
      "batch 9828, train_loss 74.354645,Time used 0.015001s\n",
      "batch 9829, train_loss 68.179184,Time used 0.025000s\n",
      "batch 9830, train_loss 78.888107,Time used 0.014001s\n",
      "batch 9831, train_loss 65.927055,Time used 0.010999s\n",
      "batch 9832, train_loss 55.440685,Time used 0.012001s\n",
      "batch 9833, train_loss 90.513481,Time used 0.010997s\n",
      "batch 9834, train_loss 77.986923,Time used 0.011002s\n",
      "batch 9835, train_loss 77.669296,Time used 0.011003s\n",
      "batch 9836, train_loss 45.304764,Time used 0.011998s\n",
      "batch 9837, train_loss 79.669785,Time used 0.012001s\n",
      "batch 9838, train_loss 58.612225,Time used 0.012001s\n",
      "batch 9839, train_loss 91.241768,Time used 0.011000s\n",
      "batch 9840, train_loss 90.090103,Time used 0.012997s\n",
      "batch 9841, train_loss 70.721504,Time used 0.012001s\n",
      "batch 9842, train_loss 88.308586,Time used 0.010999s\n",
      "batch 9843, train_loss 71.076530,Time used 0.009999s\n",
      "batch 9844, train_loss 89.023140,Time used 0.011000s\n",
      "batch 9845, train_loss 85.365440,Time used 0.012002s\n",
      "batch 9846, train_loss 81.109558,Time used 0.009997s\n",
      "batch 9847, train_loss 87.966255,Time used 0.008000s\n",
      "batch 9848, train_loss 63.518940,Time used 0.007998s\n",
      "batch 9849, train_loss 72.486946,Time used 0.007001s\n",
      "batch 9850, train_loss 72.480797,Time used 0.007999s\n",
      "batch 9851, train_loss 66.611916,Time used 0.016001s\n",
      "batch 9852, train_loss 63.208839,Time used 0.010002s\n",
      "batch 9853, train_loss 72.598663,Time used 0.011998s\n",
      "batch 9854, train_loss 65.105667,Time used 0.012002s\n",
      "batch 9855, train_loss 83.848618,Time used 0.012000s\n",
      "batch 9856, train_loss 73.530067,Time used 0.009001s\n",
      "batch 9857, train_loss 64.655037,Time used 0.010999s\n",
      "batch 9858, train_loss 65.047256,Time used 0.011009s\n",
      "batch 9859, train_loss 74.717140,Time used 0.012003s\n",
      "batch 9860, train_loss 88.196297,Time used 0.011998s\n",
      "batch 9861, train_loss 82.211266,Time used 0.013001s\n",
      "batch 9862, train_loss 80.772415,Time used 0.011000s\n",
      "batch 9863, train_loss 51.750195,Time used 0.011998s\n",
      "batch 9864, train_loss 50.563484,Time used 0.012002s\n",
      "batch 9865, train_loss 72.732475,Time used 0.014001s\n",
      "batch 9866, train_loss 57.525024,Time used 0.010997s\n",
      "batch 9867, train_loss 83.009804,Time used 0.012001s\n",
      "batch 9868, train_loss 69.003479,Time used 0.011999s\n",
      "batch 9869, train_loss 79.841431,Time used 0.011001s\n",
      "batch 9870, train_loss 71.748032,Time used 0.010000s\n",
      "batch 9871, train_loss 58.680088,Time used 0.010001s\n",
      "batch 9872, train_loss 68.632217,Time used 0.011997s\n",
      "batch 9873, train_loss 93.825691,Time used 0.020002s\n",
      "batch 9874, train_loss 67.937218,Time used 0.017000s\n",
      "batch 9875, train_loss 68.278404,Time used 0.017000s\n",
      "batch 9876, train_loss 66.018578,Time used 0.014999s\n",
      "batch 9877, train_loss 79.004692,Time used 0.011002s\n",
      "batch 9878, train_loss 78.733810,Time used 0.011001s\n",
      "batch 9879, train_loss 89.058617,Time used 0.011000s\n",
      "batch 9880, train_loss 63.874771,Time used 0.011997s\n",
      "batch 9881, train_loss 67.228516,Time used 0.010004s\n",
      "batch 9882, train_loss 69.770393,Time used 0.011999s\n",
      "batch 9883, train_loss 83.702362,Time used 0.013999s\n",
      "batch 9884, train_loss 65.444855,Time used 0.013000s\n",
      "batch 9885, train_loss 52.522251,Time used 0.011998s\n",
      "batch 9886, train_loss 78.814781,Time used 0.012002s\n",
      "batch 9887, train_loss 75.838829,Time used 0.012001s\n",
      "batch 9888, train_loss 101.475639,Time used 0.011999s\n",
      "batch 9889, train_loss 64.024391,Time used 0.011995s\n",
      "batch 9890, train_loss 67.464577,Time used 0.010000s\n",
      "batch 9891, train_loss 86.613510,Time used 0.009000s\n",
      "batch 9892, train_loss 80.341339,Time used 0.011001s\n",
      "batch 9893, train_loss 55.176018,Time used 0.007999s\n",
      "batch 9894, train_loss 77.894913,Time used 0.009002s\n",
      "batch 9895, train_loss 63.872017,Time used 0.010998s\n",
      "batch 9896, train_loss 99.265991,Time used 0.013003s\n",
      "batch 9897, train_loss 70.947868,Time used 0.017000s\n",
      "batch 9898, train_loss 89.015945,Time used 0.010999s\n",
      "batch 9899, train_loss 73.513084,Time used 0.011000s\n",
      "batch 9900, train_loss 72.446892,Time used 0.010002s\n",
      "***************************test_batch 9900, test_rmse_loss 9.866194,test_mae_loss 3.915062,test_mape_loss 60.409149,Time used 0.045001s\n",
      "batch 9901, train_loss 60.913078,Time used 0.011999s\n",
      "batch 9902, train_loss 82.953743,Time used 0.011000s\n",
      "batch 9903, train_loss 66.536209,Time used 0.010999s\n",
      "batch 9904, train_loss 78.654175,Time used 0.011999s\n",
      "batch 9905, train_loss 85.334061,Time used 0.009000s\n",
      "batch 9906, train_loss 72.968117,Time used 0.010000s\n",
      "batch 9907, train_loss 61.110462,Time used 0.010999s\n",
      "batch 9908, train_loss 71.880814,Time used 0.009002s\n",
      "batch 9909, train_loss 74.863510,Time used 0.011997s\n",
      "batch 9910, train_loss 51.099472,Time used 0.011001s\n",
      "batch 9911, train_loss 79.810051,Time used 0.011999s\n",
      "batch 9912, train_loss 70.493782,Time used 0.011001s\n",
      "batch 9913, train_loss 77.367325,Time used 0.012002s\n",
      "batch 9914, train_loss 63.484020,Time used 0.015002s\n",
      "batch 9915, train_loss 65.630348,Time used 0.023998s\n",
      "batch 9916, train_loss 64.744949,Time used 0.012999s\n",
      "batch 9917, train_loss 70.530853,Time used 0.013002s\n",
      "batch 9918, train_loss 71.043594,Time used 0.011998s\n",
      "batch 9919, train_loss 75.599037,Time used 0.011999s\n",
      "batch 9920, train_loss 95.491539,Time used 0.010002s\n",
      "batch 9921, train_loss 80.023659,Time used 0.011002s\n",
      "batch 9922, train_loss 82.598938,Time used 0.012002s\n",
      "batch 9923, train_loss 84.043655,Time used 0.010999s\n",
      "batch 9924, train_loss 81.911613,Time used 0.012000s\n",
      "batch 9925, train_loss 58.275105,Time used 0.012002s\n",
      "batch 9926, train_loss 42.478161,Time used 0.011998s\n",
      "batch 9927, train_loss 69.770523,Time used 0.013001s\n",
      "batch 9928, train_loss 78.585281,Time used 0.013000s\n",
      "batch 9929, train_loss 77.294136,Time used 0.011003s\n",
      "batch 9930, train_loss 74.072769,Time used 0.012997s\n",
      "batch 9931, train_loss 70.796326,Time used 0.010002s\n",
      "batch 9932, train_loss 75.863380,Time used 0.010999s\n",
      "batch 9933, train_loss 78.462212,Time used 0.008001s\n",
      "batch 9934, train_loss 95.187614,Time used 0.007999s\n",
      "batch 9935, train_loss 52.439018,Time used 0.007000s\n",
      "batch 9936, train_loss 67.566071,Time used 0.008001s\n",
      "batch 9937, train_loss 55.981262,Time used 0.009003s\n",
      "batch 9938, train_loss 74.494995,Time used 0.007000s\n",
      "batch 9939, train_loss 70.572914,Time used 0.007999s\n",
      "batch 9940, train_loss 74.011292,Time used 0.008998s\n",
      "batch 9941, train_loss 55.580906,Time used 0.008001s\n",
      "batch 9942, train_loss 58.228107,Time used 0.010001s\n",
      "batch 9943, train_loss 90.377449,Time used 0.009000s\n",
      "batch 9944, train_loss 56.315357,Time used 0.014003s\n",
      "batch 9945, train_loss 92.908379,Time used 0.013998s\n",
      "batch 9946, train_loss 80.800026,Time used 0.011000s\n",
      "batch 9947, train_loss 78.795555,Time used 0.012998s\n",
      "batch 9948, train_loss 70.517342,Time used 0.013001s\n",
      "batch 9949, train_loss 76.839439,Time used 0.013000s\n",
      "batch 9950, train_loss 63.463177,Time used 0.012000s\n",
      "batch 9951, train_loss 65.737358,Time used 0.011000s\n",
      "batch 9952, train_loss 67.752472,Time used 0.013000s\n",
      "batch 9953, train_loss 69.515762,Time used 0.010997s\n",
      "batch 9954, train_loss 72.895981,Time used 0.011002s\n",
      "batch 9955, train_loss 78.308159,Time used 0.010999s\n",
      "batch 9956, train_loss 78.239502,Time used 0.012001s\n",
      "batch 9957, train_loss 105.136986,Time used 0.009999s\n",
      "batch 9958, train_loss 64.371178,Time used 0.012002s\n",
      "batch 9959, train_loss 81.331482,Time used 0.012001s\n",
      "batch 9960, train_loss 67.283852,Time used 0.011999s\n",
      "batch 9961, train_loss 70.122833,Time used 0.011999s\n",
      "batch 9962, train_loss 80.200935,Time used 0.010000s\n",
      "batch 9963, train_loss 95.126610,Time used 0.011003s\n",
      "batch 9964, train_loss 63.943279,Time used 0.014000s\n",
      "batch 9965, train_loss 68.187798,Time used 0.015001s\n",
      "batch 9966, train_loss 60.255154,Time used 0.022999s\n",
      "batch 9967, train_loss 86.359474,Time used 0.013000s\n",
      "batch 9968, train_loss 66.868149,Time used 0.011000s\n",
      "batch 9969, train_loss 82.606537,Time used 0.010992s\n",
      "batch 9970, train_loss 74.001907,Time used 0.013002s\n",
      "batch 9971, train_loss 79.770744,Time used 0.010000s\n",
      "batch 9972, train_loss 49.036533,Time used 0.010998s\n",
      "batch 9973, train_loss 78.263039,Time used 0.012000s\n",
      "batch 9974, train_loss 93.223061,Time used 0.020002s\n",
      "batch 9975, train_loss 60.807693,Time used 0.011998s\n",
      "batch 9976, train_loss 83.532532,Time used 0.012001s\n",
      "batch 9977, train_loss 80.506660,Time used 0.011999s\n",
      "batch 9978, train_loss 71.339134,Time used 0.010999s\n",
      "batch 9979, train_loss 56.328960,Time used 0.012001s\n",
      "batch 9980, train_loss 70.285133,Time used 0.011003s\n",
      "batch 9981, train_loss 68.315834,Time used 0.011005s\n",
      "batch 9982, train_loss 67.587837,Time used 0.009993s\n",
      "batch 9983, train_loss 72.448494,Time used 0.009004s\n",
      "batch 9984, train_loss 67.327606,Time used 0.007998s\n",
      "batch 9985, train_loss 94.096916,Time used 0.008001s\n",
      "batch 9986, train_loss 85.495728,Time used 0.008000s\n",
      "batch 9987, train_loss 43.844536,Time used 0.007999s\n",
      "batch 9988, train_loss 58.496113,Time used 0.007000s\n",
      "batch 9989, train_loss 78.194244,Time used 0.008001s\n",
      "batch 9990, train_loss 81.020798,Time used 0.006999s\n",
      "batch 9991, train_loss 69.984344,Time used 0.008001s\n",
      "batch 9992, train_loss 81.257614,Time used 0.013000s\n",
      "batch 9993, train_loss 75.339691,Time used 0.010001s\n",
      "batch 9994, train_loss 61.064335,Time used 0.011998s\n",
      "batch 9995, train_loss 79.267349,Time used 0.011001s\n",
      "batch 9996, train_loss 61.119122,Time used 0.010000s\n",
      "batch 9997, train_loss 66.625275,Time used 0.011000s\n",
      "batch 9998, train_loss 74.830650,Time used 0.010001s\n",
      "batch 9999, train_loss 75.234024,Time used 0.011002s\n",
      "batch 10000, train_loss 87.548286,Time used 0.010997s\n",
      "***************************test_batch 10000, test_rmse_loss 9.818634,test_mae_loss 3.897967,test_mape_loss 60.199291,Time used 0.047003s\n",
      "batch 10001, train_loss 75.623459,Time used 0.011999s\n",
      "batch 10002, train_loss 93.284256,Time used 0.012001s\n",
      "batch 10003, train_loss 73.644409,Time used 0.010001s\n",
      "batch 10004, train_loss 62.648365,Time used 0.011999s\n",
      "batch 10005, train_loss 61.012527,Time used 0.010995s\n",
      "batch 10006, train_loss 61.440842,Time used 0.012999s\n",
      "batch 10007, train_loss 73.873352,Time used 0.011002s\n",
      "batch 10008, train_loss 67.246758,Time used 0.010998s\n",
      "batch 10009, train_loss 72.938828,Time used 0.011002s\n",
      "batch 10010, train_loss 65.788132,Time used 0.012999s\n",
      "batch 10011, train_loss 64.815842,Time used 0.013997s\n",
      "batch 10012, train_loss 64.447731,Time used 0.013001s\n",
      "batch 10013, train_loss 76.702827,Time used 0.024001s\n",
      "batch 10014, train_loss 79.947922,Time used 0.013000s\n",
      "batch 10015, train_loss 74.263535,Time used 0.014998s\n",
      "batch 10016, train_loss 82.892471,Time used 0.013999s\n",
      "batch 10017, train_loss 82.679436,Time used 0.010000s\n",
      "batch 10018, train_loss 72.959129,Time used 0.012001s\n",
      "batch 10019, train_loss 68.589531,Time used 0.011000s\n",
      "batch 10020, train_loss 80.533241,Time used 0.012001s\n",
      "batch 10021, train_loss 61.688625,Time used 0.012001s\n",
      "batch 10022, train_loss 58.098057,Time used 0.012000s\n",
      "batch 10023, train_loss 69.563850,Time used 0.012000s\n",
      "batch 10024, train_loss 75.195427,Time used 0.011999s\n",
      "batch 10025, train_loss 80.357979,Time used 0.011003s\n",
      "batch 10026, train_loss 72.078667,Time used 0.012001s\n",
      "batch 10027, train_loss 73.432663,Time used 0.011001s\n",
      "batch 10028, train_loss 70.266617,Time used 0.011999s\n",
      "batch 10029, train_loss 61.284718,Time used 0.014000s\n",
      "batch 10030, train_loss 90.277359,Time used 0.012001s\n",
      "batch 10031, train_loss 61.034683,Time used 0.009002s\n",
      "batch 10032, train_loss 79.085075,Time used 0.010998s\n",
      "batch 10033, train_loss 73.208214,Time used 0.010001s\n",
      "batch 10034, train_loss 81.302101,Time used 0.011001s\n",
      "batch 10035, train_loss 64.527916,Time used 0.009999s\n",
      "batch 10036, train_loss 55.031666,Time used 0.009999s\n",
      "batch 10037, train_loss 63.469154,Time used 0.013001s\n",
      "batch 10038, train_loss 93.878815,Time used 0.012001s\n",
      "batch 10039, train_loss 72.234535,Time used 0.009999s\n",
      "batch 10040, train_loss 71.063202,Time used 0.009001s\n",
      "batch 10041, train_loss 72.154564,Time used 0.011001s\n",
      "batch 10042, train_loss 80.316170,Time used 0.008000s\n",
      "batch 10043, train_loss 75.119034,Time used 0.011999s\n",
      "batch 10044, train_loss 87.481110,Time used 0.010000s\n",
      "batch 10045, train_loss 65.368362,Time used 0.008002s\n",
      "batch 10046, train_loss 64.196999,Time used 0.008000s\n",
      "batch 10047, train_loss 86.346504,Time used 0.010000s\n",
      "batch 10048, train_loss 47.074860,Time used 0.009999s\n",
      "batch 10049, train_loss 76.688889,Time used 0.009001s\n",
      "batch 10050, train_loss 64.316772,Time used 0.007999s\n",
      "batch 10051, train_loss 65.617729,Time used 0.009005s\n",
      "batch 10052, train_loss 82.503494,Time used 0.006998s\n",
      "batch 10053, train_loss 77.119873,Time used 0.008998s\n",
      "batch 10054, train_loss 60.981365,Time used 0.007000s\n",
      "batch 10055, train_loss 89.835861,Time used 0.009004s\n",
      "batch 10056, train_loss 64.675407,Time used 0.010998s\n",
      "batch 10057, train_loss 78.400681,Time used 0.008995s\n",
      "batch 10058, train_loss 58.072887,Time used 0.008000s\n",
      "batch 10059, train_loss 50.145878,Time used 0.007004s\n",
      "batch 10060, train_loss 57.918812,Time used 0.007997s\n",
      "batch 10061, train_loss 71.152702,Time used 0.008000s\n",
      "batch 10062, train_loss 68.858727,Time used 0.007999s\n",
      "batch 10063, train_loss 65.635170,Time used 0.009003s\n",
      "batch 10064, train_loss 56.719639,Time used 0.007997s\n",
      "batch 10065, train_loss 85.567886,Time used 0.008999s\n",
      "batch 10066, train_loss 70.563728,Time used 0.006999s\n",
      "batch 10067, train_loss 73.896866,Time used 0.007001s\n",
      "batch 10068, train_loss 66.546867,Time used 0.007037s\n",
      "batch 10069, train_loss 104.515785,Time used 0.008999s\n",
      "batch 10070, train_loss 59.930687,Time used 0.006962s\n",
      "batch 10071, train_loss 84.322922,Time used 0.007000s\n",
      "batch 10072, train_loss 79.556557,Time used 0.007001s\n",
      "batch 10073, train_loss 68.561172,Time used 0.007998s\n",
      "batch 10074, train_loss 89.209015,Time used 0.008000s\n",
      "batch 10075, train_loss 84.739944,Time used 0.008037s\n",
      "batch 10076, train_loss 64.427246,Time used 0.006963s\n",
      "batch 10077, train_loss 55.239132,Time used 0.006999s\n",
      "batch 10078, train_loss 78.155319,Time used 0.007001s\n",
      "batch 10079, train_loss 79.390038,Time used 0.009000s\n",
      "batch 10080, train_loss 79.898857,Time used 0.011034s\n",
      "batch 10081, train_loss 73.932121,Time used 0.011000s\n",
      "batch 10082, train_loss 94.330330,Time used 0.008998s\n",
      "batch 10083, train_loss 80.850197,Time used 0.008001s\n",
      "batch 10084, train_loss 77.260307,Time used 0.008000s\n",
      "batch 10085, train_loss 69.463768,Time used 0.007999s\n",
      "batch 10086, train_loss 60.780479,Time used 0.008000s\n",
      "batch 10087, train_loss 59.331482,Time used 0.008000s\n",
      "batch 10088, train_loss 73.657166,Time used 0.007000s\n",
      "batch 10089, train_loss 78.278023,Time used 0.008038s\n",
      "batch 10090, train_loss 52.911953,Time used 0.006997s\n",
      "batch 10091, train_loss 67.367821,Time used 0.007966s\n",
      "batch 10092, train_loss 64.855408,Time used 0.007000s\n",
      "batch 10093, train_loss 83.674210,Time used 0.007998s\n",
      "batch 10094, train_loss 93.763756,Time used 0.010000s\n",
      "batch 10095, train_loss 84.779800,Time used 0.008042s\n",
      "batch 10096, train_loss 64.938148,Time used 0.006994s\n",
      "batch 10097, train_loss 64.430611,Time used 0.008964s\n",
      "batch 10098, train_loss 60.984497,Time used 0.008005s\n",
      "batch 10099, train_loss 54.247742,Time used 0.007997s\n",
      "batch 10100, train_loss 69.888962,Time used 0.009998s\n",
      "***************************test_batch 10100, test_rmse_loss 9.773934,test_mae_loss 3.881628,test_mape_loss 59.923279,Time used 0.034002s\n",
      "batch 10101, train_loss 68.077141,Time used 0.006967s\n",
      "batch 10102, train_loss 76.870834,Time used 0.010034s\n",
      "batch 10103, train_loss 74.044662,Time used 0.008001s\n",
      "batch 10104, train_loss 78.994148,Time used 0.007965s\n",
      "batch 10105, train_loss 79.195946,Time used 0.006995s\n",
      "batch 10106, train_loss 82.604553,Time used 0.006965s\n",
      "batch 10107, train_loss 75.098022,Time used 0.007038s\n",
      "batch 10108, train_loss 65.568657,Time used 0.006963s\n",
      "batch 10109, train_loss 58.505909,Time used 0.009037s\n",
      "batch 10110, train_loss 79.365204,Time used 0.007000s\n",
      "batch 10111, train_loss 86.674492,Time used 0.006964s\n",
      "batch 10112, train_loss 77.291466,Time used 0.008998s\n",
      "batch 10113, train_loss 81.756989,Time used 0.008000s\n",
      "batch 10114, train_loss 71.379845,Time used 0.006998s\n",
      "batch 10115, train_loss 72.604874,Time used 0.009000s\n",
      "batch 10116, train_loss 72.272644,Time used 0.008004s\n",
      "batch 10117, train_loss 93.990425,Time used 0.007995s\n",
      "batch 10118, train_loss 69.654305,Time used 0.007038s\n",
      "batch 10119, train_loss 75.181877,Time used 0.010998s\n",
      "batch 10120, train_loss 78.239693,Time used 0.011001s\n",
      "batch 10121, train_loss 52.371674,Time used 0.007962s\n",
      "batch 10122, train_loss 54.808414,Time used 0.007003s\n",
      "batch 10123, train_loss 68.425896,Time used 0.006998s\n",
      "batch 10124, train_loss 51.098705,Time used 0.009001s\n",
      "batch 10125, train_loss 66.050079,Time used 0.009000s\n",
      "batch 10126, train_loss 74.217834,Time used 0.011034s\n",
      "batch 10127, train_loss 75.012177,Time used 0.008967s\n",
      "batch 10128, train_loss 61.817795,Time used 0.010998s\n",
      "batch 10129, train_loss 91.210495,Time used 0.010999s\n",
      "batch 10130, train_loss 81.705299,Time used 0.008968s\n",
      "batch 10131, train_loss 72.148598,Time used 0.006998s\n",
      "batch 10132, train_loss 79.297272,Time used 0.007001s\n",
      "batch 10133, train_loss 76.125534,Time used 0.009001s\n",
      "batch 10134, train_loss 66.486084,Time used 0.008000s\n",
      "batch 10135, train_loss 67.839630,Time used 0.008000s\n",
      "batch 10136, train_loss 72.559036,Time used 0.011000s\n",
      "batch 10137, train_loss 90.744827,Time used 0.006999s\n",
      "batch 10138, train_loss 53.356140,Time used 0.007998s\n",
      "batch 10139, train_loss 57.056671,Time used 0.007999s\n",
      "batch 10140, train_loss 57.229324,Time used 0.007001s\n",
      "batch 10141, train_loss 61.176785,Time used 0.010001s\n",
      "batch 10142, train_loss 73.469978,Time used 0.011000s\n",
      "batch 10143, train_loss 63.569557,Time used 0.010000s\n",
      "batch 10144, train_loss 72.961998,Time used 0.011000s\n",
      "batch 10145, train_loss 82.268410,Time used 0.010999s\n",
      "batch 10146, train_loss 69.385765,Time used 0.007001s\n",
      "batch 10147, train_loss 96.436638,Time used 0.007000s\n",
      "batch 10148, train_loss 63.858955,Time used 0.009000s\n",
      "batch 10149, train_loss 57.781425,Time used 0.008003s\n",
      "batch 10150, train_loss 77.106087,Time used 0.010003s\n",
      "batch 10151, train_loss 67.531212,Time used 0.010995s\n",
      "batch 10152, train_loss 68.714127,Time used 0.010999s\n",
      "batch 10153, train_loss 67.509552,Time used 0.009000s\n",
      "batch 10154, train_loss 64.146591,Time used 0.008004s\n",
      "batch 10155, train_loss 104.419006,Time used 0.009999s\n",
      "batch 10156, train_loss 72.915154,Time used 0.008003s\n",
      "batch 10157, train_loss 73.676300,Time used 0.012001s\n",
      "batch 10158, train_loss 71.297813,Time used 0.011999s\n",
      "batch 10159, train_loss 59.384327,Time used 0.009000s\n",
      "batch 10160, train_loss 90.893822,Time used 0.012000s\n",
      "batch 10161, train_loss 81.070389,Time used 0.008999s\n",
      "batch 10162, train_loss 71.633575,Time used 0.011002s\n",
      "batch 10163, train_loss 75.028687,Time used 0.011998s\n",
      "batch 10164, train_loss 59.443645,Time used 0.010003s\n",
      "batch 10165, train_loss 83.973267,Time used 0.010997s\n",
      "batch 10166, train_loss 73.410721,Time used 0.010002s\n",
      "batch 10167, train_loss 69.457275,Time used 0.009000s\n",
      "batch 10168, train_loss 70.086411,Time used 0.012999s\n",
      "batch 10169, train_loss 52.159229,Time used 0.009998s\n",
      "batch 10170, train_loss 59.793251,Time used 0.009999s\n",
      "batch 10171, train_loss 70.750221,Time used 0.008003s\n",
      "batch 10172, train_loss 58.939373,Time used 0.007000s\n",
      "batch 10173, train_loss 74.885391,Time used 0.007995s\n",
      "batch 10174, train_loss 57.869740,Time used 0.008001s\n",
      "batch 10175, train_loss 81.742142,Time used 0.010000s\n",
      "batch 10176, train_loss 72.514832,Time used 0.009000s\n",
      "batch 10177, train_loss 80.753662,Time used 0.006999s\n",
      "batch 10178, train_loss 85.739769,Time used 0.009003s\n",
      "batch 10179, train_loss 59.904942,Time used 0.011997s\n",
      "batch 10180, train_loss 75.217323,Time used 0.012000s\n",
      "batch 10181, train_loss 58.063313,Time used 0.012002s\n",
      "batch 10182, train_loss 104.702553,Time used 0.011003s\n",
      "batch 10183, train_loss 68.813309,Time used 0.009999s\n",
      "batch 10184, train_loss 57.515598,Time used 0.011999s\n",
      "batch 10185, train_loss 81.992271,Time used 0.010000s\n",
      "batch 10186, train_loss 76.218033,Time used 0.010999s\n",
      "batch 10187, train_loss 77.566864,Time used 0.011000s\n",
      "batch 10188, train_loss 63.625431,Time used 0.008000s\n",
      "batch 10189, train_loss 56.055840,Time used 0.011002s\n",
      "batch 10190, train_loss 71.480774,Time used 0.007001s\n",
      "batch 10191, train_loss 76.160751,Time used 0.008001s\n",
      "batch 10192, train_loss 76.858932,Time used 0.010998s\n",
      "batch 10193, train_loss 64.729965,Time used 0.011003s\n",
      "batch 10194, train_loss 55.839157,Time used 0.009999s\n",
      "batch 10195, train_loss 62.787720,Time used 0.009998s\n",
      "batch 10196, train_loss 77.737343,Time used 0.009001s\n",
      "batch 10197, train_loss 58.805733,Time used 0.010002s\n",
      "batch 10198, train_loss 79.261101,Time used 0.007999s\n",
      "batch 10199, train_loss 62.198277,Time used 0.009999s\n",
      "batch 10200, train_loss 81.458939,Time used 0.007000s\n",
      "***************************test_batch 10200, test_rmse_loss 9.725092,test_mae_loss 3.877260,test_mape_loss 60.592017,Time used 0.031002s\n",
      "batch 10201, train_loss 73.874237,Time used 0.010999s\n",
      "batch 10202, train_loss 58.530285,Time used 0.010002s\n",
      "batch 10203, train_loss 64.456841,Time used 0.007003s\n",
      "batch 10204, train_loss 63.980873,Time used 0.006999s\n",
      "batch 10205, train_loss 82.083191,Time used 0.007002s\n",
      "batch 10206, train_loss 57.583801,Time used 0.007996s\n",
      "batch 10207, train_loss 78.172516,Time used 0.006999s\n",
      "batch 10208, train_loss 75.359161,Time used 0.007004s\n",
      "batch 10209, train_loss 49.217056,Time used 0.007999s\n",
      "batch 10210, train_loss 100.397041,Time used 0.008998s\n",
      "batch 10211, train_loss 73.873001,Time used 0.011003s\n",
      "batch 10212, train_loss 63.191811,Time used 0.006999s\n",
      "batch 10213, train_loss 75.033905,Time used 0.007000s\n",
      "batch 10214, train_loss 76.523735,Time used 0.015000s\n",
      "batch 10215, train_loss 63.994492,Time used 0.011000s\n",
      "batch 10216, train_loss 65.730904,Time used 0.007999s\n",
      "batch 10217, train_loss 78.633179,Time used 0.007000s\n",
      "batch 10218, train_loss 73.187523,Time used 0.010999s\n",
      "batch 10219, train_loss 59.409412,Time used 0.006998s\n",
      "batch 10220, train_loss 80.700478,Time used 0.010011s\n",
      "batch 10221, train_loss 67.783554,Time used 0.009989s\n",
      "batch 10222, train_loss 60.954536,Time used 0.010002s\n",
      "batch 10223, train_loss 76.557045,Time used 0.007003s\n",
      "batch 10224, train_loss 91.135612,Time used 0.010997s\n",
      "batch 10225, train_loss 66.583687,Time used 0.006998s\n",
      "batch 10226, train_loss 61.191799,Time used 0.009001s\n",
      "batch 10227, train_loss 65.994751,Time used 0.006999s\n",
      "batch 10228, train_loss 92.157005,Time used 0.007000s\n",
      "batch 10229, train_loss 84.223015,Time used 0.007998s\n",
      "batch 10230, train_loss 63.197018,Time used 0.007001s\n",
      "batch 10231, train_loss 55.065884,Time used 0.009001s\n",
      "batch 10232, train_loss 69.049072,Time used 0.008999s\n",
      "batch 10233, train_loss 57.224117,Time used 0.010998s\n",
      "batch 10234, train_loss 75.283913,Time used 0.006999s\n",
      "batch 10235, train_loss 68.046143,Time used 0.008002s\n",
      "batch 10236, train_loss 67.607048,Time used 0.009008s\n",
      "batch 10237, train_loss 63.799194,Time used 0.007991s\n",
      "batch 10238, train_loss 83.878365,Time used 0.007000s\n",
      "batch 10239, train_loss 72.139465,Time used 0.008000s\n",
      "batch 10240, train_loss 69.822891,Time used 0.007999s\n",
      "batch 10241, train_loss 73.224007,Time used 0.007002s\n",
      "batch 10242, train_loss 49.996445,Time used 0.006999s\n",
      "batch 10243, train_loss 88.629227,Time used 0.008001s\n",
      "batch 10244, train_loss 83.493752,Time used 0.007008s\n",
      "batch 10245, train_loss 58.963387,Time used 0.007992s\n",
      "batch 10246, train_loss 79.539314,Time used 0.010001s\n",
      "batch 10247, train_loss 77.303223,Time used 0.010001s\n",
      "batch 10248, train_loss 79.876549,Time used 0.007000s\n",
      "batch 10249, train_loss 55.951614,Time used 0.007000s\n",
      "batch 10250, train_loss 69.750786,Time used 0.008005s\n",
      "batch 10251, train_loss 67.114594,Time used 0.007998s\n",
      "batch 10252, train_loss 86.968513,Time used 0.007998s\n",
      "batch 10253, train_loss 67.582359,Time used 0.007000s\n",
      "batch 10254, train_loss 76.451462,Time used 0.007000s\n",
      "batch 10255, train_loss 79.266426,Time used 0.011000s\n",
      "batch 10256, train_loss 64.220909,Time used 0.011000s\n",
      "batch 10257, train_loss 78.767082,Time used 0.009004s\n",
      "batch 10258, train_loss 63.717880,Time used 0.007997s\n",
      "batch 10259, train_loss 50.138287,Time used 0.008000s\n",
      "batch 10260, train_loss 69.724113,Time used 0.007000s\n",
      "batch 10261, train_loss 72.109032,Time used 0.008001s\n",
      "batch 10262, train_loss 59.996437,Time used 0.010039s\n",
      "batch 10263, train_loss 72.262390,Time used 0.006960s\n",
      "batch 10264, train_loss 79.520432,Time used 0.010999s\n",
      "batch 10265, train_loss 69.755424,Time used 0.012001s\n",
      "batch 10266, train_loss 76.105331,Time used 0.009996s\n",
      "batch 10267, train_loss 81.068062,Time used 0.006999s\n",
      "batch 10268, train_loss 78.745949,Time used 0.009002s\n",
      "batch 10269, train_loss 64.071907,Time used 0.007999s\n",
      "batch 10270, train_loss 59.575474,Time used 0.009004s\n",
      "batch 10271, train_loss 80.859779,Time used 0.006999s\n",
      "batch 10272, train_loss 78.745964,Time used 0.008001s\n",
      "batch 10273, train_loss 68.365997,Time used 0.008998s\n",
      "batch 10274, train_loss 72.884964,Time used 0.009003s\n",
      "batch 10275, train_loss 65.289749,Time used 0.006999s\n",
      "batch 10276, train_loss 75.114761,Time used 0.008001s\n",
      "batch 10277, train_loss 65.235725,Time used 0.008000s\n",
      "batch 10278, train_loss 78.249718,Time used 0.007999s\n",
      "batch 10279, train_loss 68.123398,Time used 0.010001s\n",
      "batch 10280, train_loss 76.812675,Time used 0.006999s\n",
      "batch 10281, train_loss 74.312698,Time used 0.006999s\n",
      "batch 10282, train_loss 41.745506,Time used 0.007998s\n",
      "batch 10283, train_loss 74.191948,Time used 0.006999s\n",
      "batch 10284, train_loss 63.596519,Time used 0.008002s\n",
      "batch 10285, train_loss 74.824821,Time used 0.010998s\n",
      "batch 10286, train_loss 55.255714,Time used 0.010001s\n",
      "batch 10287, train_loss 88.172989,Time used 0.007000s\n",
      "batch 10288, train_loss 63.856972,Time used 0.007999s\n",
      "batch 10289, train_loss 72.922646,Time used 0.009002s\n",
      "batch 10290, train_loss 55.892113,Time used 0.007998s\n",
      "batch 10291, train_loss 71.892067,Time used 0.007001s\n",
      "batch 10292, train_loss 91.788597,Time used 0.010000s\n",
      "batch 10293, train_loss 63.801456,Time used 0.010002s\n",
      "batch 10294, train_loss 71.641121,Time used 0.007001s\n",
      "batch 10295, train_loss 88.339386,Time used 0.008998s\n",
      "batch 10296, train_loss 76.502411,Time used 0.011001s\n",
      "batch 10297, train_loss 75.766617,Time used 0.006998s\n",
      "batch 10298, train_loss 83.376801,Time used 0.007002s\n",
      "batch 10299, train_loss 64.330910,Time used 0.009001s\n",
      "batch 10300, train_loss 64.324722,Time used 0.006996s\n",
      "***************************test_batch 10300, test_rmse_loss 9.680929,test_mae_loss 3.861504,test_mape_loss 60.313991,Time used 0.031001s\n",
      "batch 10301, train_loss 78.407974,Time used 0.007000s\n",
      "batch 10302, train_loss 84.861084,Time used 0.006999s\n",
      "batch 10303, train_loss 58.770012,Time used 0.006999s\n",
      "batch 10304, train_loss 74.922447,Time used 0.010000s\n",
      "batch 10305, train_loss 58.890713,Time used 0.008001s\n",
      "batch 10306, train_loss 84.921089,Time used 0.007000s\n",
      "batch 10307, train_loss 72.125832,Time used 0.010000s\n",
      "batch 10308, train_loss 69.155525,Time used 0.007000s\n",
      "batch 10309, train_loss 72.909027,Time used 0.008000s\n",
      "batch 10310, train_loss 52.557575,Time used 0.008999s\n",
      "batch 10311, train_loss 68.425537,Time used 0.010001s\n",
      "batch 10312, train_loss 51.819138,Time used 0.007002s\n",
      "batch 10313, train_loss 62.726654,Time used 0.008000s\n",
      "batch 10314, train_loss 79.650337,Time used 0.010999s\n",
      "batch 10315, train_loss 53.184074,Time used 0.007999s\n",
      "batch 10316, train_loss 96.189827,Time used 0.010004s\n",
      "batch 10317, train_loss 66.114471,Time used 0.009999s\n",
      "batch 10318, train_loss 65.681404,Time used 0.011001s\n",
      "batch 10319, train_loss 79.529160,Time used 0.011000s\n",
      "batch 10320, train_loss 76.857674,Time used 0.006999s\n",
      "batch 10321, train_loss 75.208496,Time used 0.010998s\n",
      "batch 10322, train_loss 70.324615,Time used 0.008002s\n",
      "batch 10323, train_loss 67.925476,Time used 0.008000s\n",
      "batch 10324, train_loss 74.648323,Time used 0.008000s\n",
      "batch 10325, train_loss 76.524506,Time used 0.009000s\n",
      "batch 10326, train_loss 89.541008,Time used 0.008000s\n",
      "batch 10327, train_loss 56.897335,Time used 0.009002s\n",
      "batch 10328, train_loss 88.232430,Time used 0.007000s\n",
      "batch 10329, train_loss 67.490982,Time used 0.007000s\n",
      "batch 10330, train_loss 71.889244,Time used 0.008001s\n",
      "batch 10331, train_loss 67.275780,Time used 0.008996s\n",
      "batch 10332, train_loss 91.019455,Time used 0.008003s\n",
      "batch 10333, train_loss 71.726227,Time used 0.007997s\n",
      "batch 10334, train_loss 62.582363,Time used 0.008003s\n",
      "batch 10335, train_loss 86.653877,Time used 0.008998s\n",
      "batch 10336, train_loss 53.274849,Time used 0.007001s\n",
      "batch 10337, train_loss 87.526985,Time used 0.010003s\n",
      "batch 10338, train_loss 67.576828,Time used 0.008998s\n",
      "batch 10339, train_loss 62.638611,Time used 0.008003s\n",
      "batch 10340, train_loss 61.653969,Time used 0.006997s\n",
      "batch 10341, train_loss 54.344944,Time used 0.008005s\n",
      "batch 10342, train_loss 67.902115,Time used 0.007000s\n",
      "batch 10343, train_loss 57.002899,Time used 0.007998s\n",
      "batch 10344, train_loss 61.556824,Time used 0.007999s\n",
      "batch 10345, train_loss 79.834579,Time used 0.006999s\n",
      "batch 10346, train_loss 54.643158,Time used 0.007995s\n",
      "batch 10347, train_loss 64.645233,Time used 0.007001s\n",
      "batch 10348, train_loss 59.945778,Time used 0.009002s\n",
      "batch 10349, train_loss 92.545311,Time used 0.006997s\n",
      "batch 10350, train_loss 64.654259,Time used 0.009001s\n",
      "batch 10351, train_loss 62.512177,Time used 0.007000s\n",
      "batch 10352, train_loss 85.553078,Time used 0.008000s\n",
      "batch 10353, train_loss 83.167664,Time used 0.007001s\n",
      "batch 10354, train_loss 67.934319,Time used 0.007996s\n",
      "batch 10355, train_loss 76.143661,Time used 0.008002s\n",
      "batch 10356, train_loss 63.071896,Time used 0.010000s\n",
      "batch 10357, train_loss 92.512161,Time used 0.006998s\n",
      "batch 10358, train_loss 40.328583,Time used 0.008000s\n",
      "batch 10359, train_loss 73.886604,Time used 0.008001s\n",
      "batch 10360, train_loss 63.323784,Time used 0.011000s\n",
      "batch 10361, train_loss 80.428215,Time used 0.011998s\n",
      "batch 10362, train_loss 69.283051,Time used 0.011003s\n",
      "batch 10363, train_loss 70.188110,Time used 0.006999s\n",
      "batch 10364, train_loss 86.357506,Time used 0.007000s\n",
      "batch 10365, train_loss 61.357422,Time used 0.008000s\n",
      "batch 10366, train_loss 75.454407,Time used 0.007000s\n",
      "batch 10367, train_loss 65.281647,Time used 0.010002s\n",
      "batch 10368, train_loss 54.400127,Time used 0.007004s\n",
      "batch 10369, train_loss 59.771038,Time used 0.007000s\n",
      "batch 10370, train_loss 69.699921,Time used 0.008004s\n",
      "batch 10371, train_loss 74.697189,Time used 0.010997s\n",
      "batch 10372, train_loss 75.002617,Time used 0.006999s\n",
      "batch 10373, train_loss 87.207054,Time used 0.008003s\n",
      "batch 10374, train_loss 69.573006,Time used 0.012996s\n",
      "batch 10375, train_loss 89.955513,Time used 0.011002s\n",
      "batch 10376, train_loss 74.513062,Time used 0.010000s\n",
      "batch 10377, train_loss 60.278458,Time used 0.010001s\n",
      "batch 10378, train_loss 68.299171,Time used 0.007001s\n",
      "batch 10379, train_loss 70.712555,Time used 0.009002s\n",
      "batch 10380, train_loss 77.819595,Time used 0.010997s\n",
      "batch 10381, train_loss 55.859032,Time used 0.010000s\n",
      "batch 10382, train_loss 50.862507,Time used 0.010000s\n",
      "batch 10383, train_loss 64.587486,Time used 0.007000s\n",
      "batch 10384, train_loss 63.596840,Time used 0.006999s\n",
      "batch 10385, train_loss 72.232208,Time used 0.008002s\n",
      "batch 10386, train_loss 60.479954,Time used 0.006998s\n",
      "batch 10387, train_loss 68.888611,Time used 0.008002s\n",
      "batch 10388, train_loss 60.951111,Time used 0.007999s\n",
      "batch 10389, train_loss 71.058090,Time used 0.010997s\n",
      "batch 10390, train_loss 81.163239,Time used 0.011001s\n",
      "batch 10391, train_loss 70.331131,Time used 0.008001s\n",
      "batch 10392, train_loss 87.856438,Time used 0.006999s\n",
      "batch 10393, train_loss 71.208282,Time used 0.008003s\n",
      "batch 10394, train_loss 63.025536,Time used 0.006998s\n",
      "batch 10395, train_loss 66.033928,Time used 0.009003s\n",
      "batch 10396, train_loss 59.206570,Time used 0.010001s\n",
      "batch 10397, train_loss 91.591980,Time used 0.008000s\n",
      "batch 10398, train_loss 60.741768,Time used 0.006999s\n",
      "batch 10399, train_loss 70.207138,Time used 0.010001s\n",
      "batch 10400, train_loss 79.163857,Time used 0.009997s\n",
      "***************************test_batch 10400, test_rmse_loss 9.644808,test_mae_loss 3.840717,test_mape_loss 59.592996,Time used 0.030000s\n",
      "batch 10401, train_loss 65.813187,Time used 0.008000s\n",
      "batch 10402, train_loss 79.667229,Time used 0.008003s\n",
      "batch 10403, train_loss 60.433720,Time used 0.007997s\n",
      "batch 10404, train_loss 75.311569,Time used 0.007000s\n",
      "batch 10405, train_loss 72.792816,Time used 0.008000s\n",
      "batch 10406, train_loss 71.469940,Time used 0.006999s\n",
      "batch 10407, train_loss 54.749310,Time used 0.007000s\n",
      "batch 10408, train_loss 57.274563,Time used 0.008009s\n",
      "batch 10409, train_loss 68.434074,Time used 0.010992s\n",
      "batch 10410, train_loss 59.020493,Time used 0.006999s\n",
      "batch 10411, train_loss 74.627968,Time used 0.007000s\n",
      "batch 10412, train_loss 86.173592,Time used 0.008003s\n",
      "batch 10413, train_loss 75.556076,Time used 0.006999s\n",
      "batch 10414, train_loss 86.757225,Time used 0.007000s\n",
      "batch 10415, train_loss 50.579655,Time used 0.007001s\n",
      "batch 10416, train_loss 82.348274,Time used 0.008000s\n",
      "batch 10417, train_loss 78.736664,Time used 0.009002s\n",
      "batch 10418, train_loss 70.251717,Time used 0.006997s\n",
      "batch 10419, train_loss 66.065643,Time used 0.009002s\n",
      "batch 10420, train_loss 74.261932,Time used 0.007999s\n",
      "batch 10421, train_loss 58.530956,Time used 0.008000s\n",
      "batch 10422, train_loss 74.339554,Time used 0.008000s\n",
      "batch 10423, train_loss 75.742264,Time used 0.006999s\n",
      "batch 10424, train_loss 57.732437,Time used 0.007001s\n",
      "batch 10425, train_loss 64.093117,Time used 0.007999s\n",
      "batch 10426, train_loss 52.262066,Time used 0.008002s\n",
      "batch 10427, train_loss 78.950935,Time used 0.008999s\n",
      "batch 10428, train_loss 83.802048,Time used 0.007001s\n",
      "batch 10429, train_loss 59.058613,Time used 0.007000s\n",
      "batch 10430, train_loss 70.146912,Time used 0.007001s\n",
      "batch 10431, train_loss 71.932442,Time used 0.006998s\n",
      "batch 10432, train_loss 84.517944,Time used 0.007001s\n",
      "batch 10433, train_loss 51.548088,Time used 0.009003s\n",
      "batch 10434, train_loss 76.974335,Time used 0.009997s\n",
      "batch 10435, train_loss 71.361092,Time used 0.010001s\n",
      "batch 10436, train_loss 58.555664,Time used 0.010000s\n",
      "batch 10437, train_loss 74.889236,Time used 0.009999s\n",
      "batch 10438, train_loss 67.560677,Time used 0.010999s\n",
      "batch 10439, train_loss 84.268784,Time used 0.011001s\n",
      "batch 10440, train_loss 72.535912,Time used 0.007000s\n",
      "batch 10441, train_loss 76.115578,Time used 0.008997s\n",
      "batch 10442, train_loss 76.159775,Time used 0.007003s\n",
      "batch 10443, train_loss 69.482559,Time used 0.007001s\n",
      "batch 10444, train_loss 85.990746,Time used 0.008997s\n",
      "batch 10445, train_loss 59.952919,Time used 0.008040s\n",
      "batch 10446, train_loss 54.585392,Time used 0.007998s\n",
      "batch 10447, train_loss 92.164604,Time used 0.006998s\n",
      "batch 10448, train_loss 77.641647,Time used 0.008965s\n",
      "batch 10449, train_loss 68.883018,Time used 0.008000s\n",
      "batch 10450, train_loss 64.878899,Time used 0.007998s\n",
      "batch 10451, train_loss 83.271515,Time used 0.010006s\n",
      "batch 10452, train_loss 64.012505,Time used 0.006995s\n",
      "batch 10453, train_loss 50.156975,Time used 0.007003s\n",
      "batch 10454, train_loss 63.735573,Time used 0.006967s\n",
      "batch 10455, train_loss 62.639114,Time used 0.007996s\n",
      "batch 10456, train_loss 59.048275,Time used 0.008037s\n",
      "batch 10457, train_loss 64.534775,Time used 0.007967s\n",
      "batch 10458, train_loss 66.827217,Time used 0.006999s\n",
      "batch 10459, train_loss 69.933098,Time used 0.006998s\n",
      "batch 10460, train_loss 61.580986,Time used 0.007025s\n",
      "batch 10461, train_loss 85.905693,Time used 0.007964s\n",
      "batch 10462, train_loss 57.431393,Time used 0.013997s\n",
      "batch 10463, train_loss 70.733292,Time used 0.010040s\n",
      "batch 10464, train_loss 89.412384,Time used 0.007968s\n",
      "batch 10465, train_loss 77.642982,Time used 0.008000s\n",
      "batch 10466, train_loss 52.136135,Time used 0.010000s\n",
      "batch 10467, train_loss 69.178284,Time used 0.011000s\n",
      "batch 10468, train_loss 69.866905,Time used 0.008037s\n",
      "batch 10469, train_loss 72.788742,Time used 0.006999s\n",
      "batch 10470, train_loss 51.908623,Time used 0.007998s\n",
      "batch 10471, train_loss 92.035446,Time used 0.007001s\n",
      "batch 10472, train_loss 72.737206,Time used 0.008966s\n",
      "batch 10473, train_loss 79.332123,Time used 0.008000s\n",
      "batch 10474, train_loss 57.441101,Time used 0.007000s\n",
      "batch 10475, train_loss 78.415215,Time used 0.006989s\n",
      "batch 10476, train_loss 68.004700,Time used 0.008001s\n",
      "batch 10477, train_loss 97.751495,Time used 0.013000s\n",
      "batch 10478, train_loss 63.245361,Time used 0.011000s\n",
      "batch 10479, train_loss 65.783905,Time used 0.010001s\n",
      "batch 10480, train_loss 72.843658,Time used 0.011040s\n",
      "batch 10481, train_loss 64.801292,Time used 0.008960s\n",
      "batch 10482, train_loss 58.424412,Time used 0.018001s\n",
      "batch 10483, train_loss 79.075500,Time used 0.011007s\n",
      "batch 10484, train_loss 73.992943,Time used 0.009993s\n",
      "batch 10485, train_loss 87.369263,Time used 0.013013s\n",
      "batch 10486, train_loss 56.978264,Time used 0.010985s\n",
      "batch 10487, train_loss 56.849064,Time used 0.012002s\n",
      "batch 10488, train_loss 51.815884,Time used 0.012001s\n",
      "batch 10489, train_loss 51.428844,Time used 0.008000s\n",
      "batch 10490, train_loss 95.705353,Time used 0.010998s\n",
      "batch 10491, train_loss 95.816612,Time used 0.009999s\n",
      "batch 10492, train_loss 68.005432,Time used 0.013003s\n",
      "batch 10493, train_loss 66.846039,Time used 0.011999s\n",
      "batch 10494, train_loss 57.563446,Time used 0.013000s\n",
      "batch 10495, train_loss 57.221504,Time used 0.011002s\n",
      "batch 10496, train_loss 55.056328,Time used 0.012000s\n",
      "batch 10497, train_loss 85.679649,Time used 0.009998s\n",
      "batch 10498, train_loss 84.914612,Time used 0.011001s\n",
      "batch 10499, train_loss 71.151741,Time used 0.015001s\n",
      "batch 10500, train_loss 57.076336,Time used 0.026000s\n",
      "***************************test_batch 10500, test_rmse_loss 9.603312,test_mae_loss 3.827009,test_mape_loss 59.429438,Time used 0.049000s\n",
      "batch 10501, train_loss 68.602005,Time used 0.013001s\n",
      "batch 10502, train_loss 69.236298,Time used 0.011999s\n",
      "batch 10503, train_loss 80.692535,Time used 0.012002s\n",
      "batch 10504, train_loss 67.712830,Time used 0.012000s\n",
      "batch 10505, train_loss 72.842461,Time used 0.011997s\n",
      "batch 10506, train_loss 50.186142,Time used 0.012001s\n",
      "batch 10507, train_loss 66.347000,Time used 0.011999s\n",
      "batch 10508, train_loss 46.216278,Time used 0.010001s\n",
      "batch 10509, train_loss 58.955555,Time used 0.012001s\n",
      "batch 10510, train_loss 94.474403,Time used 0.011998s\n",
      "batch 10511, train_loss 78.121094,Time used 0.010998s\n",
      "batch 10512, train_loss 67.820816,Time used 0.008000s\n",
      "batch 10513, train_loss 82.149231,Time used 0.009996s\n",
      "batch 10514, train_loss 65.795341,Time used 0.007998s\n",
      "batch 10515, train_loss 69.230171,Time used 0.012001s\n",
      "batch 10516, train_loss 86.495033,Time used 0.007999s\n",
      "batch 10517, train_loss 74.617989,Time used 0.009001s\n",
      "batch 10518, train_loss 63.463470,Time used 0.008000s\n",
      "batch 10519, train_loss 49.638962,Time used 0.009000s\n",
      "batch 10520, train_loss 75.393570,Time used 0.008000s\n",
      "batch 10521, train_loss 48.492935,Time used 0.010998s\n",
      "batch 10522, train_loss 61.082138,Time used 0.008003s\n",
      "batch 10523, train_loss 71.652588,Time used 0.008997s\n",
      "batch 10524, train_loss 80.216354,Time used 0.009000s\n",
      "batch 10525, train_loss 73.028366,Time used 0.011000s\n",
      "batch 10526, train_loss 80.667419,Time used 0.012002s\n",
      "batch 10527, train_loss 47.705833,Time used 0.010999s\n",
      "batch 10528, train_loss 74.787758,Time used 0.009001s\n",
      "batch 10529, train_loss 76.881264,Time used 0.007999s\n",
      "batch 10530, train_loss 64.828117,Time used 0.007999s\n",
      "batch 10531, train_loss 67.816650,Time used 0.007001s\n",
      "batch 10532, train_loss 70.674698,Time used 0.009001s\n",
      "batch 10533, train_loss 64.804840,Time used 0.007999s\n",
      "batch 10534, train_loss 77.362022,Time used 0.007000s\n",
      "batch 10535, train_loss 65.350212,Time used 0.011000s\n",
      "batch 10536, train_loss 72.321533,Time used 0.010000s\n",
      "batch 10537, train_loss 81.155807,Time used 0.011001s\n",
      "batch 10538, train_loss 70.826164,Time used 0.009999s\n",
      "batch 10539, train_loss 79.929901,Time used 0.007000s\n",
      "batch 10540, train_loss 77.045013,Time used 0.007999s\n",
      "batch 10541, train_loss 80.596458,Time used 0.007001s\n",
      "batch 10542, train_loss 94.725449,Time used 0.007003s\n",
      "batch 10543, train_loss 76.647636,Time used 0.007001s\n",
      "batch 10544, train_loss 76.748558,Time used 0.007002s\n",
      "batch 10545, train_loss 58.773205,Time used 0.008000s\n",
      "batch 10546, train_loss 62.213936,Time used 0.009000s\n",
      "batch 10547, train_loss 58.084667,Time used 0.007999s\n",
      "batch 10548, train_loss 55.595619,Time used 0.008000s\n",
      "batch 10549, train_loss 68.208717,Time used 0.008002s\n",
      "batch 10550, train_loss 65.435570,Time used 0.007999s\n",
      "batch 10551, train_loss 62.269402,Time used 0.008035s\n",
      "batch 10552, train_loss 61.759529,Time used 0.009001s\n",
      "batch 10553, train_loss 59.405170,Time used 0.007962s\n",
      "batch 10554, train_loss 72.074318,Time used 0.007998s\n",
      "batch 10555, train_loss 61.611233,Time used 0.007000s\n",
      "batch 10556, train_loss 54.172119,Time used 0.008007s\n",
      "batch 10557, train_loss 57.942627,Time used 0.008001s\n",
      "batch 10558, train_loss 86.234627,Time used 0.007032s\n",
      "batch 10559, train_loss 62.319817,Time used 0.007001s\n",
      "batch 10560, train_loss 77.825607,Time used 0.009002s\n",
      "batch 10561, train_loss 67.718681,Time used 0.008003s\n",
      "batch 10562, train_loss 69.924713,Time used 0.007996s\n",
      "batch 10563, train_loss 63.308468,Time used 0.007000s\n",
      "batch 10564, train_loss 68.084564,Time used 0.006999s\n",
      "batch 10565, train_loss 91.559509,Time used 0.007999s\n",
      "batch 10566, train_loss 58.522839,Time used 0.007999s\n",
      "batch 10567, train_loss 67.056847,Time used 0.010001s\n",
      "batch 10568, train_loss 70.134895,Time used 0.008000s\n",
      "batch 10569, train_loss 61.185341,Time used 0.010002s\n",
      "batch 10570, train_loss 67.965416,Time used 0.008999s\n",
      "batch 10571, train_loss 62.013817,Time used 0.007001s\n",
      "batch 10572, train_loss 88.138794,Time used 0.010004s\n",
      "batch 10573, train_loss 60.615116,Time used 0.011007s\n",
      "batch 10574, train_loss 116.837608,Time used 0.013994s\n",
      "batch 10575, train_loss 66.736992,Time used 0.007999s\n",
      "batch 10576, train_loss 80.615898,Time used 0.008999s\n",
      "batch 10577, train_loss 43.771782,Time used 0.009000s\n",
      "batch 10578, train_loss 61.313423,Time used 0.008001s\n",
      "batch 10579, train_loss 93.980309,Time used 0.007999s\n",
      "batch 10580, train_loss 57.275795,Time used 0.008002s\n",
      "batch 10581, train_loss 67.323769,Time used 0.008000s\n",
      "batch 10582, train_loss 58.176094,Time used 0.007000s\n",
      "batch 10583, train_loss 72.413376,Time used 0.008000s\n",
      "batch 10584, train_loss 42.265041,Time used 0.009001s\n",
      "batch 10585, train_loss 63.780407,Time used 0.008998s\n",
      "batch 10586, train_loss 75.187973,Time used 0.007000s\n",
      "batch 10587, train_loss 54.860657,Time used 0.011000s\n",
      "batch 10588, train_loss 92.524391,Time used 0.010003s\n",
      "batch 10589, train_loss 73.014542,Time used 0.007996s\n",
      "batch 10590, train_loss 65.705544,Time used 0.010002s\n",
      "batch 10591, train_loss 77.265564,Time used 0.008998s\n",
      "batch 10592, train_loss 57.027660,Time used 0.011001s\n",
      "batch 10593, train_loss 72.754440,Time used 0.011002s\n",
      "batch 10594, train_loss 74.709915,Time used 0.010002s\n",
      "batch 10595, train_loss 65.396797,Time used 0.007001s\n",
      "batch 10596, train_loss 67.701218,Time used 0.007000s\n",
      "batch 10597, train_loss 93.085365,Time used 0.011999s\n",
      "batch 10598, train_loss 62.959206,Time used 0.006999s\n",
      "batch 10599, train_loss 73.304901,Time used 0.008003s\n",
      "batch 10600, train_loss 70.894791,Time used 0.011997s\n",
      "***************************test_batch 10600, test_rmse_loss 9.556881,test_mae_loss 3.816340,test_mape_loss 59.622390,Time used 0.035001s\n",
      "batch 10601, train_loss 65.490173,Time used 0.009000s\n",
      "batch 10602, train_loss 74.571976,Time used 0.007003s\n",
      "batch 10603, train_loss 64.295135,Time used 0.009997s\n",
      "batch 10604, train_loss 53.849522,Time used 0.010003s\n",
      "batch 10605, train_loss 86.792587,Time used 0.006997s\n",
      "batch 10606, train_loss 69.494347,Time used 0.008002s\n",
      "batch 10607, train_loss 52.446823,Time used 0.007998s\n",
      "batch 10608, train_loss 46.661972,Time used 0.009000s\n",
      "batch 10609, train_loss 65.941559,Time used 0.009001s\n",
      "batch 10610, train_loss 62.761776,Time used 0.009999s\n",
      "batch 10611, train_loss 87.489456,Time used 0.009003s\n",
      "batch 10612, train_loss 84.577049,Time used 0.008000s\n",
      "batch 10613, train_loss 69.315346,Time used 0.011997s\n",
      "batch 10614, train_loss 89.149551,Time used 0.011037s\n",
      "batch 10615, train_loss 73.671036,Time used 0.007999s\n",
      "batch 10616, train_loss 81.397598,Time used 0.008965s\n",
      "batch 10617, train_loss 55.329720,Time used 0.007999s\n",
      "batch 10618, train_loss 47.456379,Time used 0.009995s\n",
      "batch 10619, train_loss 61.718784,Time used 0.010003s\n",
      "batch 10620, train_loss 65.595505,Time used 0.007031s\n",
      "batch 10621, train_loss 65.728088,Time used 0.009000s\n",
      "batch 10622, train_loss 79.926079,Time used 0.006965s\n",
      "batch 10623, train_loss 68.302803,Time used 0.007004s\n",
      "batch 10624, train_loss 65.573044,Time used 0.006999s\n",
      "batch 10625, train_loss 72.571159,Time used 0.009002s\n",
      "batch 10626, train_loss 57.067051,Time used 0.010000s\n",
      "batch 10627, train_loss 62.698242,Time used 0.008001s\n",
      "batch 10628, train_loss 67.875610,Time used 0.012009s\n",
      "batch 10629, train_loss 74.190552,Time used 0.010991s\n",
      "batch 10630, train_loss 66.042252,Time used 0.009001s\n",
      "batch 10631, train_loss 57.585884,Time used 0.010000s\n",
      "batch 10632, train_loss 69.158501,Time used 0.007999s\n",
      "batch 10633, train_loss 72.670914,Time used 0.008997s\n",
      "batch 10634, train_loss 65.601051,Time used 0.008001s\n",
      "batch 10635, train_loss 58.197208,Time used 0.008000s\n",
      "batch 10636, train_loss 59.221539,Time used 0.010001s\n",
      "batch 10637, train_loss 76.979515,Time used 0.008000s\n",
      "batch 10638, train_loss 52.856518,Time used 0.009000s\n",
      "batch 10639, train_loss 78.844002,Time used 0.006999s\n",
      "batch 10640, train_loss 73.730164,Time used 0.007999s\n",
      "batch 10641, train_loss 63.517212,Time used 0.008002s\n",
      "batch 10642, train_loss 78.612297,Time used 0.011999s\n",
      "batch 10643, train_loss 70.269653,Time used 0.011002s\n",
      "batch 10644, train_loss 58.786438,Time used 0.011003s\n",
      "batch 10645, train_loss 57.934532,Time used 0.006999s\n",
      "batch 10646, train_loss 81.243042,Time used 0.007000s\n",
      "batch 10647, train_loss 72.589989,Time used 0.010001s\n",
      "batch 10648, train_loss 70.833603,Time used 0.011001s\n",
      "batch 10649, train_loss 75.053558,Time used 0.009002s\n",
      "batch 10650, train_loss 79.082390,Time used 0.011000s\n",
      "batch 10651, train_loss 80.296127,Time used 0.009000s\n",
      "batch 10652, train_loss 64.773056,Time used 0.007998s\n",
      "batch 10653, train_loss 60.959560,Time used 0.008000s\n",
      "batch 10654, train_loss 65.765785,Time used 0.007001s\n",
      "batch 10655, train_loss 65.720894,Time used 0.008999s\n",
      "batch 10656, train_loss 64.251236,Time used 0.006999s\n",
      "batch 10657, train_loss 66.704468,Time used 0.009999s\n",
      "batch 10658, train_loss 84.177849,Time used 0.011001s\n",
      "batch 10659, train_loss 81.368668,Time used 0.010002s\n",
      "batch 10660, train_loss 50.168213,Time used 0.010999s\n",
      "batch 10661, train_loss 61.262104,Time used 0.007001s\n",
      "batch 10662, train_loss 63.639046,Time used 0.010005s\n",
      "batch 10663, train_loss 68.554863,Time used 0.010997s\n",
      "batch 10664, train_loss 71.097824,Time used 0.011001s\n",
      "batch 10665, train_loss 70.756248,Time used 0.007000s\n",
      "batch 10666, train_loss 71.822021,Time used 0.006999s\n",
      "batch 10667, train_loss 54.339294,Time used 0.008000s\n",
      "batch 10668, train_loss 60.400921,Time used 0.006999s\n",
      "batch 10669, train_loss 52.718910,Time used 0.010000s\n",
      "batch 10670, train_loss 84.389046,Time used 0.012006s\n",
      "batch 10671, train_loss 61.257885,Time used 0.007992s\n",
      "batch 10672, train_loss 71.047401,Time used 0.008000s\n",
      "batch 10673, train_loss 81.310600,Time used 0.008005s\n",
      "batch 10674, train_loss 64.717613,Time used 0.007998s\n",
      "batch 10675, train_loss 67.782692,Time used 0.013999s\n",
      "batch 10676, train_loss 54.652420,Time used 0.011999s\n",
      "batch 10677, train_loss 68.099396,Time used 0.008003s\n",
      "batch 10678, train_loss 83.747650,Time used 0.006998s\n",
      "batch 10679, train_loss 69.504242,Time used 0.007999s\n",
      "batch 10680, train_loss 81.932877,Time used 0.008002s\n",
      "batch 10681, train_loss 63.830334,Time used 0.007999s\n",
      "batch 10682, train_loss 62.033092,Time used 0.008003s\n",
      "batch 10683, train_loss 48.792519,Time used 0.010999s\n",
      "batch 10684, train_loss 48.450703,Time used 0.008001s\n",
      "batch 10685, train_loss 80.206116,Time used 0.008000s\n",
      "batch 10686, train_loss 72.990631,Time used 0.010000s\n",
      "batch 10687, train_loss 59.777927,Time used 0.007999s\n",
      "batch 10688, train_loss 61.348644,Time used 0.011000s\n",
      "batch 10689, train_loss 93.784683,Time used 0.008000s\n",
      "batch 10690, train_loss 92.900902,Time used 0.012002s\n",
      "batch 10691, train_loss 58.711021,Time used 0.011997s\n",
      "batch 10692, train_loss 58.801975,Time used 0.012003s\n",
      "batch 10693, train_loss 68.292336,Time used 0.008001s\n",
      "batch 10694, train_loss 81.746552,Time used 0.006998s\n",
      "batch 10695, train_loss 59.932800,Time used 0.007998s\n",
      "batch 10696, train_loss 78.781479,Time used 0.012001s\n",
      "batch 10697, train_loss 86.458763,Time used 0.008003s\n",
      "batch 10698, train_loss 53.650410,Time used 0.006997s\n",
      "batch 10699, train_loss 68.019936,Time used 0.008001s\n",
      "batch 10700, train_loss 77.786102,Time used 0.010999s\n",
      "***************************test_batch 10700, test_rmse_loss 9.520732,test_mae_loss 3.801975,test_mape_loss 59.281130,Time used 0.037001s\n",
      "batch 10701, train_loss 73.273895,Time used 0.008002s\n",
      "batch 10702, train_loss 62.096409,Time used 0.011999s\n",
      "batch 10703, train_loss 69.787544,Time used 0.009998s\n",
      "batch 10704, train_loss 59.990425,Time used 0.008001s\n",
      "batch 10705, train_loss 73.149879,Time used 0.010998s\n",
      "batch 10706, train_loss 73.533707,Time used 0.012999s\n",
      "batch 10707, train_loss 82.778305,Time used 0.009003s\n",
      "batch 10708, train_loss 69.138443,Time used 0.006999s\n",
      "batch 10709, train_loss 55.753792,Time used 0.008000s\n",
      "batch 10710, train_loss 87.655975,Time used 0.007000s\n",
      "batch 10711, train_loss 76.492119,Time used 0.008000s\n",
      "batch 10712, train_loss 60.318085,Time used 0.006999s\n",
      "batch 10713, train_loss 81.100769,Time used 0.007001s\n",
      "batch 10714, train_loss 75.811302,Time used 0.007002s\n",
      "batch 10715, train_loss 55.686832,Time used 0.007997s\n",
      "batch 10716, train_loss 54.444656,Time used 0.007001s\n",
      "batch 10717, train_loss 49.896942,Time used 0.009004s\n",
      "batch 10718, train_loss 64.183998,Time used 0.006998s\n",
      "batch 10719, train_loss 65.403519,Time used 0.009001s\n",
      "batch 10720, train_loss 85.162254,Time used 0.009000s\n",
      "batch 10721, train_loss 59.117382,Time used 0.007003s\n",
      "batch 10722, train_loss 52.347565,Time used 0.009999s\n",
      "batch 10723, train_loss 81.924187,Time used 0.010000s\n",
      "batch 10724, train_loss 55.214947,Time used 0.006999s\n",
      "batch 10725, train_loss 80.546722,Time used 0.008998s\n",
      "batch 10726, train_loss 61.654953,Time used 0.007999s\n",
      "batch 10727, train_loss 73.258148,Time used 0.009000s\n",
      "batch 10728, train_loss 63.585934,Time used 0.008003s\n",
      "batch 10729, train_loss 77.754967,Time used 0.008001s\n",
      "batch 10730, train_loss 83.069595,Time used 0.008000s\n",
      "batch 10731, train_loss 66.462685,Time used 0.009998s\n",
      "batch 10732, train_loss 60.691734,Time used 0.009999s\n",
      "batch 10733, train_loss 78.410896,Time used 0.008000s\n",
      "batch 10734, train_loss 78.512581,Time used 0.008001s\n",
      "batch 10735, train_loss 67.641731,Time used 0.008000s\n",
      "batch 10736, train_loss 78.088860,Time used 0.009001s\n",
      "batch 10737, train_loss 68.565552,Time used 0.009998s\n",
      "batch 10738, train_loss 76.879135,Time used 0.011002s\n",
      "batch 10739, train_loss 72.827362,Time used 0.009999s\n",
      "batch 10740, train_loss 71.848106,Time used 0.008001s\n",
      "batch 10741, train_loss 62.158169,Time used 0.008999s\n",
      "batch 10742, train_loss 65.423355,Time used 0.008003s\n",
      "batch 10743, train_loss 57.112705,Time used 0.007997s\n",
      "batch 10744, train_loss 70.757584,Time used 0.008000s\n",
      "batch 10745, train_loss 64.584183,Time used 0.009997s\n",
      "batch 10746, train_loss 59.725174,Time used 0.010005s\n",
      "batch 10747, train_loss 67.613182,Time used 0.011996s\n",
      "batch 10748, train_loss 67.448784,Time used 0.011003s\n",
      "batch 10749, train_loss 55.154854,Time used 0.011999s\n",
      "batch 10750, train_loss 67.951035,Time used 0.011999s\n",
      "batch 10751, train_loss 51.089531,Time used 0.006999s\n",
      "batch 10752, train_loss 65.214890,Time used 0.008002s\n",
      "batch 10753, train_loss 56.201080,Time used 0.008996s\n",
      "batch 10754, train_loss 91.487526,Time used 0.006999s\n",
      "batch 10755, train_loss 56.768520,Time used 0.008999s\n",
      "batch 10756, train_loss 48.045925,Time used 0.011000s\n",
      "batch 10757, train_loss 72.839600,Time used 0.009000s\n",
      "batch 10758, train_loss 61.124702,Time used 0.008003s\n",
      "batch 10759, train_loss 69.502777,Time used 0.008998s\n",
      "batch 10760, train_loss 62.176891,Time used 0.006999s\n",
      "batch 10761, train_loss 63.063507,Time used 0.010000s\n",
      "batch 10762, train_loss 68.664383,Time used 0.012001s\n",
      "batch 10763, train_loss 68.794273,Time used 0.009999s\n",
      "batch 10764, train_loss 80.811867,Time used 0.007999s\n",
      "batch 10765, train_loss 68.020782,Time used 0.009005s\n",
      "batch 10766, train_loss 76.046494,Time used 0.010995s\n",
      "batch 10767, train_loss 73.441612,Time used 0.008042s\n",
      "batch 10768, train_loss 55.416042,Time used 0.009957s\n",
      "batch 10769, train_loss 68.299515,Time used 0.009039s\n",
      "batch 10770, train_loss 71.546951,Time used 0.007964s\n",
      "batch 10771, train_loss 65.359856,Time used 0.007998s\n",
      "batch 10772, train_loss 61.250904,Time used 0.008000s\n",
      "batch 10773, train_loss 60.068657,Time used 0.008000s\n",
      "batch 10774, train_loss 82.563385,Time used 0.009002s\n",
      "batch 10775, train_loss 77.880295,Time used 0.007998s\n",
      "batch 10776, train_loss 72.829819,Time used 0.011001s\n",
      "batch 10777, train_loss 66.544411,Time used 0.009996s\n",
      "batch 10778, train_loss 66.869537,Time used 0.010000s\n",
      "batch 10779, train_loss 60.196850,Time used 0.008002s\n",
      "batch 10780, train_loss 64.794334,Time used 0.006992s\n",
      "batch 10781, train_loss 73.168861,Time used 0.008001s\n",
      "batch 10782, train_loss 73.389664,Time used 0.009999s\n",
      "batch 10783, train_loss 50.517746,Time used 0.009002s\n",
      "batch 10784, train_loss 67.746376,Time used 0.007998s\n",
      "batch 10785, train_loss 61.009613,Time used 0.010007s\n",
      "batch 10786, train_loss 74.990242,Time used 0.007995s\n",
      "batch 10787, train_loss 72.778244,Time used 0.007000s\n",
      "batch 10788, train_loss 90.166519,Time used 0.007998s\n",
      "batch 10789, train_loss 86.033264,Time used 0.008002s\n",
      "batch 10790, train_loss 55.742500,Time used 0.006999s\n",
      "batch 10791, train_loss 73.958763,Time used 0.008001s\n",
      "batch 10792, train_loss 68.286156,Time used 0.011000s\n",
      "batch 10793, train_loss 69.274498,Time used 0.009998s\n",
      "batch 10794, train_loss 57.982075,Time used 0.009003s\n",
      "batch 10795, train_loss 53.581631,Time used 0.007997s\n",
      "batch 10796, train_loss 63.199017,Time used 0.011000s\n",
      "batch 10797, train_loss 67.021240,Time used 0.008002s\n",
      "batch 10798, train_loss 56.697884,Time used 0.009000s\n",
      "batch 10799, train_loss 81.854195,Time used 0.008999s\n",
      "batch 10800, train_loss 73.012398,Time used 0.008999s\n",
      "***************************test_batch 10800, test_rmse_loss 9.475944,test_mae_loss 3.792726,test_mape_loss 59.461742,Time used 0.033998s\n",
      "batch 10801, train_loss 57.106792,Time used 0.012002s\n",
      "batch 10802, train_loss 77.822052,Time used 0.010997s\n",
      "batch 10803, train_loss 67.032509,Time used 0.008001s\n",
      "batch 10804, train_loss 80.976372,Time used 0.007000s\n",
      "batch 10805, train_loss 69.846024,Time used 0.006999s\n",
      "batch 10806, train_loss 54.262928,Time used 0.007999s\n",
      "batch 10807, train_loss 68.447105,Time used 0.008001s\n",
      "batch 10808, train_loss 72.926331,Time used 0.008001s\n",
      "batch 10809, train_loss 67.130051,Time used 0.011998s\n",
      "batch 10810, train_loss 79.508476,Time used 0.011002s\n",
      "batch 10811, train_loss 60.902599,Time used 0.008000s\n",
      "batch 10812, train_loss 77.439499,Time used 0.008001s\n",
      "batch 10813, train_loss 64.966301,Time used 0.007002s\n",
      "batch 10814, train_loss 82.279465,Time used 0.008998s\n",
      "batch 10815, train_loss 66.572525,Time used 0.006999s\n",
      "batch 10816, train_loss 64.919525,Time used 0.008001s\n",
      "batch 10817, train_loss 53.732491,Time used 0.006998s\n",
      "batch 10818, train_loss 72.542557,Time used 0.008001s\n",
      "batch 10819, train_loss 60.295830,Time used 0.007000s\n",
      "batch 10820, train_loss 61.400105,Time used 0.010002s\n",
      "batch 10821, train_loss 73.821800,Time used 0.009001s\n",
      "batch 10822, train_loss 66.299530,Time used 0.010000s\n",
      "batch 10823, train_loss 73.527412,Time used 0.008008s\n",
      "batch 10824, train_loss 51.276653,Time used 0.007991s\n",
      "batch 10825, train_loss 62.997768,Time used 0.008000s\n",
      "batch 10826, train_loss 72.683762,Time used 0.008001s\n",
      "batch 10827, train_loss 68.607780,Time used 0.008001s\n",
      "batch 10828, train_loss 58.936745,Time used 0.010996s\n",
      "batch 10829, train_loss 100.711098,Time used 0.008002s\n",
      "batch 10830, train_loss 68.341301,Time used 0.010999s\n",
      "batch 10831, train_loss 66.699646,Time used 0.007001s\n",
      "batch 10832, train_loss 72.918358,Time used 0.008001s\n",
      "batch 10833, train_loss 65.303741,Time used 0.010001s\n",
      "batch 10834, train_loss 58.830376,Time used 0.007000s\n",
      "batch 10835, train_loss 52.721413,Time used 0.007001s\n",
      "batch 10836, train_loss 74.381668,Time used 0.009001s\n",
      "batch 10837, train_loss 75.528374,Time used 0.010007s\n",
      "batch 10838, train_loss 57.361591,Time used 0.006996s\n",
      "batch 10839, train_loss 75.186935,Time used 0.006997s\n",
      "batch 10840, train_loss 63.387421,Time used 0.008000s\n",
      "batch 10841, train_loss 58.958038,Time used 0.008001s\n",
      "batch 10842, train_loss 66.699852,Time used 0.008000s\n",
      "batch 10843, train_loss 71.887581,Time used 0.007999s\n",
      "batch 10844, train_loss 58.235451,Time used 0.008002s\n",
      "batch 10845, train_loss 67.592758,Time used 0.009998s\n",
      "batch 10846, train_loss 70.512222,Time used 0.011000s\n",
      "batch 10847, train_loss 72.289986,Time used 0.010005s\n",
      "batch 10848, train_loss 61.571178,Time used 0.006999s\n",
      "batch 10849, train_loss 69.597588,Time used 0.011001s\n",
      "batch 10850, train_loss 57.360260,Time used 0.010000s\n",
      "batch 10851, train_loss 52.516701,Time used 0.011000s\n",
      "batch 10852, train_loss 63.923138,Time used 0.008000s\n",
      "batch 10853, train_loss 49.313229,Time used 0.008000s\n",
      "batch 10854, train_loss 66.552444,Time used 0.008001s\n",
      "batch 10855, train_loss 69.778252,Time used 0.011000s\n",
      "batch 10856, train_loss 87.773499,Time used 0.008001s\n",
      "batch 10857, train_loss 71.319237,Time used 0.007998s\n",
      "batch 10858, train_loss 69.797302,Time used 0.006999s\n",
      "batch 10859, train_loss 70.470360,Time used 0.008001s\n",
      "batch 10860, train_loss 89.399414,Time used 0.007998s\n",
      "batch 10861, train_loss 58.683025,Time used 0.007999s\n",
      "batch 10862, train_loss 80.437881,Time used 0.009001s\n",
      "batch 10863, train_loss 58.383537,Time used 0.011003s\n",
      "batch 10864, train_loss 68.267921,Time used 0.007999s\n",
      "batch 10865, train_loss 69.797455,Time used 0.007035s\n",
      "batch 10866, train_loss 78.999397,Time used 0.007969s\n",
      "batch 10867, train_loss 53.362225,Time used 0.010996s\n",
      "batch 10868, train_loss 56.428055,Time used 0.009000s\n",
      "batch 10869, train_loss 54.510521,Time used 0.009006s\n",
      "batch 10870, train_loss 71.562996,Time used 0.011002s\n",
      "batch 10871, train_loss 75.450081,Time used 0.011998s\n",
      "batch 10872, train_loss 75.798653,Time used 0.009000s\n",
      "batch 10873, train_loss 59.691738,Time used 0.009999s\n",
      "batch 10874, train_loss 73.211617,Time used 0.014001s\n",
      "batch 10875, train_loss 59.439926,Time used 0.012997s\n",
      "batch 10876, train_loss 68.407516,Time used 0.013000s\n",
      "batch 10877, train_loss 69.476845,Time used 0.010001s\n",
      "batch 10878, train_loss 72.315887,Time used 0.008999s\n",
      "batch 10879, train_loss 58.449165,Time used 0.009002s\n",
      "batch 10880, train_loss 66.251961,Time used 0.010001s\n",
      "batch 10881, train_loss 82.600868,Time used 0.012002s\n",
      "batch 10882, train_loss 78.392387,Time used 0.010995s\n",
      "batch 10883, train_loss 67.083885,Time used 0.010999s\n",
      "batch 10884, train_loss 66.772873,Time used 0.007999s\n",
      "batch 10885, train_loss 75.938431,Time used 0.011001s\n",
      "batch 10886, train_loss 57.872700,Time used 0.010000s\n",
      "batch 10887, train_loss 61.067478,Time used 0.011005s\n",
      "batch 10888, train_loss 53.432373,Time used 0.010995s\n",
      "batch 10889, train_loss 68.274109,Time used 0.010003s\n",
      "batch 10890, train_loss 76.549858,Time used 0.006998s\n",
      "batch 10891, train_loss 65.527802,Time used 0.008001s\n",
      "batch 10892, train_loss 59.593254,Time used 0.006999s\n",
      "batch 10893, train_loss 55.083042,Time used 0.007998s\n",
      "batch 10894, train_loss 65.028763,Time used 0.010002s\n",
      "batch 10895, train_loss 74.991806,Time used 0.007998s\n",
      "batch 10896, train_loss 81.400917,Time used 0.007001s\n",
      "batch 10897, train_loss 66.244560,Time used 0.008001s\n",
      "batch 10898, train_loss 81.873634,Time used 0.007999s\n",
      "batch 10899, train_loss 68.567932,Time used 0.008999s\n",
      "batch 10900, train_loss 58.052151,Time used 0.010002s\n",
      "***************************test_batch 10900, test_rmse_loss 9.440271,test_mae_loss 3.777754,test_mape_loss 59.094316,Time used 0.042001s\n",
      "batch 10901, train_loss 62.180225,Time used 0.010000s\n",
      "batch 10902, train_loss 59.388889,Time used 0.008000s\n",
      "batch 10903, train_loss 70.731163,Time used 0.008999s\n",
      "batch 10904, train_loss 54.689751,Time used 0.006999s\n",
      "batch 10905, train_loss 46.301003,Time used 0.007001s\n",
      "batch 10906, train_loss 74.673027,Time used 0.007000s\n",
      "batch 10907, train_loss 65.229172,Time used 0.007998s\n",
      "batch 10908, train_loss 79.355759,Time used 0.010002s\n",
      "batch 10909, train_loss 63.335922,Time used 0.006997s\n",
      "batch 10910, train_loss 56.715012,Time used 0.008002s\n",
      "batch 10911, train_loss 63.129150,Time used 0.007999s\n",
      "batch 10912, train_loss 71.125587,Time used 0.007000s\n",
      "batch 10913, train_loss 70.929214,Time used 0.008009s\n",
      "batch 10914, train_loss 78.239510,Time used 0.007992s\n",
      "batch 10915, train_loss 71.509895,Time used 0.008001s\n",
      "batch 10916, train_loss 68.221634,Time used 0.008998s\n",
      "batch 10917, train_loss 61.738041,Time used 0.012001s\n",
      "batch 10918, train_loss 66.967567,Time used 0.009002s\n",
      "batch 10919, train_loss 73.540070,Time used 0.010998s\n",
      "batch 10920, train_loss 81.603104,Time used 0.007999s\n",
      "batch 10921, train_loss 72.537689,Time used 0.010002s\n",
      "batch 10922, train_loss 69.451866,Time used 0.009998s\n",
      "batch 10923, train_loss 60.116608,Time used 0.008003s\n",
      "batch 10924, train_loss 85.747673,Time used 0.007999s\n",
      "batch 10925, train_loss 80.965683,Time used 0.007999s\n",
      "batch 10926, train_loss 61.578640,Time used 0.010001s\n",
      "batch 10927, train_loss 65.398270,Time used 0.010000s\n",
      "batch 10928, train_loss 66.793449,Time used 0.007001s\n",
      "batch 10929, train_loss 64.445671,Time used 0.007999s\n",
      "batch 10930, train_loss 76.996902,Time used 0.008000s\n",
      "batch 10931, train_loss 60.910557,Time used 0.008999s\n",
      "batch 10932, train_loss 57.964573,Time used 0.010004s\n",
      "batch 10933, train_loss 65.917458,Time used 0.010996s\n",
      "batch 10934, train_loss 55.483189,Time used 0.010001s\n",
      "batch 10935, train_loss 65.088081,Time used 0.006999s\n",
      "batch 10936, train_loss 58.503048,Time used 0.008003s\n",
      "batch 10937, train_loss 77.783844,Time used 0.008000s\n",
      "batch 10938, train_loss 57.841599,Time used 0.010001s\n",
      "batch 10939, train_loss 82.301003,Time used 0.007998s\n",
      "batch 10940, train_loss 74.370811,Time used 0.010002s\n",
      "batch 10941, train_loss 59.129036,Time used 0.007999s\n",
      "batch 10942, train_loss 62.711323,Time used 0.006999s\n",
      "batch 10943, train_loss 65.423798,Time used 0.012002s\n",
      "batch 10944, train_loss 62.432026,Time used 0.007998s\n",
      "batch 10945, train_loss 59.037727,Time used 0.010001s\n",
      "batch 10946, train_loss 61.083447,Time used 0.007000s\n",
      "batch 10947, train_loss 72.999825,Time used 0.008000s\n",
      "batch 10948, train_loss 73.354828,Time used 0.006998s\n",
      "batch 10949, train_loss 51.576241,Time used 0.008002s\n",
      "batch 10950, train_loss 61.271446,Time used 0.007998s\n",
      "batch 10951, train_loss 78.312271,Time used 0.008002s\n",
      "batch 10952, train_loss 69.932747,Time used 0.006998s\n",
      "batch 10953, train_loss 74.292168,Time used 0.008001s\n",
      "batch 10954, train_loss 67.792068,Time used 0.008001s\n",
      "batch 10955, train_loss 77.522102,Time used 0.008001s\n",
      "batch 10956, train_loss 78.772041,Time used 0.011997s\n",
      "batch 10957, train_loss 97.284912,Time used 0.011006s\n",
      "batch 10958, train_loss 67.781914,Time used 0.010001s\n",
      "batch 10959, train_loss 69.204041,Time used 0.010999s\n",
      "batch 10960, train_loss 57.219891,Time used 0.008999s\n",
      "batch 10961, train_loss 66.539116,Time used 0.008001s\n",
      "batch 10962, train_loss 37.516384,Time used 0.010002s\n",
      "batch 10963, train_loss 79.878090,Time used 0.009000s\n",
      "batch 10964, train_loss 61.886261,Time used 0.010999s\n",
      "batch 10965, train_loss 76.466049,Time used 0.010000s\n",
      "batch 10966, train_loss 44.267883,Time used 0.010002s\n",
      "batch 10967, train_loss 63.760921,Time used 0.010998s\n",
      "batch 10968, train_loss 58.966969,Time used 0.007000s\n",
      "batch 10969, train_loss 75.075737,Time used 0.009001s\n",
      "batch 10970, train_loss 79.008705,Time used 0.009997s\n",
      "batch 10971, train_loss 69.142113,Time used 0.008000s\n",
      "batch 10972, train_loss 62.279747,Time used 0.008001s\n",
      "batch 10973, train_loss 58.726788,Time used 0.006999s\n",
      "batch 10974, train_loss 66.804893,Time used 0.008001s\n",
      "batch 10975, train_loss 55.179562,Time used 0.007999s\n",
      "batch 10976, train_loss 50.705959,Time used 0.010001s\n",
      "batch 10977, train_loss 79.245789,Time used 0.011001s\n",
      "batch 10978, train_loss 65.757706,Time used 0.010001s\n",
      "batch 10979, train_loss 66.294876,Time used 0.010997s\n",
      "batch 10980, train_loss 75.624649,Time used 0.012002s\n",
      "batch 10981, train_loss 69.355583,Time used 0.012001s\n",
      "batch 10982, train_loss 50.228146,Time used 0.007997s\n",
      "batch 10983, train_loss 79.704414,Time used 0.008000s\n",
      "batch 10984, train_loss 69.638687,Time used 0.010000s\n",
      "batch 10985, train_loss 69.430702,Time used 0.008003s\n",
      "batch 10986, train_loss 65.506096,Time used 0.007997s\n",
      "batch 10987, train_loss 78.367516,Time used 0.007999s\n",
      "batch 10988, train_loss 53.245033,Time used 0.009001s\n",
      "batch 10989, train_loss 75.471535,Time used 0.007005s\n",
      "batch 10990, train_loss 55.375927,Time used 0.011999s\n",
      "batch 10991, train_loss 77.111656,Time used 0.008997s\n",
      "batch 10992, train_loss 56.188892,Time used 0.007000s\n",
      "batch 10993, train_loss 79.857216,Time used 0.011000s\n",
      "batch 10994, train_loss 65.567802,Time used 0.011999s\n",
      "batch 10995, train_loss 51.450821,Time used 0.009002s\n",
      "batch 10996, train_loss 61.944042,Time used 0.007998s\n",
      "batch 10997, train_loss 74.615784,Time used 0.011000s\n",
      "batch 10998, train_loss 62.756332,Time used 0.006998s\n",
      "batch 10999, train_loss 81.516693,Time used 0.011003s\n",
      "batch 11000, train_loss 66.338829,Time used 0.011999s\n",
      "***************************test_batch 11000, test_rmse_loss 9.399970,test_mae_loss 3.765823,test_mape_loss 59.027002,Time used 0.037001s\n",
      "batch 11001, train_loss 72.131821,Time used 0.008999s\n",
      "batch 11002, train_loss 72.069138,Time used 0.007001s\n",
      "batch 11003, train_loss 53.397892,Time used 0.007999s\n",
      "batch 11004, train_loss 63.778637,Time used 0.009001s\n",
      "batch 11005, train_loss 87.035614,Time used 0.006999s\n",
      "batch 11006, train_loss 61.831341,Time used 0.007001s\n",
      "batch 11007, train_loss 69.222664,Time used 0.007999s\n",
      "batch 11008, train_loss 81.756447,Time used 0.007002s\n",
      "batch 11009, train_loss 58.799049,Time used 0.007001s\n",
      "batch 11010, train_loss 64.194191,Time used 0.009001s\n",
      "batch 11011, train_loss 61.566780,Time used 0.011035s\n",
      "batch 11012, train_loss 42.889248,Time used 0.013001s\n",
      "batch 11013, train_loss 59.120659,Time used 0.011002s\n",
      "batch 11014, train_loss 68.787849,Time used 0.010996s\n",
      "batch 11015, train_loss 80.256828,Time used 0.012000s\n",
      "batch 11016, train_loss 59.842087,Time used 0.010002s\n",
      "batch 11017, train_loss 84.570007,Time used 0.014000s\n",
      "batch 11018, train_loss 76.584686,Time used 0.012999s\n",
      "batch 11019, train_loss 77.645531,Time used 0.013000s\n",
      "batch 11020, train_loss 68.686462,Time used 0.013002s\n",
      "batch 11021, train_loss 52.550041,Time used 0.011997s\n",
      "batch 11022, train_loss 57.157043,Time used 0.013001s\n",
      "batch 11023, train_loss 72.773804,Time used 0.013000s\n",
      "batch 11024, train_loss 56.078926,Time used 0.010999s\n",
      "batch 11025, train_loss 62.373798,Time used 0.013000s\n",
      "batch 11026, train_loss 77.158760,Time used 0.014001s\n",
      "batch 11027, train_loss 62.782848,Time used 0.010999s\n",
      "batch 11028, train_loss 78.610954,Time used 0.012002s\n",
      "batch 11029, train_loss 66.334167,Time used 0.011001s\n",
      "batch 11030, train_loss 71.530037,Time used 0.010000s\n",
      "batch 11031, train_loss 73.153534,Time used 0.012002s\n",
      "batch 11032, train_loss 50.464931,Time used 0.013999s\n",
      "batch 11033, train_loss 78.285324,Time used 0.013999s\n",
      "batch 11034, train_loss 47.746651,Time used 0.013999s\n",
      "batch 11035, train_loss 62.389332,Time used 0.027003s\n",
      "batch 11036, train_loss 74.903351,Time used 0.012997s\n",
      "batch 11037, train_loss 76.404350,Time used 0.016001s\n",
      "batch 11038, train_loss 45.404545,Time used 0.013000s\n",
      "batch 11039, train_loss 58.625004,Time used 0.009999s\n",
      "batch 11040, train_loss 65.871628,Time used 0.012001s\n",
      "batch 11041, train_loss 72.174751,Time used 0.010002s\n",
      "batch 11042, train_loss 52.344128,Time used 0.011000s\n",
      "batch 11043, train_loss 54.353840,Time used 0.011001s\n",
      "batch 11044, train_loss 62.676281,Time used 0.016000s\n",
      "batch 11045, train_loss 71.698036,Time used 0.012000s\n",
      "batch 11046, train_loss 78.209778,Time used 0.011999s\n",
      "batch 11047, train_loss 65.050217,Time used 0.013000s\n",
      "batch 11048, train_loss 63.694454,Time used 0.013999s\n",
      "batch 11049, train_loss 58.459511,Time used 0.012000s\n",
      "batch 11050, train_loss 80.682007,Time used 0.013005s\n",
      "batch 11051, train_loss 58.589939,Time used 0.010996s\n",
      "batch 11052, train_loss 59.966721,Time used 0.010999s\n",
      "batch 11053, train_loss 70.663536,Time used 0.009001s\n",
      "batch 11054, train_loss 71.073723,Time used 0.011998s\n",
      "batch 11055, train_loss 74.502220,Time used 0.008002s\n",
      "batch 11056, train_loss 77.363907,Time used 0.007998s\n",
      "batch 11057, train_loss 67.958908,Time used 0.007000s\n",
      "batch 11058, train_loss 58.840714,Time used 0.013001s\n",
      "batch 11059, train_loss 50.656342,Time used 0.011000s\n",
      "batch 11060, train_loss 70.274765,Time used 0.012000s\n",
      "batch 11061, train_loss 68.636108,Time used 0.012999s\n",
      "batch 11062, train_loss 64.204033,Time used 0.012000s\n",
      "batch 11063, train_loss 59.821529,Time used 0.011003s\n",
      "batch 11064, train_loss 83.644096,Time used 0.017000s\n",
      "batch 11065, train_loss 96.421722,Time used 0.012001s\n",
      "batch 11066, train_loss 66.750710,Time used 0.011999s\n",
      "batch 11067, train_loss 74.020737,Time used 0.011001s\n",
      "batch 11068, train_loss 74.356384,Time used 0.014001s\n",
      "batch 11069, train_loss 66.204651,Time used 0.011000s\n",
      "batch 11070, train_loss 56.666168,Time used 0.011999s\n",
      "batch 11071, train_loss 71.533127,Time used 0.012001s\n",
      "batch 11072, train_loss 60.128620,Time used 0.011000s\n",
      "batch 11073, train_loss 66.081978,Time used 0.012000s\n",
      "batch 11074, train_loss 79.641548,Time used 0.014000s\n",
      "batch 11075, train_loss 54.061172,Time used 0.017001s\n",
      "batch 11076, train_loss 63.995823,Time used 0.011000s\n",
      "batch 11077, train_loss 59.917633,Time used 0.013004s\n",
      "batch 11078, train_loss 54.587502,Time used 0.014999s\n",
      "batch 11079, train_loss 74.981895,Time used 0.014998s\n",
      "batch 11080, train_loss 63.662731,Time used 0.028000s\n",
      "batch 11081, train_loss 77.495705,Time used 0.013003s\n",
      "batch 11082, train_loss 52.196110,Time used 0.012997s\n",
      "batch 11083, train_loss 66.622223,Time used 0.013000s\n",
      "batch 11084, train_loss 67.703667,Time used 0.011004s\n",
      "batch 11085, train_loss 63.758297,Time used 0.011998s\n",
      "batch 11086, train_loss 58.470879,Time used 0.012998s\n",
      "batch 11087, train_loss 62.240005,Time used 0.012001s\n",
      "batch 11088, train_loss 60.295479,Time used 0.013000s\n",
      "batch 11089, train_loss 60.489578,Time used 0.015999s\n",
      "batch 11090, train_loss 61.762100,Time used 0.011001s\n",
      "batch 11091, train_loss 59.863876,Time used 0.009001s\n",
      "batch 11092, train_loss 55.112106,Time used 0.014000s\n",
      "batch 11093, train_loss 65.810913,Time used 0.011998s\n",
      "batch 11094, train_loss 53.054794,Time used 0.012005s\n",
      "batch 11095, train_loss 56.916359,Time used 0.010001s\n",
      "batch 11096, train_loss 75.961838,Time used 0.012998s\n",
      "batch 11097, train_loss 77.466850,Time used 0.011000s\n",
      "batch 11098, train_loss 64.445763,Time used 0.010001s\n",
      "batch 11099, train_loss 66.943619,Time used 0.009002s\n",
      "batch 11100, train_loss 68.880119,Time used 0.010997s\n",
      "***************************test_batch 11100, test_rmse_loss 9.364336,test_mae_loss 3.752297,test_mape_loss 58.779345,Time used 0.049000s\n",
      "batch 11101, train_loss 62.612621,Time used 0.012000s\n",
      "batch 11102, train_loss 84.182327,Time used 0.011000s\n",
      "batch 11103, train_loss 69.136253,Time used 0.011000s\n",
      "batch 11104, train_loss 67.812759,Time used 0.011997s\n",
      "batch 11105, train_loss 66.977417,Time used 0.010999s\n",
      "batch 11106, train_loss 73.513069,Time used 0.012000s\n",
      "batch 11107, train_loss 76.682892,Time used 0.011002s\n",
      "batch 11108, train_loss 56.407166,Time used 0.012001s\n",
      "batch 11109, train_loss 64.876564,Time used 0.010000s\n",
      "batch 11110, train_loss 64.278732,Time used 0.012000s\n",
      "batch 11111, train_loss 60.971851,Time used 0.010999s\n",
      "batch 11112, train_loss 74.961136,Time used 0.012000s\n",
      "batch 11113, train_loss 68.128532,Time used 0.011003s\n",
      "batch 11114, train_loss 65.377831,Time used 0.011999s\n",
      "batch 11115, train_loss 73.173798,Time used 0.010001s\n",
      "batch 11116, train_loss 71.548660,Time used 0.011003s\n",
      "batch 11117, train_loss 73.966118,Time used 0.011998s\n",
      "batch 11118, train_loss 63.142643,Time used 0.018002s\n",
      "batch 11119, train_loss 51.801479,Time used 0.015998s\n",
      "batch 11120, train_loss 71.382118,Time used 0.023002s\n",
      "batch 11121, train_loss 63.769615,Time used 0.012004s\n",
      "batch 11122, train_loss 64.032639,Time used 0.007995s\n",
      "batch 11123, train_loss 70.016838,Time used 0.010000s\n",
      "batch 11124, train_loss 60.555717,Time used 0.012003s\n",
      "batch 11125, train_loss 76.803696,Time used 0.013002s\n",
      "batch 11126, train_loss 71.852936,Time used 0.009996s\n",
      "batch 11127, train_loss 71.107086,Time used 0.011998s\n",
      "batch 11128, train_loss 59.719524,Time used 0.013002s\n",
      "batch 11129, train_loss 69.446777,Time used 0.013001s\n",
      "batch 11130, train_loss 71.820244,Time used 0.011998s\n",
      "batch 11131, train_loss 66.578300,Time used 0.011001s\n",
      "batch 11132, train_loss 54.195736,Time used 0.011997s\n",
      "batch 11133, train_loss 60.978779,Time used 0.016000s\n",
      "batch 11134, train_loss 68.087509,Time used 0.012004s\n",
      "batch 11135, train_loss 55.479565,Time used 0.008001s\n",
      "batch 11136, train_loss 62.825756,Time used 0.010002s\n",
      "batch 11137, train_loss 71.568474,Time used 0.010000s\n",
      "batch 11138, train_loss 76.947365,Time used 0.010001s\n",
      "batch 11139, train_loss 71.598526,Time used 0.008998s\n",
      "batch 11140, train_loss 54.252476,Time used 0.008002s\n",
      "batch 11141, train_loss 57.787788,Time used 0.008000s\n",
      "batch 11142, train_loss 68.359421,Time used 0.010000s\n",
      "batch 11143, train_loss 77.220802,Time used 0.010999s\n",
      "batch 11144, train_loss 63.909096,Time used 0.008000s\n",
      "batch 11145, train_loss 59.684166,Time used 0.007999s\n",
      "batch 11146, train_loss 59.706081,Time used 0.009001s\n",
      "batch 11147, train_loss 58.478737,Time used 0.013002s\n",
      "batch 11148, train_loss 69.908440,Time used 0.012998s\n",
      "batch 11149, train_loss 60.768013,Time used 0.010003s\n",
      "batch 11150, train_loss 61.131893,Time used 0.011001s\n",
      "batch 11151, train_loss 90.141747,Time used 0.012998s\n",
      "batch 11152, train_loss 82.134171,Time used 0.011998s\n",
      "batch 11153, train_loss 58.321445,Time used 0.011002s\n",
      "batch 11154, train_loss 77.059395,Time used 0.011999s\n",
      "batch 11155, train_loss 58.668392,Time used 0.013004s\n",
      "batch 11156, train_loss 71.219032,Time used 0.011998s\n",
      "batch 11157, train_loss 47.104851,Time used 0.014000s\n",
      "batch 11158, train_loss 51.485878,Time used 0.012001s\n",
      "batch 11159, train_loss 68.189125,Time used 0.012999s\n",
      "batch 11160, train_loss 67.432480,Time used 0.011003s\n",
      "batch 11161, train_loss 60.534309,Time used 0.012003s\n",
      "batch 11162, train_loss 61.493874,Time used 0.011997s\n",
      "batch 11163, train_loss 91.168854,Time used 0.010999s\n",
      "batch 11164, train_loss 63.944942,Time used 0.011997s\n",
      "batch 11165, train_loss 64.141800,Time used 0.011999s\n",
      "batch 11166, train_loss 72.858452,Time used 0.009003s\n",
      "batch 11167, train_loss 53.595680,Time used 0.012002s\n",
      "batch 11168, train_loss 78.076927,Time used 0.015002s\n",
      "batch 11169, train_loss 63.574104,Time used 0.024999s\n",
      "batch 11170, train_loss 64.375496,Time used 0.012005s\n",
      "batch 11171, train_loss 44.434292,Time used 0.010994s\n",
      "batch 11172, train_loss 66.711983,Time used 0.011001s\n",
      "batch 11173, train_loss 71.639603,Time used 0.010999s\n",
      "batch 11174, train_loss 92.243217,Time used 0.012001s\n",
      "batch 11175, train_loss 71.622101,Time used 0.012997s\n",
      "batch 11176, train_loss 62.543343,Time used 0.012003s\n",
      "batch 11177, train_loss 49.847569,Time used 0.011001s\n",
      "batch 11178, train_loss 63.819668,Time used 0.011000s\n",
      "batch 11179, train_loss 68.532722,Time used 0.011999s\n",
      "batch 11180, train_loss 56.844604,Time used 0.012001s\n",
      "batch 11181, train_loss 48.707302,Time used 0.011002s\n",
      "batch 11182, train_loss 60.168327,Time used 0.010998s\n",
      "batch 11183, train_loss 89.650368,Time used 0.013000s\n",
      "batch 11184, train_loss 59.127357,Time used 0.010997s\n",
      "batch 11185, train_loss 53.266575,Time used 0.010000s\n",
      "batch 11186, train_loss 72.992249,Time used 0.010002s\n",
      "batch 11187, train_loss 72.408783,Time used 0.008001s\n",
      "batch 11188, train_loss 97.885368,Time used 0.007999s\n",
      "batch 11189, train_loss 71.822945,Time used 0.009001s\n",
      "batch 11190, train_loss 56.318756,Time used 0.007999s\n",
      "batch 11191, train_loss 61.984421,Time used 0.010999s\n",
      "batch 11192, train_loss 45.934032,Time used 0.011002s\n",
      "batch 11193, train_loss 77.445671,Time used 0.008999s\n",
      "batch 11194, train_loss 52.807571,Time used 0.012001s\n",
      "batch 11195, train_loss 59.230194,Time used 0.010999s\n",
      "batch 11196, train_loss 80.221863,Time used 0.011000s\n",
      "batch 11197, train_loss 67.869156,Time used 0.012000s\n",
      "batch 11198, train_loss 61.299000,Time used 0.011002s\n",
      "batch 11199, train_loss 57.183235,Time used 0.010999s\n",
      "batch 11200, train_loss 58.252613,Time used 0.012000s\n",
      "***************************test_batch 11200, test_rmse_loss 9.327888,test_mae_loss 3.738799,test_mape_loss 58.475283,Time used 0.046998s\n",
      "batch 11201, train_loss 60.379505,Time used 0.012004s\n",
      "batch 11202, train_loss 60.627750,Time used 0.007999s\n",
      "batch 11203, train_loss 59.168556,Time used 0.008001s\n",
      "batch 11204, train_loss 77.751648,Time used 0.012001s\n",
      "batch 11205, train_loss 67.302124,Time used 0.011009s\n",
      "batch 11206, train_loss 62.624310,Time used 0.012991s\n",
      "batch 11207, train_loss 70.694084,Time used 0.011001s\n",
      "batch 11208, train_loss 71.974297,Time used 0.012004s\n",
      "batch 11209, train_loss 70.662086,Time used 0.011999s\n",
      "batch 11210, train_loss 58.767933,Time used 0.016000s\n",
      "batch 11211, train_loss 68.575981,Time used 0.015998s\n",
      "batch 11212, train_loss 83.522430,Time used 0.026001s\n",
      "batch 11213, train_loss 63.152058,Time used 0.013001s\n",
      "batch 11214, train_loss 69.955284,Time used 0.014999s\n",
      "batch 11215, train_loss 71.730186,Time used 0.010002s\n",
      "batch 11216, train_loss 69.701569,Time used 0.014003s\n",
      "batch 11217, train_loss 84.185654,Time used 0.010000s\n",
      "batch 11218, train_loss 58.132961,Time used 0.011006s\n",
      "batch 11219, train_loss 67.039513,Time used 0.012999s\n",
      "batch 11220, train_loss 65.655449,Time used 0.012001s\n",
      "batch 11221, train_loss 77.583763,Time used 0.011000s\n",
      "batch 11222, train_loss 59.763893,Time used 0.011999s\n",
      "batch 11223, train_loss 90.216110,Time used 0.012001s\n",
      "batch 11224, train_loss 62.721279,Time used 0.010999s\n",
      "batch 11225, train_loss 57.343990,Time used 0.012004s\n",
      "batch 11226, train_loss 60.479805,Time used 0.010997s\n",
      "batch 11227, train_loss 41.789032,Time used 0.008996s\n",
      "batch 11228, train_loss 51.282269,Time used 0.010000s\n",
      "batch 11229, train_loss 57.393345,Time used 0.009001s\n",
      "batch 11230, train_loss 62.007000,Time used 0.008999s\n",
      "batch 11231, train_loss 50.950871,Time used 0.006999s\n",
      "batch 11232, train_loss 72.002609,Time used 0.009999s\n",
      "batch 11233, train_loss 77.645775,Time used 0.008004s\n",
      "batch 11234, train_loss 51.403458,Time used 0.007998s\n",
      "batch 11235, train_loss 61.734062,Time used 0.006999s\n",
      "batch 11236, train_loss 79.181778,Time used 0.008000s\n",
      "batch 11237, train_loss 55.283718,Time used 0.010002s\n",
      "batch 11238, train_loss 71.714050,Time used 0.012998s\n",
      "batch 11239, train_loss 74.271507,Time used 0.011003s\n",
      "batch 11240, train_loss 65.480385,Time used 0.009999s\n",
      "batch 11241, train_loss 64.710411,Time used 0.010002s\n",
      "batch 11242, train_loss 66.907898,Time used 0.011002s\n",
      "batch 11243, train_loss 47.393993,Time used 0.012001s\n",
      "batch 11244, train_loss 80.416519,Time used 0.011999s\n",
      "batch 11245, train_loss 60.063194,Time used 0.011001s\n",
      "batch 11246, train_loss 69.184456,Time used 0.013003s\n",
      "batch 11247, train_loss 66.940414,Time used 0.009997s\n",
      "batch 11248, train_loss 63.908344,Time used 0.011999s\n",
      "batch 11249, train_loss 59.827103,Time used 0.012001s\n",
      "batch 11250, train_loss 88.146935,Time used 0.008001s\n",
      "batch 11251, train_loss 65.301567,Time used 0.009002s\n",
      "batch 11252, train_loss 49.038456,Time used 0.009999s\n",
      "batch 11253, train_loss 58.853008,Time used 0.010998s\n",
      "batch 11254, train_loss 54.542942,Time used 0.011002s\n",
      "batch 11255, train_loss 74.604797,Time used 0.011000s\n",
      "batch 11256, train_loss 64.621262,Time used 0.012002s\n",
      "batch 11257, train_loss 80.086029,Time used 0.010997s\n",
      "batch 11258, train_loss 58.459156,Time used 0.011002s\n",
      "batch 11259, train_loss 65.846146,Time used 0.016000s\n",
      "batch 11260, train_loss 66.641068,Time used 0.016001s\n",
      "batch 11261, train_loss 70.224823,Time used 0.021999s\n",
      "batch 11262, train_loss 71.951897,Time used 0.012001s\n",
      "batch 11263, train_loss 57.730835,Time used 0.011998s\n",
      "batch 11264, train_loss 70.088692,Time used 0.013001s\n",
      "batch 11265, train_loss 52.885498,Time used 0.011998s\n",
      "batch 11266, train_loss 43.868919,Time used 0.011002s\n",
      "batch 11267, train_loss 62.134243,Time used 0.012000s\n",
      "batch 11268, train_loss 60.509747,Time used 0.010001s\n",
      "batch 11269, train_loss 62.304081,Time used 0.010997s\n",
      "batch 11270, train_loss 65.300156,Time used 0.009002s\n",
      "batch 11271, train_loss 70.741295,Time used 0.011999s\n",
      "batch 11272, train_loss 80.167763,Time used 0.012001s\n",
      "batch 11273, train_loss 68.927986,Time used 0.012001s\n",
      "batch 11274, train_loss 92.516327,Time used 0.011998s\n",
      "batch 11275, train_loss 54.167404,Time used 0.012002s\n",
      "batch 11276, train_loss 52.100754,Time used 0.011001s\n",
      "batch 11277, train_loss 77.685310,Time used 0.007998s\n",
      "batch 11278, train_loss 60.293900,Time used 0.011000s\n",
      "batch 11279, train_loss 56.336441,Time used 0.011001s\n",
      "batch 11280, train_loss 67.556915,Time used 0.010000s\n",
      "batch 11281, train_loss 51.756161,Time used 0.010001s\n",
      "batch 11282, train_loss 77.638664,Time used 0.009001s\n",
      "batch 11283, train_loss 62.282104,Time used 0.011999s\n",
      "batch 11284, train_loss 64.643234,Time used 0.008003s\n",
      "batch 11285, train_loss 73.222534,Time used 0.006998s\n",
      "batch 11286, train_loss 46.843491,Time used 0.007000s\n",
      "batch 11287, train_loss 71.880409,Time used 0.012001s\n",
      "batch 11288, train_loss 52.062706,Time used 0.011999s\n",
      "batch 11289, train_loss 78.390991,Time used 0.011001s\n",
      "batch 11290, train_loss 79.223267,Time used 0.010001s\n",
      "batch 11291, train_loss 61.592464,Time used 0.013997s\n",
      "batch 11292, train_loss 46.365753,Time used 0.011000s\n",
      "batch 11293, train_loss 90.031799,Time used 0.011998s\n",
      "batch 11294, train_loss 66.195923,Time used 0.013005s\n",
      "batch 11295, train_loss 71.865128,Time used 0.011998s\n",
      "batch 11296, train_loss 53.249474,Time used 0.011999s\n",
      "batch 11297, train_loss 62.998634,Time used 0.010998s\n",
      "batch 11298, train_loss 63.022087,Time used 0.014003s\n",
      "batch 11299, train_loss 69.432213,Time used 0.014997s\n",
      "batch 11300, train_loss 49.552990,Time used 0.011001s\n",
      "***************************test_batch 11300, test_rmse_loss 9.287956,test_mae_loss 3.728332,test_mape_loss 58.463535,Time used 0.040999s\n",
      "batch 11301, train_loss 61.296478,Time used 0.012000s\n",
      "batch 11302, train_loss 68.142456,Time used 0.010999s\n",
      "batch 11303, train_loss 61.193161,Time used 0.011001s\n",
      "batch 11304, train_loss 83.240143,Time used 0.012001s\n",
      "batch 11305, train_loss 60.902889,Time used 0.014998s\n",
      "batch 11306, train_loss 66.113136,Time used 0.024001s\n",
      "batch 11307, train_loss 46.902805,Time used 0.013002s\n",
      "batch 11308, train_loss 64.385277,Time used 0.012999s\n",
      "batch 11309, train_loss 46.919689,Time used 0.011003s\n",
      "batch 11310, train_loss 63.077972,Time used 0.012995s\n",
      "batch 11311, train_loss 61.204529,Time used 0.010004s\n",
      "batch 11312, train_loss 64.751579,Time used 0.010996s\n",
      "batch 11313, train_loss 73.701401,Time used 0.012000s\n",
      "batch 11314, train_loss 60.825485,Time used 0.009999s\n",
      "batch 11315, train_loss 56.438541,Time used 0.011002s\n",
      "batch 11316, train_loss 67.962494,Time used 0.013000s\n",
      "batch 11317, train_loss 80.227333,Time used 0.010001s\n",
      "batch 11318, train_loss 67.623192,Time used 0.011001s\n",
      "batch 11319, train_loss 71.501427,Time used 0.011998s\n",
      "batch 11320, train_loss 85.375145,Time used 0.011003s\n",
      "batch 11321, train_loss 73.502693,Time used 0.012999s\n",
      "batch 11322, train_loss 57.005646,Time used 0.011999s\n",
      "batch 11323, train_loss 64.483498,Time used 0.008001s\n",
      "batch 11324, train_loss 60.848175,Time used 0.011000s\n",
      "batch 11325, train_loss 66.396065,Time used 0.010998s\n",
      "batch 11326, train_loss 52.596512,Time used 0.009999s\n",
      "batch 11327, train_loss 79.552246,Time used 0.009001s\n",
      "batch 11328, train_loss 70.446304,Time used 0.007997s\n",
      "batch 11329, train_loss 68.744431,Time used 0.008002s\n",
      "batch 11330, train_loss 58.868999,Time used 0.008000s\n",
      "batch 11331, train_loss 39.347420,Time used 0.006999s\n",
      "batch 11332, train_loss 64.587982,Time used 0.006999s\n",
      "batch 11333, train_loss 58.198921,Time used 0.010997s\n",
      "batch 11334, train_loss 89.915756,Time used 0.012002s\n",
      "batch 11335, train_loss 72.284462,Time used 0.012003s\n",
      "batch 11336, train_loss 67.358795,Time used 0.010001s\n",
      "batch 11337, train_loss 71.423767,Time used 0.010998s\n",
      "batch 11338, train_loss 74.612823,Time used 0.012001s\n",
      "batch 11339, train_loss 71.010468,Time used 0.010998s\n",
      "batch 11340, train_loss 58.488472,Time used 0.010999s\n",
      "batch 11341, train_loss 64.846588,Time used 0.011998s\n",
      "batch 11342, train_loss 53.101242,Time used 0.009000s\n",
      "batch 11343, train_loss 65.189262,Time used 0.011001s\n",
      "batch 11344, train_loss 59.138855,Time used 0.011000s\n",
      "batch 11345, train_loss 74.561821,Time used 0.012001s\n",
      "batch 11346, train_loss 63.567963,Time used 0.012000s\n",
      "batch 11347, train_loss 46.648399,Time used 0.013000s\n",
      "batch 11348, train_loss 56.369610,Time used 0.010002s\n",
      "batch 11349, train_loss 83.536209,Time used 0.011000s\n",
      "batch 11350, train_loss 61.807686,Time used 0.012001s\n",
      "batch 11351, train_loss 67.088272,Time used 0.012000s\n",
      "batch 11352, train_loss 69.368469,Time used 0.011998s\n",
      "batch 11353, train_loss 43.225967,Time used 0.011998s\n",
      "batch 11354, train_loss 62.768444,Time used 0.018000s\n",
      "batch 11355, train_loss 70.590530,Time used 0.016002s\n",
      "batch 11356, train_loss 69.275002,Time used 0.022997s\n",
      "batch 11357, train_loss 59.176384,Time used 0.012001s\n",
      "batch 11358, train_loss 71.533585,Time used 0.013003s\n",
      "batch 11359, train_loss 76.351257,Time used 0.010997s\n",
      "batch 11360, train_loss 55.207787,Time used 0.010000s\n",
      "batch 11361, train_loss 71.361679,Time used 0.012001s\n",
      "batch 11362, train_loss 68.479485,Time used 0.014001s\n",
      "batch 11363, train_loss 67.873146,Time used 0.011997s\n",
      "batch 11364, train_loss 58.066231,Time used 0.013001s\n",
      "batch 11365, train_loss 59.198288,Time used 0.011002s\n",
      "batch 11366, train_loss 51.188419,Time used 0.014001s\n",
      "batch 11367, train_loss 54.134773,Time used 0.012000s\n",
      "batch 11368, train_loss 70.081558,Time used 0.010000s\n",
      "batch 11369, train_loss 60.545891,Time used 0.011000s\n",
      "batch 11370, train_loss 70.105324,Time used 0.013000s\n",
      "batch 11371, train_loss 78.959427,Time used 0.009996s\n",
      "batch 11372, train_loss 55.288139,Time used 0.008000s\n",
      "batch 11373, train_loss 80.214455,Time used 0.010000s\n",
      "batch 11374, train_loss 75.696228,Time used 0.013002s\n",
      "batch 11375, train_loss 57.765430,Time used 0.011999s\n",
      "batch 11376, train_loss 70.064957,Time used 0.012999s\n",
      "batch 11377, train_loss 53.415581,Time used 0.010997s\n",
      "batch 11378, train_loss 44.829895,Time used 0.012001s\n",
      "batch 11379, train_loss 58.611443,Time used 0.007999s\n",
      "batch 11380, train_loss 65.085930,Time used 0.007001s\n",
      "batch 11381, train_loss 74.352295,Time used 0.008003s\n",
      "batch 11382, train_loss 62.913715,Time used 0.012996s\n",
      "batch 11383, train_loss 60.737186,Time used 0.010999s\n",
      "batch 11384, train_loss 62.751305,Time used 0.012002s\n",
      "batch 11385, train_loss 62.331371,Time used 0.011000s\n",
      "batch 11386, train_loss 61.650742,Time used 0.008002s\n",
      "batch 11387, train_loss 59.851681,Time used 0.010998s\n",
      "batch 11388, train_loss 80.478394,Time used 0.011004s\n",
      "batch 11389, train_loss 76.538017,Time used 0.011997s\n",
      "batch 11390, train_loss 46.039001,Time used 0.011998s\n",
      "batch 11391, train_loss 67.623367,Time used 0.012000s\n",
      "batch 11392, train_loss 68.223969,Time used 0.012001s\n",
      "batch 11393, train_loss 72.192924,Time used 0.011998s\n",
      "batch 11394, train_loss 68.151337,Time used 0.012000s\n",
      "batch 11395, train_loss 56.636505,Time used 0.012002s\n",
      "batch 11396, train_loss 55.610386,Time used 0.012000s\n",
      "batch 11397, train_loss 80.071220,Time used 0.012001s\n",
      "batch 11398, train_loss 71.445145,Time used 0.011999s\n",
      "batch 11399, train_loss 74.899673,Time used 0.010999s\n",
      "batch 11400, train_loss 69.769646,Time used 0.011001s\n",
      "***************************test_batch 11400, test_rmse_loss 9.251980,test_mae_loss 3.717292,test_mape_loss 58.448110,Time used 0.050999s\n",
      "batch 11401, train_loss 80.291908,Time used 0.023000s\n",
      "batch 11402, train_loss 68.545586,Time used 0.013999s\n",
      "batch 11403, train_loss 63.827549,Time used 0.012002s\n",
      "batch 11404, train_loss 58.103931,Time used 0.010997s\n",
      "batch 11405, train_loss 76.614189,Time used 0.012003s\n",
      "batch 11406, train_loss 62.244843,Time used 0.010999s\n",
      "batch 11407, train_loss 74.226219,Time used 0.009003s\n",
      "batch 11408, train_loss 50.430477,Time used 0.010000s\n",
      "batch 11409, train_loss 55.009674,Time used 0.010000s\n",
      "batch 11410, train_loss 58.077415,Time used 0.012000s\n",
      "batch 11411, train_loss 52.546570,Time used 0.012002s\n",
      "batch 11412, train_loss 72.484955,Time used 0.011000s\n",
      "batch 11413, train_loss 67.090157,Time used 0.010997s\n",
      "batch 11414, train_loss 51.435020,Time used 0.012001s\n",
      "batch 11415, train_loss 70.878418,Time used 0.011000s\n",
      "batch 11416, train_loss 57.192932,Time used 0.011001s\n",
      "batch 11417, train_loss 85.260925,Time used 0.010998s\n",
      "batch 11418, train_loss 52.924767,Time used 0.008000s\n",
      "batch 11419, train_loss 62.972244,Time used 0.010001s\n",
      "batch 11420, train_loss 70.910255,Time used 0.010000s\n",
      "batch 11421, train_loss 57.616894,Time used 0.009002s\n",
      "batch 11422, train_loss 51.325409,Time used 0.009000s\n",
      "batch 11423, train_loss 74.213333,Time used 0.009001s\n",
      "batch 11424, train_loss 77.661240,Time used 0.007997s\n",
      "batch 11425, train_loss 72.301300,Time used 0.011998s\n",
      "batch 11426, train_loss 79.474663,Time used 0.007001s\n",
      "batch 11427, train_loss 60.391319,Time used 0.007001s\n",
      "batch 11428, train_loss 65.339432,Time used 0.008001s\n",
      "batch 11429, train_loss 57.184120,Time used 0.010998s\n",
      "batch 11430, train_loss 75.047424,Time used 0.010004s\n",
      "batch 11431, train_loss 64.344566,Time used 0.011001s\n",
      "batch 11432, train_loss 50.175888,Time used 0.010000s\n",
      "batch 11433, train_loss 68.312462,Time used 0.012001s\n",
      "batch 11434, train_loss 53.157238,Time used 0.011999s\n",
      "batch 11435, train_loss 48.862713,Time used 0.008002s\n",
      "batch 11436, train_loss 73.641670,Time used 0.011996s\n",
      "batch 11437, train_loss 61.665569,Time used 0.012000s\n",
      "batch 11438, train_loss 73.703087,Time used 0.011001s\n",
      "batch 11439, train_loss 69.901550,Time used 0.011000s\n",
      "batch 11440, train_loss 81.231010,Time used 0.011999s\n",
      "batch 11441, train_loss 44.644321,Time used 0.011000s\n",
      "batch 11442, train_loss 62.577553,Time used 0.011002s\n",
      "batch 11443, train_loss 53.475918,Time used 0.012997s\n",
      "batch 11444, train_loss 63.913536,Time used 0.010999s\n",
      "batch 11445, train_loss 65.354660,Time used 0.012003s\n",
      "batch 11446, train_loss 57.706375,Time used 0.010002s\n",
      "batch 11447, train_loss 78.590271,Time used 0.011998s\n",
      "batch 11448, train_loss 68.005089,Time used 0.009998s\n",
      "batch 11449, train_loss 65.826187,Time used 0.011003s\n",
      "batch 11450, train_loss 74.389671,Time used 0.011995s\n",
      "batch 11451, train_loss 59.255249,Time used 0.013002s\n",
      "batch 11452, train_loss 67.003838,Time used 0.015996s\n",
      "batch 11453, train_loss 61.906525,Time used 0.013001s\n",
      "batch 11454, train_loss 52.948139,Time used 0.025001s\n",
      "batch 11455, train_loss 71.320000,Time used 0.016006s\n",
      "batch 11456, train_loss 67.986099,Time used 0.021994s\n",
      "batch 11457, train_loss 67.351265,Time used 0.014000s\n",
      "batch 11458, train_loss 79.183327,Time used 0.011998s\n",
      "batch 11459, train_loss 56.922958,Time used 0.011000s\n",
      "batch 11460, train_loss 67.407471,Time used 0.012002s\n",
      "batch 11461, train_loss 53.306915,Time used 0.012999s\n",
      "batch 11462, train_loss 64.435341,Time used 0.012002s\n",
      "batch 11463, train_loss 60.540867,Time used 0.013000s\n",
      "batch 11464, train_loss 70.838631,Time used 0.011002s\n",
      "batch 11465, train_loss 76.041969,Time used 0.013995s\n",
      "batch 11466, train_loss 67.447838,Time used 0.010003s\n",
      "batch 11467, train_loss 58.870152,Time used 0.011001s\n",
      "batch 11468, train_loss 56.304676,Time used 0.010002s\n",
      "batch 11469, train_loss 61.755096,Time used 0.010995s\n",
      "batch 11470, train_loss 63.114849,Time used 0.013002s\n",
      "batch 11471, train_loss 62.214050,Time used 0.010999s\n",
      "batch 11472, train_loss 59.148087,Time used 0.008000s\n",
      "batch 11473, train_loss 59.037731,Time used 0.008001s\n",
      "batch 11474, train_loss 79.888535,Time used 0.009999s\n",
      "batch 11475, train_loss 70.014061,Time used 0.008000s\n",
      "batch 11476, train_loss 64.653320,Time used 0.011001s\n",
      "batch 11477, train_loss 68.054039,Time used 0.011000s\n",
      "batch 11478, train_loss 58.944714,Time used 0.009000s\n",
      "batch 11479, train_loss 48.710693,Time used 0.011001s\n",
      "batch 11480, train_loss 74.779305,Time used 0.007999s\n",
      "batch 11481, train_loss 63.301071,Time used 0.007999s\n",
      "batch 11482, train_loss 55.265568,Time used 0.007999s\n",
      "batch 11483, train_loss 66.346893,Time used 0.008001s\n",
      "batch 11484, train_loss 80.619965,Time used 0.009001s\n",
      "batch 11485, train_loss 58.317207,Time used 0.011001s\n",
      "batch 11486, train_loss 52.801968,Time used 0.007000s\n",
      "batch 11487, train_loss 66.403900,Time used 0.010001s\n",
      "batch 11488, train_loss 59.333576,Time used 0.008001s\n",
      "batch 11489, train_loss 67.032745,Time used 0.008001s\n",
      "batch 11490, train_loss 75.460823,Time used 0.010997s\n",
      "batch 11491, train_loss 65.173401,Time used 0.009000s\n",
      "batch 11492, train_loss 61.853580,Time used 0.008001s\n",
      "batch 11493, train_loss 77.726730,Time used 0.008003s\n",
      "batch 11494, train_loss 65.243469,Time used 0.007998s\n",
      "batch 11495, train_loss 63.351910,Time used 0.010002s\n",
      "batch 11496, train_loss 40.036102,Time used 0.009031s\n",
      "batch 11497, train_loss 66.076347,Time used 0.008994s\n",
      "batch 11498, train_loss 57.201351,Time used 0.008001s\n",
      "batch 11499, train_loss 80.083931,Time used 0.007000s\n",
      "batch 11500, train_loss 54.812775,Time used 0.012001s\n",
      "***************************test_batch 11500, test_rmse_loss 9.218834,test_mae_loss 3.703914,test_mape_loss 58.084271,Time used 0.039999s\n",
      "batch 11501, train_loss 59.434151,Time used 0.008002s\n",
      "batch 11502, train_loss 50.483013,Time used 0.008000s\n",
      "batch 11503, train_loss 60.253902,Time used 0.007998s\n",
      "batch 11504, train_loss 63.692139,Time used 0.007000s\n",
      "batch 11505, train_loss 62.469101,Time used 0.008000s\n",
      "batch 11506, train_loss 64.056877,Time used 0.008000s\n",
      "batch 11507, train_loss 57.991680,Time used 0.009000s\n",
      "batch 11508, train_loss 84.816055,Time used 0.007999s\n",
      "batch 11509, train_loss 66.369362,Time used 0.010000s\n",
      "batch 11510, train_loss 68.283440,Time used 0.006999s\n",
      "batch 11511, train_loss 70.812157,Time used 0.008003s\n",
      "batch 11512, train_loss 67.119484,Time used 0.010001s\n",
      "batch 11513, train_loss 75.199188,Time used 0.009998s\n",
      "batch 11514, train_loss 77.205482,Time used 0.008001s\n",
      "batch 11515, train_loss 53.587334,Time used 0.007033s\n",
      "batch 11516, train_loss 66.057945,Time used 0.006965s\n",
      "batch 11517, train_loss 54.369629,Time used 0.008035s\n",
      "batch 11518, train_loss 59.646393,Time used 0.007964s\n",
      "batch 11519, train_loss 64.335022,Time used 0.008029s\n",
      "batch 11520, train_loss 56.070637,Time used 0.006969s\n",
      "batch 11521, train_loss 82.315704,Time used 0.009001s\n",
      "batch 11522, train_loss 57.692783,Time used 0.011034s\n",
      "batch 11523, train_loss 67.285507,Time used 0.007999s\n",
      "batch 11524, train_loss 57.586739,Time used 0.008967s\n",
      "batch 11525, train_loss 64.423477,Time used 0.008999s\n",
      "batch 11526, train_loss 48.523487,Time used 0.010035s\n",
      "batch 11527, train_loss 67.220100,Time used 0.006996s\n",
      "batch 11528, train_loss 76.621620,Time used 0.007000s\n",
      "batch 11529, train_loss 66.655563,Time used 0.009001s\n",
      "batch 11530, train_loss 56.630970,Time used 0.007999s\n",
      "batch 11531, train_loss 54.326534,Time used 0.008964s\n",
      "batch 11532, train_loss 67.930412,Time used 0.009007s\n",
      "batch 11533, train_loss 61.955345,Time used 0.007993s\n",
      "batch 11534, train_loss 81.535812,Time used 0.007037s\n",
      "batch 11535, train_loss 43.091846,Time used 0.007963s\n",
      "batch 11536, train_loss 73.910561,Time used 0.011002s\n",
      "batch 11537, train_loss 72.116295,Time used 0.010004s\n",
      "batch 11538, train_loss 70.144272,Time used 0.006996s\n",
      "batch 11539, train_loss 62.809734,Time used 0.008002s\n",
      "batch 11540, train_loss 72.017647,Time used 0.008000s\n",
      "batch 11541, train_loss 66.767746,Time used 0.009001s\n",
      "batch 11542, train_loss 58.681038,Time used 0.009998s\n",
      "batch 11543, train_loss 62.458321,Time used 0.007038s\n",
      "batch 11544, train_loss 44.360485,Time used 0.007962s\n",
      "batch 11545, train_loss 60.454044,Time used 0.006986s\n",
      "batch 11546, train_loss 56.141590,Time used 0.007967s\n",
      "batch 11547, train_loss 58.104546,Time used 0.006995s\n",
      "batch 11548, train_loss 59.483978,Time used 0.006967s\n",
      "batch 11549, train_loss 65.245918,Time used 0.010998s\n",
      "batch 11550, train_loss 48.564384,Time used 0.011002s\n",
      "batch 11551, train_loss 76.761124,Time used 0.007000s\n",
      "batch 11552, train_loss 80.242935,Time used 0.008001s\n",
      "batch 11553, train_loss 70.191307,Time used 0.009000s\n",
      "batch 11554, train_loss 55.988560,Time used 0.013001s\n",
      "batch 11555, train_loss 71.200584,Time used 0.007001s\n",
      "batch 11556, train_loss 66.109535,Time used 0.007999s\n",
      "batch 11557, train_loss 57.666824,Time used 0.010031s\n",
      "batch 11558, train_loss 64.121429,Time used 0.010002s\n",
      "batch 11559, train_loss 61.838139,Time used 0.008999s\n",
      "batch 11560, train_loss 74.922310,Time used 0.008001s\n",
      "batch 11561, train_loss 76.015121,Time used 0.010999s\n",
      "batch 11562, train_loss 73.536446,Time used 0.011006s\n",
      "batch 11563, train_loss 58.277538,Time used 0.010995s\n",
      "batch 11564, train_loss 77.582359,Time used 0.007000s\n",
      "batch 11565, train_loss 59.394516,Time used 0.012000s\n",
      "batch 11566, train_loss 51.648846,Time used 0.009002s\n",
      "batch 11567, train_loss 52.945015,Time used 0.009997s\n",
      "batch 11568, train_loss 58.052574,Time used 0.011002s\n",
      "batch 11569, train_loss 74.737282,Time used 0.007000s\n",
      "batch 11570, train_loss 68.703697,Time used 0.009004s\n",
      "batch 11571, train_loss 50.056767,Time used 0.007999s\n",
      "batch 11572, train_loss 67.571358,Time used 0.009998s\n",
      "batch 11573, train_loss 64.798874,Time used 0.011002s\n",
      "batch 11574, train_loss 65.985977,Time used 0.006997s\n",
      "batch 11575, train_loss 64.412582,Time used 0.008002s\n",
      "batch 11576, train_loss 68.784935,Time used 0.008999s\n",
      "batch 11577, train_loss 66.523857,Time used 0.007001s\n",
      "batch 11578, train_loss 78.465378,Time used 0.009001s\n",
      "batch 11579, train_loss 56.771950,Time used 0.010996s\n",
      "batch 11580, train_loss 48.546551,Time used 0.010001s\n",
      "batch 11581, train_loss 52.257248,Time used 0.011033s\n",
      "batch 11582, train_loss 73.265579,Time used 0.008966s\n",
      "batch 11583, train_loss 57.171471,Time used 0.007998s\n",
      "batch 11584, train_loss 50.924538,Time used 0.011003s\n",
      "batch 11585, train_loss 64.527344,Time used 0.008999s\n",
      "batch 11586, train_loss 76.383270,Time used 0.007999s\n",
      "batch 11587, train_loss 83.753166,Time used 0.009002s\n",
      "batch 11588, train_loss 69.539803,Time used 0.006996s\n",
      "batch 11589, train_loss 62.199390,Time used 0.008002s\n",
      "batch 11590, train_loss 54.350285,Time used 0.008001s\n",
      "batch 11591, train_loss 54.961281,Time used 0.009998s\n",
      "batch 11592, train_loss 56.947262,Time used 0.010999s\n",
      "batch 11593, train_loss 75.495697,Time used 0.011998s\n",
      "batch 11594, train_loss 58.195217,Time used 0.009998s\n",
      "batch 11595, train_loss 69.008186,Time used 0.007002s\n",
      "batch 11596, train_loss 80.355736,Time used 0.006999s\n",
      "batch 11597, train_loss 62.416420,Time used 0.006997s\n",
      "batch 11598, train_loss 50.141129,Time used 0.006998s\n",
      "batch 11599, train_loss 76.197891,Time used 0.007001s\n",
      "batch 11600, train_loss 66.682014,Time used 0.007999s\n",
      "***************************test_batch 11600, test_rmse_loss 9.185467,test_mae_loss 3.692720,test_mape_loss 57.905860,Time used 0.031998s\n",
      "batch 11601, train_loss 51.329674,Time used 0.007999s\n",
      "batch 11602, train_loss 71.242599,Time used 0.008002s\n",
      "batch 11603, train_loss 58.688828,Time used 0.007998s\n",
      "batch 11604, train_loss 54.667946,Time used 0.008002s\n",
      "batch 11605, train_loss 63.219894,Time used 0.010998s\n",
      "batch 11606, train_loss 48.388309,Time used 0.008002s\n",
      "batch 11607, train_loss 73.017136,Time used 0.007998s\n",
      "batch 11608, train_loss 75.630356,Time used 0.009999s\n",
      "batch 11609, train_loss 65.326851,Time used 0.008001s\n",
      "batch 11610, train_loss 53.084549,Time used 0.007001s\n",
      "batch 11611, train_loss 57.752666,Time used 0.006998s\n",
      "batch 11612, train_loss 61.759754,Time used 0.010999s\n",
      "batch 11613, train_loss 53.616474,Time used 0.008002s\n",
      "batch 11614, train_loss 86.261978,Time used 0.009998s\n",
      "batch 11615, train_loss 64.527328,Time used 0.010001s\n",
      "batch 11616, train_loss 51.999001,Time used 0.008001s\n",
      "batch 11617, train_loss 68.816368,Time used 0.010000s\n",
      "batch 11618, train_loss 71.042709,Time used 0.009001s\n",
      "batch 11619, train_loss 63.082260,Time used 0.007999s\n",
      "batch 11620, train_loss 65.406654,Time used 0.007999s\n",
      "batch 11621, train_loss 57.180779,Time used 0.007999s\n",
      "batch 11622, train_loss 46.786827,Time used 0.009001s\n",
      "batch 11623, train_loss 71.351509,Time used 0.006999s\n",
      "batch 11624, train_loss 58.679405,Time used 0.011000s\n",
      "batch 11625, train_loss 72.142517,Time used 0.011000s\n",
      "batch 11626, train_loss 60.117527,Time used 0.008003s\n",
      "batch 11627, train_loss 73.843216,Time used 0.007999s\n",
      "batch 11628, train_loss 59.337643,Time used 0.011000s\n",
      "batch 11629, train_loss 60.136078,Time used 0.010000s\n",
      "batch 11630, train_loss 67.717133,Time used 0.007000s\n",
      "batch 11631, train_loss 84.330780,Time used 0.011000s\n",
      "batch 11632, train_loss 60.713081,Time used 0.007999s\n",
      "batch 11633, train_loss 75.347580,Time used 0.008004s\n",
      "batch 11634, train_loss 60.525459,Time used 0.008998s\n",
      "batch 11635, train_loss 61.806210,Time used 0.012001s\n",
      "batch 11636, train_loss 56.152874,Time used 0.007999s\n",
      "batch 11637, train_loss 58.896351,Time used 0.011000s\n",
      "batch 11638, train_loss 46.942501,Time used 0.011999s\n",
      "batch 11639, train_loss 65.307999,Time used 0.010000s\n",
      "batch 11640, train_loss 60.874264,Time used 0.010001s\n",
      "batch 11641, train_loss 61.737061,Time used 0.008002s\n",
      "batch 11642, train_loss 56.165298,Time used 0.008000s\n",
      "batch 11643, train_loss 63.522385,Time used 0.008998s\n",
      "batch 11644, train_loss 62.342270,Time used 0.008000s\n",
      "batch 11645, train_loss 84.628319,Time used 0.011000s\n",
      "batch 11646, train_loss 68.758453,Time used 0.007000s\n",
      "batch 11647, train_loss 68.572540,Time used 0.008002s\n",
      "batch 11648, train_loss 66.210960,Time used 0.011000s\n",
      "batch 11649, train_loss 56.886330,Time used 0.010000s\n",
      "batch 11650, train_loss 67.864807,Time used 0.010000s\n",
      "batch 11651, train_loss 77.981209,Time used 0.008999s\n",
      "batch 11652, train_loss 75.423256,Time used 0.009001s\n",
      "batch 11653, train_loss 60.672653,Time used 0.011000s\n",
      "batch 11654, train_loss 54.328049,Time used 0.012998s\n",
      "batch 11655, train_loss 70.353035,Time used 0.008002s\n",
      "batch 11656, train_loss 65.878777,Time used 0.009999s\n",
      "batch 11657, train_loss 61.067543,Time used 0.012001s\n",
      "batch 11658, train_loss 57.107800,Time used 0.011000s\n",
      "batch 11659, train_loss 51.803493,Time used 0.010002s\n",
      "batch 11660, train_loss 56.490997,Time used 0.009998s\n",
      "batch 11661, train_loss 81.395515,Time used 0.006999s\n",
      "batch 11662, train_loss 55.973930,Time used 0.008002s\n",
      "batch 11663, train_loss 45.015152,Time used 0.010998s\n",
      "batch 11664, train_loss 53.253937,Time used 0.007002s\n",
      "batch 11665, train_loss 65.826874,Time used 0.010999s\n",
      "batch 11666, train_loss 59.684990,Time used 0.008000s\n",
      "batch 11667, train_loss 57.929371,Time used 0.008001s\n",
      "batch 11668, train_loss 48.940937,Time used 0.007000s\n",
      "batch 11669, train_loss 63.206448,Time used 0.012001s\n",
      "batch 11670, train_loss 76.607880,Time used 0.009000s\n",
      "batch 11671, train_loss 61.556427,Time used 0.010001s\n",
      "batch 11672, train_loss 65.691872,Time used 0.010998s\n",
      "batch 11673, train_loss 67.200424,Time used 0.011004s\n",
      "batch 11674, train_loss 74.982414,Time used 0.007997s\n",
      "batch 11675, train_loss 60.495689,Time used 0.014998s\n",
      "batch 11676, train_loss 60.086933,Time used 0.008002s\n",
      "batch 11677, train_loss 75.571671,Time used 0.007999s\n",
      "batch 11678, train_loss 48.530838,Time used 0.008000s\n",
      "batch 11679, train_loss 60.392235,Time used 0.007999s\n",
      "batch 11680, train_loss 68.686249,Time used 0.008003s\n",
      "batch 11681, train_loss 76.625900,Time used 0.007999s\n",
      "batch 11682, train_loss 53.973003,Time used 0.011000s\n",
      "batch 11683, train_loss 48.576847,Time used 0.009000s\n",
      "batch 11684, train_loss 60.920025,Time used 0.008000s\n",
      "batch 11685, train_loss 74.098495,Time used 0.010001s\n",
      "batch 11686, train_loss 78.318680,Time used 0.009000s\n",
      "batch 11687, train_loss 53.116310,Time used 0.009001s\n",
      "batch 11688, train_loss 60.256721,Time used 0.011000s\n",
      "batch 11689, train_loss 76.467987,Time used 0.008998s\n",
      "batch 11690, train_loss 53.815792,Time used 0.009000s\n",
      "batch 11691, train_loss 62.547100,Time used 0.012001s\n",
      "batch 11692, train_loss 64.951523,Time used 0.009000s\n",
      "batch 11693, train_loss 74.283386,Time used 0.013000s\n",
      "batch 11694, train_loss 79.417953,Time used 0.015001s\n",
      "batch 11695, train_loss 58.365482,Time used 0.008998s\n",
      "batch 11696, train_loss 56.893665,Time used 0.008003s\n",
      "batch 11697, train_loss 59.586582,Time used 0.011999s\n",
      "batch 11698, train_loss 61.429409,Time used 0.009998s\n",
      "batch 11699, train_loss 66.020622,Time used 0.008003s\n",
      "batch 11700, train_loss 71.589615,Time used 0.009999s\n",
      "***************************test_batch 11700, test_rmse_loss 9.143608,test_mae_loss 3.683971,test_mape_loss 58.086589,Time used 0.032000s\n",
      "batch 11701, train_loss 60.715218,Time used 0.011001s\n",
      "batch 11702, train_loss 48.303577,Time used 0.009000s\n",
      "batch 11703, train_loss 50.982780,Time used 0.011001s\n",
      "batch 11704, train_loss 60.461807,Time used 0.009998s\n",
      "batch 11705, train_loss 67.666496,Time used 0.010000s\n",
      "batch 11706, train_loss 66.867149,Time used 0.010002s\n",
      "batch 11707, train_loss 53.437683,Time used 0.008999s\n",
      "batch 11708, train_loss 55.859085,Time used 0.009002s\n",
      "batch 11709, train_loss 68.103218,Time used 0.011001s\n",
      "batch 11710, train_loss 65.921181,Time used 0.010997s\n",
      "batch 11711, train_loss 77.393829,Time used 0.007000s\n",
      "batch 11712, train_loss 57.444485,Time used 0.009998s\n",
      "batch 11713, train_loss 52.417919,Time used 0.006998s\n",
      "batch 11714, train_loss 56.831474,Time used 0.007001s\n",
      "batch 11715, train_loss 67.876343,Time used 0.012000s\n",
      "batch 11716, train_loss 44.724167,Time used 0.008004s\n",
      "batch 11717, train_loss 67.309891,Time used 0.006998s\n",
      "batch 11718, train_loss 56.909561,Time used 0.008998s\n",
      "batch 11719, train_loss 74.396431,Time used 0.006998s\n",
      "batch 11720, train_loss 57.128216,Time used 0.010001s\n",
      "batch 11721, train_loss 61.338161,Time used 0.009039s\n",
      "batch 11722, train_loss 50.056271,Time used 0.010997s\n",
      "batch 11723, train_loss 70.840576,Time used 0.007965s\n",
      "batch 11724, train_loss 75.511856,Time used 0.008037s\n",
      "batch 11725, train_loss 68.165466,Time used 0.007999s\n",
      "batch 11726, train_loss 61.089485,Time used 0.007000s\n",
      "batch 11727, train_loss 63.914265,Time used 0.008036s\n",
      "batch 11728, train_loss 67.797974,Time used 0.006965s\n",
      "batch 11729, train_loss 64.654938,Time used 0.008000s\n",
      "batch 11730, train_loss 64.792038,Time used 0.010001s\n",
      "batch 11731, train_loss 69.811913,Time used 0.009002s\n",
      "batch 11732, train_loss 64.724678,Time used 0.008996s\n",
      "batch 11733, train_loss 62.877121,Time used 0.008000s\n",
      "batch 11734, train_loss 73.038040,Time used 0.008002s\n",
      "batch 11735, train_loss 51.219547,Time used 0.009000s\n",
      "batch 11736, train_loss 68.754616,Time used 0.008000s\n",
      "batch 11737, train_loss 68.702591,Time used 0.008000s\n",
      "batch 11738, train_loss 69.907265,Time used 0.009001s\n",
      "batch 11739, train_loss 78.446579,Time used 0.008000s\n",
      "batch 11740, train_loss 60.878944,Time used 0.006999s\n",
      "batch 11741, train_loss 65.439056,Time used 0.009000s\n",
      "batch 11742, train_loss 54.920052,Time used 0.009001s\n",
      "batch 11743, train_loss 58.428761,Time used 0.008998s\n",
      "batch 11744, train_loss 42.806293,Time used 0.010001s\n",
      "batch 11745, train_loss 61.065517,Time used 0.009000s\n",
      "batch 11746, train_loss 70.876610,Time used 0.011000s\n",
      "batch 11747, train_loss 60.617844,Time used 0.008000s\n",
      "batch 11748, train_loss 75.087593,Time used 0.009000s\n",
      "batch 11749, train_loss 68.708839,Time used 0.012003s\n",
      "batch 11750, train_loss 65.044594,Time used 0.011998s\n",
      "batch 11751, train_loss 58.613773,Time used 0.010000s\n",
      "batch 11752, train_loss 55.615791,Time used 0.011002s\n",
      "batch 11753, train_loss 58.698780,Time used 0.014000s\n",
      "batch 11754, train_loss 53.478001,Time used 0.009002s\n",
      "batch 11755, train_loss 67.380913,Time used 0.007998s\n",
      "batch 11756, train_loss 65.531403,Time used 0.007000s\n",
      "batch 11757, train_loss 61.992584,Time used 0.007001s\n",
      "batch 11758, train_loss 43.505352,Time used 0.009000s\n",
      "batch 11759, train_loss 66.199501,Time used 0.007998s\n",
      "batch 11760, train_loss 82.309723,Time used 0.009000s\n",
      "batch 11761, train_loss 58.252987,Time used 0.008000s\n",
      "batch 11762, train_loss 57.949127,Time used 0.011001s\n",
      "batch 11763, train_loss 65.313889,Time used 0.007999s\n",
      "batch 11764, train_loss 79.963654,Time used 0.010001s\n",
      "batch 11765, train_loss 56.104824,Time used 0.008999s\n",
      "batch 11766, train_loss 65.338989,Time used 0.008000s\n",
      "batch 11767, train_loss 52.713215,Time used 0.008001s\n",
      "batch 11768, train_loss 93.126953,Time used 0.010001s\n",
      "batch 11769, train_loss 67.718307,Time used 0.007998s\n",
      "batch 11770, train_loss 48.392132,Time used 0.008000s\n",
      "batch 11771, train_loss 58.616962,Time used 0.009000s\n",
      "batch 11772, train_loss 59.400677,Time used 0.008003s\n",
      "batch 11773, train_loss 70.004349,Time used 0.009997s\n",
      "batch 11774, train_loss 65.981094,Time used 0.011001s\n",
      "batch 11775, train_loss 63.808167,Time used 0.008998s\n",
      "batch 11776, train_loss 55.538933,Time used 0.009001s\n",
      "batch 11777, train_loss 71.276207,Time used 0.008001s\n",
      "batch 11778, train_loss 66.069107,Time used 0.009998s\n",
      "batch 11779, train_loss 48.066105,Time used 0.011002s\n",
      "batch 11780, train_loss 62.370026,Time used 0.010998s\n",
      "batch 11781, train_loss 57.555977,Time used 0.007000s\n",
      "batch 11782, train_loss 70.273788,Time used 0.007001s\n",
      "batch 11783, train_loss 65.153175,Time used 0.008002s\n",
      "batch 11784, train_loss 51.283363,Time used 0.009998s\n",
      "batch 11785, train_loss 68.384666,Time used 0.010000s\n",
      "batch 11786, train_loss 68.844986,Time used 0.009001s\n",
      "batch 11787, train_loss 47.546665,Time used 0.007002s\n",
      "batch 11788, train_loss 53.821259,Time used 0.008001s\n",
      "batch 11789, train_loss 49.893215,Time used 0.006999s\n",
      "batch 11790, train_loss 68.167397,Time used 0.009997s\n",
      "batch 11791, train_loss 52.523663,Time used 0.011001s\n",
      "batch 11792, train_loss 73.121529,Time used 0.011001s\n",
      "batch 11793, train_loss 74.137894,Time used 0.011998s\n",
      "batch 11794, train_loss 61.121204,Time used 0.009005s\n",
      "batch 11795, train_loss 79.041451,Time used 0.007997s\n",
      "batch 11796, train_loss 76.097221,Time used 0.008001s\n",
      "batch 11797, train_loss 67.712044,Time used 0.008001s\n",
      "batch 11798, train_loss 67.273834,Time used 0.008001s\n",
      "batch 11799, train_loss 62.120075,Time used 0.006997s\n",
      "batch 11800, train_loss 53.983002,Time used 0.008001s\n",
      "***************************test_batch 11800, test_rmse_loss 9.111417,test_mae_loss 3.675610,test_mape_loss 58.038215,Time used 0.033001s\n",
      "batch 11801, train_loss 50.978977,Time used 0.007998s\n",
      "batch 11802, train_loss 64.298836,Time used 0.007998s\n",
      "batch 11803, train_loss 53.303616,Time used 0.007000s\n",
      "batch 11804, train_loss 66.523880,Time used 0.007002s\n",
      "batch 11805, train_loss 63.916332,Time used 0.011999s\n",
      "batch 11806, train_loss 56.977631,Time used 0.010999s\n",
      "batch 11807, train_loss 63.238258,Time used 0.010000s\n",
      "batch 11808, train_loss 64.918259,Time used 0.008000s\n",
      "batch 11809, train_loss 55.313931,Time used 0.007998s\n",
      "batch 11810, train_loss 62.193253,Time used 0.007999s\n",
      "batch 11811, train_loss 67.702751,Time used 0.008003s\n",
      "batch 11812, train_loss 63.317654,Time used 0.009999s\n",
      "batch 11813, train_loss 46.596371,Time used 0.010999s\n",
      "batch 11814, train_loss 58.364899,Time used 0.010999s\n",
      "batch 11815, train_loss 59.454281,Time used 0.011000s\n",
      "batch 11816, train_loss 68.007057,Time used 0.009000s\n",
      "batch 11817, train_loss 74.251709,Time used 0.006999s\n",
      "batch 11818, train_loss 58.233311,Time used 0.010000s\n",
      "batch 11819, train_loss 71.092354,Time used 0.010000s\n",
      "batch 11820, train_loss 60.264816,Time used 0.006999s\n",
      "batch 11821, train_loss 71.726311,Time used 0.009001s\n",
      "batch 11822, train_loss 71.424461,Time used 0.009000s\n",
      "batch 11823, train_loss 60.597088,Time used 0.008001s\n",
      "batch 11824, train_loss 57.875111,Time used 0.006999s\n",
      "batch 11825, train_loss 77.446594,Time used 0.010002s\n",
      "batch 11826, train_loss 79.145432,Time used 0.009997s\n",
      "batch 11827, train_loss 55.783875,Time used 0.012001s\n",
      "batch 11828, train_loss 63.805817,Time used 0.011001s\n",
      "batch 11829, train_loss 58.948498,Time used 0.009005s\n",
      "batch 11830, train_loss 57.061958,Time used 0.009000s\n",
      "batch 11831, train_loss 49.967484,Time used 0.006998s\n",
      "batch 11832, train_loss 57.096474,Time used 0.008001s\n",
      "batch 11833, train_loss 64.696815,Time used 0.010004s\n",
      "batch 11834, train_loss 82.378426,Time used 0.008002s\n",
      "batch 11835, train_loss 74.999832,Time used 0.007997s\n",
      "batch 11836, train_loss 73.294594,Time used 0.008001s\n",
      "batch 11837, train_loss 50.268147,Time used 0.009000s\n",
      "batch 11838, train_loss 74.492706,Time used 0.012001s\n",
      "batch 11839, train_loss 57.187481,Time used 0.008000s\n",
      "batch 11840, train_loss 51.472561,Time used 0.008000s\n",
      "batch 11841, train_loss 63.241051,Time used 0.012001s\n",
      "batch 11842, train_loss 61.819229,Time used 0.012000s\n",
      "batch 11843, train_loss 58.674847,Time used 0.011001s\n",
      "batch 11844, train_loss 54.872463,Time used 0.007999s\n",
      "batch 11845, train_loss 58.539158,Time used 0.008999s\n",
      "batch 11846, train_loss 56.964115,Time used 0.010001s\n",
      "batch 11847, train_loss 58.523396,Time used 0.011999s\n",
      "batch 11848, train_loss 73.164406,Time used 0.009002s\n",
      "batch 11849, train_loss 69.614609,Time used 0.010999s\n",
      "batch 11850, train_loss 66.643250,Time used 0.012001s\n",
      "batch 11851, train_loss 65.301033,Time used 0.007998s\n",
      "batch 11852, train_loss 48.510315,Time used 0.014002s\n",
      "batch 11853, train_loss 68.252312,Time used 0.010000s\n",
      "batch 11854, train_loss 58.059109,Time used 0.011000s\n",
      "batch 11855, train_loss 64.404747,Time used 0.008999s\n",
      "batch 11856, train_loss 46.842083,Time used 0.007001s\n",
      "batch 11857, train_loss 67.605652,Time used 0.011003s\n",
      "batch 11858, train_loss 61.007942,Time used 0.009001s\n",
      "batch 11859, train_loss 56.305370,Time used 0.006995s\n",
      "batch 11860, train_loss 56.117760,Time used 0.010998s\n",
      "batch 11861, train_loss 48.490211,Time used 0.010000s\n",
      "batch 11862, train_loss 62.040356,Time used 0.011003s\n",
      "batch 11863, train_loss 71.751770,Time used 0.006999s\n",
      "batch 11864, train_loss 66.332169,Time used 0.008000s\n",
      "batch 11865, train_loss 71.561714,Time used 0.009001s\n",
      "batch 11866, train_loss 62.919456,Time used 0.009998s\n",
      "batch 11867, train_loss 71.210197,Time used 0.010001s\n",
      "batch 11868, train_loss 46.172791,Time used 0.011000s\n",
      "batch 11869, train_loss 62.432262,Time used 0.008000s\n",
      "batch 11870, train_loss 65.548195,Time used 0.010998s\n",
      "batch 11871, train_loss 61.511772,Time used 0.007999s\n",
      "batch 11872, train_loss 57.831573,Time used 0.007001s\n",
      "batch 11873, train_loss 53.971813,Time used 0.007001s\n",
      "batch 11874, train_loss 60.588455,Time used 0.006000s\n",
      "batch 11875, train_loss 71.968857,Time used 0.008001s\n",
      "batch 11876, train_loss 69.774902,Time used 0.010999s\n",
      "batch 11877, train_loss 66.353951,Time used 0.007000s\n",
      "batch 11878, train_loss 75.190201,Time used 0.006999s\n",
      "batch 11879, train_loss 53.493179,Time used 0.008000s\n",
      "batch 11880, train_loss 60.031609,Time used 0.008001s\n",
      "batch 11881, train_loss 69.010094,Time used 0.007002s\n",
      "batch 11882, train_loss 83.475327,Time used 0.007999s\n",
      "batch 11883, train_loss 52.413380,Time used 0.010999s\n",
      "batch 11884, train_loss 53.004139,Time used 0.010000s\n",
      "batch 11885, train_loss 67.161453,Time used 0.009003s\n",
      "batch 11886, train_loss 67.595825,Time used 0.008001s\n",
      "batch 11887, train_loss 86.545959,Time used 0.008998s\n",
      "batch 11888, train_loss 43.813713,Time used 0.011000s\n",
      "batch 11889, train_loss 58.706421,Time used 0.010003s\n",
      "batch 11890, train_loss 60.426834,Time used 0.010998s\n",
      "batch 11891, train_loss 59.433437,Time used 0.009999s\n",
      "batch 11892, train_loss 61.457676,Time used 0.011004s\n",
      "batch 11893, train_loss 48.522961,Time used 0.006999s\n",
      "batch 11894, train_loss 45.886341,Time used 0.009002s\n",
      "batch 11895, train_loss 67.830994,Time used 0.009997s\n",
      "batch 11896, train_loss 54.189892,Time used 0.007002s\n",
      "batch 11897, train_loss 70.156799,Time used 0.008000s\n",
      "batch 11898, train_loss 68.407707,Time used 0.006998s\n",
      "batch 11899, train_loss 62.288467,Time used 0.009997s\n",
      "batch 11900, train_loss 66.460464,Time used 0.007000s\n",
      "***************************test_batch 11900, test_rmse_loss 9.080450,test_mae_loss 3.662691,test_mape_loss 57.764512,Time used 0.036999s\n",
      "batch 11901, train_loss 58.210396,Time used 0.008003s\n",
      "batch 11902, train_loss 66.429573,Time used 0.008994s\n",
      "batch 11903, train_loss 50.807537,Time used 0.006999s\n",
      "batch 11904, train_loss 75.852180,Time used 0.008036s\n",
      "batch 11905, train_loss 47.663395,Time used 0.008968s\n",
      "batch 11906, train_loss 65.873932,Time used 0.011004s\n",
      "batch 11907, train_loss 63.525723,Time used 0.007998s\n",
      "batch 11908, train_loss 38.815056,Time used 0.006998s\n",
      "batch 11909, train_loss 60.692650,Time used 0.008036s\n",
      "batch 11910, train_loss 66.743279,Time used 0.007001s\n",
      "batch 11911, train_loss 62.056404,Time used 0.010998s\n",
      "batch 11912, train_loss 52.443455,Time used 0.007971s\n",
      "batch 11913, train_loss 84.481003,Time used 0.007996s\n",
      "batch 11914, train_loss 55.380699,Time used 0.007998s\n",
      "batch 11915, train_loss 57.452904,Time used 0.009001s\n",
      "batch 11916, train_loss 64.125458,Time used 0.008998s\n",
      "batch 11917, train_loss 53.637085,Time used 0.011005s\n",
      "batch 11918, train_loss 58.543308,Time used 0.007997s\n",
      "batch 11919, train_loss 88.025200,Time used 0.009004s\n",
      "batch 11920, train_loss 76.646622,Time used 0.010999s\n",
      "batch 11921, train_loss 69.940369,Time used 0.010999s\n",
      "batch 11922, train_loss 55.245831,Time used 0.013034s\n",
      "batch 11923, train_loss 76.152740,Time used 0.011966s\n",
      "batch 11924, train_loss 77.589241,Time used 0.011003s\n",
      "batch 11925, train_loss 54.417717,Time used 0.008004s\n",
      "batch 11926, train_loss 49.529282,Time used 0.007998s\n",
      "batch 11927, train_loss 56.935463,Time used 0.007002s\n",
      "batch 11928, train_loss 59.308884,Time used 0.007999s\n",
      "batch 11929, train_loss 61.163300,Time used 0.009997s\n",
      "batch 11930, train_loss 63.400513,Time used 0.008001s\n",
      "batch 11931, train_loss 55.017773,Time used 0.007997s\n",
      "batch 11932, train_loss 44.642181,Time used 0.008003s\n",
      "batch 11933, train_loss 53.007515,Time used 0.009996s\n",
      "batch 11934, train_loss 66.450249,Time used 0.007000s\n",
      "batch 11935, train_loss 69.885353,Time used 0.006999s\n",
      "batch 11936, train_loss 73.390472,Time used 0.007001s\n",
      "batch 11937, train_loss 60.808399,Time used 0.010998s\n",
      "batch 11938, train_loss 59.241615,Time used 0.010002s\n",
      "batch 11939, train_loss 60.035706,Time used 0.007996s\n",
      "batch 11940, train_loss 57.589657,Time used 0.012003s\n",
      "batch 11941, train_loss 61.849270,Time used 0.009000s\n",
      "batch 11942, train_loss 66.074478,Time used 0.009997s\n",
      "batch 11943, train_loss 62.691006,Time used 0.010003s\n",
      "batch 11944, train_loss 72.270554,Time used 0.007998s\n",
      "batch 11945, train_loss 76.227379,Time used 0.007001s\n",
      "batch 11946, train_loss 70.390511,Time used 0.010000s\n",
      "batch 11947, train_loss 56.453033,Time used 0.007002s\n",
      "batch 11948, train_loss 60.493858,Time used 0.008998s\n",
      "batch 11949, train_loss 54.823273,Time used 0.012001s\n",
      "batch 11950, train_loss 68.343445,Time used 0.011000s\n",
      "batch 11951, train_loss 68.824921,Time used 0.009001s\n",
      "batch 11952, train_loss 49.057304,Time used 0.007998s\n",
      "batch 11953, train_loss 55.120312,Time used 0.011003s\n",
      "batch 11954, train_loss 55.165329,Time used 0.008998s\n",
      "batch 11955, train_loss 53.139919,Time used 0.006999s\n",
      "batch 11956, train_loss 59.119553,Time used 0.008000s\n",
      "batch 11957, train_loss 75.121361,Time used 0.008001s\n",
      "batch 11958, train_loss 71.444969,Time used 0.007999s\n",
      "batch 11959, train_loss 59.517826,Time used 0.007002s\n",
      "batch 11960, train_loss 47.966373,Time used 0.007998s\n",
      "batch 11961, train_loss 67.028442,Time used 0.009003s\n",
      "batch 11962, train_loss 67.496544,Time used 0.007000s\n",
      "batch 11963, train_loss 66.842590,Time used 0.009998s\n",
      "batch 11964, train_loss 75.316696,Time used 0.009998s\n",
      "batch 11965, train_loss 66.030899,Time used 0.007998s\n",
      "batch 11966, train_loss 47.524414,Time used 0.010999s\n",
      "batch 11967, train_loss 67.206215,Time used 0.007001s\n",
      "batch 11968, train_loss 46.860466,Time used 0.011995s\n",
      "batch 11969, train_loss 61.822262,Time used 0.010005s\n",
      "batch 11970, train_loss 73.814262,Time used 0.007997s\n",
      "batch 11971, train_loss 71.904251,Time used 0.007999s\n",
      "batch 11972, train_loss 58.877937,Time used 0.007999s\n",
      "batch 11973, train_loss 47.132290,Time used 0.007999s\n",
      "batch 11974, train_loss 58.050690,Time used 0.007002s\n",
      "batch 11975, train_loss 63.178013,Time used 0.008000s\n",
      "batch 11976, train_loss 74.836060,Time used 0.008004s\n",
      "batch 11977, train_loss 50.194027,Time used 0.008002s\n",
      "batch 11978, train_loss 71.956871,Time used 0.007998s\n",
      "batch 11979, train_loss 69.930962,Time used 0.006997s\n",
      "batch 11980, train_loss 45.468456,Time used 0.008001s\n",
      "batch 11981, train_loss 56.999710,Time used 0.008998s\n",
      "batch 11982, train_loss 70.572556,Time used 0.012002s\n",
      "batch 11983, train_loss 64.444756,Time used 0.009998s\n",
      "batch 11984, train_loss 56.590675,Time used 0.012001s\n",
      "batch 11985, train_loss 70.305351,Time used 0.012003s\n",
      "batch 11986, train_loss 57.249897,Time used 0.010997s\n",
      "batch 11987, train_loss 81.312897,Time used 0.011998s\n",
      "batch 11988, train_loss 44.068218,Time used 0.012001s\n",
      "batch 11989, train_loss 65.339241,Time used 0.012002s\n",
      "batch 11990, train_loss 77.361557,Time used 0.008999s\n",
      "batch 11991, train_loss 65.162033,Time used 0.007999s\n",
      "batch 11992, train_loss 57.340137,Time used 0.011999s\n",
      "batch 11993, train_loss 61.414963,Time used 0.011004s\n",
      "batch 11994, train_loss 44.059509,Time used 0.008997s\n",
      "batch 11995, train_loss 48.704601,Time used 0.010998s\n",
      "batch 11996, train_loss 62.084362,Time used 0.013001s\n",
      "batch 11997, train_loss 66.060471,Time used 0.011000s\n",
      "batch 11998, train_loss 72.713684,Time used 0.010999s\n",
      "batch 11999, train_loss 61.075851,Time used 0.010999s\n",
      "batch 12000, train_loss 67.421921,Time used 0.011998s\n",
      "***************************test_batch 12000, test_rmse_loss 9.045444,test_mae_loss 3.655070,test_mape_loss 57.933887,Time used 0.051002s\n",
      "batch 12001, train_loss 85.055672,Time used 0.014002s\n",
      "batch 12002, train_loss 64.860428,Time used 0.011996s\n",
      "batch 12003, train_loss 67.980057,Time used 0.012002s\n",
      "batch 12004, train_loss 53.374043,Time used 0.010998s\n",
      "batch 12005, train_loss 62.172672,Time used 0.011000s\n",
      "batch 12006, train_loss 60.619511,Time used 0.010999s\n",
      "batch 12007, train_loss 69.470039,Time used 0.010999s\n",
      "batch 12008, train_loss 72.759705,Time used 0.012002s\n",
      "batch 12009, train_loss 50.024288,Time used 0.012000s\n",
      "batch 12010, train_loss 48.048306,Time used 0.010999s\n",
      "batch 12011, train_loss 65.612381,Time used 0.011002s\n",
      "batch 12012, train_loss 66.037666,Time used 0.008000s\n",
      "batch 12013, train_loss 57.383526,Time used 0.009001s\n",
      "batch 12014, train_loss 53.007370,Time used 0.010999s\n",
      "batch 12015, train_loss 58.705276,Time used 0.014001s\n",
      "batch 12016, train_loss 47.618587,Time used 0.009999s\n",
      "batch 12017, train_loss 74.917404,Time used 0.011001s\n",
      "batch 12018, train_loss 59.224422,Time used 0.010998s\n",
      "batch 12019, train_loss 61.535034,Time used 0.011000s\n",
      "batch 12020, train_loss 63.606998,Time used 0.012001s\n",
      "batch 12021, train_loss 60.294529,Time used 0.008003s\n",
      "batch 12022, train_loss 54.160660,Time used 0.008996s\n",
      "batch 12023, train_loss 68.088104,Time used 0.011039s\n",
      "batch 12024, train_loss 60.329926,Time used 0.009965s\n",
      "batch 12025, train_loss 63.313847,Time used 0.012000s\n",
      "batch 12026, train_loss 48.710182,Time used 0.008963s\n",
      "batch 12027, train_loss 74.736572,Time used 0.009002s\n",
      "batch 12028, train_loss 61.676788,Time used 0.011000s\n",
      "batch 12029, train_loss 74.184608,Time used 0.009999s\n",
      "batch 12030, train_loss 61.269844,Time used 0.008002s\n",
      "batch 12031, train_loss 59.890362,Time used 0.007998s\n",
      "batch 12032, train_loss 59.230946,Time used 0.011000s\n",
      "batch 12033, train_loss 68.972099,Time used 0.011000s\n",
      "batch 12034, train_loss 64.774597,Time used 0.012003s\n",
      "batch 12035, train_loss 63.209576,Time used 0.007996s\n",
      "batch 12036, train_loss 75.417809,Time used 0.008006s\n",
      "batch 12037, train_loss 66.325523,Time used 0.010997s\n",
      "batch 12038, train_loss 52.860321,Time used 0.010998s\n",
      "batch 12039, train_loss 51.968575,Time used 0.007002s\n",
      "batch 12040, train_loss 64.630974,Time used 0.008998s\n",
      "batch 12041, train_loss 53.202209,Time used 0.007003s\n",
      "batch 12042, train_loss 63.225883,Time used 0.007003s\n",
      "batch 12043, train_loss 61.488224,Time used 0.006998s\n",
      "batch 12044, train_loss 57.431305,Time used 0.010001s\n",
      "batch 12045, train_loss 67.534309,Time used 0.009997s\n",
      "batch 12046, train_loss 41.471260,Time used 0.006999s\n",
      "batch 12047, train_loss 55.350285,Time used 0.010002s\n",
      "batch 12048, train_loss 72.167633,Time used 0.007999s\n",
      "batch 12049, train_loss 58.994278,Time used 0.011995s\n",
      "batch 12050, train_loss 70.505608,Time used 0.009004s\n",
      "batch 12051, train_loss 66.241516,Time used 0.008000s\n",
      "batch 12052, train_loss 61.906055,Time used 0.008002s\n",
      "batch 12053, train_loss 72.144577,Time used 0.007000s\n",
      "batch 12054, train_loss 59.825546,Time used 0.008002s\n",
      "batch 12055, train_loss 58.825199,Time used 0.010997s\n",
      "batch 12056, train_loss 56.955769,Time used 0.008998s\n",
      "batch 12057, train_loss 57.038090,Time used 0.013001s\n",
      "batch 12058, train_loss 68.711617,Time used 0.011998s\n",
      "batch 12059, train_loss 60.249622,Time used 0.011001s\n",
      "batch 12060, train_loss 63.331539,Time used 0.010001s\n",
      "batch 12061, train_loss 56.218674,Time used 0.012002s\n",
      "batch 12062, train_loss 71.115631,Time used 0.010998s\n",
      "batch 12063, train_loss 60.793865,Time used 0.012002s\n",
      "batch 12064, train_loss 70.797737,Time used 0.012997s\n",
      "batch 12065, train_loss 50.311302,Time used 0.012000s\n",
      "batch 12066, train_loss 38.562717,Time used 0.010003s\n",
      "batch 12067, train_loss 60.617050,Time used 0.008999s\n",
      "batch 12068, train_loss 60.602116,Time used 0.011000s\n",
      "batch 12069, train_loss 67.400490,Time used 0.011999s\n",
      "batch 12070, train_loss 67.174713,Time used 0.012002s\n",
      "batch 12071, train_loss 53.327911,Time used 0.013000s\n",
      "batch 12072, train_loss 68.389481,Time used 0.013001s\n",
      "batch 12073, train_loss 63.191128,Time used 0.011997s\n",
      "batch 12074, train_loss 50.269138,Time used 0.012002s\n",
      "batch 12075, train_loss 59.066685,Time used 0.009998s\n",
      "batch 12076, train_loss 54.197159,Time used 0.013002s\n",
      "batch 12077, train_loss 66.595314,Time used 0.014001s\n",
      "batch 12078, train_loss 60.725433,Time used 0.014000s\n",
      "batch 12079, train_loss 52.475105,Time used 0.022001s\n",
      "batch 12080, train_loss 56.571079,Time used 0.012999s\n",
      "batch 12081, train_loss 52.285069,Time used 0.012001s\n",
      "batch 12082, train_loss 60.823895,Time used 0.011999s\n",
      "batch 12083, train_loss 41.698154,Time used 0.011001s\n",
      "batch 12084, train_loss 48.890427,Time used 0.013001s\n",
      "batch 12085, train_loss 54.692696,Time used 0.010999s\n",
      "batch 12086, train_loss 81.857079,Time used 0.012000s\n",
      "batch 12087, train_loss 72.054695,Time used 0.011002s\n",
      "batch 12088, train_loss 69.611687,Time used 0.011001s\n",
      "batch 12089, train_loss 69.303780,Time used 0.011999s\n",
      "batch 12090, train_loss 77.430382,Time used 0.012002s\n",
      "batch 12091, train_loss 69.715935,Time used 0.014001s\n",
      "batch 12092, train_loss 65.062286,Time used 0.013000s\n",
      "batch 12093, train_loss 57.866371,Time used 0.011001s\n",
      "batch 12094, train_loss 68.206299,Time used 0.012000s\n",
      "batch 12095, train_loss 66.061409,Time used 0.012999s\n",
      "batch 12096, train_loss 58.751667,Time used 0.008999s\n",
      "batch 12097, train_loss 55.539677,Time used 0.008002s\n",
      "batch 12098, train_loss 55.227650,Time used 0.011998s\n",
      "batch 12099, train_loss 65.425499,Time used 0.012003s\n",
      "batch 12100, train_loss 62.530540,Time used 0.010999s\n",
      "***************************test_batch 12100, test_rmse_loss 9.013678,test_mae_loss 3.642449,test_mape_loss 57.582414,Time used 0.035002s\n",
      "batch 12101, train_loss 66.751511,Time used 0.006997s\n",
      "batch 12102, train_loss 66.456261,Time used 0.008002s\n",
      "batch 12103, train_loss 51.546154,Time used 0.012996s\n",
      "batch 12104, train_loss 64.206154,Time used 0.008002s\n",
      "batch 12105, train_loss 60.020172,Time used 0.007999s\n",
      "batch 12106, train_loss 66.589088,Time used 0.007002s\n",
      "batch 12107, train_loss 57.019169,Time used 0.006999s\n",
      "batch 12108, train_loss 63.630024,Time used 0.008999s\n",
      "batch 12109, train_loss 56.071686,Time used 0.010000s\n",
      "batch 12110, train_loss 56.178448,Time used 0.008001s\n",
      "batch 12111, train_loss 72.172539,Time used 0.007001s\n",
      "batch 12112, train_loss 51.778778,Time used 0.009997s\n",
      "batch 12113, train_loss 76.168541,Time used 0.008000s\n",
      "batch 12114, train_loss 57.994968,Time used 0.008037s\n",
      "batch 12115, train_loss 60.022022,Time used 0.006965s\n",
      "batch 12116, train_loss 60.505070,Time used 0.007999s\n",
      "batch 12117, train_loss 50.797226,Time used 0.009001s\n",
      "batch 12118, train_loss 70.093636,Time used 0.011999s\n",
      "batch 12119, train_loss 63.300873,Time used 0.011000s\n",
      "batch 12120, train_loss 64.943199,Time used 0.008000s\n",
      "batch 12121, train_loss 56.360725,Time used 0.009001s\n",
      "batch 12122, train_loss 56.261822,Time used 0.008000s\n",
      "batch 12123, train_loss 63.173382,Time used 0.007001s\n",
      "batch 12124, train_loss 58.104801,Time used 0.007999s\n",
      "batch 12125, train_loss 81.419876,Time used 0.010000s\n",
      "batch 12126, train_loss 57.013596,Time used 0.012001s\n",
      "batch 12127, train_loss 43.603268,Time used 0.010999s\n",
      "batch 12128, train_loss 72.668312,Time used 0.010000s\n",
      "batch 12129, train_loss 58.177299,Time used 0.012002s\n",
      "batch 12130, train_loss 47.309868,Time used 0.010999s\n",
      "batch 12131, train_loss 72.440742,Time used 0.010000s\n",
      "batch 12132, train_loss 67.400291,Time used 0.009000s\n",
      "batch 12133, train_loss 50.728287,Time used 0.009004s\n",
      "batch 12134, train_loss 49.363235,Time used 0.011995s\n",
      "batch 12135, train_loss 56.255211,Time used 0.011000s\n",
      "batch 12136, train_loss 68.451569,Time used 0.010000s\n",
      "batch 12137, train_loss 72.649361,Time used 0.012000s\n",
      "batch 12138, train_loss 63.800655,Time used 0.009002s\n",
      "batch 12139, train_loss 58.065483,Time used 0.006999s\n",
      "batch 12140, train_loss 55.489113,Time used 0.010022s\n",
      "batch 12141, train_loss 63.364353,Time used 0.006976s\n",
      "batch 12142, train_loss 63.036873,Time used 0.009006s\n",
      "batch 12143, train_loss 56.733746,Time used 0.010994s\n",
      "batch 12144, train_loss 81.681602,Time used 0.011003s\n",
      "batch 12145, train_loss 73.888420,Time used 0.008003s\n",
      "batch 12146, train_loss 74.772247,Time used 0.007001s\n",
      "batch 12147, train_loss 52.855324,Time used 0.007000s\n",
      "batch 12148, train_loss 55.778618,Time used 0.008000s\n",
      "batch 12149, train_loss 53.385818,Time used 0.008000s\n",
      "batch 12150, train_loss 82.186089,Time used 0.007034s\n",
      "batch 12151, train_loss 58.537849,Time used 0.008961s\n",
      "batch 12152, train_loss 59.215511,Time used 0.011004s\n",
      "batch 12153, train_loss 58.687019,Time used 0.010999s\n",
      "batch 12154, train_loss 46.422798,Time used 0.011003s\n",
      "batch 12155, train_loss 57.807243,Time used 0.008000s\n",
      "batch 12156, train_loss 62.185715,Time used 0.007995s\n",
      "batch 12157, train_loss 65.068054,Time used 0.007998s\n",
      "batch 12158, train_loss 65.157166,Time used 0.008004s\n",
      "batch 12159, train_loss 65.543350,Time used 0.008001s\n",
      "batch 12160, train_loss 52.797504,Time used 0.008003s\n",
      "batch 12161, train_loss 75.223816,Time used 0.010996s\n",
      "batch 12162, train_loss 59.307903,Time used 0.007998s\n",
      "batch 12163, train_loss 56.413464,Time used 0.011998s\n",
      "batch 12164, train_loss 68.641685,Time used 0.011000s\n",
      "batch 12165, train_loss 61.184101,Time used 0.008000s\n",
      "batch 12166, train_loss 51.428886,Time used 0.007999s\n",
      "batch 12167, train_loss 64.607635,Time used 0.010004s\n",
      "batch 12168, train_loss 48.631252,Time used 0.007001s\n",
      "batch 12169, train_loss 62.640560,Time used 0.012000s\n",
      "batch 12170, train_loss 75.913017,Time used 0.008000s\n",
      "batch 12171, train_loss 54.631256,Time used 0.012000s\n",
      "batch 12172, train_loss 69.375671,Time used 0.012002s\n",
      "batch 12173, train_loss 47.668167,Time used 0.013001s\n",
      "batch 12174, train_loss 51.822102,Time used 0.010999s\n",
      "batch 12175, train_loss 64.794830,Time used 0.012000s\n",
      "batch 12176, train_loss 68.365402,Time used 0.011003s\n",
      "batch 12177, train_loss 61.652184,Time used 0.011997s\n",
      "batch 12178, train_loss 62.847626,Time used 0.011998s\n",
      "batch 12179, train_loss 71.017014,Time used 0.010003s\n",
      "batch 12180, train_loss 69.002426,Time used 0.012999s\n",
      "batch 12181, train_loss 64.753967,Time used 0.012999s\n",
      "batch 12182, train_loss 55.152138,Time used 0.010003s\n",
      "batch 12183, train_loss 57.484444,Time used 0.010999s\n",
      "batch 12184, train_loss 58.314098,Time used 0.012999s\n",
      "batch 12185, train_loss 51.508171,Time used 0.012000s\n",
      "batch 12186, train_loss 52.461971,Time used 0.012002s\n",
      "batch 12187, train_loss 60.306232,Time used 0.009998s\n",
      "batch 12188, train_loss 61.796391,Time used 0.011000s\n",
      "batch 12189, train_loss 66.802757,Time used 0.014000s\n",
      "batch 12190, train_loss 67.173203,Time used 0.016001s\n",
      "batch 12191, train_loss 58.436325,Time used 0.023004s\n",
      "batch 12192, train_loss 53.227177,Time used 0.011996s\n",
      "batch 12193, train_loss 52.089695,Time used 0.011003s\n",
      "batch 12194, train_loss 56.239155,Time used 0.011998s\n",
      "batch 12195, train_loss 66.881989,Time used 0.012001s\n",
      "batch 12196, train_loss 58.823086,Time used 0.012000s\n",
      "batch 12197, train_loss 66.280106,Time used 0.015003s\n",
      "batch 12198, train_loss 50.738010,Time used 0.011999s\n",
      "batch 12199, train_loss 65.993187,Time used 0.015002s\n",
      "batch 12200, train_loss 43.001263,Time used 0.014999s\n",
      "***************************test_batch 12200, test_rmse_loss 8.983432,test_mae_loss 3.630535,test_mape_loss 57.375265,Time used 0.050997s\n",
      "batch 12201, train_loss 45.650185,Time used 0.011002s\n",
      "batch 12202, train_loss 41.026169,Time used 0.010999s\n",
      "batch 12203, train_loss 49.135944,Time used 0.011003s\n",
      "batch 12204, train_loss 78.411163,Time used 0.008999s\n",
      "batch 12205, train_loss 75.412308,Time used 0.007999s\n",
      "batch 12206, train_loss 55.950108,Time used 0.010999s\n",
      "batch 12207, train_loss 66.884293,Time used 0.009002s\n",
      "batch 12208, train_loss 63.362339,Time used 0.008001s\n",
      "batch 12209, train_loss 72.090752,Time used 0.007998s\n",
      "batch 12210, train_loss 61.756535,Time used 0.009001s\n",
      "batch 12211, train_loss 50.760082,Time used 0.010003s\n",
      "batch 12212, train_loss 65.566757,Time used 0.010998s\n",
      "batch 12213, train_loss 59.649250,Time used 0.009000s\n",
      "batch 12214, train_loss 70.214104,Time used 0.011002s\n",
      "batch 12215, train_loss 84.849899,Time used 0.008000s\n",
      "batch 12216, train_loss 64.449402,Time used 0.012000s\n",
      "batch 12217, train_loss 64.776253,Time used 0.008001s\n",
      "batch 12218, train_loss 64.670670,Time used 0.009998s\n",
      "batch 12219, train_loss 58.351158,Time used 0.008002s\n",
      "batch 12220, train_loss 62.035427,Time used 0.008999s\n",
      "batch 12221, train_loss 67.587425,Time used 0.011003s\n",
      "batch 12222, train_loss 45.419041,Time used 0.010997s\n",
      "batch 12223, train_loss 41.230499,Time used 0.009001s\n",
      "batch 12224, train_loss 55.149048,Time used 0.009999s\n",
      "batch 12225, train_loss 74.504234,Time used 0.012002s\n",
      "batch 12226, train_loss 49.243557,Time used 0.011999s\n",
      "batch 12227, train_loss 53.362488,Time used 0.011999s\n",
      "batch 12228, train_loss 58.007812,Time used 0.010004s\n",
      "batch 12229, train_loss 70.267540,Time used 0.007996s\n",
      "batch 12230, train_loss 51.409939,Time used 0.011002s\n",
      "batch 12231, train_loss 77.609680,Time used 0.008999s\n",
      "batch 12232, train_loss 65.094086,Time used 0.008002s\n",
      "batch 12233, train_loss 61.799095,Time used 0.007996s\n",
      "batch 12234, train_loss 58.979057,Time used 0.007000s\n",
      "batch 12235, train_loss 78.706085,Time used 0.010001s\n",
      "batch 12236, train_loss 53.221779,Time used 0.011000s\n",
      "batch 12237, train_loss 55.698639,Time used 0.006999s\n",
      "batch 12238, train_loss 73.277367,Time used 0.010006s\n",
      "batch 12239, train_loss 74.681831,Time used 0.008999s\n",
      "batch 12240, train_loss 47.224873,Time used 0.008999s\n",
      "batch 12241, train_loss 56.139561,Time used 0.012001s\n",
      "batch 12242, train_loss 56.402943,Time used 0.009000s\n",
      "batch 12243, train_loss 74.041611,Time used 0.008000s\n",
      "batch 12244, train_loss 54.700424,Time used 0.008000s\n",
      "batch 12245, train_loss 68.680573,Time used 0.009001s\n",
      "batch 12246, train_loss 73.545631,Time used 0.008000s\n",
      "batch 12247, train_loss 57.831879,Time used 0.008003s\n",
      "batch 12248, train_loss 63.231205,Time used 0.010997s\n",
      "batch 12249, train_loss 52.108849,Time used 0.010004s\n",
      "batch 12250, train_loss 51.342869,Time used 0.007001s\n",
      "batch 12251, train_loss 61.457874,Time used 0.009000s\n",
      "batch 12252, train_loss 53.083191,Time used 0.009999s\n",
      "batch 12253, train_loss 59.859394,Time used 0.010000s\n",
      "batch 12254, train_loss 60.620464,Time used 0.011999s\n",
      "batch 12255, train_loss 59.161152,Time used 0.009997s\n",
      "batch 12256, train_loss 74.586739,Time used 0.009000s\n",
      "batch 12257, train_loss 63.968472,Time used 0.011001s\n",
      "batch 12258, train_loss 55.267902,Time used 0.008001s\n",
      "batch 12259, train_loss 54.090157,Time used 0.007999s\n",
      "batch 12260, train_loss 61.901680,Time used 0.009998s\n",
      "batch 12261, train_loss 62.488087,Time used 0.007035s\n",
      "batch 12262, train_loss 46.684155,Time used 0.010002s\n",
      "batch 12263, train_loss 65.151939,Time used 0.007965s\n",
      "batch 12264, train_loss 74.691231,Time used 0.008999s\n",
      "batch 12265, train_loss 73.268082,Time used 0.008966s\n",
      "batch 12266, train_loss 68.937477,Time used 0.011000s\n",
      "batch 12267, train_loss 61.218788,Time used 0.011036s\n",
      "batch 12268, train_loss 73.667435,Time used 0.010964s\n",
      "batch 12269, train_loss 63.248791,Time used 0.011003s\n",
      "batch 12270, train_loss 56.453899,Time used 0.007997s\n",
      "batch 12271, train_loss 58.232365,Time used 0.007002s\n",
      "batch 12272, train_loss 52.096485,Time used 0.007001s\n",
      "batch 12273, train_loss 73.038574,Time used 0.008003s\n",
      "batch 12274, train_loss 60.328331,Time used 0.010996s\n",
      "batch 12275, train_loss 56.699345,Time used 0.011001s\n",
      "batch 12276, train_loss 57.793842,Time used 0.007999s\n",
      "batch 12277, train_loss 45.274818,Time used 0.010003s\n",
      "batch 12278, train_loss 60.884491,Time used 0.010995s\n",
      "batch 12279, train_loss 73.812950,Time used 0.012001s\n",
      "batch 12280, train_loss 52.209740,Time used 0.011001s\n",
      "batch 12281, train_loss 53.848473,Time used 0.012003s\n",
      "batch 12282, train_loss 56.263641,Time used 0.007997s\n",
      "batch 12283, train_loss 56.418400,Time used 0.009002s\n",
      "batch 12284, train_loss 58.665657,Time used 0.011997s\n",
      "batch 12285, train_loss 54.265614,Time used 0.008002s\n",
      "batch 12286, train_loss 64.870087,Time used 0.007032s\n",
      "batch 12287, train_loss 60.039997,Time used 0.007966s\n",
      "batch 12288, train_loss 66.502983,Time used 0.008000s\n",
      "batch 12289, train_loss 61.872734,Time used 0.012003s\n",
      "batch 12290, train_loss 52.061516,Time used 0.008999s\n",
      "batch 12291, train_loss 64.878502,Time used 0.008006s\n",
      "batch 12292, train_loss 64.549423,Time used 0.007001s\n",
      "batch 12293, train_loss 54.555855,Time used 0.007997s\n",
      "batch 12294, train_loss 50.906330,Time used 0.008999s\n",
      "batch 12295, train_loss 56.870144,Time used 0.008002s\n",
      "batch 12296, train_loss 50.672527,Time used 0.010000s\n",
      "batch 12297, train_loss 65.845833,Time used 0.011999s\n",
      "batch 12298, train_loss 46.640778,Time used 0.011002s\n",
      "batch 12299, train_loss 63.699207,Time used 0.010000s\n",
      "batch 12300, train_loss 59.355137,Time used 0.011000s\n",
      "***************************test_batch 12300, test_rmse_loss 8.951201,test_mae_loss 3.621711,test_mape_loss 57.214738,Time used 0.042000s\n",
      "batch 12301, train_loss 63.519325,Time used 0.009000s\n",
      "batch 12302, train_loss 52.481968,Time used 0.007998s\n",
      "batch 12303, train_loss 73.682175,Time used 0.008004s\n",
      "batch 12304, train_loss 62.873188,Time used 0.007001s\n",
      "batch 12305, train_loss 56.735752,Time used 0.008000s\n",
      "batch 12306, train_loss 66.724968,Time used 0.008996s\n",
      "batch 12307, train_loss 71.578674,Time used 0.010998s\n",
      "batch 12308, train_loss 63.123714,Time used 0.008001s\n",
      "batch 12309, train_loss 74.419327,Time used 0.011998s\n",
      "batch 12310, train_loss 59.927589,Time used 0.011004s\n",
      "batch 12311, train_loss 56.849361,Time used 0.007996s\n",
      "batch 12312, train_loss 61.556118,Time used 0.007997s\n",
      "batch 12313, train_loss 61.901886,Time used 0.011999s\n",
      "batch 12314, train_loss 46.799255,Time used 0.011999s\n",
      "batch 12315, train_loss 77.333488,Time used 0.010001s\n",
      "batch 12316, train_loss 56.734444,Time used 0.012001s\n",
      "batch 12317, train_loss 70.603905,Time used 0.008000s\n",
      "batch 12318, train_loss 57.513988,Time used 0.009996s\n",
      "batch 12319, train_loss 62.589203,Time used 0.010000s\n",
      "batch 12320, train_loss 56.514244,Time used 0.012002s\n",
      "batch 12321, train_loss 62.546757,Time used 0.008002s\n",
      "batch 12322, train_loss 69.320755,Time used 0.007997s\n",
      "batch 12323, train_loss 63.234604,Time used 0.008007s\n",
      "batch 12324, train_loss 66.859558,Time used 0.009002s\n",
      "batch 12325, train_loss 53.141750,Time used 0.012999s\n",
      "batch 12326, train_loss 54.643578,Time used 0.011999s\n",
      "batch 12327, train_loss 62.235462,Time used 0.011001s\n",
      "batch 12328, train_loss 50.233463,Time used 0.010001s\n",
      "batch 12329, train_loss 79.092674,Time used 0.010001s\n",
      "batch 12330, train_loss 73.758316,Time used 0.011000s\n",
      "batch 12331, train_loss 51.237450,Time used 0.010998s\n",
      "batch 12332, train_loss 53.326714,Time used 0.011000s\n",
      "batch 12333, train_loss 59.249729,Time used 0.012000s\n",
      "batch 12334, train_loss 65.888924,Time used 0.010999s\n",
      "batch 12335, train_loss 53.608578,Time used 0.009002s\n",
      "batch 12336, train_loss 44.154320,Time used 0.010000s\n",
      "batch 12337, train_loss 68.245323,Time used 0.009000s\n",
      "batch 12338, train_loss 56.169029,Time used 0.009002s\n",
      "batch 12339, train_loss 61.979702,Time used 0.007999s\n",
      "batch 12340, train_loss 57.105095,Time used 0.008003s\n",
      "batch 12341, train_loss 51.421535,Time used 0.007997s\n",
      "batch 12342, train_loss 58.397629,Time used 0.008004s\n",
      "batch 12343, train_loss 52.995895,Time used 0.008997s\n",
      "batch 12344, train_loss 61.560993,Time used 0.010003s\n",
      "batch 12345, train_loss 59.027988,Time used 0.010999s\n",
      "batch 12346, train_loss 53.063965,Time used 0.008000s\n",
      "batch 12347, train_loss 67.522903,Time used 0.009999s\n",
      "batch 12348, train_loss 68.394661,Time used 0.010999s\n",
      "batch 12349, train_loss 52.764626,Time used 0.010002s\n",
      "batch 12350, train_loss 53.112453,Time used 0.011000s\n",
      "batch 12351, train_loss 64.075111,Time used 0.009004s\n",
      "batch 12352, train_loss 58.128876,Time used 0.010998s\n",
      "batch 12353, train_loss 63.886795,Time used 0.012002s\n",
      "batch 12354, train_loss 81.371552,Time used 0.009001s\n",
      "batch 12355, train_loss 76.915550,Time used 0.007999s\n",
      "batch 12356, train_loss 60.885548,Time used 0.009003s\n",
      "batch 12357, train_loss 48.284035,Time used 0.011995s\n",
      "batch 12358, train_loss 71.355766,Time used 0.008001s\n",
      "batch 12359, train_loss 46.212345,Time used 0.006998s\n",
      "batch 12360, train_loss 57.284050,Time used 0.009002s\n",
      "batch 12361, train_loss 66.145622,Time used 0.006997s\n",
      "batch 12362, train_loss 58.717300,Time used 0.006999s\n",
      "batch 12363, train_loss 59.242382,Time used 0.009001s\n",
      "batch 12364, train_loss 57.614574,Time used 0.009002s\n",
      "batch 12365, train_loss 59.979576,Time used 0.007997s\n",
      "batch 12366, train_loss 47.219524,Time used 0.008000s\n",
      "batch 12367, train_loss 52.566746,Time used 0.008001s\n",
      "batch 12368, train_loss 41.775829,Time used 0.007000s\n",
      "batch 12369, train_loss 59.513161,Time used 0.008000s\n",
      "batch 12370, train_loss 78.975769,Time used 0.013001s\n",
      "batch 12371, train_loss 64.525314,Time used 0.008001s\n",
      "batch 12372, train_loss 56.905487,Time used 0.008000s\n",
      "batch 12373, train_loss 65.430214,Time used 0.007998s\n",
      "batch 12374, train_loss 58.762493,Time used 0.009004s\n",
      "batch 12375, train_loss 76.869415,Time used 0.011998s\n",
      "batch 12376, train_loss 48.842426,Time used 0.012997s\n",
      "batch 12377, train_loss 65.172104,Time used 0.010004s\n",
      "batch 12378, train_loss 67.243248,Time used 0.007000s\n",
      "batch 12379, train_loss 52.928772,Time used 0.008998s\n",
      "batch 12380, train_loss 71.246811,Time used 0.008001s\n",
      "batch 12381, train_loss 62.407093,Time used 0.008041s\n",
      "batch 12382, train_loss 49.056007,Time used 0.007000s\n",
      "batch 12383, train_loss 55.413010,Time used 0.008966s\n",
      "batch 12384, train_loss 72.052124,Time used 0.010999s\n",
      "batch 12385, train_loss 67.393456,Time used 0.006997s\n",
      "batch 12386, train_loss 67.932686,Time used 0.010002s\n",
      "batch 12387, train_loss 48.426449,Time used 0.009995s\n",
      "batch 12388, train_loss 56.475132,Time used 0.009002s\n",
      "batch 12389, train_loss 57.557446,Time used 0.007998s\n",
      "batch 12390, train_loss 66.525276,Time used 0.010002s\n",
      "batch 12391, train_loss 56.375648,Time used 0.008997s\n",
      "batch 12392, train_loss 70.304077,Time used 0.010001s\n",
      "batch 12393, train_loss 54.385098,Time used 0.007003s\n",
      "batch 12394, train_loss 55.246933,Time used 0.006999s\n",
      "batch 12395, train_loss 61.863728,Time used 0.011003s\n",
      "batch 12396, train_loss 51.407139,Time used 0.011996s\n",
      "batch 12397, train_loss 64.969856,Time used 0.009004s\n",
      "batch 12398, train_loss 73.970177,Time used 0.008996s\n",
      "batch 12399, train_loss 53.410881,Time used 0.008998s\n",
      "batch 12400, train_loss 63.365349,Time used 0.009002s\n",
      "***************************test_batch 12400, test_rmse_loss 8.926012,test_mae_loss 3.610157,test_mape_loss 56.915081,Time used 0.039998s\n",
      "batch 12401, train_loss 69.686546,Time used 0.009003s\n",
      "batch 12402, train_loss 58.332905,Time used 0.008999s\n",
      "batch 12403, train_loss 53.490047,Time used 0.012001s\n",
      "batch 12404, train_loss 52.419170,Time used 0.009998s\n",
      "batch 12405, train_loss 59.939476,Time used 0.008002s\n",
      "batch 12406, train_loss 67.860985,Time used 0.007999s\n",
      "batch 12407, train_loss 43.833408,Time used 0.010003s\n",
      "batch 12408, train_loss 71.003761,Time used 0.010000s\n",
      "batch 12409, train_loss 51.301437,Time used 0.010998s\n",
      "batch 12410, train_loss 63.896633,Time used 0.011001s\n",
      "batch 12411, train_loss 61.184586,Time used 0.011001s\n",
      "batch 12412, train_loss 63.204151,Time used 0.010000s\n",
      "batch 12413, train_loss 55.626053,Time used 0.009002s\n",
      "batch 12414, train_loss 51.918621,Time used 0.010001s\n",
      "batch 12415, train_loss 41.454868,Time used 0.009998s\n",
      "batch 12416, train_loss 56.503063,Time used 0.011003s\n",
      "batch 12417, train_loss 62.421806,Time used 0.007999s\n",
      "batch 12418, train_loss 46.659492,Time used 0.008997s\n",
      "batch 12419, train_loss 55.572086,Time used 0.006999s\n",
      "batch 12420, train_loss 52.038769,Time used 0.007999s\n",
      "batch 12421, train_loss 72.073296,Time used 0.008001s\n",
      "batch 12422, train_loss 76.863968,Time used 0.009999s\n",
      "batch 12423, train_loss 61.254707,Time used 0.008003s\n",
      "batch 12424, train_loss 57.903488,Time used 0.009036s\n",
      "batch 12425, train_loss 57.831036,Time used 0.008963s\n",
      "batch 12426, train_loss 74.349052,Time used 0.009002s\n",
      "batch 12427, train_loss 66.274017,Time used 0.007000s\n",
      "batch 12428, train_loss 72.259888,Time used 0.009997s\n",
      "batch 12429, train_loss 67.321487,Time used 0.010998s\n",
      "batch 12430, train_loss 72.108940,Time used 0.008004s\n",
      "batch 12431, train_loss 53.293495,Time used 0.009003s\n",
      "batch 12432, train_loss 49.389252,Time used 0.007995s\n",
      "batch 12433, train_loss 73.584084,Time used 0.010001s\n",
      "batch 12434, train_loss 59.114357,Time used 0.010998s\n",
      "batch 12435, train_loss 56.894257,Time used 0.009002s\n",
      "batch 12436, train_loss 46.412312,Time used 0.007998s\n",
      "batch 12437, train_loss 55.481926,Time used 0.010999s\n",
      "batch 12438, train_loss 73.527908,Time used 0.008001s\n",
      "batch 12439, train_loss 53.366520,Time used 0.008000s\n",
      "batch 12440, train_loss 49.721298,Time used 0.007998s\n",
      "batch 12441, train_loss 54.808388,Time used 0.008000s\n",
      "batch 12442, train_loss 64.523537,Time used 0.008003s\n",
      "batch 12443, train_loss 63.879623,Time used 0.008000s\n",
      "batch 12444, train_loss 59.645905,Time used 0.008002s\n",
      "batch 12445, train_loss 55.618317,Time used 0.008998s\n",
      "batch 12446, train_loss 62.141979,Time used 0.010002s\n",
      "batch 12447, train_loss 56.344997,Time used 0.010036s\n",
      "batch 12448, train_loss 69.536499,Time used 0.007961s\n",
      "batch 12449, train_loss 56.449554,Time used 0.010004s\n",
      "batch 12450, train_loss 79.089561,Time used 0.009997s\n",
      "batch 12451, train_loss 57.399101,Time used 0.010975s\n",
      "batch 12452, train_loss 50.576874,Time used 0.009995s\n",
      "batch 12453, train_loss 51.295853,Time used 0.009002s\n",
      "batch 12454, train_loss 59.521358,Time used 0.009034s\n",
      "batch 12455, train_loss 69.995758,Time used 0.007998s\n",
      "batch 12456, train_loss 62.090435,Time used 0.007967s\n",
      "batch 12457, train_loss 56.113808,Time used 0.007003s\n",
      "batch 12458, train_loss 45.195019,Time used 0.007996s\n",
      "batch 12459, train_loss 62.701279,Time used 0.007033s\n",
      "batch 12460, train_loss 68.918472,Time used 0.008963s\n",
      "batch 12461, train_loss 60.645466,Time used 0.009036s\n",
      "batch 12462, train_loss 48.680908,Time used 0.007001s\n",
      "batch 12463, train_loss 67.952850,Time used 0.008962s\n",
      "batch 12464, train_loss 76.172195,Time used 0.010004s\n",
      "batch 12465, train_loss 67.461372,Time used 0.010001s\n",
      "batch 12466, train_loss 77.803947,Time used 0.010003s\n",
      "batch 12467, train_loss 68.513321,Time used 0.007996s\n",
      "batch 12468, train_loss 56.261265,Time used 0.008004s\n",
      "batch 12469, train_loss 40.803406,Time used 0.009993s\n",
      "batch 12470, train_loss 51.270260,Time used 0.011005s\n",
      "batch 12471, train_loss 55.220978,Time used 0.007998s\n",
      "batch 12472, train_loss 62.421406,Time used 0.007997s\n",
      "batch 12473, train_loss 51.551849,Time used 0.009004s\n",
      "batch 12474, train_loss 75.151428,Time used 0.008000s\n",
      "batch 12475, train_loss 66.487900,Time used 0.009999s\n",
      "batch 12476, train_loss 54.078854,Time used 0.009999s\n",
      "batch 12477, train_loss 56.761501,Time used 0.007999s\n",
      "batch 12478, train_loss 65.720306,Time used 0.008000s\n",
      "batch 12479, train_loss 50.531929,Time used 0.008002s\n",
      "batch 12480, train_loss 51.538097,Time used 0.007997s\n",
      "batch 12481, train_loss 49.752460,Time used 0.008001s\n",
      "batch 12482, train_loss 46.874393,Time used 0.008001s\n",
      "batch 12483, train_loss 60.419933,Time used 0.009000s\n",
      "batch 12484, train_loss 58.695652,Time used 0.007998s\n",
      "batch 12485, train_loss 61.274853,Time used 0.010000s\n",
      "batch 12486, train_loss 57.847382,Time used 0.011999s\n",
      "batch 12487, train_loss 54.609772,Time used 0.011003s\n",
      "batch 12488, train_loss 51.330605,Time used 0.008999s\n",
      "batch 12489, train_loss 55.677013,Time used 0.007998s\n",
      "batch 12490, train_loss 61.349560,Time used 0.011000s\n",
      "batch 12491, train_loss 67.728157,Time used 0.009001s\n",
      "batch 12492, train_loss 85.691643,Time used 0.006998s\n",
      "batch 12493, train_loss 63.777950,Time used 0.008001s\n",
      "batch 12494, train_loss 57.733036,Time used 0.008001s\n",
      "batch 12495, train_loss 63.553074,Time used 0.008999s\n",
      "batch 12496, train_loss 77.689796,Time used 0.006999s\n",
      "batch 12497, train_loss 55.873142,Time used 0.008000s\n",
      "batch 12498, train_loss 64.237427,Time used 0.008999s\n",
      "batch 12499, train_loss 62.636974,Time used 0.008004s\n",
      "batch 12500, train_loss 59.508724,Time used 0.009996s\n",
      "***************************test_batch 12500, test_rmse_loss 8.885326,test_mae_loss 3.604529,test_mape_loss 57.355891,Time used 0.035005s\n",
      "batch 12501, train_loss 49.097321,Time used 0.006998s\n",
      "batch 12502, train_loss 56.030037,Time used 0.008002s\n",
      "batch 12503, train_loss 51.933399,Time used 0.008000s\n",
      "batch 12504, train_loss 62.887897,Time used 0.009001s\n",
      "batch 12505, train_loss 47.845890,Time used 0.009001s\n",
      "batch 12506, train_loss 77.730804,Time used 0.009001s\n",
      "batch 12507, train_loss 65.634720,Time used 0.011000s\n",
      "batch 12508, train_loss 47.811092,Time used 0.012004s\n",
      "batch 12509, train_loss 39.724873,Time used 0.010998s\n",
      "batch 12510, train_loss 62.511738,Time used 0.008000s\n",
      "batch 12511, train_loss 61.741066,Time used 0.009998s\n",
      "batch 12512, train_loss 55.664898,Time used 0.012006s\n",
      "batch 12513, train_loss 88.087212,Time used 0.007000s\n",
      "batch 12514, train_loss 46.529346,Time used 0.009001s\n",
      "batch 12515, train_loss 73.754402,Time used 0.009000s\n",
      "batch 12516, train_loss 52.054153,Time used 0.009995s\n",
      "batch 12517, train_loss 49.415436,Time used 0.008000s\n",
      "batch 12518, train_loss 66.928040,Time used 0.008001s\n",
      "batch 12519, train_loss 66.601372,Time used 0.007000s\n",
      "batch 12520, train_loss 61.278057,Time used 0.008000s\n",
      "batch 12521, train_loss 68.380531,Time used 0.007999s\n",
      "batch 12522, train_loss 66.746048,Time used 0.007036s\n",
      "batch 12523, train_loss 57.900818,Time used 0.008002s\n",
      "batch 12524, train_loss 50.740509,Time used 0.006962s\n",
      "batch 12525, train_loss 56.533100,Time used 0.008035s\n",
      "batch 12526, train_loss 47.282528,Time used 0.010964s\n",
      "batch 12527, train_loss 69.565796,Time used 0.010999s\n",
      "batch 12528, train_loss 53.174023,Time used 0.010005s\n",
      "batch 12529, train_loss 64.221809,Time used 0.010994s\n",
      "batch 12530, train_loss 60.244419,Time used 0.012001s\n",
      "batch 12531, train_loss 57.211319,Time used 0.010999s\n",
      "batch 12532, train_loss 64.055527,Time used 0.010000s\n",
      "batch 12533, train_loss 61.157040,Time used 0.012003s\n",
      "batch 12534, train_loss 57.414982,Time used 0.012999s\n",
      "batch 12535, train_loss 60.276066,Time used 0.010998s\n",
      "batch 12536, train_loss 60.153412,Time used 0.012002s\n",
      "batch 12537, train_loss 68.372688,Time used 0.012001s\n",
      "batch 12538, train_loss 55.729664,Time used 0.010998s\n",
      "batch 12539, train_loss 55.898666,Time used 0.010002s\n",
      "batch 12540, train_loss 63.308735,Time used 0.012000s\n",
      "batch 12541, train_loss 64.008713,Time used 0.010001s\n",
      "batch 12542, train_loss 39.954830,Time used 0.010999s\n",
      "batch 12543, train_loss 71.848991,Time used 0.013000s\n",
      "batch 12544, train_loss 56.071117,Time used 0.010998s\n",
      "batch 12545, train_loss 53.047680,Time used 0.011000s\n",
      "batch 12546, train_loss 58.327209,Time used 0.012001s\n",
      "batch 12547, train_loss 52.049202,Time used 0.011002s\n",
      "batch 12548, train_loss 60.846840,Time used 0.013004s\n",
      "batch 12549, train_loss 80.577744,Time used 0.011995s\n",
      "batch 12550, train_loss 53.811596,Time used 0.012001s\n",
      "batch 12551, train_loss 55.685101,Time used 0.011000s\n",
      "batch 12552, train_loss 56.817856,Time used 0.011001s\n",
      "batch 12553, train_loss 65.855850,Time used 0.010998s\n",
      "batch 12554, train_loss 49.815681,Time used 0.013000s\n",
      "batch 12555, train_loss 56.635044,Time used 0.015998s\n",
      "batch 12556, train_loss 49.611832,Time used 0.015999s\n",
      "batch 12557, train_loss 58.727589,Time used 0.023000s\n",
      "batch 12558, train_loss 72.433823,Time used 0.017002s\n",
      "batch 12559, train_loss 62.016209,Time used 0.013998s\n",
      "batch 12560, train_loss 72.471970,Time used 0.014001s\n",
      "batch 12561, train_loss 65.843582,Time used 0.011999s\n",
      "batch 12562, train_loss 57.548645,Time used 0.015001s\n",
      "batch 12563, train_loss 68.466248,Time used 0.012001s\n",
      "batch 12564, train_loss 61.251823,Time used 0.010002s\n",
      "batch 12565, train_loss 48.736816,Time used 0.010998s\n",
      "batch 12566, train_loss 55.541122,Time used 0.011999s\n",
      "batch 12567, train_loss 40.211281,Time used 0.013003s\n",
      "batch 12568, train_loss 52.864338,Time used 0.012997s\n",
      "batch 12569, train_loss 65.690460,Time used 0.012002s\n",
      "batch 12570, train_loss 65.770439,Time used 0.013001s\n",
      "batch 12571, train_loss 52.410061,Time used 0.014000s\n",
      "batch 12572, train_loss 58.096741,Time used 0.011001s\n",
      "batch 12573, train_loss 68.343742,Time used 0.011997s\n",
      "batch 12574, train_loss 64.596336,Time used 0.009001s\n",
      "batch 12575, train_loss 50.576767,Time used 0.013000s\n",
      "batch 12576, train_loss 65.700417,Time used 0.008999s\n",
      "batch 12577, train_loss 63.549591,Time used 0.010999s\n",
      "batch 12578, train_loss 57.038486,Time used 0.010002s\n",
      "batch 12579, train_loss 50.086548,Time used 0.008000s\n",
      "batch 12580, train_loss 60.847618,Time used 0.010000s\n",
      "batch 12581, train_loss 62.518131,Time used 0.008000s\n",
      "batch 12582, train_loss 61.987656,Time used 0.008001s\n",
      "batch 12583, train_loss 56.316330,Time used 0.008999s\n",
      "batch 12584, train_loss 47.304409,Time used 0.009999s\n",
      "batch 12585, train_loss 41.602715,Time used 0.008000s\n",
      "batch 12586, train_loss 61.978245,Time used 0.011004s\n",
      "batch 12587, train_loss 69.210831,Time used 0.010997s\n",
      "batch 12588, train_loss 58.585663,Time used 0.010001s\n",
      "batch 12589, train_loss 71.673645,Time used 0.008999s\n",
      "batch 12590, train_loss 64.211693,Time used 0.011001s\n",
      "batch 12591, train_loss 58.395885,Time used 0.010998s\n",
      "batch 12592, train_loss 66.828430,Time used 0.012002s\n",
      "batch 12593, train_loss 65.986259,Time used 0.009001s\n",
      "batch 12594, train_loss 54.664936,Time used 0.007000s\n",
      "batch 12595, train_loss 58.899754,Time used 0.008002s\n",
      "batch 12596, train_loss 63.559246,Time used 0.008003s\n",
      "batch 12597, train_loss 54.162872,Time used 0.012000s\n",
      "batch 12598, train_loss 59.828384,Time used 0.012998s\n",
      "batch 12599, train_loss 61.367298,Time used 0.010000s\n",
      "batch 12600, train_loss 55.939945,Time used 0.007999s\n",
      "***************************test_batch 12600, test_rmse_loss 8.860439,test_mae_loss 3.589993,test_mape_loss 56.813682,Time used 0.041002s\n",
      "batch 12601, train_loss 51.530342,Time used 0.010003s\n",
      "batch 12602, train_loss 55.246841,Time used 0.007999s\n",
      "batch 12603, train_loss 49.064831,Time used 0.010998s\n",
      "batch 12604, train_loss 68.118446,Time used 0.010003s\n",
      "batch 12605, train_loss 54.105782,Time used 0.010999s\n",
      "batch 12606, train_loss 52.517014,Time used 0.009000s\n",
      "batch 12607, train_loss 66.119934,Time used 0.006997s\n",
      "batch 12608, train_loss 57.617199,Time used 0.011001s\n",
      "batch 12609, train_loss 64.329071,Time used 0.012000s\n",
      "batch 12610, train_loss 76.106499,Time used 0.011002s\n",
      "batch 12611, train_loss 44.272423,Time used 0.007998s\n",
      "batch 12612, train_loss 65.895042,Time used 0.012001s\n",
      "batch 12613, train_loss 69.773369,Time used 0.007998s\n",
      "batch 12614, train_loss 70.053223,Time used 0.008000s\n",
      "batch 12615, train_loss 47.157913,Time used 0.009001s\n",
      "batch 12616, train_loss 54.927845,Time used 0.012001s\n",
      "batch 12617, train_loss 58.637798,Time used 0.009998s\n",
      "batch 12618, train_loss 58.462849,Time used 0.010003s\n",
      "batch 12619, train_loss 64.731216,Time used 0.010998s\n",
      "batch 12620, train_loss 58.717869,Time used 0.008001s\n",
      "batch 12621, train_loss 70.300728,Time used 0.006999s\n",
      "batch 12622, train_loss 60.891895,Time used 0.008001s\n",
      "batch 12623, train_loss 53.557739,Time used 0.008998s\n",
      "batch 12624, train_loss 51.915833,Time used 0.008001s\n",
      "batch 12625, train_loss 53.391201,Time used 0.010998s\n",
      "batch 12626, train_loss 53.836811,Time used 0.010001s\n",
      "batch 12627, train_loss 64.986992,Time used 0.010000s\n",
      "batch 12628, train_loss 61.159737,Time used 0.010002s\n",
      "batch 12629, train_loss 60.531929,Time used 0.011001s\n",
      "batch 12630, train_loss 40.515507,Time used 0.007999s\n",
      "batch 12631, train_loss 64.881310,Time used 0.010998s\n",
      "batch 12632, train_loss 64.640945,Time used 0.011999s\n",
      "batch 12633, train_loss 74.654076,Time used 0.008002s\n",
      "batch 12634, train_loss 67.805336,Time used 0.007003s\n",
      "batch 12635, train_loss 56.265743,Time used 0.007998s\n",
      "batch 12636, train_loss 62.811623,Time used 0.008000s\n",
      "batch 12637, train_loss 53.091373,Time used 0.008001s\n",
      "batch 12638, train_loss 63.971031,Time used 0.011000s\n",
      "batch 12639, train_loss 58.619995,Time used 0.011996s\n",
      "batch 12640, train_loss 63.793034,Time used 0.009005s\n",
      "batch 12641, train_loss 53.649822,Time used 0.007998s\n",
      "batch 12642, train_loss 59.198647,Time used 0.008999s\n",
      "batch 12643, train_loss 51.911221,Time used 0.011002s\n",
      "batch 12644, train_loss 60.365429,Time used 0.010999s\n",
      "batch 12645, train_loss 64.866463,Time used 0.010001s\n",
      "batch 12646, train_loss 51.619949,Time used 0.011000s\n",
      "batch 12647, train_loss 55.195312,Time used 0.010001s\n",
      "batch 12648, train_loss 60.398643,Time used 0.009998s\n",
      "batch 12649, train_loss 52.373741,Time used 0.009999s\n",
      "batch 12650, train_loss 65.484550,Time used 0.008000s\n",
      "batch 12651, train_loss 78.634094,Time used 0.008003s\n",
      "batch 12652, train_loss 60.368710,Time used 0.008000s\n",
      "batch 12653, train_loss 53.695045,Time used 0.009001s\n",
      "batch 12654, train_loss 65.244087,Time used 0.010998s\n",
      "batch 12655, train_loss 59.558262,Time used 0.009001s\n",
      "batch 12656, train_loss 71.418167,Time used 0.010000s\n",
      "batch 12657, train_loss 47.379108,Time used 0.008000s\n",
      "batch 12658, train_loss 55.317986,Time used 0.008001s\n",
      "batch 12659, train_loss 49.431065,Time used 0.008000s\n",
      "batch 12660, train_loss 51.004818,Time used 0.010000s\n",
      "batch 12661, train_loss 56.250427,Time used 0.007999s\n",
      "batch 12662, train_loss 52.807499,Time used 0.007000s\n",
      "batch 12663, train_loss 61.902920,Time used 0.009000s\n",
      "batch 12664, train_loss 50.247162,Time used 0.011000s\n",
      "batch 12665, train_loss 72.414276,Time used 0.008000s\n",
      "batch 12666, train_loss 48.923916,Time used 0.007001s\n",
      "batch 12667, train_loss 58.922699,Time used 0.006998s\n",
      "batch 12668, train_loss 55.897182,Time used 0.008003s\n",
      "batch 12669, train_loss 76.074486,Time used 0.010998s\n",
      "batch 12670, train_loss 56.939934,Time used 0.011004s\n",
      "batch 12671, train_loss 60.304165,Time used 0.011995s\n",
      "batch 12672, train_loss 59.217644,Time used 0.010001s\n",
      "batch 12673, train_loss 62.993793,Time used 0.007001s\n",
      "batch 12674, train_loss 64.044937,Time used 0.009999s\n",
      "batch 12675, train_loss 40.720501,Time used 0.007002s\n",
      "batch 12676, train_loss 68.919563,Time used 0.007998s\n",
      "batch 12677, train_loss 64.253937,Time used 0.007000s\n",
      "batch 12678, train_loss 53.172356,Time used 0.008003s\n",
      "batch 12679, train_loss 59.939957,Time used 0.011999s\n",
      "batch 12680, train_loss 54.473347,Time used 0.007999s\n",
      "batch 12681, train_loss 56.804848,Time used 0.007998s\n",
      "batch 12682, train_loss 60.732151,Time used 0.008001s\n",
      "batch 12683, train_loss 45.890488,Time used 0.008002s\n",
      "batch 12684, train_loss 68.066910,Time used 0.007998s\n",
      "batch 12685, train_loss 76.780792,Time used 0.008001s\n",
      "batch 12686, train_loss 60.446018,Time used 0.011999s\n",
      "batch 12687, train_loss 58.419182,Time used 0.010999s\n",
      "batch 12688, train_loss 50.425144,Time used 0.010999s\n",
      "batch 12689, train_loss 66.162987,Time used 0.011002s\n",
      "batch 12690, train_loss 64.658440,Time used 0.009001s\n",
      "batch 12691, train_loss 58.760563,Time used 0.010000s\n",
      "batch 12692, train_loss 51.990200,Time used 0.011002s\n",
      "batch 12693, train_loss 55.444561,Time used 0.009001s\n",
      "batch 12694, train_loss 49.832676,Time used 0.009997s\n",
      "batch 12695, train_loss 71.863281,Time used 0.014001s\n",
      "batch 12696, train_loss 52.601292,Time used 0.007996s\n",
      "batch 12697, train_loss 51.281189,Time used 0.007999s\n",
      "batch 12698, train_loss 55.213924,Time used 0.010004s\n",
      "batch 12699, train_loss 68.810417,Time used 0.010998s\n",
      "batch 12700, train_loss 61.561794,Time used 0.009000s\n",
      "***************************test_batch 12700, test_rmse_loss 8.823223,test_mae_loss 3.584838,test_mape_loss 57.137646,Time used 0.045999s\n",
      "batch 12701, train_loss 49.428967,Time used 0.009998s\n",
      "batch 12702, train_loss 48.329193,Time used 0.008001s\n",
      "batch 12703, train_loss 61.591816,Time used 0.006998s\n",
      "batch 12704, train_loss 45.463772,Time used 0.007000s\n",
      "batch 12705, train_loss 49.611462,Time used 0.009001s\n",
      "batch 12706, train_loss 48.325996,Time used 0.009000s\n",
      "batch 12707, train_loss 70.377037,Time used 0.008996s\n",
      "batch 12708, train_loss 57.315987,Time used 0.008005s\n",
      "batch 12709, train_loss 64.338188,Time used 0.011999s\n",
      "batch 12710, train_loss 58.134159,Time used 0.007998s\n",
      "batch 12711, train_loss 49.983196,Time used 0.008001s\n",
      "batch 12712, train_loss 59.398666,Time used 0.008998s\n",
      "batch 12713, train_loss 62.120213,Time used 0.009975s\n",
      "batch 12714, train_loss 66.019951,Time used 0.006998s\n",
      "batch 12715, train_loss 60.463863,Time used 0.008000s\n",
      "batch 12716, train_loss 69.109726,Time used 0.008000s\n",
      "batch 12717, train_loss 62.039600,Time used 0.008003s\n",
      "batch 12718, train_loss 76.378952,Time used 0.008997s\n",
      "batch 12719, train_loss 57.031727,Time used 0.008998s\n",
      "batch 12720, train_loss 62.884186,Time used 0.008003s\n",
      "batch 12721, train_loss 57.223423,Time used 0.007999s\n",
      "batch 12722, train_loss 57.713921,Time used 0.007999s\n",
      "batch 12723, train_loss 62.620171,Time used 0.012000s\n",
      "batch 12724, train_loss 64.037590,Time used 0.010999s\n",
      "batch 12725, train_loss 48.061302,Time used 0.009000s\n",
      "batch 12726, train_loss 45.876778,Time used 0.007998s\n",
      "batch 12727, train_loss 61.064167,Time used 0.008002s\n",
      "batch 12728, train_loss 46.985115,Time used 0.007999s\n",
      "batch 12729, train_loss 66.246796,Time used 0.009001s\n",
      "batch 12730, train_loss 61.589874,Time used 0.008000s\n",
      "batch 12731, train_loss 65.004234,Time used 0.010000s\n",
      "batch 12732, train_loss 53.551258,Time used 0.007999s\n",
      "batch 12733, train_loss 69.842041,Time used 0.008000s\n",
      "batch 12734, train_loss 51.180149,Time used 0.009001s\n",
      "batch 12735, train_loss 57.605377,Time used 0.006999s\n",
      "batch 12736, train_loss 71.138588,Time used 0.007999s\n",
      "batch 12737, train_loss 65.333389,Time used 0.012000s\n",
      "batch 12738, train_loss 59.509529,Time used 0.010000s\n",
      "batch 12739, train_loss 52.898834,Time used 0.010999s\n",
      "batch 12740, train_loss 65.026787,Time used 0.012001s\n",
      "batch 12741, train_loss 60.935745,Time used 0.009002s\n",
      "batch 12742, train_loss 48.034374,Time used 0.008998s\n",
      "batch 12743, train_loss 62.744736,Time used 0.006999s\n",
      "batch 12744, train_loss 58.581467,Time used 0.008002s\n",
      "batch 12745, train_loss 68.252533,Time used 0.007999s\n",
      "batch 12746, train_loss 58.558762,Time used 0.009998s\n",
      "batch 12747, train_loss 62.977203,Time used 0.011001s\n",
      "batch 12748, train_loss 56.400269,Time used 0.013002s\n",
      "batch 12749, train_loss 58.053120,Time used 0.007000s\n",
      "batch 12750, train_loss 72.187485,Time used 0.007998s\n",
      "batch 12751, train_loss 57.069405,Time used 0.006999s\n",
      "batch 12752, train_loss 47.379318,Time used 0.008004s\n",
      "batch 12753, train_loss 74.574211,Time used 0.009003s\n",
      "batch 12754, train_loss 61.144268,Time used 0.008998s\n",
      "batch 12755, train_loss 59.850952,Time used 0.008002s\n",
      "batch 12756, train_loss 61.528915,Time used 0.008001s\n",
      "batch 12757, train_loss 56.374748,Time used 0.008000s\n",
      "batch 12758, train_loss 57.681877,Time used 0.007000s\n",
      "batch 12759, train_loss 68.742943,Time used 0.011995s\n",
      "batch 12760, train_loss 49.788513,Time used 0.011000s\n",
      "batch 12761, train_loss 66.623535,Time used 0.010997s\n",
      "batch 12762, train_loss 53.546146,Time used 0.008002s\n",
      "batch 12763, train_loss 44.358891,Time used 0.009000s\n",
      "batch 12764, train_loss 49.102539,Time used 0.008002s\n",
      "batch 12765, train_loss 46.270653,Time used 0.009000s\n",
      "batch 12766, train_loss 50.537239,Time used 0.007998s\n",
      "batch 12767, train_loss 57.078739,Time used 0.007999s\n",
      "batch 12768, train_loss 72.812614,Time used 0.010001s\n",
      "batch 12769, train_loss 53.820705,Time used 0.014000s\n",
      "batch 12770, train_loss 62.816696,Time used 0.009999s\n",
      "batch 12771, train_loss 50.153854,Time used 0.008999s\n",
      "batch 12772, train_loss 46.459362,Time used 0.008003s\n",
      "batch 12773, train_loss 58.394615,Time used 0.007998s\n",
      "batch 12774, train_loss 62.400509,Time used 0.008000s\n",
      "batch 12775, train_loss 59.809906,Time used 0.007002s\n",
      "batch 12776, train_loss 65.767044,Time used 0.007998s\n",
      "batch 12777, train_loss 62.153606,Time used 0.010002s\n",
      "batch 12778, train_loss 58.501312,Time used 0.006999s\n",
      "batch 12779, train_loss 73.715050,Time used 0.007001s\n",
      "batch 12780, train_loss 48.211052,Time used 0.009999s\n",
      "batch 12781, train_loss 50.803802,Time used 0.011000s\n",
      "batch 12782, train_loss 59.676388,Time used 0.010000s\n",
      "batch 12783, train_loss 53.283825,Time used 0.010998s\n",
      "batch 12784, train_loss 47.682671,Time used 0.007998s\n",
      "batch 12785, train_loss 53.892860,Time used 0.007000s\n",
      "batch 12786, train_loss 61.898926,Time used 0.009003s\n",
      "batch 12787, train_loss 62.510960,Time used 0.007998s\n",
      "batch 12788, train_loss 57.226730,Time used 0.011002s\n",
      "batch 12789, train_loss 68.073944,Time used 0.007000s\n",
      "batch 12790, train_loss 63.496933,Time used 0.007999s\n",
      "batch 12791, train_loss 62.194431,Time used 0.007999s\n",
      "batch 12792, train_loss 65.607315,Time used 0.010999s\n",
      "batch 12793, train_loss 62.145889,Time used 0.008001s\n",
      "batch 12794, train_loss 70.584755,Time used 0.007000s\n",
      "batch 12795, train_loss 52.825260,Time used 0.008001s\n",
      "batch 12796, train_loss 61.855145,Time used 0.010000s\n",
      "batch 12797, train_loss 61.590073,Time used 0.012001s\n",
      "batch 12798, train_loss 59.802555,Time used 0.006999s\n",
      "batch 12799, train_loss 58.331596,Time used 0.007001s\n",
      "batch 12800, train_loss 53.235806,Time used 0.007998s\n",
      "***************************test_batch 12800, test_rmse_loss 8.796039,test_mae_loss 3.573889,test_mape_loss 56.949572,Time used 0.034002s\n",
      "batch 12801, train_loss 64.993156,Time used 0.010000s\n",
      "batch 12802, train_loss 49.584866,Time used 0.010000s\n",
      "batch 12803, train_loss 51.164696,Time used 0.008999s\n",
      "batch 12804, train_loss 53.571804,Time used 0.011001s\n",
      "batch 12805, train_loss 64.351562,Time used 0.010999s\n",
      "batch 12806, train_loss 53.185532,Time used 0.010001s\n",
      "batch 12807, train_loss 55.852898,Time used 0.011001s\n",
      "batch 12808, train_loss 68.475540,Time used 0.008002s\n",
      "batch 12809, train_loss 58.792629,Time used 0.006998s\n",
      "batch 12810, train_loss 56.351723,Time used 0.008000s\n",
      "batch 12811, train_loss 41.900253,Time used 0.006998s\n",
      "batch 12812, train_loss 64.814117,Time used 0.008002s\n",
      "batch 12813, train_loss 64.581604,Time used 0.008002s\n",
      "batch 12814, train_loss 49.374577,Time used 0.010035s\n",
      "batch 12815, train_loss 56.510937,Time used 0.008002s\n",
      "batch 12816, train_loss 72.735992,Time used 0.006962s\n",
      "batch 12817, train_loss 58.572113,Time used 0.007036s\n",
      "batch 12818, train_loss 53.190121,Time used 0.008001s\n",
      "batch 12819, train_loss 61.676464,Time used 0.008999s\n",
      "batch 12820, train_loss 60.071083,Time used 0.009000s\n",
      "batch 12821, train_loss 71.896126,Time used 0.007999s\n",
      "batch 12822, train_loss 63.084221,Time used 0.007996s\n",
      "batch 12823, train_loss 64.368828,Time used 0.008001s\n",
      "batch 12824, train_loss 60.422985,Time used 0.008000s\n",
      "batch 12825, train_loss 57.804428,Time used 0.009001s\n",
      "batch 12826, train_loss 42.499302,Time used 0.008001s\n",
      "batch 12827, train_loss 69.458878,Time used 0.012036s\n",
      "batch 12828, train_loss 57.450375,Time used 0.007963s\n",
      "batch 12829, train_loss 63.590183,Time used 0.008001s\n",
      "batch 12830, train_loss 53.839859,Time used 0.008001s\n",
      "batch 12831, train_loss 49.089077,Time used 0.008998s\n",
      "batch 12832, train_loss 53.722748,Time used 0.007034s\n",
      "batch 12833, train_loss 65.224030,Time used 0.007003s\n",
      "batch 12834, train_loss 55.449200,Time used 0.008000s\n",
      "batch 12835, train_loss 57.952061,Time used 0.006964s\n",
      "batch 12836, train_loss 60.977604,Time used 0.008000s\n",
      "batch 12837, train_loss 58.170456,Time used 0.008036s\n",
      "batch 12838, train_loss 52.324646,Time used 0.007965s\n",
      "batch 12839, train_loss 58.224792,Time used 0.008001s\n",
      "batch 12840, train_loss 54.519615,Time used 0.007999s\n",
      "batch 12841, train_loss 52.204498,Time used 0.009999s\n",
      "batch 12842, train_loss 57.294113,Time used 0.009998s\n",
      "batch 12843, train_loss 60.695038,Time used 0.009003s\n",
      "batch 12844, train_loss 38.436745,Time used 0.010000s\n",
      "batch 12845, train_loss 51.028763,Time used 0.010000s\n",
      "batch 12846, train_loss 62.703098,Time used 0.010998s\n",
      "batch 12847, train_loss 75.562080,Time used 0.011000s\n",
      "batch 12848, train_loss 61.423584,Time used 0.008002s\n",
      "batch 12849, train_loss 58.178490,Time used 0.010001s\n",
      "batch 12850, train_loss 68.844421,Time used 0.007000s\n",
      "batch 12851, train_loss 62.635212,Time used 0.011000s\n",
      "batch 12852, train_loss 58.126423,Time used 0.010998s\n",
      "batch 12853, train_loss 57.626923,Time used 0.010001s\n",
      "batch 12854, train_loss 49.769428,Time used 0.007000s\n",
      "batch 12855, train_loss 64.421654,Time used 0.007995s\n",
      "batch 12856, train_loss 69.325714,Time used 0.008000s\n",
      "batch 12857, train_loss 51.404850,Time used 0.010003s\n",
      "batch 12858, train_loss 58.803299,Time used 0.007999s\n",
      "batch 12859, train_loss 63.220905,Time used 0.007004s\n",
      "batch 12860, train_loss 55.860050,Time used 0.007993s\n",
      "batch 12861, train_loss 59.968010,Time used 0.008000s\n",
      "batch 12862, train_loss 60.120396,Time used 0.007999s\n",
      "batch 12863, train_loss 47.642437,Time used 0.008000s\n",
      "batch 12864, train_loss 56.499702,Time used 0.010014s\n",
      "batch 12865, train_loss 57.746059,Time used 0.009998s\n",
      "batch 12866, train_loss 61.845051,Time used 0.007999s\n",
      "batch 12867, train_loss 46.971020,Time used 0.010005s\n",
      "batch 12868, train_loss 60.932816,Time used 0.007997s\n",
      "batch 12869, train_loss 59.139580,Time used 0.009036s\n",
      "batch 12870, train_loss 56.532707,Time used 0.010963s\n",
      "batch 12871, train_loss 59.944233,Time used 0.008003s\n",
      "batch 12872, train_loss 45.589054,Time used 0.007001s\n",
      "batch 12873, train_loss 68.893341,Time used 0.009998s\n",
      "batch 12874, train_loss 52.840538,Time used 0.009002s\n",
      "batch 12875, train_loss 62.034531,Time used 0.010001s\n",
      "batch 12876, train_loss 50.993023,Time used 0.007996s\n",
      "batch 12877, train_loss 56.270332,Time used 0.009000s\n",
      "batch 12878, train_loss 69.071564,Time used 0.007999s\n",
      "batch 12879, train_loss 59.417934,Time used 0.008001s\n",
      "batch 12880, train_loss 62.294815,Time used 0.008000s\n",
      "batch 12881, train_loss 48.547123,Time used 0.007997s\n",
      "batch 12882, train_loss 66.157829,Time used 0.011000s\n",
      "batch 12883, train_loss 78.734985,Time used 0.011000s\n",
      "batch 12884, train_loss 60.341599,Time used 0.007999s\n",
      "batch 12885, train_loss 54.628895,Time used 0.010001s\n",
      "batch 12886, train_loss 48.446774,Time used 0.010001s\n",
      "batch 12887, train_loss 60.024456,Time used 0.010000s\n",
      "batch 12888, train_loss 51.500534,Time used 0.008999s\n",
      "batch 12889, train_loss 62.739094,Time used 0.009001s\n",
      "batch 12890, train_loss 72.318802,Time used 0.007998s\n",
      "batch 12891, train_loss 51.776173,Time used 0.006994s\n",
      "batch 12892, train_loss 57.822979,Time used 0.007002s\n",
      "batch 12893, train_loss 57.568981,Time used 0.008000s\n",
      "batch 12894, train_loss 53.859322,Time used 0.007001s\n",
      "batch 12895, train_loss 56.494579,Time used 0.008001s\n",
      "batch 12896, train_loss 56.063667,Time used 0.010999s\n",
      "batch 12897, train_loss 80.096352,Time used 0.008000s\n",
      "batch 12898, train_loss 49.742828,Time used 0.012001s\n",
      "batch 12899, train_loss 58.900612,Time used 0.010000s\n",
      "batch 12900, train_loss 52.035275,Time used 0.006999s\n",
      "***************************test_batch 12900, test_rmse_loss 8.772446,test_mae_loss 3.562529,test_mape_loss 56.542193,Time used 0.042034s\n",
      "batch 12901, train_loss 60.178822,Time used 0.007965s\n",
      "batch 12902, train_loss 50.304379,Time used 0.007999s\n",
      "batch 12903, train_loss 58.332165,Time used 0.007999s\n",
      "batch 12904, train_loss 54.086685,Time used 0.009001s\n",
      "batch 12905, train_loss 59.791676,Time used 0.010000s\n",
      "batch 12906, train_loss 59.663223,Time used 0.008035s\n",
      "batch 12907, train_loss 62.363476,Time used 0.008966s\n",
      "batch 12908, train_loss 54.398117,Time used 0.008003s\n",
      "batch 12909, train_loss 52.482853,Time used 0.008031s\n",
      "batch 12910, train_loss 76.514816,Time used 0.007001s\n",
      "batch 12911, train_loss 44.271008,Time used 0.007999s\n",
      "batch 12912, train_loss 55.060966,Time used 0.006965s\n",
      "batch 12913, train_loss 52.709686,Time used 0.008000s\n",
      "batch 12914, train_loss 55.526325,Time used 0.008000s\n",
      "batch 12915, train_loss 49.831329,Time used 0.007998s\n",
      "batch 12916, train_loss 70.047577,Time used 0.007000s\n",
      "batch 12917, train_loss 62.641048,Time used 0.008003s\n",
      "batch 12918, train_loss 58.717209,Time used 0.009999s\n",
      "batch 12919, train_loss 55.615162,Time used 0.011998s\n",
      "batch 12920, train_loss 83.455956,Time used 0.011002s\n",
      "batch 12921, train_loss 51.789131,Time used 0.008003s\n",
      "batch 12922, train_loss 60.284374,Time used 0.008001s\n",
      "batch 12923, train_loss 59.498634,Time used 0.008031s\n",
      "batch 12924, train_loss 56.752369,Time used 0.010964s\n",
      "batch 12925, train_loss 57.925705,Time used 0.010001s\n",
      "batch 12926, train_loss 56.296124,Time used 0.009036s\n",
      "batch 12927, train_loss 58.725796,Time used 0.006999s\n",
      "batch 12928, train_loss 54.719193,Time used 0.008004s\n",
      "batch 12929, train_loss 46.075104,Time used 0.007999s\n",
      "batch 12930, train_loss 78.461327,Time used 0.006998s\n",
      "batch 12931, train_loss 51.287655,Time used 0.007037s\n",
      "batch 12932, train_loss 59.540779,Time used 0.009966s\n",
      "batch 12933, train_loss 51.740257,Time used 0.009002s\n",
      "batch 12934, train_loss 51.932365,Time used 0.006999s\n",
      "batch 12935, train_loss 52.987968,Time used 0.008999s\n",
      "batch 12936, train_loss 58.106339,Time used 0.008002s\n",
      "batch 12937, train_loss 62.787979,Time used 0.008004s\n",
      "batch 12938, train_loss 64.617203,Time used 0.007996s\n",
      "batch 12939, train_loss 54.602196,Time used 0.010000s\n",
      "batch 12940, train_loss 47.732517,Time used 0.008000s\n",
      "batch 12941, train_loss 50.183514,Time used 0.008000s\n",
      "batch 12942, train_loss 54.458393,Time used 0.010999s\n",
      "batch 12943, train_loss 55.331020,Time used 0.010003s\n",
      "batch 12944, train_loss 52.963577,Time used 0.010998s\n",
      "batch 12945, train_loss 72.055763,Time used 0.010999s\n",
      "batch 12946, train_loss 62.818203,Time used 0.010005s\n",
      "batch 12947, train_loss 53.349880,Time used 0.008997s\n",
      "batch 12948, train_loss 57.059452,Time used 0.009997s\n",
      "batch 12949, train_loss 63.414818,Time used 0.006999s\n",
      "batch 12950, train_loss 52.252171,Time used 0.007007s\n",
      "batch 12951, train_loss 56.831280,Time used 0.006997s\n",
      "batch 12952, train_loss 58.143909,Time used 0.008000s\n",
      "batch 12953, train_loss 60.742607,Time used 0.011000s\n",
      "batch 12954, train_loss 67.820885,Time used 0.008000s\n",
      "batch 12955, train_loss 54.747066,Time used 0.008998s\n",
      "batch 12956, train_loss 58.395199,Time used 0.010999s\n",
      "batch 12957, train_loss 53.284130,Time used 0.010039s\n",
      "batch 12958, train_loss 63.975258,Time used 0.006998s\n",
      "batch 12959, train_loss 56.377522,Time used 0.007966s\n",
      "batch 12960, train_loss 58.616581,Time used 0.008001s\n",
      "batch 12961, train_loss 72.487694,Time used 0.007004s\n",
      "batch 12962, train_loss 63.348442,Time used 0.010994s\n",
      "batch 12963, train_loss 71.876472,Time used 0.010000s\n",
      "batch 12964, train_loss 59.049313,Time used 0.011002s\n",
      "batch 12965, train_loss 48.398289,Time used 0.007000s\n",
      "batch 12966, train_loss 59.750286,Time used 0.008001s\n",
      "batch 12967, train_loss 45.771729,Time used 0.011001s\n",
      "batch 12968, train_loss 57.951931,Time used 0.009999s\n",
      "batch 12969, train_loss 50.597210,Time used 0.007003s\n",
      "batch 12970, train_loss 55.039093,Time used 0.008998s\n",
      "batch 12971, train_loss 48.626705,Time used 0.007999s\n",
      "batch 12972, train_loss 64.437157,Time used 0.006999s\n",
      "batch 12973, train_loss 57.294037,Time used 0.008001s\n",
      "batch 12974, train_loss 47.523220,Time used 0.007999s\n",
      "batch 12975, train_loss 71.516548,Time used 0.010999s\n",
      "batch 12976, train_loss 55.834961,Time used 0.011000s\n",
      "batch 12977, train_loss 65.614609,Time used 0.008005s\n",
      "batch 12978, train_loss 55.315552,Time used 0.007998s\n",
      "batch 12979, train_loss 71.783836,Time used 0.008999s\n",
      "batch 12980, train_loss 42.816532,Time used 0.008001s\n",
      "batch 12981, train_loss 61.761696,Time used 0.006999s\n",
      "batch 12982, train_loss 44.963707,Time used 0.008001s\n",
      "batch 12983, train_loss 53.038807,Time used 0.007998s\n",
      "batch 12984, train_loss 65.948151,Time used 0.006999s\n",
      "batch 12985, train_loss 55.606728,Time used 0.008003s\n",
      "batch 12986, train_loss 59.913414,Time used 0.009000s\n",
      "batch 12987, train_loss 53.814838,Time used 0.010998s\n",
      "batch 12988, train_loss 72.809746,Time used 0.011000s\n",
      "batch 12989, train_loss 58.222103,Time used 0.010999s\n",
      "batch 12990, train_loss 45.025070,Time used 0.010000s\n",
      "batch 12991, train_loss 62.842293,Time used 0.008001s\n",
      "batch 12992, train_loss 68.196281,Time used 0.008000s\n",
      "batch 12993, train_loss 50.879940,Time used 0.009001s\n",
      "batch 12994, train_loss 65.103287,Time used 0.007996s\n",
      "batch 12995, train_loss 54.075401,Time used 0.007000s\n",
      "batch 12996, train_loss 65.498871,Time used 0.008000s\n",
      "batch 12997, train_loss 58.639912,Time used 0.007001s\n",
      "batch 12998, train_loss 53.833313,Time used 0.008036s\n",
      "batch 12999, train_loss 50.146301,Time used 0.007968s\n",
      "batch 13000, train_loss 60.023586,Time used 0.010993s\n",
      "***************************test_batch 13000, test_rmse_loss 8.739414,test_mae_loss 3.554820,test_mape_loss 56.624160,Time used 0.039002s\n",
      "batch 13001, train_loss 58.973377,Time used 0.008996s\n",
      "batch 13002, train_loss 47.970959,Time used 0.010006s\n",
      "batch 13003, train_loss 61.042728,Time used 0.012993s\n",
      "batch 13004, train_loss 52.844009,Time used 0.008005s\n",
      "batch 13005, train_loss 54.582630,Time used 0.008998s\n",
      "batch 13006, train_loss 66.653755,Time used 0.007998s\n",
      "batch 13007, train_loss 59.712788,Time used 0.008003s\n",
      "batch 13008, train_loss 51.011971,Time used 0.010991s\n",
      "batch 13009, train_loss 44.492489,Time used 0.011999s\n",
      "batch 13010, train_loss 61.396038,Time used 0.010999s\n",
      "batch 13011, train_loss 57.312855,Time used 0.007000s\n",
      "batch 13012, train_loss 58.500221,Time used 0.009000s\n",
      "batch 13013, train_loss 54.633739,Time used 0.006999s\n",
      "batch 13014, train_loss 56.379490,Time used 0.007002s\n",
      "batch 13015, train_loss 50.960518,Time used 0.011998s\n",
      "batch 13016, train_loss 62.069397,Time used 0.013000s\n",
      "batch 13017, train_loss 56.769398,Time used 0.012000s\n",
      "batch 13018, train_loss 66.909164,Time used 0.012000s\n",
      "batch 13019, train_loss 57.918163,Time used 0.013001s\n",
      "batch 13020, train_loss 58.718906,Time used 0.011999s\n",
      "batch 13021, train_loss 57.330765,Time used 0.011000s\n",
      "batch 13022, train_loss 48.483433,Time used 0.012001s\n",
      "batch 13023, train_loss 53.378521,Time used 0.011998s\n",
      "batch 13024, train_loss 50.919853,Time used 0.012000s\n",
      "batch 13025, train_loss 47.484524,Time used 0.011998s\n",
      "batch 13026, train_loss 59.466152,Time used 0.012002s\n",
      "batch 13027, train_loss 62.554886,Time used 0.011999s\n",
      "batch 13028, train_loss 58.537594,Time used 0.010999s\n",
      "batch 13029, train_loss 64.000366,Time used 0.012999s\n",
      "batch 13030, train_loss 73.714066,Time used 0.012002s\n",
      "batch 13031, train_loss 68.349022,Time used 0.010998s\n",
      "batch 13032, train_loss 55.050797,Time used 0.010999s\n",
      "batch 13033, train_loss 50.366573,Time used 0.015999s\n",
      "batch 13034, train_loss 59.174629,Time used 0.012001s\n",
      "batch 13035, train_loss 56.481583,Time used 0.014000s\n",
      "batch 13036, train_loss 40.978642,Time used 0.015004s\n",
      "batch 13037, train_loss 51.663197,Time used 0.014997s\n",
      "batch 13038, train_loss 68.672188,Time used 0.022999s\n",
      "batch 13039, train_loss 59.125977,Time used 0.015001s\n",
      "batch 13040, train_loss 41.567444,Time used 0.013001s\n",
      "batch 13041, train_loss 55.189987,Time used 0.012998s\n",
      "batch 13042, train_loss 49.756134,Time used 0.012000s\n",
      "batch 13043, train_loss 61.556778,Time used 0.013001s\n",
      "batch 13044, train_loss 34.413166,Time used 0.010998s\n",
      "batch 13045, train_loss 61.740364,Time used 0.011001s\n",
      "batch 13046, train_loss 56.382057,Time used 0.012000s\n",
      "batch 13047, train_loss 51.339569,Time used 0.012000s\n",
      "batch 13048, train_loss 76.909966,Time used 0.011000s\n",
      "batch 13049, train_loss 66.054016,Time used 0.013998s\n",
      "batch 13050, train_loss 66.378891,Time used 0.008998s\n",
      "batch 13051, train_loss 51.447205,Time used 0.012002s\n",
      "batch 13052, train_loss 64.548370,Time used 0.011998s\n",
      "batch 13053, train_loss 74.360733,Time used 0.012003s\n",
      "batch 13054, train_loss 72.009094,Time used 0.013000s\n",
      "batch 13055, train_loss 53.063866,Time used 0.012001s\n",
      "batch 13056, train_loss 60.292698,Time used 0.009001s\n",
      "batch 13057, train_loss 57.294758,Time used 0.011001s\n",
      "batch 13058, train_loss 73.644531,Time used 0.012001s\n",
      "batch 13059, train_loss 51.997608,Time used 0.011997s\n",
      "batch 13060, train_loss 53.736332,Time used 0.011001s\n",
      "batch 13061, train_loss 67.339241,Time used 0.010999s\n",
      "batch 13062, train_loss 50.676292,Time used 0.010001s\n",
      "batch 13063, train_loss 77.262802,Time used 0.011000s\n",
      "batch 13064, train_loss 51.885139,Time used 0.012999s\n",
      "batch 13065, train_loss 58.343571,Time used 0.011001s\n",
      "batch 13066, train_loss 50.370972,Time used 0.010999s\n",
      "batch 13067, train_loss 53.994011,Time used 0.011001s\n",
      "batch 13068, train_loss 52.664322,Time used 0.011999s\n",
      "batch 13069, train_loss 57.775021,Time used 0.011002s\n",
      "batch 13070, train_loss 55.546787,Time used 0.011998s\n",
      "batch 13071, train_loss 64.409637,Time used 0.008000s\n",
      "batch 13072, train_loss 55.246387,Time used 0.010000s\n",
      "batch 13073, train_loss 46.487171,Time used 0.011002s\n",
      "batch 13074, train_loss 71.126518,Time used 0.011001s\n",
      "batch 13075, train_loss 59.263416,Time used 0.008997s\n",
      "batch 13076, train_loss 53.953281,Time used 0.010001s\n",
      "batch 13077, train_loss 58.782951,Time used 0.007001s\n",
      "batch 13078, train_loss 48.630032,Time used 0.007002s\n",
      "batch 13079, train_loss 50.093365,Time used 0.010000s\n",
      "batch 13080, train_loss 60.735249,Time used 0.012000s\n",
      "batch 13081, train_loss 67.479874,Time used 0.009000s\n",
      "batch 13082, train_loss 67.653885,Time used 0.011004s\n",
      "batch 13083, train_loss 67.443985,Time used 0.010996s\n",
      "batch 13084, train_loss 62.420174,Time used 0.012000s\n",
      "batch 13085, train_loss 51.668243,Time used 0.011001s\n",
      "batch 13086, train_loss 54.900127,Time used 0.013999s\n",
      "batch 13087, train_loss 49.000397,Time used 0.008000s\n",
      "batch 13088, train_loss 57.676910,Time used 0.007000s\n",
      "batch 13089, train_loss 58.778706,Time used 0.009000s\n",
      "batch 13090, train_loss 46.876450,Time used 0.008003s\n",
      "batch 13091, train_loss 74.837601,Time used 0.009001s\n",
      "batch 13092, train_loss 68.323242,Time used 0.009000s\n",
      "batch 13093, train_loss 54.871185,Time used 0.009003s\n",
      "batch 13094, train_loss 52.216896,Time used 0.007001s\n",
      "batch 13095, train_loss 47.100834,Time used 0.008999s\n",
      "batch 13096, train_loss 51.968472,Time used 0.007002s\n",
      "batch 13097, train_loss 50.909176,Time used 0.008001s\n",
      "batch 13098, train_loss 56.914139,Time used 0.007032s\n",
      "batch 13099, train_loss 49.992088,Time used 0.007999s\n",
      "batch 13100, train_loss 60.174145,Time used 0.008000s\n",
      "***************************test_batch 13100, test_rmse_loss 8.708092,test_mae_loss 3.546503,test_mape_loss 56.582047,Time used 0.033968s\n",
      "batch 13101, train_loss 44.477020,Time used 0.008000s\n",
      "batch 13102, train_loss 62.735077,Time used 0.011000s\n",
      "batch 13103, train_loss 60.522141,Time used 0.009997s\n",
      "batch 13104, train_loss 60.260235,Time used 0.008004s\n",
      "batch 13105, train_loss 63.154568,Time used 0.009998s\n",
      "batch 13106, train_loss 48.916378,Time used 0.012032s\n",
      "batch 13107, train_loss 70.231590,Time used 0.010000s\n",
      "batch 13108, train_loss 62.603466,Time used 0.006966s\n",
      "batch 13109, train_loss 62.617516,Time used 0.009034s\n",
      "batch 13110, train_loss 54.400093,Time used 0.011008s\n",
      "batch 13111, train_loss 50.257622,Time used 0.007955s\n",
      "batch 13112, train_loss 57.402679,Time used 0.008003s\n",
      "batch 13113, train_loss 50.534973,Time used 0.007000s\n",
      "batch 13114, train_loss 64.562477,Time used 0.008002s\n",
      "batch 13115, train_loss 64.211540,Time used 0.008001s\n",
      "batch 13116, train_loss 56.568108,Time used 0.008001s\n",
      "batch 13117, train_loss 58.697071,Time used 0.007001s\n",
      "batch 13118, train_loss 59.168217,Time used 0.008996s\n",
      "batch 13119, train_loss 49.264549,Time used 0.008000s\n",
      "batch 13120, train_loss 57.903461,Time used 0.008005s\n",
      "batch 13121, train_loss 59.926556,Time used 0.010034s\n",
      "batch 13122, train_loss 54.990772,Time used 0.010963s\n",
      "batch 13123, train_loss 57.021740,Time used 0.008005s\n",
      "batch 13124, train_loss 55.244308,Time used 0.007994s\n",
      "batch 13125, train_loss 58.947552,Time used 0.008000s\n",
      "batch 13126, train_loss 43.388828,Time used 0.008032s\n",
      "batch 13127, train_loss 70.632385,Time used 0.008970s\n",
      "batch 13128, train_loss 45.873947,Time used 0.007997s\n",
      "batch 13129, train_loss 57.059948,Time used 0.007997s\n",
      "batch 13130, train_loss 50.273121,Time used 0.007034s\n",
      "batch 13131, train_loss 61.207935,Time used 0.007000s\n",
      "batch 13132, train_loss 63.127029,Time used 0.009005s\n",
      "batch 13133, train_loss 50.107235,Time used 0.007000s\n",
      "batch 13134, train_loss 56.085392,Time used 0.007001s\n",
      "batch 13135, train_loss 56.250614,Time used 0.007040s\n",
      "batch 13136, train_loss 54.089973,Time used 0.006994s\n",
      "batch 13137, train_loss 65.766716,Time used 0.008002s\n",
      "batch 13138, train_loss 51.477688,Time used 0.007963s\n",
      "batch 13139, train_loss 52.603981,Time used 0.007001s\n",
      "batch 13140, train_loss 46.489758,Time used 0.008997s\n",
      "batch 13141, train_loss 60.243595,Time used 0.011038s\n",
      "batch 13142, train_loss 62.785091,Time used 0.007003s\n",
      "batch 13143, train_loss 66.232254,Time used 0.010997s\n",
      "batch 13144, train_loss 47.571507,Time used 0.011002s\n",
      "batch 13145, train_loss 70.946350,Time used 0.010998s\n",
      "batch 13146, train_loss 75.456139,Time used 0.007996s\n",
      "batch 13147, train_loss 56.825851,Time used 0.011002s\n",
      "batch 13148, train_loss 55.276131,Time used 0.010998s\n",
      "batch 13149, train_loss 63.911259,Time used 0.008999s\n",
      "batch 13150, train_loss 50.840103,Time used 0.008003s\n",
      "batch 13151, train_loss 47.883705,Time used 0.012032s\n",
      "batch 13152, train_loss 51.821491,Time used 0.007000s\n",
      "batch 13153, train_loss 48.905365,Time used 0.008039s\n",
      "batch 13154, train_loss 60.378838,Time used 0.007961s\n",
      "batch 13155, train_loss 56.284138,Time used 0.008000s\n",
      "batch 13156, train_loss 58.563469,Time used 0.008002s\n",
      "batch 13157, train_loss 35.999832,Time used 0.006999s\n",
      "batch 13158, train_loss 46.390186,Time used 0.008001s\n",
      "batch 13159, train_loss 52.598499,Time used 0.007000s\n",
      "batch 13160, train_loss 57.598335,Time used 0.008001s\n",
      "batch 13161, train_loss 50.477478,Time used 0.011001s\n",
      "batch 13162, train_loss 48.409447,Time used 0.011038s\n",
      "batch 13163, train_loss 44.016426,Time used 0.007958s\n",
      "batch 13164, train_loss 73.738731,Time used 0.008001s\n",
      "batch 13165, train_loss 67.459671,Time used 0.008000s\n",
      "batch 13166, train_loss 64.738968,Time used 0.007000s\n",
      "batch 13167, train_loss 75.517670,Time used 0.010036s\n",
      "batch 13168, train_loss 51.384274,Time used 0.010969s\n",
      "batch 13169, train_loss 57.394066,Time used 0.008031s\n",
      "batch 13170, train_loss 60.679119,Time used 0.007966s\n",
      "batch 13171, train_loss 68.176697,Time used 0.013002s\n",
      "batch 13172, train_loss 53.265671,Time used 0.010998s\n",
      "batch 13173, train_loss 51.100861,Time used 0.011000s\n",
      "batch 13174, train_loss 51.240692,Time used 0.008000s\n",
      "batch 13175, train_loss 67.104546,Time used 0.008000s\n",
      "batch 13176, train_loss 71.421700,Time used 0.008033s\n",
      "batch 13177, train_loss 47.102978,Time used 0.006999s\n",
      "batch 13178, train_loss 61.376354,Time used 0.007997s\n",
      "batch 13179, train_loss 68.015213,Time used 0.008002s\n",
      "batch 13180, train_loss 62.361294,Time used 0.006999s\n",
      "batch 13181, train_loss 63.525024,Time used 0.008003s\n",
      "batch 13182, train_loss 57.117359,Time used 0.009000s\n",
      "batch 13183, train_loss 52.228966,Time used 0.010997s\n",
      "batch 13184, train_loss 62.750919,Time used 0.012002s\n",
      "batch 13185, train_loss 54.398151,Time used 0.007996s\n",
      "batch 13186, train_loss 57.009621,Time used 0.007999s\n",
      "batch 13187, train_loss 53.975155,Time used 0.011006s\n",
      "batch 13188, train_loss 49.334984,Time used 0.011000s\n",
      "batch 13189, train_loss 45.246395,Time used 0.011001s\n",
      "batch 13190, train_loss 52.098534,Time used 0.012999s\n",
      "batch 13191, train_loss 45.460617,Time used 0.011998s\n",
      "batch 13192, train_loss 64.390030,Time used 0.010001s\n",
      "batch 13193, train_loss 50.036983,Time used 0.008004s\n",
      "batch 13194, train_loss 67.132782,Time used 0.012032s\n",
      "batch 13195, train_loss 69.766815,Time used 0.007963s\n",
      "batch 13196, train_loss 50.616444,Time used 0.009041s\n",
      "batch 13197, train_loss 70.924477,Time used 0.007963s\n",
      "batch 13198, train_loss 47.016727,Time used 0.007002s\n",
      "batch 13199, train_loss 63.801041,Time used 0.008998s\n",
      "batch 13200, train_loss 54.173149,Time used 0.007004s\n",
      "***************************test_batch 13200, test_rmse_loss 8.684688,test_mae_loss 3.534290,test_mape_loss 56.215910,Time used 0.031001s\n",
      "batch 13201, train_loss 53.180073,Time used 0.010033s\n",
      "batch 13202, train_loss 43.648571,Time used 0.007966s\n",
      "batch 13203, train_loss 51.569199,Time used 0.007998s\n",
      "batch 13204, train_loss 64.869484,Time used 0.013003s\n",
      "batch 13205, train_loss 61.063328,Time used 0.007998s\n",
      "batch 13206, train_loss 48.324112,Time used 0.012034s\n",
      "batch 13207, train_loss 76.066513,Time used 0.010966s\n",
      "batch 13208, train_loss 50.765663,Time used 0.007972s\n",
      "batch 13209, train_loss 59.619751,Time used 0.008002s\n",
      "batch 13210, train_loss 54.607887,Time used 0.007996s\n",
      "batch 13211, train_loss 64.069092,Time used 0.007999s\n",
      "batch 13212, train_loss 58.106941,Time used 0.008001s\n",
      "batch 13213, train_loss 55.336082,Time used 0.008000s\n",
      "batch 13214, train_loss 50.807060,Time used 0.008001s\n",
      "batch 13215, train_loss 56.891533,Time used 0.008002s\n",
      "batch 13216, train_loss 57.035408,Time used 0.010999s\n",
      "batch 13217, train_loss 53.329922,Time used 0.007036s\n",
      "batch 13218, train_loss 57.426945,Time used 0.007966s\n",
      "batch 13219, train_loss 44.892723,Time used 0.007001s\n",
      "batch 13220, train_loss 58.954525,Time used 0.008001s\n",
      "batch 13221, train_loss 71.071861,Time used 0.009997s\n",
      "batch 13222, train_loss 47.376942,Time used 0.008002s\n",
      "batch 13223, train_loss 69.409912,Time used 0.007996s\n",
      "batch 13224, train_loss 59.454304,Time used 0.007001s\n",
      "batch 13225, train_loss 59.969490,Time used 0.012003s\n",
      "batch 13226, train_loss 69.500778,Time used 0.010997s\n",
      "batch 13227, train_loss 54.720951,Time used 0.010004s\n",
      "batch 13228, train_loss 60.229168,Time used 0.008004s\n",
      "batch 13229, train_loss 47.280617,Time used 0.008998s\n",
      "batch 13230, train_loss 50.735523,Time used 0.007999s\n",
      "batch 13231, train_loss 56.506687,Time used 0.008003s\n",
      "batch 13232, train_loss 45.289429,Time used 0.007998s\n",
      "batch 13233, train_loss 53.243286,Time used 0.010001s\n",
      "batch 13234, train_loss 55.788593,Time used 0.007003s\n",
      "batch 13235, train_loss 39.148987,Time used 0.009998s\n",
      "batch 13236, train_loss 65.817398,Time used 0.010003s\n",
      "batch 13237, train_loss 51.921814,Time used 0.011003s\n",
      "batch 13238, train_loss 66.391907,Time used 0.009001s\n",
      "batch 13239, train_loss 62.511623,Time used 0.006998s\n",
      "batch 13240, train_loss 69.359764,Time used 0.007998s\n",
      "batch 13241, train_loss 54.562038,Time used 0.008003s\n",
      "batch 13242, train_loss 59.910892,Time used 0.011000s\n",
      "batch 13243, train_loss 63.750488,Time used 0.011000s\n",
      "batch 13244, train_loss 58.377586,Time used 0.012001s\n",
      "batch 13245, train_loss 46.925484,Time used 0.007996s\n",
      "batch 13246, train_loss 64.397606,Time used 0.009007s\n",
      "batch 13247, train_loss 51.156918,Time used 0.008994s\n",
      "batch 13248, train_loss 58.226936,Time used 0.008004s\n",
      "batch 13249, train_loss 59.662846,Time used 0.007036s\n",
      "batch 13250, train_loss 48.001423,Time used 0.008967s\n",
      "batch 13251, train_loss 64.137619,Time used 0.007001s\n",
      "batch 13252, train_loss 59.053238,Time used 0.008032s\n",
      "batch 13253, train_loss 45.398987,Time used 0.007002s\n",
      "batch 13254, train_loss 52.064541,Time used 0.008998s\n",
      "batch 13255, train_loss 52.269966,Time used 0.007965s\n",
      "batch 13256, train_loss 48.586739,Time used 0.008002s\n",
      "batch 13257, train_loss 55.274673,Time used 0.008003s\n",
      "batch 13258, train_loss 56.898937,Time used 0.009997s\n",
      "batch 13259, train_loss 54.536053,Time used 0.008000s\n",
      "batch 13260, train_loss 72.556473,Time used 0.007997s\n",
      "batch 13261, train_loss 45.897579,Time used 0.007004s\n",
      "batch 13262, train_loss 53.732628,Time used 0.007000s\n",
      "batch 13263, train_loss 70.318909,Time used 0.007000s\n",
      "batch 13264, train_loss 55.982662,Time used 0.010999s\n",
      "batch 13265, train_loss 61.524746,Time used 0.009000s\n",
      "batch 13266, train_loss 60.549904,Time used 0.007997s\n",
      "batch 13267, train_loss 67.517342,Time used 0.007000s\n",
      "batch 13268, train_loss 39.368141,Time used 0.007000s\n",
      "batch 13269, train_loss 54.418137,Time used 0.009000s\n",
      "batch 13270, train_loss 62.884693,Time used 0.008998s\n",
      "batch 13271, train_loss 61.223431,Time used 0.008999s\n",
      "batch 13272, train_loss 61.863605,Time used 0.010002s\n",
      "batch 13273, train_loss 54.770210,Time used 0.011999s\n",
      "batch 13274, train_loss 40.346786,Time used 0.011003s\n",
      "batch 13275, train_loss 74.164757,Time used 0.007001s\n",
      "batch 13276, train_loss 37.392143,Time used 0.006969s\n",
      "batch 13277, train_loss 67.784409,Time used 0.011000s\n",
      "batch 13278, train_loss 55.708294,Time used 0.009998s\n",
      "batch 13279, train_loss 54.781723,Time used 0.010000s\n",
      "batch 13280, train_loss 43.486912,Time used 0.009001s\n",
      "batch 13281, train_loss 46.575256,Time used 0.010010s\n",
      "batch 13282, train_loss 43.342709,Time used 0.010988s\n",
      "batch 13283, train_loss 56.592342,Time used 0.010005s\n",
      "batch 13284, train_loss 57.293854,Time used 0.010998s\n",
      "batch 13285, train_loss 60.277008,Time used 0.010000s\n",
      "batch 13286, train_loss 56.017353,Time used 0.012000s\n",
      "batch 13287, train_loss 66.775169,Time used 0.008996s\n",
      "batch 13288, train_loss 66.338326,Time used 0.010000s\n",
      "batch 13289, train_loss 69.171173,Time used 0.006999s\n",
      "batch 13290, train_loss 55.577579,Time used 0.010001s\n",
      "batch 13291, train_loss 51.898048,Time used 0.007001s\n",
      "batch 13292, train_loss 58.197918,Time used 0.008000s\n",
      "batch 13293, train_loss 59.569019,Time used 0.010998s\n",
      "batch 13294, train_loss 59.065666,Time used 0.007003s\n",
      "batch 13295, train_loss 61.371887,Time used 0.007999s\n",
      "batch 13296, train_loss 65.028664,Time used 0.010000s\n",
      "batch 13297, train_loss 59.129040,Time used 0.007997s\n",
      "batch 13298, train_loss 80.322441,Time used 0.007999s\n",
      "batch 13299, train_loss 66.480965,Time used 0.009004s\n",
      "batch 13300, train_loss 71.157639,Time used 0.007999s\n",
      "***************************test_batch 13300, test_rmse_loss 8.650041,test_mae_loss 3.528684,test_mape_loss 56.387929,Time used 0.040999s\n",
      "batch 13301, train_loss 56.696629,Time used 0.009001s\n",
      "batch 13302, train_loss 71.305885,Time used 0.008000s\n",
      "batch 13303, train_loss 46.021439,Time used 0.008999s\n",
      "batch 13304, train_loss 61.266567,Time used 0.007999s\n",
      "batch 13305, train_loss 65.177162,Time used 0.010001s\n",
      "batch 13306, train_loss 45.823433,Time used 0.007999s\n",
      "batch 13307, train_loss 45.030449,Time used 0.007998s\n",
      "batch 13308, train_loss 53.385918,Time used 0.011002s\n",
      "batch 13309, train_loss 48.424335,Time used 0.008001s\n",
      "batch 13310, train_loss 41.914005,Time used 0.007000s\n",
      "batch 13311, train_loss 58.532764,Time used 0.007999s\n",
      "batch 13312, train_loss 53.293224,Time used 0.007999s\n",
      "batch 13313, train_loss 47.319195,Time used 0.009001s\n",
      "batch 13314, train_loss 62.356007,Time used 0.009999s\n",
      "batch 13315, train_loss 54.759743,Time used 0.008002s\n",
      "batch 13316, train_loss 53.973354,Time used 0.009999s\n",
      "batch 13317, train_loss 57.763832,Time used 0.011000s\n",
      "batch 13318, train_loss 47.814804,Time used 0.008001s\n",
      "batch 13319, train_loss 55.733997,Time used 0.009999s\n",
      "batch 13320, train_loss 55.384247,Time used 0.010005s\n",
      "batch 13321, train_loss 60.724983,Time used 0.009003s\n",
      "batch 13322, train_loss 47.971844,Time used 0.007999s\n",
      "batch 13323, train_loss 52.156708,Time used 0.009002s\n",
      "batch 13324, train_loss 55.523407,Time used 0.007001s\n",
      "batch 13325, train_loss 58.537663,Time used 0.007996s\n",
      "batch 13326, train_loss 71.511559,Time used 0.007000s\n",
      "batch 13327, train_loss 62.086361,Time used 0.008001s\n",
      "batch 13328, train_loss 60.799992,Time used 0.006999s\n",
      "batch 13329, train_loss 63.942589,Time used 0.009002s\n",
      "batch 13330, train_loss 53.949432,Time used 0.009000s\n",
      "batch 13331, train_loss 47.072536,Time used 0.007998s\n",
      "batch 13332, train_loss 50.463486,Time used 0.007003s\n",
      "batch 13333, train_loss 63.582500,Time used 0.009002s\n",
      "batch 13334, train_loss 60.106747,Time used 0.007996s\n",
      "batch 13335, train_loss 68.148796,Time used 0.008003s\n",
      "batch 13336, train_loss 51.444382,Time used 0.008995s\n",
      "batch 13337, train_loss 59.953529,Time used 0.008000s\n",
      "batch 13338, train_loss 62.350861,Time used 0.010039s\n",
      "batch 13339, train_loss 54.951389,Time used 0.010001s\n",
      "batch 13340, train_loss 36.803612,Time used 0.006964s\n",
      "batch 13341, train_loss 53.715607,Time used 0.007964s\n",
      "batch 13342, train_loss 53.809326,Time used 0.010997s\n",
      "batch 13343, train_loss 47.695320,Time used 0.008002s\n",
      "batch 13344, train_loss 59.707703,Time used 0.012001s\n",
      "batch 13345, train_loss 51.688431,Time used 0.010999s\n",
      "batch 13346, train_loss 52.138649,Time used 0.008000s\n",
      "batch 13347, train_loss 50.910835,Time used 0.010000s\n",
      "batch 13348, train_loss 50.316307,Time used 0.009003s\n",
      "batch 13349, train_loss 46.555794,Time used 0.009997s\n",
      "batch 13350, train_loss 66.874535,Time used 0.009002s\n",
      "batch 13351, train_loss 57.564102,Time used 0.009000s\n",
      "batch 13352, train_loss 60.735069,Time used 0.008000s\n",
      "batch 13353, train_loss 59.060314,Time used 0.007004s\n",
      "batch 13354, train_loss 48.238922,Time used 0.007000s\n",
      "batch 13355, train_loss 52.238525,Time used 0.007996s\n",
      "batch 13356, train_loss 57.803768,Time used 0.008001s\n",
      "batch 13357, train_loss 69.711067,Time used 0.010997s\n",
      "batch 13358, train_loss 60.197659,Time used 0.010000s\n",
      "batch 13359, train_loss 46.869709,Time used 0.010002s\n",
      "batch 13360, train_loss 72.916725,Time used 0.011000s\n",
      "batch 13361, train_loss 51.499763,Time used 0.009997s\n",
      "batch 13362, train_loss 59.481865,Time used 0.008003s\n",
      "batch 13363, train_loss 54.107456,Time used 0.008999s\n",
      "batch 13364, train_loss 48.110538,Time used 0.007000s\n",
      "batch 13365, train_loss 54.505909,Time used 0.008001s\n",
      "batch 13366, train_loss 64.529221,Time used 0.008001s\n",
      "batch 13367, train_loss 58.052387,Time used 0.008002s\n",
      "batch 13368, train_loss 61.002918,Time used 0.008998s\n",
      "batch 13369, train_loss 73.610931,Time used 0.008000s\n",
      "batch 13370, train_loss 65.250557,Time used 0.010000s\n",
      "batch 13371, train_loss 58.017815,Time used 0.007002s\n",
      "batch 13372, train_loss 49.976349,Time used 0.008002s\n",
      "batch 13373, train_loss 54.833443,Time used 0.007999s\n",
      "batch 13374, train_loss 51.246887,Time used 0.007000s\n",
      "batch 13375, train_loss 47.563911,Time used 0.007002s\n",
      "batch 13376, train_loss 63.321701,Time used 0.010002s\n",
      "batch 13377, train_loss 60.232174,Time used 0.009999s\n",
      "batch 13378, train_loss 49.439941,Time used 0.007000s\n",
      "batch 13379, train_loss 58.746414,Time used 0.007005s\n",
      "batch 13380, train_loss 54.280163,Time used 0.008997s\n",
      "batch 13381, train_loss 52.280277,Time used 0.008001s\n",
      "batch 13382, train_loss 52.574917,Time used 0.008999s\n",
      "batch 13383, train_loss 64.586021,Time used 0.010001s\n",
      "batch 13384, train_loss 54.702793,Time used 0.009003s\n",
      "batch 13385, train_loss 55.908188,Time used 0.011003s\n",
      "batch 13386, train_loss 59.189648,Time used 0.013000s\n",
      "batch 13387, train_loss 45.150433,Time used 0.007999s\n",
      "batch 13388, train_loss 59.756920,Time used 0.006999s\n",
      "batch 13389, train_loss 55.002991,Time used 0.009005s\n",
      "batch 13390, train_loss 48.938019,Time used 0.007998s\n",
      "batch 13391, train_loss 59.350864,Time used 0.008042s\n",
      "batch 13392, train_loss 58.715046,Time used 0.009958s\n",
      "batch 13393, train_loss 47.843510,Time used 0.007967s\n",
      "batch 13394, train_loss 67.250824,Time used 0.009996s\n",
      "batch 13395, train_loss 65.059174,Time used 0.011002s\n",
      "batch 13396, train_loss 43.091377,Time used 0.008004s\n",
      "batch 13397, train_loss 61.990768,Time used 0.010993s\n",
      "batch 13398, train_loss 57.797405,Time used 0.012001s\n",
      "batch 13399, train_loss 66.072922,Time used 0.008002s\n",
      "batch 13400, train_loss 50.404499,Time used 0.007999s\n",
      "***************************test_batch 13400, test_rmse_loss 8.626269,test_mae_loss 3.519572,test_mape_loss 56.225799,Time used 0.043002s\n",
      "batch 13401, train_loss 47.769409,Time used 0.012998s\n",
      "batch 13402, train_loss 66.455391,Time used 0.010000s\n",
      "batch 13403, train_loss 52.191792,Time used 0.009000s\n",
      "batch 13404, train_loss 62.080605,Time used 0.008002s\n",
      "batch 13405, train_loss 57.494709,Time used 0.009997s\n",
      "batch 13406, train_loss 53.458286,Time used 0.009002s\n",
      "batch 13407, train_loss 50.023075,Time used 0.008000s\n",
      "batch 13408, train_loss 53.495792,Time used 0.011999s\n",
      "batch 13409, train_loss 63.322670,Time used 0.010002s\n",
      "batch 13410, train_loss 59.675316,Time used 0.007998s\n",
      "batch 13411, train_loss 55.318184,Time used 0.010001s\n",
      "batch 13412, train_loss 61.395107,Time used 0.011000s\n",
      "batch 13413, train_loss 50.356895,Time used 0.011000s\n",
      "batch 13414, train_loss 47.591473,Time used 0.011001s\n",
      "batch 13415, train_loss 58.462303,Time used 0.009001s\n",
      "batch 13416, train_loss 51.683109,Time used 0.010002s\n",
      "batch 13417, train_loss 44.638943,Time used 0.013000s\n",
      "batch 13418, train_loss 67.137024,Time used 0.010000s\n",
      "batch 13419, train_loss 54.128654,Time used 0.009000s\n",
      "batch 13420, train_loss 54.836987,Time used 0.011999s\n",
      "batch 13421, train_loss 62.720268,Time used 0.012002s\n",
      "batch 13422, train_loss 42.950275,Time used 0.009000s\n",
      "batch 13423, train_loss 50.392830,Time used 0.008000s\n",
      "batch 13424, train_loss 61.407520,Time used 0.008000s\n",
      "batch 13425, train_loss 48.426254,Time used 0.008001s\n",
      "batch 13426, train_loss 44.809479,Time used 0.011001s\n",
      "batch 13427, train_loss 39.026093,Time used 0.011000s\n",
      "batch 13428, train_loss 53.225365,Time used 0.010002s\n",
      "batch 13429, train_loss 56.104015,Time used 0.007997s\n",
      "batch 13430, train_loss 54.173347,Time used 0.009002s\n",
      "batch 13431, train_loss 48.036026,Time used 0.008999s\n",
      "batch 13432, train_loss 57.232853,Time used 0.010000s\n",
      "batch 13433, train_loss 79.207687,Time used 0.010998s\n",
      "batch 13434, train_loss 61.963959,Time used 0.009001s\n",
      "batch 13435, train_loss 53.816109,Time used 0.007001s\n",
      "batch 13436, train_loss 57.961754,Time used 0.006999s\n",
      "batch 13437, train_loss 64.213539,Time used 0.009997s\n",
      "batch 13438, train_loss 79.098953,Time used 0.010001s\n",
      "batch 13439, train_loss 49.978870,Time used 0.009004s\n",
      "batch 13440, train_loss 63.278366,Time used 0.011998s\n",
      "batch 13441, train_loss 52.593018,Time used 0.007997s\n",
      "batch 13442, train_loss 55.788311,Time used 0.006999s\n",
      "batch 13443, train_loss 61.426472,Time used 0.012002s\n",
      "batch 13444, train_loss 48.219307,Time used 0.007002s\n",
      "batch 13445, train_loss 48.384304,Time used 0.007002s\n",
      "batch 13446, train_loss 59.523705,Time used 0.007997s\n",
      "batch 13447, train_loss 49.637867,Time used 0.006998s\n",
      "batch 13448, train_loss 64.104546,Time used 0.008004s\n",
      "batch 13449, train_loss 64.176842,Time used 0.007001s\n",
      "batch 13450, train_loss 55.737747,Time used 0.011002s\n",
      "batch 13451, train_loss 54.354927,Time used 0.010996s\n",
      "batch 13452, train_loss 55.451759,Time used 0.007001s\n",
      "batch 13453, train_loss 55.263618,Time used 0.007996s\n",
      "batch 13454, train_loss 38.245190,Time used 0.007003s\n",
      "batch 13455, train_loss 49.707352,Time used 0.008004s\n",
      "batch 13456, train_loss 68.064079,Time used 0.007997s\n",
      "batch 13457, train_loss 54.548618,Time used 0.009001s\n",
      "batch 13458, train_loss 60.620213,Time used 0.009998s\n",
      "batch 13459, train_loss 60.290520,Time used 0.010998s\n",
      "batch 13460, train_loss 54.207203,Time used 0.010003s\n",
      "batch 13461, train_loss 63.100510,Time used 0.008996s\n",
      "batch 13462, train_loss 47.224689,Time used 0.008004s\n",
      "batch 13463, train_loss 62.157169,Time used 0.006998s\n",
      "batch 13464, train_loss 63.577965,Time used 0.006999s\n",
      "batch 13465, train_loss 51.794537,Time used 0.008000s\n",
      "batch 13466, train_loss 53.598595,Time used 0.007999s\n",
      "batch 13467, train_loss 62.734097,Time used 0.007005s\n",
      "batch 13468, train_loss 51.093887,Time used 0.007998s\n",
      "batch 13469, train_loss 60.009636,Time used 0.008997s\n",
      "batch 13470, train_loss 44.899868,Time used 0.009037s\n",
      "batch 13471, train_loss 51.202526,Time used 0.007963s\n",
      "batch 13472, train_loss 54.508450,Time used 0.008004s\n",
      "batch 13473, train_loss 36.251385,Time used 0.011000s\n",
      "batch 13474, train_loss 56.140049,Time used 0.008995s\n",
      "batch 13475, train_loss 62.999771,Time used 0.008001s\n",
      "batch 13476, train_loss 58.691185,Time used 0.008002s\n",
      "batch 13477, train_loss 72.625786,Time used 0.007002s\n",
      "batch 13478, train_loss 57.665718,Time used 0.006998s\n",
      "batch 13479, train_loss 51.562408,Time used 0.008999s\n",
      "batch 13480, train_loss 66.504097,Time used 0.010006s\n",
      "batch 13481, train_loss 48.139046,Time used 0.007995s\n",
      "batch 13482, train_loss 74.228783,Time used 0.008001s\n",
      "batch 13483, train_loss 49.967052,Time used 0.008002s\n",
      "batch 13484, train_loss 57.772697,Time used 0.008003s\n",
      "batch 13485, train_loss 57.941586,Time used 0.008995s\n",
      "batch 13486, train_loss 50.133488,Time used 0.008000s\n",
      "batch 13487, train_loss 59.542625,Time used 0.010003s\n",
      "batch 13488, train_loss 53.878860,Time used 0.008002s\n",
      "batch 13489, train_loss 66.190865,Time used 0.011001s\n",
      "batch 13490, train_loss 48.478851,Time used 0.008001s\n",
      "batch 13491, train_loss 50.926586,Time used 0.010995s\n",
      "batch 13492, train_loss 70.111366,Time used 0.011002s\n",
      "batch 13493, train_loss 60.515385,Time used 0.012002s\n",
      "batch 13494, train_loss 43.853657,Time used 0.015999s\n",
      "batch 13495, train_loss 61.122421,Time used 0.010001s\n",
      "batch 13496, train_loss 62.775890,Time used 0.008000s\n",
      "batch 13497, train_loss 58.373581,Time used 0.008999s\n",
      "batch 13498, train_loss 52.005318,Time used 0.009003s\n",
      "batch 13499, train_loss 50.352188,Time used 0.011997s\n",
      "batch 13500, train_loss 36.988235,Time used 0.010007s\n",
      "***************************test_batch 13500, test_rmse_loss 8.605664,test_mae_loss 3.508154,test_mape_loss 55.724872,Time used 0.035994s\n",
      "batch 13501, train_loss 56.182667,Time used 0.010004s\n",
      "batch 13502, train_loss 49.705639,Time used 0.010996s\n",
      "batch 13503, train_loss 47.081562,Time used 0.010003s\n",
      "batch 13504, train_loss 60.351116,Time used 0.008001s\n",
      "batch 13505, train_loss 56.572483,Time used 0.007998s\n",
      "batch 13506, train_loss 54.469048,Time used 0.008000s\n",
      "batch 13507, train_loss 50.519711,Time used 0.010000s\n",
      "batch 13508, train_loss 54.645790,Time used 0.007999s\n",
      "batch 13509, train_loss 69.448730,Time used 0.010000s\n",
      "batch 13510, train_loss 58.660095,Time used 0.006998s\n",
      "batch 13511, train_loss 55.165127,Time used 0.006999s\n",
      "batch 13512, train_loss 67.824867,Time used 0.008001s\n",
      "batch 13513, train_loss 54.579887,Time used 0.008002s\n",
      "batch 13514, train_loss 65.904312,Time used 0.007999s\n",
      "batch 13515, train_loss 82.491043,Time used 0.008002s\n",
      "batch 13516, train_loss 68.592262,Time used 0.007998s\n",
      "batch 13517, train_loss 67.515373,Time used 0.007999s\n",
      "batch 13518, train_loss 50.988708,Time used 0.009999s\n",
      "batch 13519, train_loss 52.918785,Time used 0.009000s\n",
      "batch 13520, train_loss 38.024521,Time used 0.007035s\n",
      "batch 13521, train_loss 68.120438,Time used 0.008997s\n",
      "batch 13522, train_loss 67.967361,Time used 0.009966s\n",
      "batch 13523, train_loss 64.090981,Time used 0.012001s\n",
      "batch 13524, train_loss 60.439800,Time used 0.011000s\n",
      "batch 13525, train_loss 56.945919,Time used 0.007998s\n",
      "batch 13526, train_loss 47.916264,Time used 0.007999s\n",
      "batch 13527, train_loss 53.396843,Time used 0.008005s\n",
      "batch 13528, train_loss 39.669842,Time used 0.010994s\n",
      "batch 13529, train_loss 49.593941,Time used 0.010002s\n",
      "batch 13530, train_loss 35.717739,Time used 0.010000s\n",
      "batch 13531, train_loss 39.560131,Time used 0.006999s\n",
      "batch 13532, train_loss 62.584248,Time used 0.011000s\n",
      "batch 13533, train_loss 46.143349,Time used 0.013002s\n",
      "batch 13534, train_loss 48.818081,Time used 0.007997s\n",
      "batch 13535, train_loss 52.767769,Time used 0.009002s\n",
      "batch 13536, train_loss 65.152222,Time used 0.007999s\n",
      "batch 13537, train_loss 55.683830,Time used 0.008002s\n",
      "batch 13538, train_loss 54.961563,Time used 0.009003s\n",
      "batch 13539, train_loss 65.486092,Time used 0.010999s\n",
      "batch 13540, train_loss 58.341953,Time used 0.006998s\n",
      "batch 13541, train_loss 53.767967,Time used 0.009003s\n",
      "batch 13542, train_loss 61.100643,Time used 0.008002s\n",
      "batch 13543, train_loss 57.380844,Time used 0.007000s\n",
      "batch 13544, train_loss 60.534370,Time used 0.007998s\n",
      "batch 13545, train_loss 66.077538,Time used 0.008001s\n",
      "batch 13546, train_loss 53.270432,Time used 0.009998s\n",
      "batch 13547, train_loss 61.184250,Time used 0.009997s\n",
      "batch 13548, train_loss 50.240292,Time used 0.011001s\n",
      "batch 13549, train_loss 51.339012,Time used 0.008000s\n",
      "batch 13550, train_loss 53.669552,Time used 0.007003s\n",
      "batch 13551, train_loss 57.464195,Time used 0.009000s\n",
      "batch 13552, train_loss 58.400211,Time used 0.009998s\n",
      "batch 13553, train_loss 50.858078,Time used 0.011000s\n",
      "batch 13554, train_loss 59.558239,Time used 0.010999s\n",
      "batch 13555, train_loss 48.982464,Time used 0.010000s\n",
      "batch 13556, train_loss 55.282742,Time used 0.009001s\n",
      "batch 13557, train_loss 53.137516,Time used 0.009000s\n",
      "batch 13558, train_loss 50.607868,Time used 0.008004s\n",
      "batch 13559, train_loss 56.439857,Time used 0.011998s\n",
      "batch 13560, train_loss 43.753338,Time used 0.008996s\n",
      "batch 13561, train_loss 61.687675,Time used 0.007997s\n",
      "batch 13562, train_loss 56.841049,Time used 0.008000s\n",
      "batch 13563, train_loss 54.295563,Time used 0.008003s\n",
      "batch 13564, train_loss 67.555473,Time used 0.007998s\n",
      "batch 13565, train_loss 59.537956,Time used 0.008000s\n",
      "batch 13566, train_loss 71.984650,Time used 0.009001s\n",
      "batch 13567, train_loss 50.191242,Time used 0.009003s\n",
      "batch 13568, train_loss 54.603210,Time used 0.010996s\n",
      "batch 13569, train_loss 55.884514,Time used 0.009005s\n",
      "batch 13570, train_loss 52.539040,Time used 0.010002s\n",
      "batch 13571, train_loss 61.093128,Time used 0.011000s\n",
      "batch 13572, train_loss 52.783367,Time used 0.011000s\n",
      "batch 13573, train_loss 48.476418,Time used 0.008000s\n",
      "batch 13574, train_loss 50.881481,Time used 0.007002s\n",
      "batch 13575, train_loss 58.318104,Time used 0.009002s\n",
      "batch 13576, train_loss 43.716076,Time used 0.012994s\n",
      "batch 13577, train_loss 50.134228,Time used 0.011000s\n",
      "batch 13578, train_loss 60.715229,Time used 0.011003s\n",
      "batch 13579, train_loss 49.320839,Time used 0.007000s\n",
      "batch 13580, train_loss 52.536453,Time used 0.010000s\n",
      "batch 13581, train_loss 45.303654,Time used 0.009003s\n",
      "batch 13582, train_loss 61.315063,Time used 0.007000s\n",
      "batch 13583, train_loss 49.206112,Time used 0.007999s\n",
      "batch 13584, train_loss 67.097534,Time used 0.008003s\n",
      "batch 13585, train_loss 57.997135,Time used 0.011999s\n",
      "batch 13586, train_loss 58.882244,Time used 0.009006s\n",
      "batch 13587, train_loss 55.234787,Time used 0.011003s\n",
      "batch 13588, train_loss 60.626511,Time used 0.008997s\n",
      "batch 13589, train_loss 36.465160,Time used 0.009001s\n",
      "batch 13590, train_loss 71.773071,Time used 0.008002s\n",
      "batch 13591, train_loss 60.106472,Time used 0.010996s\n",
      "batch 13592, train_loss 65.483841,Time used 0.011002s\n",
      "batch 13593, train_loss 54.204456,Time used 0.007997s\n",
      "batch 13594, train_loss 55.567699,Time used 0.008001s\n",
      "batch 13595, train_loss 47.880886,Time used 0.007999s\n",
      "batch 13596, train_loss 67.879425,Time used 0.011000s\n",
      "batch 13597, train_loss 59.311943,Time used 0.008000s\n",
      "batch 13598, train_loss 64.523758,Time used 0.009001s\n",
      "batch 13599, train_loss 52.670952,Time used 0.010997s\n",
      "batch 13600, train_loss 52.041550,Time used 0.009001s\n",
      "***************************test_batch 13600, test_rmse_loss 8.570740,test_mae_loss 3.499250,test_mape_loss 55.876505,Time used 0.034001s\n",
      "batch 13601, train_loss 56.858536,Time used 0.008999s\n",
      "batch 13602, train_loss 44.522884,Time used 0.007000s\n",
      "batch 13603, train_loss 36.564472,Time used 0.011000s\n",
      "batch 13604, train_loss 75.552155,Time used 0.011002s\n",
      "batch 13605, train_loss 43.807297,Time used 0.007999s\n",
      "batch 13606, train_loss 53.858757,Time used 0.008002s\n",
      "batch 13607, train_loss 52.378761,Time used 0.010999s\n",
      "batch 13608, train_loss 48.880592,Time used 0.006999s\n",
      "batch 13609, train_loss 59.757908,Time used 0.008000s\n",
      "batch 13610, train_loss 65.341576,Time used 0.008000s\n",
      "batch 13611, train_loss 68.455643,Time used 0.008001s\n",
      "batch 13612, train_loss 54.846455,Time used 0.008000s\n",
      "batch 13613, train_loss 58.332027,Time used 0.008000s\n",
      "batch 13614, train_loss 61.226925,Time used 0.007999s\n",
      "batch 13615, train_loss 44.170891,Time used 0.008000s\n",
      "batch 13616, train_loss 49.721523,Time used 0.008038s\n",
      "batch 13617, train_loss 66.689583,Time used 0.008002s\n",
      "batch 13618, train_loss 53.568878,Time used 0.009007s\n",
      "batch 13619, train_loss 48.622173,Time used 0.007958s\n",
      "batch 13620, train_loss 65.354942,Time used 0.007999s\n",
      "batch 13621, train_loss 56.326668,Time used 0.012034s\n",
      "batch 13622, train_loss 50.769093,Time used 0.007961s\n",
      "batch 13623, train_loss 56.764366,Time used 0.008004s\n",
      "batch 13624, train_loss 59.444672,Time used 0.007036s\n",
      "batch 13625, train_loss 55.441738,Time used 0.006966s\n",
      "batch 13626, train_loss 49.480576,Time used 0.009998s\n",
      "batch 13627, train_loss 45.542812,Time used 0.011999s\n",
      "batch 13628, train_loss 52.597809,Time used 0.010999s\n",
      "batch 13629, train_loss 48.077911,Time used 0.010006s\n",
      "batch 13630, train_loss 62.943928,Time used 0.011999s\n",
      "batch 13631, train_loss 58.891094,Time used 0.007997s\n",
      "batch 13632, train_loss 38.013191,Time used 0.009002s\n",
      "batch 13633, train_loss 54.548077,Time used 0.009000s\n",
      "batch 13634, train_loss 56.343719,Time used 0.011001s\n",
      "batch 13635, train_loss 51.795296,Time used 0.008036s\n",
      "batch 13636, train_loss 50.571934,Time used 0.007963s\n",
      "batch 13637, train_loss 48.690891,Time used 0.008036s\n",
      "batch 13638, train_loss 54.078629,Time used 0.007963s\n",
      "batch 13639, train_loss 56.966499,Time used 0.007000s\n",
      "batch 13640, train_loss 58.891075,Time used 0.008002s\n",
      "batch 13641, train_loss 72.005165,Time used 0.010004s\n",
      "batch 13642, train_loss 54.443405,Time used 0.008000s\n",
      "batch 13643, train_loss 49.228493,Time used 0.007999s\n",
      "batch 13644, train_loss 67.734367,Time used 0.008000s\n",
      "batch 13645, train_loss 56.695652,Time used 0.008034s\n",
      "batch 13646, train_loss 49.507896,Time used 0.008968s\n",
      "batch 13647, train_loss 49.491199,Time used 0.010998s\n",
      "batch 13648, train_loss 63.604614,Time used 0.007999s\n",
      "batch 13649, train_loss 55.274208,Time used 0.010000s\n",
      "batch 13650, train_loss 40.729366,Time used 0.010001s\n",
      "batch 13651, train_loss 58.168373,Time used 0.010007s\n",
      "batch 13652, train_loss 60.620396,Time used 0.009992s\n",
      "batch 13653, train_loss 49.634480,Time used 0.010999s\n",
      "batch 13654, train_loss 55.988712,Time used 0.008001s\n",
      "batch 13655, train_loss 53.869797,Time used 0.007001s\n",
      "batch 13656, train_loss 60.418125,Time used 0.009000s\n",
      "batch 13657, train_loss 54.170155,Time used 0.007000s\n",
      "batch 13658, train_loss 61.415005,Time used 0.008001s\n",
      "batch 13659, train_loss 53.794865,Time used 0.011000s\n",
      "batch 13660, train_loss 55.569897,Time used 0.010001s\n",
      "batch 13661, train_loss 49.220894,Time used 0.007000s\n",
      "batch 13662, train_loss 51.572449,Time used 0.009999s\n",
      "batch 13663, train_loss 51.830154,Time used 0.007002s\n",
      "batch 13664, train_loss 67.940895,Time used 0.011999s\n",
      "batch 13665, train_loss 48.853355,Time used 0.010002s\n",
      "batch 13666, train_loss 67.365730,Time used 0.011000s\n",
      "batch 13667, train_loss 54.634762,Time used 0.007999s\n",
      "batch 13668, train_loss 49.635944,Time used 0.010000s\n",
      "batch 13669, train_loss 60.877701,Time used 0.009999s\n",
      "batch 13670, train_loss 48.204552,Time used 0.008002s\n",
      "batch 13671, train_loss 55.978523,Time used 0.007998s\n",
      "batch 13672, train_loss 56.864025,Time used 0.010000s\n",
      "batch 13673, train_loss 45.386852,Time used 0.007000s\n",
      "batch 13674, train_loss 55.537830,Time used 0.008003s\n",
      "batch 13675, train_loss 66.860825,Time used 0.008999s\n",
      "batch 13676, train_loss 50.934048,Time used 0.011000s\n",
      "batch 13677, train_loss 47.846714,Time used 0.011002s\n",
      "batch 13678, train_loss 58.973137,Time used 0.008998s\n",
      "batch 13679, train_loss 53.091618,Time used 0.007000s\n",
      "batch 13680, train_loss 60.718990,Time used 0.007001s\n",
      "batch 13681, train_loss 50.714085,Time used 0.008002s\n",
      "batch 13682, train_loss 62.378128,Time used 0.007000s\n",
      "batch 13683, train_loss 57.437328,Time used 0.008999s\n",
      "batch 13684, train_loss 46.569630,Time used 0.008000s\n",
      "batch 13685, train_loss 56.407734,Time used 0.009999s\n",
      "batch 13686, train_loss 50.526146,Time used 0.007001s\n",
      "batch 13687, train_loss 48.697777,Time used 0.008001s\n",
      "batch 13688, train_loss 68.537384,Time used 0.007998s\n",
      "batch 13689, train_loss 40.377010,Time used 0.010000s\n",
      "batch 13690, train_loss 51.584118,Time used 0.010002s\n",
      "batch 13691, train_loss 65.270508,Time used 0.007002s\n",
      "batch 13692, train_loss 45.077579,Time used 0.009998s\n",
      "batch 13693, train_loss 53.093243,Time used 0.007999s\n",
      "batch 13694, train_loss 50.301888,Time used 0.011002s\n",
      "batch 13695, train_loss 58.652973,Time used 0.012999s\n",
      "batch 13696, train_loss 52.829102,Time used 0.010001s\n",
      "batch 13697, train_loss 47.561577,Time used 0.011000s\n",
      "batch 13698, train_loss 57.494656,Time used 0.010000s\n",
      "batch 13699, train_loss 52.854179,Time used 0.007002s\n",
      "batch 13700, train_loss 61.930393,Time used 0.008004s\n",
      "***************************test_batch 13700, test_rmse_loss 8.544707,test_mae_loss 3.494159,test_mape_loss 56.064259,Time used 0.038993s\n",
      "batch 13701, train_loss 59.805271,Time used 0.009002s\n",
      "batch 13702, train_loss 65.606400,Time used 0.008003s\n",
      "batch 13703, train_loss 66.710106,Time used 0.008000s\n",
      "batch 13704, train_loss 54.517506,Time used 0.007999s\n",
      "batch 13705, train_loss 52.000595,Time used 0.008999s\n",
      "batch 13706, train_loss 49.658607,Time used 0.008999s\n",
      "batch 13707, train_loss 56.641983,Time used 0.008000s\n",
      "batch 13708, train_loss 47.359077,Time used 0.009003s\n",
      "batch 13709, train_loss 79.057259,Time used 0.007995s\n",
      "batch 13710, train_loss 52.384853,Time used 0.008005s\n",
      "batch 13711, train_loss 45.843861,Time used 0.007001s\n",
      "batch 13712, train_loss 52.112698,Time used 0.007999s\n",
      "batch 13713, train_loss 53.277050,Time used 0.007998s\n",
      "batch 13714, train_loss 62.083080,Time used 0.011004s\n",
      "batch 13715, train_loss 61.351181,Time used 0.009998s\n",
      "batch 13716, train_loss 53.415543,Time used 0.008000s\n",
      "batch 13717, train_loss 59.352810,Time used 0.008000s\n",
      "batch 13718, train_loss 57.101902,Time used 0.008000s\n",
      "batch 13719, train_loss 55.444435,Time used 0.008004s\n",
      "batch 13720, train_loss 70.644241,Time used 0.007996s\n",
      "batch 13721, train_loss 57.762779,Time used 0.007999s\n",
      "batch 13722, train_loss 45.963139,Time used 0.008001s\n",
      "batch 13723, train_loss 45.449081,Time used 0.009001s\n",
      "batch 13724, train_loss 59.541023,Time used 0.007001s\n",
      "batch 13725, train_loss 48.771061,Time used 0.008997s\n",
      "batch 13726, train_loss 68.387901,Time used 0.011000s\n",
      "batch 13727, train_loss 40.631626,Time used 0.011000s\n",
      "batch 13728, train_loss 48.314095,Time used 0.010001s\n",
      "batch 13729, train_loss 72.894287,Time used 0.010002s\n",
      "batch 13730, train_loss 49.455803,Time used 0.006998s\n",
      "batch 13731, train_loss 58.191463,Time used 0.009001s\n",
      "batch 13732, train_loss 59.079113,Time used 0.008000s\n",
      "batch 13733, train_loss 53.339825,Time used 0.007999s\n",
      "batch 13734, train_loss 56.258949,Time used 0.007001s\n",
      "batch 13735, train_loss 52.421177,Time used 0.007997s\n",
      "batch 13736, train_loss 53.417362,Time used 0.007004s\n",
      "batch 13737, train_loss 53.087906,Time used 0.007999s\n",
      "batch 13738, train_loss 51.841446,Time used 0.006999s\n",
      "batch 13739, train_loss 41.139698,Time used 0.009006s\n",
      "batch 13740, train_loss 55.410725,Time used 0.011035s\n",
      "batch 13741, train_loss 53.761292,Time used 0.007962s\n",
      "batch 13742, train_loss 56.417538,Time used 0.009999s\n",
      "batch 13743, train_loss 58.639423,Time used 0.010038s\n",
      "batch 13744, train_loss 50.490860,Time used 0.010003s\n",
      "batch 13745, train_loss 53.060474,Time used 0.009995s\n",
      "batch 13746, train_loss 50.699825,Time used 0.010000s\n",
      "batch 13747, train_loss 67.721855,Time used 0.011004s\n",
      "batch 13748, train_loss 61.157906,Time used 0.010998s\n",
      "batch 13749, train_loss 54.934448,Time used 0.010000s\n",
      "batch 13750, train_loss 48.261482,Time used 0.009000s\n",
      "batch 13751, train_loss 49.499634,Time used 0.009002s\n",
      "batch 13752, train_loss 59.630943,Time used 0.009998s\n",
      "batch 13753, train_loss 54.563892,Time used 0.008999s\n",
      "batch 13754, train_loss 69.045547,Time used 0.007999s\n",
      "batch 13755, train_loss 47.214790,Time used 0.008000s\n",
      "batch 13756, train_loss 57.390053,Time used 0.008000s\n",
      "batch 13757, train_loss 64.117722,Time used 0.007999s\n",
      "batch 13758, train_loss 65.210411,Time used 0.009003s\n",
      "batch 13759, train_loss 48.169495,Time used 0.007997s\n",
      "batch 13760, train_loss 60.178467,Time used 0.006999s\n",
      "batch 13761, train_loss 54.539967,Time used 0.008002s\n",
      "batch 13762, train_loss 51.617958,Time used 0.008000s\n",
      "batch 13763, train_loss 47.151684,Time used 0.007999s\n",
      "batch 13764, train_loss 47.629131,Time used 0.006999s\n",
      "batch 13765, train_loss 45.727398,Time used 0.008000s\n",
      "batch 13766, train_loss 56.147247,Time used 0.010001s\n",
      "batch 13767, train_loss 56.527699,Time used 0.010999s\n",
      "batch 13768, train_loss 54.897423,Time used 0.009001s\n",
      "batch 13769, train_loss 60.710560,Time used 0.008002s\n",
      "batch 13770, train_loss 41.404343,Time used 0.007998s\n",
      "batch 13771, train_loss 61.661415,Time used 0.010002s\n",
      "batch 13772, train_loss 56.471558,Time used 0.007000s\n",
      "batch 13773, train_loss 61.461563,Time used 0.007999s\n",
      "batch 13774, train_loss 43.893047,Time used 0.006998s\n",
      "batch 13775, train_loss 54.071655,Time used 0.009003s\n",
      "batch 13776, train_loss 59.026131,Time used 0.006999s\n",
      "batch 13777, train_loss 49.419025,Time used 0.011000s\n",
      "batch 13778, train_loss 54.568607,Time used 0.008999s\n",
      "batch 13779, train_loss 60.983036,Time used 0.007002s\n",
      "batch 13780, train_loss 56.386978,Time used 0.008003s\n",
      "batch 13781, train_loss 67.449936,Time used 0.007997s\n",
      "batch 13782, train_loss 61.080753,Time used 0.009000s\n",
      "batch 13783, train_loss 66.203369,Time used 0.006999s\n",
      "batch 13784, train_loss 55.822792,Time used 0.007999s\n",
      "batch 13785, train_loss 51.432472,Time used 0.011002s\n",
      "batch 13786, train_loss 55.986111,Time used 0.010001s\n",
      "batch 13787, train_loss 48.915722,Time used 0.010001s\n",
      "batch 13788, train_loss 70.112198,Time used 0.007001s\n",
      "batch 13789, train_loss 50.117794,Time used 0.007001s\n",
      "batch 13790, train_loss 47.178917,Time used 0.012001s\n",
      "batch 13791, train_loss 57.380432,Time used 0.007998s\n",
      "batch 13792, train_loss 49.799511,Time used 0.008003s\n",
      "batch 13793, train_loss 51.620182,Time used 0.008001s\n",
      "batch 13794, train_loss 45.777393,Time used 0.010998s\n",
      "batch 13795, train_loss 56.113533,Time used 0.008002s\n",
      "batch 13796, train_loss 63.889549,Time used 0.007997s\n",
      "batch 13797, train_loss 41.865932,Time used 0.009002s\n",
      "batch 13798, train_loss 48.069950,Time used 0.010998s\n",
      "batch 13799, train_loss 51.376286,Time used 0.012004s\n",
      "batch 13800, train_loss 55.129044,Time used 0.008000s\n",
      "***************************test_batch 13800, test_rmse_loss 8.518850,test_mae_loss 3.483588,test_mape_loss 55.753502,Time used 0.032001s\n",
      "batch 13801, train_loss 48.738277,Time used 0.007999s\n",
      "batch 13802, train_loss 60.852707,Time used 0.006999s\n",
      "batch 13803, train_loss 53.956810,Time used 0.007000s\n",
      "batch 13804, train_loss 55.931824,Time used 0.008998s\n",
      "batch 13805, train_loss 45.014599,Time used 0.009002s\n",
      "batch 13806, train_loss 37.461861,Time used 0.010035s\n",
      "batch 13807, train_loss 68.265297,Time used 0.010003s\n",
      "batch 13808, train_loss 58.005707,Time used 0.007998s\n",
      "batch 13809, train_loss 50.439930,Time used 0.008964s\n",
      "batch 13810, train_loss 44.059372,Time used 0.008000s\n",
      "batch 13811, train_loss 58.451324,Time used 0.008999s\n",
      "batch 13812, train_loss 69.966522,Time used 0.008998s\n",
      "batch 13813, train_loss 56.106110,Time used 0.007002s\n",
      "batch 13814, train_loss 48.842110,Time used 0.010000s\n",
      "batch 13815, train_loss 67.332024,Time used 0.007999s\n",
      "batch 13816, train_loss 53.085308,Time used 0.007002s\n",
      "batch 13817, train_loss 54.570114,Time used 0.009999s\n",
      "batch 13818, train_loss 65.381142,Time used 0.010000s\n",
      "batch 13819, train_loss 58.967957,Time used 0.009000s\n",
      "batch 13820, train_loss 44.328491,Time used 0.007000s\n",
      "batch 13821, train_loss 61.713707,Time used 0.009001s\n",
      "batch 13822, train_loss 52.273273,Time used 0.012000s\n",
      "batch 13823, train_loss 51.615395,Time used 0.009999s\n",
      "batch 13824, train_loss 49.311394,Time used 0.010000s\n",
      "batch 13825, train_loss 61.977722,Time used 0.009998s\n",
      "batch 13826, train_loss 73.640457,Time used 0.011004s\n",
      "batch 13827, train_loss 63.366016,Time used 0.010997s\n",
      "batch 13828, train_loss 54.177185,Time used 0.010000s\n",
      "batch 13829, train_loss 54.326202,Time used 0.009000s\n",
      "batch 13830, train_loss 54.129848,Time used 0.010998s\n",
      "batch 13831, train_loss 42.750645,Time used 0.008002s\n",
      "batch 13832, train_loss 63.586670,Time used 0.006999s\n",
      "batch 13833, train_loss 53.085278,Time used 0.010000s\n",
      "batch 13834, train_loss 52.342690,Time used 0.008000s\n",
      "batch 13835, train_loss 48.348362,Time used 0.009000s\n",
      "batch 13836, train_loss 49.453476,Time used 0.007000s\n",
      "batch 13837, train_loss 58.089962,Time used 0.008001s\n",
      "batch 13838, train_loss 58.246094,Time used 0.008000s\n",
      "batch 13839, train_loss 58.847309,Time used 0.008000s\n",
      "batch 13840, train_loss 60.263359,Time used 0.007999s\n",
      "batch 13841, train_loss 54.858143,Time used 0.009001s\n",
      "batch 13842, train_loss 44.981789,Time used 0.008000s\n",
      "batch 13843, train_loss 45.957607,Time used 0.008001s\n",
      "batch 13844, train_loss 48.202347,Time used 0.007998s\n",
      "batch 13845, train_loss 63.002903,Time used 0.009001s\n",
      "batch 13846, train_loss 51.867191,Time used 0.009998s\n",
      "batch 13847, train_loss 44.618584,Time used 0.009001s\n",
      "batch 13848, train_loss 51.991638,Time used 0.008001s\n",
      "batch 13849, train_loss 61.062862,Time used 0.011003s\n",
      "batch 13850, train_loss 57.140862,Time used 0.008996s\n",
      "batch 13851, train_loss 50.020405,Time used 0.008000s\n",
      "batch 13852, train_loss 70.864059,Time used 0.007001s\n",
      "batch 13853, train_loss 50.155590,Time used 0.011000s\n",
      "batch 13854, train_loss 54.957199,Time used 0.007999s\n",
      "batch 13855, train_loss 49.169441,Time used 0.007001s\n",
      "batch 13856, train_loss 45.516472,Time used 0.008002s\n",
      "batch 13857, train_loss 58.213123,Time used 0.006999s\n",
      "batch 13858, train_loss 48.775566,Time used 0.012004s\n",
      "batch 13859, train_loss 60.545925,Time used 0.009032s\n",
      "batch 13860, train_loss 59.194595,Time used 0.007016s\n",
      "batch 13861, train_loss 64.599396,Time used 0.006959s\n",
      "batch 13862, train_loss 49.283180,Time used 0.008002s\n",
      "batch 13863, train_loss 46.409058,Time used 0.009001s\n",
      "batch 13864, train_loss 52.798283,Time used 0.007033s\n",
      "batch 13865, train_loss 50.545586,Time used 0.007963s\n",
      "batch 13866, train_loss 61.354954,Time used 0.007036s\n",
      "batch 13867, train_loss 51.945004,Time used 0.006962s\n",
      "batch 13868, train_loss 53.790821,Time used 0.007033s\n",
      "batch 13869, train_loss 50.008682,Time used 0.008002s\n",
      "batch 13870, train_loss 59.927238,Time used 0.012000s\n",
      "batch 13871, train_loss 46.220840,Time used 0.011001s\n",
      "batch 13872, train_loss 57.911831,Time used 0.011001s\n",
      "batch 13873, train_loss 52.448658,Time used 0.008000s\n",
      "batch 13874, train_loss 48.054211,Time used 0.008001s\n",
      "batch 13875, train_loss 44.874104,Time used 0.008003s\n",
      "batch 13876, train_loss 47.895390,Time used 0.007998s\n",
      "batch 13877, train_loss 60.746944,Time used 0.008001s\n",
      "batch 13878, train_loss 47.996113,Time used 0.010998s\n",
      "batch 13879, train_loss 60.381081,Time used 0.009001s\n",
      "batch 13880, train_loss 58.545067,Time used 0.007999s\n",
      "batch 13881, train_loss 64.202568,Time used 0.007000s\n",
      "batch 13882, train_loss 62.849537,Time used 0.007002s\n",
      "batch 13883, train_loss 54.971481,Time used 0.008999s\n",
      "batch 13884, train_loss 52.187271,Time used 0.009001s\n",
      "batch 13885, train_loss 55.745552,Time used 0.007004s\n",
      "batch 13886, train_loss 53.908203,Time used 0.008996s\n",
      "batch 13887, train_loss 52.509617,Time used 0.010000s\n",
      "batch 13888, train_loss 53.450138,Time used 0.009000s\n",
      "batch 13889, train_loss 49.773621,Time used 0.010998s\n",
      "batch 13890, train_loss 51.445534,Time used 0.007004s\n",
      "batch 13891, train_loss 64.398064,Time used 0.007998s\n",
      "batch 13892, train_loss 47.130089,Time used 0.009000s\n",
      "batch 13893, train_loss 47.776264,Time used 0.010000s\n",
      "batch 13894, train_loss 65.596802,Time used 0.011000s\n",
      "batch 13895, train_loss 45.990971,Time used 0.010998s\n",
      "batch 13896, train_loss 65.912224,Time used 0.007002s\n",
      "batch 13897, train_loss 68.461006,Time used 0.010000s\n",
      "batch 13898, train_loss 49.884850,Time used 0.008000s\n",
      "batch 13899, train_loss 62.535053,Time used 0.007000s\n",
      "batch 13900, train_loss 57.719898,Time used 0.007998s\n",
      "***************************test_batch 13900, test_rmse_loss 8.487298,test_mae_loss 3.472524,test_mape_loss 55.662267,Time used 0.038005s\n",
      "batch 13901, train_loss 58.559414,Time used 0.009995s\n",
      "batch 13902, train_loss 52.813305,Time used 0.011000s\n",
      "batch 13903, train_loss 55.635456,Time used 0.009000s\n",
      "batch 13904, train_loss 61.781315,Time used 0.009000s\n",
      "batch 13905, train_loss 59.911373,Time used 0.008000s\n",
      "batch 13906, train_loss 46.430420,Time used 0.007001s\n",
      "batch 13907, train_loss 53.004181,Time used 0.010002s\n",
      "batch 13908, train_loss 59.288544,Time used 0.010999s\n",
      "batch 13909, train_loss 50.764061,Time used 0.010002s\n",
      "batch 13910, train_loss 61.516457,Time used 0.011998s\n",
      "batch 13911, train_loss 59.285606,Time used 0.007999s\n",
      "batch 13912, train_loss 49.613728,Time used 0.008002s\n",
      "batch 13913, train_loss 37.624569,Time used 0.007999s\n",
      "batch 13914, train_loss 53.408585,Time used 0.008000s\n",
      "batch 13915, train_loss 63.866890,Time used 0.008000s\n",
      "batch 13916, train_loss 47.027927,Time used 0.008000s\n",
      "batch 13917, train_loss 52.369385,Time used 0.010999s\n",
      "batch 13918, train_loss 50.432564,Time used 0.007002s\n",
      "batch 13919, train_loss 51.086452,Time used 0.007997s\n",
      "batch 13920, train_loss 42.666862,Time used 0.007000s\n",
      "batch 13921, train_loss 61.036545,Time used 0.008000s\n",
      "batch 13922, train_loss 57.414928,Time used 0.007999s\n",
      "batch 13923, train_loss 62.658413,Time used 0.007002s\n",
      "batch 13924, train_loss 58.159096,Time used 0.007000s\n",
      "batch 13925, train_loss 51.113941,Time used 0.007003s\n",
      "batch 13926, train_loss 54.662640,Time used 0.007000s\n",
      "batch 13927, train_loss 55.551018,Time used 0.008002s\n",
      "batch 13928, train_loss 47.776936,Time used 0.011003s\n",
      "batch 13929, train_loss 47.932728,Time used 0.007997s\n",
      "batch 13930, train_loss 58.186481,Time used 0.008002s\n",
      "batch 13931, train_loss 60.160751,Time used 0.010000s\n",
      "batch 13932, train_loss 40.423492,Time used 0.007997s\n",
      "batch 13933, train_loss 55.822365,Time used 0.008000s\n",
      "batch 13934, train_loss 57.531750,Time used 0.008000s\n",
      "batch 13935, train_loss 36.593601,Time used 0.008001s\n",
      "batch 13936, train_loss 61.887375,Time used 0.007999s\n",
      "batch 13937, train_loss 45.009727,Time used 0.007001s\n",
      "batch 13938, train_loss 66.869629,Time used 0.007997s\n",
      "batch 13939, train_loss 52.729572,Time used 0.008000s\n",
      "batch 13940, train_loss 43.457474,Time used 0.007000s\n",
      "batch 13941, train_loss 57.188198,Time used 0.007002s\n",
      "batch 13942, train_loss 67.309151,Time used 0.008000s\n",
      "batch 13943, train_loss 46.781628,Time used 0.008000s\n",
      "batch 13944, train_loss 58.304192,Time used 0.010000s\n",
      "batch 13945, train_loss 57.540962,Time used 0.011000s\n",
      "batch 13946, train_loss 44.258163,Time used 0.007002s\n",
      "batch 13947, train_loss 70.145638,Time used 0.008998s\n",
      "batch 13948, train_loss 61.645164,Time used 0.008001s\n",
      "batch 13949, train_loss 62.429035,Time used 0.008002s\n",
      "batch 13950, train_loss 45.895741,Time used 0.008000s\n",
      "batch 13951, train_loss 49.964825,Time used 0.008002s\n",
      "batch 13952, train_loss 51.419926,Time used 0.007998s\n",
      "batch 13953, train_loss 38.627048,Time used 0.010998s\n",
      "batch 13954, train_loss 61.489006,Time used 0.009000s\n",
      "batch 13955, train_loss 59.253586,Time used 0.009000s\n",
      "batch 13956, train_loss 46.888718,Time used 0.008999s\n",
      "batch 13957, train_loss 44.542606,Time used 0.007001s\n",
      "batch 13958, train_loss 57.463871,Time used 0.007001s\n",
      "batch 13959, train_loss 59.564991,Time used 0.007999s\n",
      "batch 13960, train_loss 48.640705,Time used 0.006999s\n",
      "batch 13961, train_loss 53.824574,Time used 0.007999s\n",
      "batch 13962, train_loss 44.709576,Time used 0.008001s\n",
      "batch 13963, train_loss 47.480721,Time used 0.008000s\n",
      "batch 13964, train_loss 53.941383,Time used 0.010999s\n",
      "batch 13965, train_loss 63.064148,Time used 0.008000s\n",
      "batch 13966, train_loss 65.096077,Time used 0.011002s\n",
      "batch 13967, train_loss 45.234394,Time used 0.008999s\n",
      "batch 13968, train_loss 69.596657,Time used 0.011000s\n",
      "batch 13969, train_loss 54.081326,Time used 0.010999s\n",
      "batch 13970, train_loss 56.035927,Time used 0.012000s\n",
      "batch 13971, train_loss 65.641548,Time used 0.010001s\n",
      "batch 13972, train_loss 48.664974,Time used 0.007999s\n",
      "batch 13973, train_loss 50.544514,Time used 0.008000s\n",
      "batch 13974, train_loss 49.512566,Time used 0.009999s\n",
      "batch 13975, train_loss 54.600048,Time used 0.007000s\n",
      "batch 13976, train_loss 44.957520,Time used 0.007000s\n",
      "batch 13977, train_loss 57.427227,Time used 0.006997s\n",
      "batch 13978, train_loss 59.684078,Time used 0.012000s\n",
      "batch 13979, train_loss 61.368484,Time used 0.007001s\n",
      "batch 13980, train_loss 62.983517,Time used 0.008000s\n",
      "batch 13981, train_loss 53.989532,Time used 0.008000s\n",
      "batch 13982, train_loss 47.533810,Time used 0.010999s\n",
      "batch 13983, train_loss 46.869621,Time used 0.008000s\n",
      "batch 13984, train_loss 47.148808,Time used 0.012001s\n",
      "batch 13985, train_loss 48.902946,Time used 0.011001s\n",
      "batch 13986, train_loss 67.244598,Time used 0.011998s\n",
      "batch 13987, train_loss 46.862373,Time used 0.012002s\n",
      "batch 13988, train_loss 43.438545,Time used 0.010999s\n",
      "batch 13989, train_loss 44.938194,Time used 0.012000s\n",
      "batch 13990, train_loss 66.678246,Time used 0.010001s\n",
      "batch 13991, train_loss 63.001320,Time used 0.011999s\n",
      "batch 13992, train_loss 57.986809,Time used 0.010000s\n",
      "batch 13993, train_loss 68.494949,Time used 0.011997s\n",
      "batch 13994, train_loss 56.763138,Time used 0.012002s\n",
      "batch 13995, train_loss 51.787453,Time used 0.012006s\n",
      "batch 13996, train_loss 50.784065,Time used 0.011998s\n",
      "batch 13997, train_loss 46.819416,Time used 0.011002s\n",
      "batch 13998, train_loss 49.162041,Time used 0.011999s\n",
      "batch 13999, train_loss 57.876347,Time used 0.012001s\n",
      "batch 14000, train_loss 53.226437,Time used 0.011999s\n",
      "***************************test_batch 14000, test_rmse_loss 8.463920,test_mae_loss 3.464379,test_mape_loss 55.588525,Time used 0.059001s\n",
      "batch 14001, train_loss 48.226101,Time used 0.016000s\n",
      "batch 14002, train_loss 64.954880,Time used 0.023001s\n",
      "batch 14003, train_loss 55.484550,Time used 0.011001s\n",
      "batch 14004, train_loss 63.507637,Time used 0.013999s\n",
      "batch 14005, train_loss 51.198147,Time used 0.017000s\n",
      "batch 14006, train_loss 54.523994,Time used 0.012999s\n",
      "batch 14007, train_loss 48.078865,Time used 0.012000s\n",
      "batch 14008, train_loss 42.824558,Time used 0.011002s\n",
      "batch 14009, train_loss 62.782906,Time used 0.012997s\n",
      "batch 14010, train_loss 58.800247,Time used 0.012001s\n",
      "batch 14011, train_loss 56.336529,Time used 0.012001s\n",
      "batch 14012, train_loss 66.517693,Time used 0.014000s\n",
      "batch 14013, train_loss 52.603226,Time used 0.013002s\n",
      "batch 14014, train_loss 36.948578,Time used 0.012001s\n",
      "batch 14015, train_loss 53.834625,Time used 0.013001s\n",
      "batch 14016, train_loss 45.959393,Time used 0.012000s\n",
      "batch 14017, train_loss 55.331375,Time used 0.012998s\n",
      "batch 14018, train_loss 60.577003,Time used 0.012000s\n",
      "batch 14019, train_loss 43.897518,Time used 0.009001s\n",
      "batch 14020, train_loss 64.805458,Time used 0.011000s\n",
      "batch 14021, train_loss 66.858582,Time used 0.012000s\n",
      "batch 14022, train_loss 47.585453,Time used 0.009000s\n",
      "batch 14023, train_loss 38.544861,Time used 0.007000s\n",
      "batch 14024, train_loss 61.475010,Time used 0.009998s\n",
      "batch 14025, train_loss 44.944290,Time used 0.008004s\n",
      "batch 14026, train_loss 71.165146,Time used 0.006999s\n",
      "batch 14027, train_loss 61.010086,Time used 0.008003s\n",
      "batch 14028, train_loss 50.180984,Time used 0.006998s\n",
      "batch 14029, train_loss 44.810287,Time used 0.009001s\n",
      "batch 14030, train_loss 51.193691,Time used 0.010999s\n",
      "batch 14031, train_loss 56.047520,Time used 0.009995s\n",
      "batch 14032, train_loss 54.016720,Time used 0.008000s\n",
      "batch 14033, train_loss 49.393383,Time used 0.011002s\n",
      "batch 14034, train_loss 43.768776,Time used 0.010999s\n",
      "batch 14035, train_loss 53.645325,Time used 0.008002s\n",
      "batch 14036, train_loss 50.576004,Time used 0.011997s\n",
      "batch 14037, train_loss 58.324783,Time used 0.009001s\n",
      "batch 14038, train_loss 53.902012,Time used 0.008999s\n",
      "batch 14039, train_loss 52.402641,Time used 0.008001s\n",
      "batch 14040, train_loss 61.605141,Time used 0.008000s\n",
      "batch 14041, train_loss 45.113068,Time used 0.006999s\n",
      "batch 14042, train_loss 54.153702,Time used 0.010998s\n",
      "batch 14043, train_loss 54.796936,Time used 0.006997s\n",
      "batch 14044, train_loss 48.956215,Time used 0.010002s\n",
      "batch 14045, train_loss 56.463131,Time used 0.011999s\n",
      "batch 14046, train_loss 61.795269,Time used 0.012002s\n",
      "batch 14047, train_loss 57.916737,Time used 0.010000s\n",
      "batch 14048, train_loss 51.308887,Time used 0.010993s\n",
      "batch 14049, train_loss 53.218254,Time used 0.012002s\n",
      "batch 14050, train_loss 49.127663,Time used 0.012000s\n",
      "batch 14051, train_loss 54.556778,Time used 0.011002s\n",
      "batch 14052, train_loss 47.968418,Time used 0.011999s\n",
      "batch 14053, train_loss 63.967335,Time used 0.009998s\n",
      "batch 14054, train_loss 57.892021,Time used 0.012002s\n",
      "batch 14055, train_loss 54.987297,Time used 0.012000s\n",
      "batch 14056, train_loss 57.097359,Time used 0.012000s\n",
      "batch 14057, train_loss 52.169834,Time used 0.011999s\n",
      "batch 14058, train_loss 57.365070,Time used 0.013002s\n",
      "batch 14059, train_loss 52.800804,Time used 0.012004s\n",
      "batch 14060, train_loss 52.765423,Time used 0.010995s\n",
      "batch 14061, train_loss 60.232105,Time used 0.011000s\n",
      "batch 14062, train_loss 47.064888,Time used 0.011000s\n",
      "batch 14063, train_loss 47.012211,Time used 0.013000s\n",
      "batch 14064, train_loss 54.902954,Time used 0.012002s\n",
      "batch 14065, train_loss 60.482792,Time used 0.015001s\n",
      "batch 14066, train_loss 43.183216,Time used 0.024002s\n",
      "batch 14067, train_loss 56.279400,Time used 0.011998s\n",
      "batch 14068, train_loss 52.709217,Time used 0.012997s\n",
      "batch 14069, train_loss 56.556473,Time used 0.012000s\n",
      "batch 14070, train_loss 60.632862,Time used 0.012001s\n",
      "batch 14071, train_loss 56.721760,Time used 0.010000s\n",
      "batch 14072, train_loss 49.192051,Time used 0.013000s\n",
      "batch 14073, train_loss 64.987534,Time used 0.011000s\n",
      "batch 14074, train_loss 62.582268,Time used 0.010000s\n",
      "batch 14075, train_loss 50.866982,Time used 0.012005s\n",
      "batch 14076, train_loss 54.040516,Time used 0.015998s\n",
      "batch 14077, train_loss 53.295021,Time used 0.011999s\n",
      "batch 14078, train_loss 62.877701,Time used 0.012000s\n",
      "batch 14079, train_loss 57.346470,Time used 0.011999s\n",
      "batch 14080, train_loss 49.560398,Time used 0.020999s\n",
      "batch 14081, train_loss 44.332397,Time used 0.007998s\n",
      "batch 14082, train_loss 51.863861,Time used 0.009002s\n",
      "batch 14083, train_loss 55.893440,Time used 0.007999s\n",
      "batch 14084, train_loss 41.407448,Time used 0.009000s\n",
      "batch 14085, train_loss 42.812832,Time used 0.010999s\n",
      "batch 14086, train_loss 47.157806,Time used 0.011000s\n",
      "batch 14087, train_loss 56.671417,Time used 0.011999s\n",
      "batch 14088, train_loss 60.395493,Time used 0.011003s\n",
      "batch 14089, train_loss 44.212261,Time used 0.009999s\n",
      "batch 14090, train_loss 52.838562,Time used 0.008000s\n",
      "batch 14091, train_loss 47.816967,Time used 0.009998s\n",
      "batch 14092, train_loss 70.730240,Time used 0.008003s\n",
      "batch 14093, train_loss 58.018669,Time used 0.007998s\n",
      "batch 14094, train_loss 43.088943,Time used 0.008001s\n",
      "batch 14095, train_loss 56.392017,Time used 0.007000s\n",
      "batch 14096, train_loss 50.953888,Time used 0.008000s\n",
      "batch 14097, train_loss 59.312031,Time used 0.011999s\n",
      "batch 14098, train_loss 61.068901,Time used 0.010000s\n",
      "batch 14099, train_loss 56.926315,Time used 0.007998s\n",
      "batch 14100, train_loss 54.788731,Time used 0.010002s\n",
      "***************************test_batch 14100, test_rmse_loss 8.436946,test_mae_loss 3.459364,test_mape_loss 55.656096,Time used 0.048001s\n",
      "batch 14101, train_loss 63.269806,Time used 0.008999s\n",
      "batch 14102, train_loss 48.145260,Time used 0.006999s\n",
      "batch 14103, train_loss 64.815720,Time used 0.012000s\n",
      "batch 14104, train_loss 47.340305,Time used 0.011000s\n",
      "batch 14105, train_loss 50.573353,Time used 0.008999s\n",
      "batch 14106, train_loss 43.768871,Time used 0.008002s\n",
      "batch 14107, train_loss 62.134029,Time used 0.009000s\n",
      "batch 14108, train_loss 50.820393,Time used 0.008001s\n",
      "batch 14109, train_loss 47.902569,Time used 0.010000s\n",
      "batch 14110, train_loss 60.760288,Time used 0.009999s\n",
      "batch 14111, train_loss 54.528706,Time used 0.010000s\n",
      "batch 14112, train_loss 38.887035,Time used 0.010001s\n",
      "batch 14113, train_loss 62.995644,Time used 0.010000s\n",
      "batch 14114, train_loss 58.836761,Time used 0.012001s\n",
      "batch 14115, train_loss 45.515121,Time used 0.010000s\n",
      "batch 14116, train_loss 45.363457,Time used 0.009001s\n",
      "batch 14117, train_loss 59.325016,Time used 0.010000s\n",
      "batch 14118, train_loss 47.353790,Time used 0.008002s\n",
      "batch 14119, train_loss 56.581631,Time used 0.008999s\n",
      "batch 14120, train_loss 58.829971,Time used 0.010997s\n",
      "batch 14121, train_loss 46.931858,Time used 0.007001s\n",
      "batch 14122, train_loss 61.781506,Time used 0.009001s\n",
      "batch 14123, train_loss 45.623554,Time used 0.007998s\n",
      "batch 14124, train_loss 56.051903,Time used 0.008001s\n",
      "batch 14125, train_loss 68.810982,Time used 0.008000s\n",
      "batch 14126, train_loss 54.049450,Time used 0.008001s\n",
      "batch 14127, train_loss 53.131916,Time used 0.008000s\n",
      "batch 14128, train_loss 45.900780,Time used 0.009000s\n",
      "batch 14129, train_loss 60.730972,Time used 0.007998s\n",
      "batch 14130, train_loss 53.429379,Time used 0.009003s\n",
      "batch 14131, train_loss 51.910671,Time used 0.010999s\n",
      "batch 14132, train_loss 56.121410,Time used 0.006999s\n",
      "batch 14133, train_loss 56.986603,Time used 0.009000s\n",
      "batch 14134, train_loss 51.706448,Time used 0.010004s\n",
      "batch 14135, train_loss 42.396320,Time used 0.009996s\n",
      "batch 14136, train_loss 47.095238,Time used 0.012004s\n",
      "batch 14137, train_loss 52.988022,Time used 0.012006s\n",
      "batch 14138, train_loss 43.882401,Time used 0.008997s\n",
      "batch 14139, train_loss 54.928139,Time used 0.009998s\n",
      "batch 14140, train_loss 46.735523,Time used 0.006999s\n",
      "batch 14141, train_loss 60.164047,Time used 0.008001s\n",
      "batch 14142, train_loss 61.419727,Time used 0.008000s\n",
      "batch 14143, train_loss 59.365646,Time used 0.007002s\n",
      "batch 14144, train_loss 51.865627,Time used 0.009032s\n",
      "batch 14145, train_loss 55.940235,Time used 0.008005s\n",
      "batch 14146, train_loss 46.011459,Time used 0.007961s\n",
      "batch 14147, train_loss 58.649067,Time used 0.013005s\n",
      "batch 14148, train_loss 45.504154,Time used 0.010998s\n",
      "batch 14149, train_loss 58.652405,Time used 0.010997s\n",
      "batch 14150, train_loss 56.750584,Time used 0.008004s\n",
      "batch 14151, train_loss 59.304676,Time used 0.007031s\n",
      "batch 14152, train_loss 57.406784,Time used 0.006966s\n",
      "batch 14153, train_loss 47.210720,Time used 0.007997s\n",
      "batch 14154, train_loss 63.986412,Time used 0.009001s\n",
      "batch 14155, train_loss 52.566200,Time used 0.008000s\n",
      "batch 14156, train_loss 49.596718,Time used 0.009999s\n",
      "batch 14157, train_loss 56.856968,Time used 0.008999s\n",
      "batch 14158, train_loss 47.285595,Time used 0.010036s\n",
      "batch 14159, train_loss 44.467579,Time used 0.011965s\n",
      "batch 14160, train_loss 53.929775,Time used 0.011000s\n",
      "batch 14161, train_loss 50.989567,Time used 0.011001s\n",
      "batch 14162, train_loss 58.603561,Time used 0.011998s\n",
      "batch 14163, train_loss 58.221500,Time used 0.009000s\n",
      "batch 14164, train_loss 56.437405,Time used 0.006999s\n",
      "batch 14165, train_loss 52.836197,Time used 0.008004s\n",
      "batch 14166, train_loss 49.465500,Time used 0.007999s\n",
      "batch 14167, train_loss 43.879398,Time used 0.008998s\n",
      "batch 14168, train_loss 60.976055,Time used 0.010000s\n",
      "batch 14169, train_loss 47.603344,Time used 0.010000s\n",
      "batch 14170, train_loss 47.976185,Time used 0.007000s\n",
      "batch 14171, train_loss 45.834503,Time used 0.010001s\n",
      "batch 14172, train_loss 54.032509,Time used 0.012002s\n",
      "batch 14173, train_loss 68.160492,Time used 0.010996s\n",
      "batch 14174, train_loss 58.805485,Time used 0.010996s\n",
      "batch 14175, train_loss 57.887184,Time used 0.009002s\n",
      "batch 14176, train_loss 57.808365,Time used 0.014003s\n",
      "batch 14177, train_loss 58.842915,Time used 0.010002s\n",
      "batch 14178, train_loss 52.791283,Time used 0.007997s\n",
      "batch 14179, train_loss 50.818573,Time used 0.008003s\n",
      "batch 14180, train_loss 53.358711,Time used 0.007998s\n",
      "batch 14181, train_loss 54.733418,Time used 0.007005s\n",
      "batch 14182, train_loss 48.340366,Time used 0.007996s\n",
      "batch 14183, train_loss 57.311020,Time used 0.009001s\n",
      "batch 14184, train_loss 36.938988,Time used 0.007999s\n",
      "batch 14185, train_loss 48.662312,Time used 0.008000s\n",
      "batch 14186, train_loss 53.409355,Time used 0.008001s\n",
      "batch 14187, train_loss 50.596615,Time used 0.007999s\n",
      "batch 14188, train_loss 45.805756,Time used 0.008000s\n",
      "batch 14189, train_loss 50.521160,Time used 0.008000s\n",
      "batch 14190, train_loss 48.666790,Time used 0.008000s\n",
      "batch 14191, train_loss 50.000221,Time used 0.008001s\n",
      "batch 14192, train_loss 44.004723,Time used 0.009000s\n",
      "batch 14193, train_loss 46.120888,Time used 0.007999s\n",
      "batch 14194, train_loss 50.177200,Time used 0.008000s\n",
      "batch 14195, train_loss 53.008923,Time used 0.008002s\n",
      "batch 14196, train_loss 56.190544,Time used 0.007999s\n",
      "batch 14197, train_loss 62.748760,Time used 0.007000s\n",
      "batch 14198, train_loss 52.815495,Time used 0.008000s\n",
      "batch 14199, train_loss 49.582802,Time used 0.009999s\n",
      "batch 14200, train_loss 62.439445,Time used 0.011001s\n",
      "***************************test_batch 14200, test_rmse_loss 8.418421,test_mae_loss 3.449339,test_mape_loss 55.341409,Time used 0.035999s\n",
      "batch 14201, train_loss 52.490887,Time used 0.008000s\n",
      "batch 14202, train_loss 67.917191,Time used 0.008003s\n",
      "batch 14203, train_loss 45.974972,Time used 0.007999s\n",
      "batch 14204, train_loss 60.034462,Time used 0.006999s\n",
      "batch 14205, train_loss 59.635971,Time used 0.011000s\n",
      "batch 14206, train_loss 57.759388,Time used 0.011002s\n",
      "batch 14207, train_loss 49.877632,Time used 0.009998s\n",
      "batch 14208, train_loss 63.201458,Time used 0.011000s\n",
      "batch 14209, train_loss 46.856041,Time used 0.011997s\n",
      "batch 14210, train_loss 56.193359,Time used 0.012999s\n",
      "batch 14211, train_loss 59.670601,Time used 0.008005s\n",
      "batch 14212, train_loss 55.556652,Time used 0.009000s\n",
      "batch 14213, train_loss 66.579758,Time used 0.017002s\n",
      "batch 14214, train_loss 50.595257,Time used 0.014997s\n",
      "batch 14215, train_loss 39.760426,Time used 0.011002s\n",
      "batch 14216, train_loss 49.752552,Time used 0.008003s\n",
      "batch 14217, train_loss 50.689407,Time used 0.010000s\n",
      "batch 14218, train_loss 58.879684,Time used 0.009999s\n",
      "batch 14219, train_loss 44.968880,Time used 0.009001s\n",
      "batch 14220, train_loss 49.219662,Time used 0.009002s\n",
      "batch 14221, train_loss 70.656334,Time used 0.008997s\n",
      "batch 14222, train_loss 44.707062,Time used 0.008000s\n",
      "batch 14223, train_loss 53.867676,Time used 0.008001s\n",
      "batch 14224, train_loss 44.134380,Time used 0.010998s\n",
      "batch 14225, train_loss 45.332195,Time used 0.011002s\n",
      "batch 14226, train_loss 46.646702,Time used 0.007999s\n",
      "batch 14227, train_loss 62.418972,Time used 0.011002s\n",
      "batch 14228, train_loss 55.636879,Time used 0.010000s\n",
      "batch 14229, train_loss 50.988674,Time used 0.008000s\n",
      "batch 14230, train_loss 66.047623,Time used 0.008999s\n",
      "batch 14231, train_loss 46.324680,Time used 0.008001s\n",
      "batch 14232, train_loss 64.062164,Time used 0.009999s\n",
      "batch 14233, train_loss 51.432484,Time used 0.010994s\n",
      "batch 14234, train_loss 57.954853,Time used 0.011002s\n",
      "batch 14235, train_loss 48.854206,Time used 0.006999s\n",
      "batch 14236, train_loss 44.433754,Time used 0.008000s\n",
      "batch 14237, train_loss 57.333733,Time used 0.008001s\n",
      "batch 14238, train_loss 56.899498,Time used 0.009998s\n",
      "batch 14239, train_loss 50.237495,Time used 0.011001s\n",
      "batch 14240, train_loss 47.052952,Time used 0.008000s\n",
      "batch 14241, train_loss 54.543941,Time used 0.008004s\n",
      "batch 14242, train_loss 50.624966,Time used 0.008998s\n",
      "batch 14243, train_loss 41.852310,Time used 0.010997s\n",
      "batch 14244, train_loss 64.597382,Time used 0.010001s\n",
      "batch 14245, train_loss 64.244324,Time used 0.010001s\n",
      "batch 14246, train_loss 39.727776,Time used 0.010000s\n",
      "batch 14247, train_loss 45.063065,Time used 0.009997s\n",
      "batch 14248, train_loss 52.874660,Time used 0.008002s\n",
      "batch 14249, train_loss 48.853596,Time used 0.007999s\n",
      "batch 14250, train_loss 48.195457,Time used 0.012001s\n",
      "batch 14251, train_loss 56.436474,Time used 0.008002s\n",
      "batch 14252, train_loss 62.636101,Time used 0.008999s\n",
      "batch 14253, train_loss 58.279816,Time used 0.006999s\n",
      "batch 14254, train_loss 58.298416,Time used 0.008002s\n",
      "batch 14255, train_loss 66.362648,Time used 0.011998s\n",
      "batch 14256, train_loss 50.522911,Time used 0.009998s\n",
      "batch 14257, train_loss 51.404881,Time used 0.008999s\n",
      "batch 14258, train_loss 49.274315,Time used 0.010002s\n",
      "batch 14259, train_loss 55.630577,Time used 0.010999s\n",
      "batch 14260, train_loss 53.948597,Time used 0.009000s\n",
      "batch 14261, train_loss 59.276489,Time used 0.007001s\n",
      "batch 14262, train_loss 62.533131,Time used 0.007002s\n",
      "batch 14263, train_loss 46.554203,Time used 0.007999s\n",
      "batch 14264, train_loss 56.979683,Time used 0.008003s\n",
      "batch 14265, train_loss 55.298004,Time used 0.010998s\n",
      "batch 14266, train_loss 55.506100,Time used 0.009998s\n",
      "batch 14267, train_loss 65.752647,Time used 0.011000s\n",
      "batch 14268, train_loss 50.490395,Time used 0.012001s\n",
      "batch 14269, train_loss 50.619934,Time used 0.011000s\n",
      "batch 14270, train_loss 45.656734,Time used 0.010998s\n",
      "batch 14271, train_loss 46.238369,Time used 0.010002s\n",
      "batch 14272, train_loss 40.691319,Time used 0.008002s\n",
      "batch 14273, train_loss 39.073154,Time used 0.010001s\n",
      "batch 14274, train_loss 54.754787,Time used 0.011001s\n",
      "batch 14275, train_loss 49.720036,Time used 0.012000s\n",
      "batch 14276, train_loss 60.142891,Time used 0.012999s\n",
      "batch 14277, train_loss 56.241291,Time used 0.014001s\n",
      "batch 14278, train_loss 55.758991,Time used 0.013997s\n",
      "batch 14279, train_loss 58.509193,Time used 0.018002s\n",
      "batch 14280, train_loss 55.354912,Time used 0.013000s\n",
      "batch 14281, train_loss 50.419003,Time used 0.013999s\n",
      "batch 14282, train_loss 41.833286,Time used 0.010998s\n",
      "batch 14283, train_loss 53.862076,Time used 0.008000s\n",
      "batch 14284, train_loss 52.277954,Time used 0.008999s\n",
      "batch 14285, train_loss 62.376411,Time used 0.012004s\n",
      "batch 14286, train_loss 57.613781,Time used 0.009998s\n",
      "batch 14287, train_loss 46.410629,Time used 0.009999s\n",
      "batch 14288, train_loss 58.369740,Time used 0.010000s\n",
      "batch 14289, train_loss 45.279007,Time used 0.010999s\n",
      "batch 14290, train_loss 50.188896,Time used 0.010000s\n",
      "batch 14291, train_loss 61.239540,Time used 0.009005s\n",
      "batch 14292, train_loss 53.639603,Time used 0.008996s\n",
      "batch 14293, train_loss 36.580185,Time used 0.008999s\n",
      "batch 14294, train_loss 66.170845,Time used 0.008001s\n",
      "batch 14295, train_loss 44.314819,Time used 0.008002s\n",
      "batch 14296, train_loss 54.976971,Time used 0.008999s\n",
      "batch 14297, train_loss 46.447803,Time used 0.010006s\n",
      "batch 14298, train_loss 42.281555,Time used 0.009996s\n",
      "batch 14299, train_loss 55.460949,Time used 0.009998s\n",
      "batch 14300, train_loss 51.472675,Time used 0.009001s\n",
      "***************************test_batch 14300, test_rmse_loss 8.392415,test_mae_loss 3.439074,test_mape_loss 55.052012,Time used 0.048998s\n",
      "batch 14301, train_loss 57.317871,Time used 0.011999s\n",
      "batch 14302, train_loss 70.862816,Time used 0.012005s\n",
      "batch 14303, train_loss 56.865166,Time used 0.011996s\n",
      "batch 14304, train_loss 57.002190,Time used 0.009998s\n",
      "batch 14305, train_loss 49.438606,Time used 0.008002s\n",
      "batch 14306, train_loss 54.785202,Time used 0.006998s\n",
      "batch 14307, train_loss 61.954182,Time used 0.009001s\n",
      "batch 14308, train_loss 56.485317,Time used 0.010999s\n",
      "batch 14309, train_loss 57.347576,Time used 0.011004s\n",
      "batch 14310, train_loss 63.092903,Time used 0.007998s\n",
      "batch 14311, train_loss 45.546917,Time used 0.007999s\n",
      "batch 14312, train_loss 46.149727,Time used 0.007000s\n",
      "batch 14313, train_loss 50.701885,Time used 0.008000s\n",
      "batch 14314, train_loss 48.384617,Time used 0.009999s\n",
      "batch 14315, train_loss 57.349667,Time used 0.007000s\n",
      "batch 14316, train_loss 55.104256,Time used 0.008002s\n",
      "batch 14317, train_loss 56.610588,Time used 0.009996s\n",
      "batch 14318, train_loss 53.525276,Time used 0.008001s\n",
      "batch 14319, train_loss 56.818130,Time used 0.007999s\n",
      "batch 14320, train_loss 49.059475,Time used 0.008002s\n",
      "batch 14321, train_loss 42.409130,Time used 0.007998s\n",
      "batch 14322, train_loss 54.620449,Time used 0.008001s\n",
      "batch 14323, train_loss 46.923294,Time used 0.009001s\n",
      "batch 14324, train_loss 47.995415,Time used 0.008001s\n",
      "batch 14325, train_loss 50.585762,Time used 0.007999s\n",
      "batch 14326, train_loss 54.682892,Time used 0.008001s\n",
      "batch 14327, train_loss 56.299744,Time used 0.006999s\n",
      "batch 14328, train_loss 55.513035,Time used 0.007999s\n",
      "batch 14329, train_loss 48.959328,Time used 0.007999s\n",
      "batch 14330, train_loss 50.131512,Time used 0.006998s\n",
      "batch 14331, train_loss 63.093536,Time used 0.010000s\n",
      "batch 14332, train_loss 54.081493,Time used 0.010000s\n",
      "batch 14333, train_loss 45.769798,Time used 0.008002s\n",
      "batch 14334, train_loss 58.463856,Time used 0.009999s\n",
      "batch 14335, train_loss 46.688541,Time used 0.011001s\n",
      "batch 14336, train_loss 46.504803,Time used 0.008999s\n",
      "batch 14337, train_loss 60.772369,Time used 0.010001s\n",
      "batch 14338, train_loss 58.478466,Time used 0.007998s\n",
      "batch 14339, train_loss 50.168640,Time used 0.009002s\n",
      "batch 14340, train_loss 46.045315,Time used 0.007999s\n",
      "batch 14341, train_loss 51.732174,Time used 0.010001s\n",
      "batch 14342, train_loss 46.642162,Time used 0.011999s\n",
      "batch 14343, train_loss 61.212349,Time used 0.011999s\n",
      "batch 14344, train_loss 44.437378,Time used 0.011001s\n",
      "batch 14345, train_loss 58.522781,Time used 0.008002s\n",
      "batch 14346, train_loss 54.626049,Time used 0.007999s\n",
      "batch 14347, train_loss 52.868927,Time used 0.008000s\n",
      "batch 14348, train_loss 47.486958,Time used 0.008002s\n",
      "batch 14349, train_loss 54.480858,Time used 0.009000s\n",
      "batch 14350, train_loss 60.448521,Time used 0.010000s\n",
      "batch 14351, train_loss 48.791023,Time used 0.011998s\n",
      "batch 14352, train_loss 58.929295,Time used 0.008001s\n",
      "batch 14353, train_loss 50.965202,Time used 0.009000s\n",
      "batch 14354, train_loss 58.990822,Time used 0.012001s\n",
      "batch 14355, train_loss 53.013172,Time used 0.010998s\n",
      "batch 14356, train_loss 49.890686,Time used 0.012000s\n",
      "batch 14357, train_loss 58.245380,Time used 0.012002s\n",
      "batch 14358, train_loss 56.110588,Time used 0.010001s\n",
      "batch 14359, train_loss 43.443295,Time used 0.008998s\n",
      "batch 14360, train_loss 59.546890,Time used 0.008999s\n",
      "batch 14361, train_loss 44.902534,Time used 0.009001s\n",
      "batch 14362, train_loss 46.016392,Time used 0.011998s\n",
      "batch 14363, train_loss 52.654888,Time used 0.008003s\n",
      "batch 14364, train_loss 50.527710,Time used 0.007998s\n",
      "batch 14365, train_loss 59.711266,Time used 0.010003s\n",
      "batch 14366, train_loss 50.012775,Time used 0.012999s\n",
      "batch 14367, train_loss 49.941856,Time used 0.010000s\n",
      "batch 14368, train_loss 47.631596,Time used 0.011000s\n",
      "batch 14369, train_loss 46.858223,Time used 0.010001s\n",
      "batch 14370, train_loss 62.875690,Time used 0.011003s\n",
      "batch 14371, train_loss 53.498844,Time used 0.011000s\n",
      "batch 14372, train_loss 54.470932,Time used 0.007999s\n",
      "batch 14373, train_loss 53.079872,Time used 0.008000s\n",
      "batch 14374, train_loss 57.029114,Time used 0.007000s\n",
      "batch 14375, train_loss 57.095943,Time used 0.011001s\n",
      "batch 14376, train_loss 50.398544,Time used 0.007998s\n",
      "batch 14377, train_loss 51.880024,Time used 0.008999s\n",
      "batch 14378, train_loss 48.243019,Time used 0.007999s\n",
      "batch 14379, train_loss 44.705002,Time used 0.009001s\n",
      "batch 14380, train_loss 57.571182,Time used 0.010997s\n",
      "batch 14381, train_loss 55.560474,Time used 0.009000s\n",
      "batch 14382, train_loss 49.027454,Time used 0.008001s\n",
      "batch 14383, train_loss 68.461357,Time used 0.007999s\n",
      "batch 14384, train_loss 58.089348,Time used 0.009001s\n",
      "batch 14385, train_loss 49.199413,Time used 0.011999s\n",
      "batch 14386, train_loss 54.254841,Time used 0.010998s\n",
      "batch 14387, train_loss 44.495140,Time used 0.009002s\n",
      "batch 14388, train_loss 51.751457,Time used 0.007998s\n",
      "batch 14389, train_loss 49.329987,Time used 0.010999s\n",
      "batch 14390, train_loss 53.736771,Time used 0.009002s\n",
      "batch 14391, train_loss 53.260189,Time used 0.009001s\n",
      "batch 14392, train_loss 51.598301,Time used 0.008998s\n",
      "batch 14393, train_loss 52.784393,Time used 0.010004s\n",
      "batch 14394, train_loss 40.584274,Time used 0.010998s\n",
      "batch 14395, train_loss 59.127308,Time used 0.010998s\n",
      "batch 14396, train_loss 52.684444,Time used 0.009007s\n",
      "batch 14397, train_loss 44.099373,Time used 0.010000s\n",
      "batch 14398, train_loss 61.544403,Time used 0.011003s\n",
      "batch 14399, train_loss 43.072624,Time used 0.007998s\n",
      "batch 14400, train_loss 70.326248,Time used 0.010001s\n",
      "***************************test_batch 14400, test_rmse_loss 8.361159,test_mae_loss 3.433963,test_mape_loss 55.335223,Time used 0.044001s\n",
      "batch 14401, train_loss 59.000404,Time used 0.012000s\n",
      "batch 14402, train_loss 57.156570,Time used 0.009002s\n",
      "batch 14403, train_loss 44.383888,Time used 0.012002s\n",
      "batch 14404, train_loss 44.190975,Time used 0.009998s\n",
      "batch 14405, train_loss 52.397354,Time used 0.010999s\n",
      "batch 14406, train_loss 56.265461,Time used 0.010003s\n",
      "batch 14407, train_loss 42.899837,Time used 0.009000s\n",
      "batch 14408, train_loss 52.128025,Time used 0.008001s\n",
      "batch 14409, train_loss 57.450050,Time used 0.008000s\n",
      "batch 14410, train_loss 56.843327,Time used 0.006998s\n",
      "batch 14411, train_loss 50.830109,Time used 0.008001s\n",
      "batch 14412, train_loss 49.114468,Time used 0.008001s\n",
      "batch 14413, train_loss 49.238388,Time used 0.011000s\n",
      "batch 14414, train_loss 65.833397,Time used 0.007999s\n",
      "batch 14415, train_loss 62.348549,Time used 0.008000s\n",
      "batch 14416, train_loss 62.969334,Time used 0.008999s\n",
      "batch 14417, train_loss 44.843056,Time used 0.012001s\n",
      "batch 14418, train_loss 49.389141,Time used 0.011000s\n",
      "batch 14419, train_loss 39.134399,Time used 0.007000s\n",
      "batch 14420, train_loss 40.992531,Time used 0.008002s\n",
      "batch 14421, train_loss 53.744675,Time used 0.008001s\n",
      "batch 14422, train_loss 55.602833,Time used 0.010997s\n",
      "batch 14423, train_loss 59.739033,Time used 0.008000s\n",
      "batch 14424, train_loss 56.600502,Time used 0.009001s\n",
      "batch 14425, train_loss 52.458694,Time used 0.010000s\n",
      "batch 14426, train_loss 37.663048,Time used 0.007999s\n",
      "batch 14427, train_loss 52.920101,Time used 0.012004s\n",
      "batch 14428, train_loss 64.272049,Time used 0.008000s\n",
      "batch 14429, train_loss 53.191040,Time used 0.013000s\n",
      "batch 14430, train_loss 42.743111,Time used 0.011000s\n",
      "batch 14431, train_loss 65.544975,Time used 0.009001s\n",
      "batch 14432, train_loss 62.943756,Time used 0.008002s\n",
      "batch 14433, train_loss 59.756470,Time used 0.010000s\n",
      "batch 14434, train_loss 49.365353,Time used 0.006999s\n",
      "batch 14435, train_loss 64.878494,Time used 0.007999s\n",
      "batch 14436, train_loss 38.687046,Time used 0.008002s\n",
      "batch 14437, train_loss 50.509785,Time used 0.007997s\n",
      "batch 14438, train_loss 46.407108,Time used 0.011002s\n",
      "batch 14439, train_loss 49.327946,Time used 0.008998s\n",
      "batch 14440, train_loss 56.132889,Time used 0.009001s\n",
      "batch 14441, train_loss 45.569778,Time used 0.011003s\n",
      "batch 14442, train_loss 61.567280,Time used 0.012001s\n",
      "batch 14443, train_loss 47.093567,Time used 0.032003s\n",
      "batch 14444, train_loss 58.125252,Time used 0.024997s\n",
      "batch 14445, train_loss 56.363487,Time used 0.015001s\n",
      "batch 14446, train_loss 48.708687,Time used 0.012999s\n",
      "batch 14447, train_loss 51.576538,Time used 0.012007s\n",
      "batch 14448, train_loss 44.659538,Time used 0.011992s\n",
      "batch 14449, train_loss 59.443077,Time used 0.013999s\n",
      "batch 14450, train_loss 65.651131,Time used 0.014003s\n",
      "batch 14451, train_loss 45.773788,Time used 0.013005s\n",
      "batch 14452, train_loss 38.146919,Time used 0.014004s\n",
      "batch 14453, train_loss 66.861862,Time used 0.014991s\n",
      "batch 14454, train_loss 52.367798,Time used 0.009000s\n",
      "batch 14455, train_loss 52.826702,Time used 0.010000s\n",
      "batch 14456, train_loss 44.602959,Time used 0.008002s\n",
      "batch 14457, train_loss 53.721119,Time used 0.011997s\n",
      "batch 14458, train_loss 56.619366,Time used 0.010000s\n",
      "batch 14459, train_loss 54.606850,Time used 0.012000s\n",
      "batch 14460, train_loss 43.533268,Time used 0.010000s\n",
      "batch 14461, train_loss 65.972542,Time used 0.010001s\n",
      "batch 14462, train_loss 43.609131,Time used 0.008003s\n",
      "batch 14463, train_loss 51.545570,Time used 0.010997s\n",
      "batch 14464, train_loss 46.234627,Time used 0.009005s\n",
      "batch 14465, train_loss 41.846069,Time used 0.007999s\n",
      "batch 14466, train_loss 59.066429,Time used 0.013999s\n",
      "batch 14467, train_loss 56.508835,Time used 0.014000s\n",
      "batch 14468, train_loss 42.331600,Time used 0.012001s\n",
      "batch 14469, train_loss 48.451317,Time used 0.011997s\n",
      "batch 14470, train_loss 60.542522,Time used 0.011003s\n",
      "batch 14471, train_loss 48.781345,Time used 0.012998s\n",
      "batch 14472, train_loss 59.860279,Time used 0.011002s\n",
      "batch 14473, train_loss 57.904842,Time used 0.012001s\n",
      "batch 14474, train_loss 72.773590,Time used 0.010996s\n",
      "batch 14475, train_loss 50.707108,Time used 0.013000s\n",
      "batch 14476, train_loss 61.079372,Time used 0.013000s\n",
      "batch 14477, train_loss 44.739075,Time used 0.013000s\n",
      "batch 14478, train_loss 66.667473,Time used 0.012000s\n",
      "batch 14479, train_loss 51.657822,Time used 0.011996s\n",
      "batch 14480, train_loss 55.348236,Time used 0.013002s\n",
      "batch 14481, train_loss 40.235855,Time used 0.011002s\n",
      "batch 14482, train_loss 49.935577,Time used 0.011997s\n",
      "batch 14483, train_loss 48.168785,Time used 0.011000s\n",
      "batch 14484, train_loss 65.652542,Time used 0.013000s\n",
      "batch 14485, train_loss 48.507126,Time used 0.011001s\n",
      "batch 14486, train_loss 38.239220,Time used 0.014000s\n",
      "batch 14487, train_loss 41.911041,Time used 0.017001s\n",
      "batch 14488, train_loss 55.375298,Time used 0.024998s\n",
      "batch 14489, train_loss 49.841381,Time used 0.011002s\n",
      "batch 14490, train_loss 59.857983,Time used 0.010998s\n",
      "batch 14491, train_loss 48.457500,Time used 0.012000s\n",
      "batch 14492, train_loss 53.466568,Time used 0.012000s\n",
      "batch 14493, train_loss 41.344681,Time used 0.011002s\n",
      "batch 14494, train_loss 58.895420,Time used 0.011998s\n",
      "batch 14495, train_loss 48.358810,Time used 0.012001s\n",
      "batch 14496, train_loss 47.809906,Time used 0.014003s\n",
      "batch 14497, train_loss 39.997448,Time used 0.011001s\n",
      "batch 14498, train_loss 61.166615,Time used 0.013000s\n",
      "batch 14499, train_loss 39.947517,Time used 0.015001s\n",
      "batch 14500, train_loss 44.122578,Time used 0.012999s\n",
      "***************************test_batch 14500, test_rmse_loss 8.337829,test_mae_loss 3.424355,test_mape_loss 55.149170,Time used 0.059998s\n",
      "batch 14501, train_loss 62.514538,Time used 0.012003s\n",
      "batch 14502, train_loss 43.835342,Time used 0.008000s\n",
      "batch 14503, train_loss 55.768978,Time used 0.009001s\n",
      "batch 14504, train_loss 49.539711,Time used 0.012000s\n",
      "batch 14505, train_loss 56.349346,Time used 0.011003s\n",
      "batch 14506, train_loss 51.301300,Time used 0.012999s\n",
      "batch 14507, train_loss 54.733082,Time used 0.013002s\n",
      "batch 14508, train_loss 58.295536,Time used 0.011999s\n",
      "batch 14509, train_loss 63.972149,Time used 0.011998s\n",
      "batch 14510, train_loss 57.949348,Time used 0.013000s\n",
      "batch 14511, train_loss 51.875404,Time used 0.010002s\n",
      "batch 14512, train_loss 55.927891,Time used 0.010000s\n",
      "batch 14513, train_loss 48.481613,Time used 0.010002s\n",
      "batch 14514, train_loss 50.905792,Time used 0.009001s\n",
      "batch 14515, train_loss 66.432503,Time used 0.011998s\n",
      "batch 14516, train_loss 45.030899,Time used 0.011997s\n",
      "batch 14517, train_loss 41.865898,Time used 0.009002s\n",
      "batch 14518, train_loss 61.927944,Time used 0.008000s\n",
      "batch 14519, train_loss 45.007000,Time used 0.012002s\n",
      "batch 14520, train_loss 47.680645,Time used 0.012001s\n",
      "batch 14521, train_loss 48.030720,Time used 0.013995s\n",
      "batch 14522, train_loss 53.255043,Time used 0.014001s\n",
      "batch 14523, train_loss 61.951469,Time used 0.011005s\n",
      "batch 14524, train_loss 47.388519,Time used 0.009998s\n",
      "batch 14525, train_loss 54.022987,Time used 0.011998s\n",
      "batch 14526, train_loss 65.322044,Time used 0.011999s\n",
      "batch 14527, train_loss 49.220413,Time used 0.009002s\n",
      "batch 14528, train_loss 50.861996,Time used 0.008997s\n",
      "batch 14529, train_loss 50.352562,Time used 0.012004s\n",
      "batch 14530, train_loss 52.288654,Time used 0.010996s\n",
      "batch 14531, train_loss 43.065796,Time used 0.012002s\n",
      "batch 14532, train_loss 64.676888,Time used 0.011000s\n",
      "batch 14533, train_loss 45.212891,Time used 0.009998s\n",
      "batch 14534, train_loss 49.955627,Time used 0.010999s\n",
      "batch 14535, train_loss 42.783119,Time used 0.012002s\n",
      "batch 14536, train_loss 43.849049,Time used 0.024002s\n",
      "batch 14537, train_loss 51.913002,Time used 0.018002s\n",
      "batch 14538, train_loss 56.991123,Time used 0.018998s\n",
      "batch 14539, train_loss 62.909050,Time used 0.015997s\n",
      "batch 14540, train_loss 40.500916,Time used 0.011999s\n",
      "batch 14541, train_loss 48.717785,Time used 0.012000s\n",
      "batch 14542, train_loss 60.085770,Time used 0.013005s\n",
      "batch 14543, train_loss 49.038429,Time used 0.012995s\n",
      "batch 14544, train_loss 60.475990,Time used 0.012000s\n",
      "batch 14545, train_loss 70.553841,Time used 0.011998s\n",
      "batch 14546, train_loss 46.649189,Time used 0.010999s\n",
      "batch 14547, train_loss 44.972843,Time used 0.011000s\n",
      "batch 14548, train_loss 67.356453,Time used 0.011000s\n",
      "batch 14549, train_loss 57.405571,Time used 0.014002s\n",
      "batch 14550, train_loss 50.859215,Time used 0.013000s\n",
      "batch 14551, train_loss 49.145187,Time used 0.042002s\n",
      "batch 14552, train_loss 48.904362,Time used 0.066001s\n",
      "batch 14553, train_loss 58.464592,Time used 0.060002s\n",
      "batch 14554, train_loss 47.594429,Time used 0.023997s\n",
      "batch 14555, train_loss 53.859470,Time used 0.016000s\n",
      "batch 14556, train_loss 33.581493,Time used 0.011000s\n",
      "batch 14557, train_loss 59.763611,Time used 0.011002s\n",
      "batch 14558, train_loss 42.162926,Time used 0.011000s\n",
      "batch 14559, train_loss 40.685493,Time used 0.011999s\n",
      "batch 14560, train_loss 49.490917,Time used 0.012000s\n",
      "batch 14561, train_loss 46.299053,Time used 0.013001s\n",
      "batch 14562, train_loss 63.530006,Time used 0.009998s\n",
      "batch 14563, train_loss 65.179451,Time used 0.009002s\n",
      "batch 14564, train_loss 53.869850,Time used 0.009000s\n",
      "batch 14565, train_loss 51.363804,Time used 0.008000s\n",
      "batch 14566, train_loss 51.608997,Time used 0.008000s\n",
      "batch 14567, train_loss 46.903854,Time used 0.011999s\n",
      "batch 14568, train_loss 50.415131,Time used 0.008998s\n",
      "batch 14569, train_loss 48.568989,Time used 0.011999s\n",
      "batch 14570, train_loss 55.570553,Time used 0.011000s\n",
      "batch 14571, train_loss 43.524910,Time used 0.010000s\n",
      "batch 14572, train_loss 38.174217,Time used 0.010003s\n",
      "batch 14573, train_loss 52.292683,Time used 0.009999s\n",
      "batch 14574, train_loss 63.922245,Time used 0.008000s\n",
      "batch 14575, train_loss 51.484035,Time used 0.009010s\n",
      "batch 14576, train_loss 54.315109,Time used 0.007990s\n",
      "batch 14577, train_loss 51.345684,Time used 0.009001s\n",
      "batch 14578, train_loss 60.172813,Time used 0.012001s\n",
      "batch 14579, train_loss 58.498260,Time used 0.011998s\n",
      "batch 14580, train_loss 50.487392,Time used 0.011001s\n",
      "batch 14581, train_loss 43.869644,Time used 0.011001s\n",
      "batch 14582, train_loss 55.796299,Time used 0.008001s\n",
      "batch 14583, train_loss 48.475864,Time used 0.009001s\n",
      "batch 14584, train_loss 52.020508,Time used 0.010998s\n",
      "batch 14585, train_loss 60.918114,Time used 0.011002s\n",
      "batch 14586, train_loss 52.319927,Time used 0.011000s\n",
      "batch 14587, train_loss 56.358311,Time used 0.014000s\n",
      "batch 14588, train_loss 48.325802,Time used 0.013002s\n",
      "batch 14589, train_loss 63.817028,Time used 0.014000s\n",
      "batch 14590, train_loss 47.638302,Time used 0.012002s\n",
      "batch 14591, train_loss 42.212654,Time used 0.014000s\n",
      "batch 14592, train_loss 48.329880,Time used 0.014997s\n",
      "batch 14593, train_loss 69.912689,Time used 0.017995s\n",
      "batch 14594, train_loss 55.606594,Time used 0.017994s\n",
      "batch 14595, train_loss 52.724724,Time used 0.027015s\n",
      "batch 14596, train_loss 42.103466,Time used 0.016998s\n",
      "batch 14597, train_loss 48.592171,Time used 0.015999s\n",
      "batch 14598, train_loss 46.923897,Time used 0.019003s\n",
      "batch 14599, train_loss 51.504627,Time used 0.014999s\n",
      "batch 14600, train_loss 52.510567,Time used 0.016000s\n",
      "***************************test_batch 14600, test_rmse_loss 8.311450,test_mae_loss 3.414295,test_mape_loss 54.923378,Time used 0.072002s\n",
      "batch 14601, train_loss 48.139748,Time used 0.015998s\n",
      "batch 14602, train_loss 57.038410,Time used 0.017999s\n",
      "batch 14603, train_loss 66.542717,Time used 0.015000s\n",
      "batch 14604, train_loss 41.666595,Time used 0.011001s\n",
      "batch 14605, train_loss 48.398651,Time used 0.018001s\n",
      "batch 14606, train_loss 51.331001,Time used 0.010999s\n",
      "batch 14607, train_loss 60.040024,Time used 0.010998s\n",
      "batch 14608, train_loss 58.257797,Time used 0.016002s\n",
      "batch 14609, train_loss 45.843407,Time used 0.014000s\n",
      "batch 14610, train_loss 47.195137,Time used 0.013001s\n",
      "batch 14611, train_loss 51.975979,Time used 0.013000s\n",
      "batch 14612, train_loss 55.019249,Time used 0.018999s\n",
      "batch 14613, train_loss 41.643349,Time used 0.016000s\n",
      "batch 14614, train_loss 45.256031,Time used 0.015001s\n",
      "batch 14615, train_loss 54.979748,Time used 0.013018s\n",
      "batch 14616, train_loss 53.617176,Time used 0.012995s\n",
      "batch 14617, train_loss 50.391663,Time used 0.011000s\n",
      "batch 14618, train_loss 52.642387,Time used 0.013004s\n",
      "batch 14619, train_loss 73.745300,Time used 0.011994s\n",
      "batch 14620, train_loss 51.338543,Time used 0.011000s\n",
      "batch 14621, train_loss 52.511543,Time used 0.011999s\n",
      "batch 14622, train_loss 47.921562,Time used 0.008002s\n",
      "batch 14623, train_loss 53.654202,Time used 0.009998s\n",
      "batch 14624, train_loss 58.578079,Time used 0.009001s\n",
      "batch 14625, train_loss 50.889671,Time used 0.008001s\n",
      "batch 14626, train_loss 55.473530,Time used 0.010002s\n",
      "batch 14627, train_loss 49.167694,Time used 0.009001s\n",
      "batch 14628, train_loss 44.998871,Time used 0.008997s\n",
      "batch 14629, train_loss 59.989841,Time used 0.010001s\n",
      "batch 14630, train_loss 52.604923,Time used 0.007998s\n",
      "batch 14631, train_loss 40.183815,Time used 0.008000s\n",
      "batch 14632, train_loss 54.293411,Time used 0.009000s\n",
      "batch 14633, train_loss 51.115490,Time used 0.009001s\n",
      "batch 14634, train_loss 68.264336,Time used 0.012001s\n",
      "batch 14635, train_loss 42.152882,Time used 0.011999s\n",
      "batch 14636, train_loss 35.717014,Time used 0.013002s\n",
      "batch 14637, train_loss 59.572514,Time used 0.012000s\n",
      "batch 14638, train_loss 44.794281,Time used 0.012001s\n",
      "batch 14639, train_loss 49.834984,Time used 0.011000s\n",
      "batch 14640, train_loss 44.690430,Time used 0.009996s\n",
      "batch 14641, train_loss 45.926762,Time used 0.009998s\n",
      "batch 14642, train_loss 67.907257,Time used 0.010001s\n",
      "batch 14643, train_loss 60.026939,Time used 0.008000s\n",
      "batch 14644, train_loss 37.892780,Time used 0.008998s\n",
      "batch 14645, train_loss 49.511806,Time used 0.008003s\n",
      "batch 14646, train_loss 59.178871,Time used 0.011999s\n",
      "batch 14647, train_loss 50.485245,Time used 0.011998s\n",
      "batch 14648, train_loss 45.899387,Time used 0.009999s\n",
      "batch 14649, train_loss 45.248661,Time used 0.008000s\n",
      "batch 14650, train_loss 56.401947,Time used 0.009001s\n",
      "batch 14651, train_loss 45.330803,Time used 0.008001s\n",
      "batch 14652, train_loss 55.693092,Time used 0.009001s\n",
      "batch 14653, train_loss 51.016644,Time used 0.007998s\n",
      "batch 14654, train_loss 64.739235,Time used 0.009002s\n",
      "batch 14655, train_loss 41.943043,Time used 0.006999s\n",
      "batch 14656, train_loss 60.923363,Time used 0.011001s\n",
      "batch 14657, train_loss 53.991539,Time used 0.009001s\n",
      "batch 14658, train_loss 50.273979,Time used 0.009999s\n",
      "batch 14659, train_loss 71.285545,Time used 0.008001s\n",
      "batch 14660, train_loss 37.188663,Time used 0.010998s\n",
      "batch 14661, train_loss 47.342754,Time used 0.007998s\n",
      "batch 14662, train_loss 50.913399,Time used 0.008002s\n",
      "batch 14663, train_loss 46.901081,Time used 0.008000s\n",
      "batch 14664, train_loss 46.687428,Time used 0.008000s\n",
      "batch 14665, train_loss 61.613876,Time used 0.009999s\n",
      "batch 14666, train_loss 59.573505,Time used 0.011000s\n",
      "batch 14667, train_loss 42.359901,Time used 0.012000s\n",
      "batch 14668, train_loss 50.961769,Time used 0.011000s\n",
      "batch 14669, train_loss 48.389481,Time used 0.010000s\n",
      "batch 14670, train_loss 46.640095,Time used 0.012000s\n",
      "batch 14671, train_loss 50.607662,Time used 0.009999s\n",
      "batch 14672, train_loss 41.236816,Time used 0.011000s\n",
      "batch 14673, train_loss 43.966885,Time used 0.013002s\n",
      "batch 14674, train_loss 45.891167,Time used 0.011999s\n",
      "batch 14675, train_loss 48.435017,Time used 0.008001s\n",
      "batch 14676, train_loss 68.007111,Time used 0.009003s\n",
      "batch 14677, train_loss 69.777565,Time used 0.010997s\n",
      "batch 14678, train_loss 40.933586,Time used 0.011999s\n",
      "batch 14679, train_loss 53.267178,Time used 0.008000s\n",
      "batch 14680, train_loss 47.102364,Time used 0.010999s\n",
      "batch 14681, train_loss 61.022732,Time used 0.010001s\n",
      "batch 14682, train_loss 54.607094,Time used 0.010001s\n",
      "batch 14683, train_loss 50.711243,Time used 0.008001s\n",
      "batch 14684, train_loss 50.157192,Time used 0.011002s\n",
      "batch 14685, train_loss 54.518978,Time used 0.008000s\n",
      "batch 14686, train_loss 47.703255,Time used 0.010000s\n",
      "batch 14687, train_loss 48.837860,Time used 0.011999s\n",
      "batch 14688, train_loss 54.546261,Time used 0.010001s\n",
      "batch 14689, train_loss 60.706860,Time used 0.007994s\n",
      "batch 14690, train_loss 54.950432,Time used 0.008000s\n",
      "batch 14691, train_loss 48.314587,Time used 0.012000s\n",
      "batch 14692, train_loss 55.961773,Time used 0.008002s\n",
      "batch 14693, train_loss 45.969261,Time used 0.011000s\n",
      "batch 14694, train_loss 49.945255,Time used 0.008000s\n",
      "batch 14695, train_loss 41.802280,Time used 0.010000s\n",
      "batch 14696, train_loss 61.266148,Time used 0.010000s\n",
      "batch 14697, train_loss 56.712734,Time used 0.008000s\n",
      "batch 14698, train_loss 58.764015,Time used 0.008999s\n",
      "batch 14699, train_loss 48.732544,Time used 0.008999s\n",
      "batch 14700, train_loss 47.414326,Time used 0.011002s\n",
      "***************************test_batch 14700, test_rmse_loss 8.286819,test_mae_loss 3.406588,test_mape_loss 54.851916,Time used 0.035000s\n",
      "batch 14701, train_loss 45.202118,Time used 0.010998s\n",
      "batch 14702, train_loss 40.546646,Time used 0.009002s\n",
      "batch 14703, train_loss 54.004372,Time used 0.011999s\n",
      "batch 14704, train_loss 56.114914,Time used 0.011002s\n",
      "batch 14705, train_loss 44.876289,Time used 0.009999s\n",
      "batch 14706, train_loss 49.658039,Time used 0.009998s\n",
      "batch 14707, train_loss 60.054806,Time used 0.011003s\n",
      "batch 14708, train_loss 50.354759,Time used 0.007998s\n",
      "batch 14709, train_loss 49.656582,Time used 0.009998s\n",
      "batch 14710, train_loss 55.589451,Time used 0.012002s\n",
      "batch 14711, train_loss 44.856400,Time used 0.006999s\n",
      "batch 14712, train_loss 57.826366,Time used 0.010001s\n",
      "batch 14713, train_loss 36.496502,Time used 0.011001s\n",
      "batch 14714, train_loss 43.032394,Time used 0.011998s\n",
      "batch 14715, train_loss 63.281143,Time used 0.011001s\n",
      "batch 14716, train_loss 44.871811,Time used 0.010999s\n",
      "batch 14717, train_loss 60.610630,Time used 0.008001s\n",
      "batch 14718, train_loss 52.803764,Time used 0.009000s\n",
      "batch 14719, train_loss 54.126869,Time used 0.008000s\n",
      "batch 14720, train_loss 54.196468,Time used 0.012001s\n",
      "batch 14721, train_loss 57.576927,Time used 0.012999s\n",
      "batch 14722, train_loss 57.894341,Time used 0.011002s\n",
      "batch 14723, train_loss 51.199200,Time used 0.007999s\n",
      "batch 14724, train_loss 52.495239,Time used 0.008000s\n",
      "batch 14725, train_loss 47.479252,Time used 0.008999s\n",
      "batch 14726, train_loss 70.376472,Time used 0.013000s\n",
      "batch 14727, train_loss 47.443993,Time used 0.008001s\n",
      "batch 14728, train_loss 49.693520,Time used 0.008000s\n",
      "batch 14729, train_loss 47.186020,Time used 0.007001s\n",
      "batch 14730, train_loss 55.676430,Time used 0.007002s\n",
      "batch 14731, train_loss 46.511318,Time used 0.007998s\n",
      "batch 14732, train_loss 51.071331,Time used 0.011999s\n",
      "batch 14733, train_loss 40.035294,Time used 0.011000s\n",
      "batch 14734, train_loss 52.354694,Time used 0.011000s\n",
      "batch 14735, train_loss 49.432976,Time used 0.011001s\n",
      "batch 14736, train_loss 51.560928,Time used 0.012000s\n",
      "batch 14737, train_loss 49.376915,Time used 0.009001s\n",
      "batch 14738, train_loss 42.850658,Time used 0.007001s\n",
      "batch 14739, train_loss 59.948406,Time used 0.007999s\n",
      "batch 14740, train_loss 47.246372,Time used 0.008003s\n",
      "batch 14741, train_loss 56.480335,Time used 0.010996s\n",
      "batch 14742, train_loss 40.748962,Time used 0.011003s\n",
      "batch 14743, train_loss 48.210835,Time used 0.008999s\n",
      "batch 14744, train_loss 46.271999,Time used 0.007999s\n",
      "batch 14745, train_loss 48.752857,Time used 0.008002s\n",
      "batch 14746, train_loss 55.396805,Time used 0.010000s\n",
      "batch 14747, train_loss 50.036964,Time used 0.008998s\n",
      "batch 14748, train_loss 58.838364,Time used 0.010004s\n",
      "batch 14749, train_loss 57.289562,Time used 0.011998s\n",
      "batch 14750, train_loss 41.310970,Time used 0.011000s\n",
      "batch 14751, train_loss 44.898018,Time used 0.011001s\n",
      "batch 14752, train_loss 50.503353,Time used 0.011998s\n",
      "batch 14753, train_loss 50.304321,Time used 0.011001s\n",
      "batch 14754, train_loss 59.930435,Time used 0.006999s\n",
      "batch 14755, train_loss 62.051060,Time used 0.008000s\n",
      "batch 14756, train_loss 50.237103,Time used 0.011004s\n",
      "batch 14757, train_loss 46.900608,Time used 0.011001s\n",
      "batch 14758, train_loss 59.236317,Time used 0.007999s\n",
      "batch 14759, train_loss 58.917820,Time used 0.011999s\n",
      "batch 14760, train_loss 49.535473,Time used 0.008002s\n",
      "batch 14761, train_loss 63.580261,Time used 0.011000s\n",
      "batch 14762, train_loss 36.294262,Time used 0.008000s\n",
      "batch 14763, train_loss 35.756214,Time used 0.007998s\n",
      "batch 14764, train_loss 49.038994,Time used 0.007000s\n",
      "batch 14765, train_loss 49.998009,Time used 0.008997s\n",
      "batch 14766, train_loss 38.806839,Time used 0.013999s\n",
      "batch 14767, train_loss 64.006470,Time used 0.007998s\n",
      "batch 14768, train_loss 44.696472,Time used 0.010003s\n",
      "batch 14769, train_loss 50.495724,Time used 0.012000s\n",
      "batch 14770, train_loss 51.500946,Time used 0.010999s\n",
      "batch 14771, train_loss 56.931461,Time used 0.010001s\n",
      "batch 14772, train_loss 56.104179,Time used 0.009002s\n",
      "batch 14773, train_loss 36.257633,Time used 0.010000s\n",
      "batch 14774, train_loss 56.805843,Time used 0.008000s\n",
      "batch 14775, train_loss 53.369900,Time used 0.010999s\n",
      "batch 14776, train_loss 53.647694,Time used 0.011002s\n",
      "batch 14777, train_loss 46.988567,Time used 0.011004s\n",
      "batch 14778, train_loss 53.815128,Time used 0.007999s\n",
      "batch 14779, train_loss 62.486534,Time used 0.010006s\n",
      "batch 14780, train_loss 57.803108,Time used 0.011001s\n",
      "batch 14781, train_loss 52.557568,Time used 0.007000s\n",
      "batch 14782, train_loss 58.470287,Time used 0.011000s\n",
      "batch 14783, train_loss 50.067669,Time used 0.011001s\n",
      "batch 14784, train_loss 53.429474,Time used 0.011999s\n",
      "batch 14785, train_loss 50.288830,Time used 0.010999s\n",
      "batch 14786, train_loss 61.805157,Time used 0.009001s\n",
      "batch 14787, train_loss 58.041565,Time used 0.012000s\n",
      "batch 14788, train_loss 58.550369,Time used 0.010997s\n",
      "batch 14789, train_loss 47.424789,Time used 0.011003s\n",
      "batch 14790, train_loss 43.946003,Time used 0.011001s\n",
      "batch 14791, train_loss 51.494606,Time used 0.010003s\n",
      "batch 14792, train_loss 45.243114,Time used 0.011999s\n",
      "batch 14793, train_loss 51.579548,Time used 0.007998s\n",
      "batch 14794, train_loss 35.507004,Time used 0.009001s\n",
      "batch 14795, train_loss 67.195518,Time used 0.009003s\n",
      "batch 14796, train_loss 48.747700,Time used 0.007998s\n",
      "batch 14797, train_loss 51.822224,Time used 0.007003s\n",
      "batch 14798, train_loss 47.009834,Time used 0.009000s\n",
      "batch 14799, train_loss 50.534927,Time used 0.009999s\n",
      "batch 14800, train_loss 58.357536,Time used 0.010997s\n",
      "***************************test_batch 14800, test_rmse_loss 8.259807,test_mae_loss 3.394006,test_mape_loss 54.601056,Time used 0.047002s\n",
      "batch 14801, train_loss 50.645779,Time used 0.011000s\n",
      "batch 14802, train_loss 48.156792,Time used 0.012000s\n",
      "batch 14803, train_loss 48.039127,Time used 0.009998s\n",
      "batch 14804, train_loss 50.995659,Time used 0.011999s\n",
      "batch 14805, train_loss 58.184460,Time used 0.011002s\n",
      "batch 14806, train_loss 42.875248,Time used 0.009001s\n",
      "batch 14807, train_loss 55.748047,Time used 0.009999s\n",
      "batch 14808, train_loss 48.486076,Time used 0.008000s\n",
      "batch 14809, train_loss 50.345451,Time used 0.006999s\n",
      "batch 14810, train_loss 41.227535,Time used 0.010000s\n",
      "batch 14811, train_loss 51.613735,Time used 0.012000s\n",
      "batch 14812, train_loss 54.195816,Time used 0.008000s\n",
      "batch 14813, train_loss 54.826405,Time used 0.011998s\n",
      "batch 14814, train_loss 51.750999,Time used 0.009001s\n",
      "batch 14815, train_loss 50.614101,Time used 0.012000s\n",
      "batch 14816, train_loss 54.820889,Time used 0.011000s\n",
      "batch 14817, train_loss 36.693054,Time used 0.009001s\n",
      "batch 14818, train_loss 55.964058,Time used 0.010999s\n",
      "batch 14819, train_loss 58.360195,Time used 0.008001s\n",
      "batch 14820, train_loss 43.957115,Time used 0.007999s\n",
      "batch 14821, train_loss 52.854782,Time used 0.011000s\n",
      "batch 14822, train_loss 49.420406,Time used 0.010001s\n",
      "batch 14823, train_loss 49.761745,Time used 0.011999s\n",
      "batch 14824, train_loss 49.955414,Time used 0.012001s\n",
      "batch 14825, train_loss 40.608082,Time used 0.010999s\n",
      "batch 14826, train_loss 55.600868,Time used 0.011999s\n",
      "batch 14827, train_loss 54.792175,Time used 0.008001s\n",
      "batch 14828, train_loss 58.368015,Time used 0.008998s\n",
      "batch 14829, train_loss 52.533970,Time used 0.012000s\n",
      "batch 14830, train_loss 55.160194,Time used 0.008001s\n",
      "batch 14831, train_loss 62.155231,Time used 0.009999s\n",
      "batch 14832, train_loss 42.989922,Time used 0.012001s\n",
      "batch 14833, train_loss 52.780869,Time used 0.008000s\n",
      "batch 14834, train_loss 37.011929,Time used 0.009000s\n",
      "batch 14835, train_loss 60.078552,Time used 0.010996s\n",
      "batch 14836, train_loss 46.994526,Time used 0.010001s\n",
      "batch 14837, train_loss 50.940842,Time used 0.011003s\n",
      "batch 14838, train_loss 39.278309,Time used 0.010997s\n",
      "batch 14839, train_loss 51.905121,Time used 0.011000s\n",
      "batch 14840, train_loss 50.006752,Time used 0.011003s\n",
      "batch 14841, train_loss 49.521389,Time used 0.010999s\n",
      "batch 14842, train_loss 51.574760,Time used 0.012000s\n",
      "batch 14843, train_loss 56.961094,Time used 0.010001s\n",
      "batch 14844, train_loss 54.272961,Time used 0.011002s\n",
      "batch 14845, train_loss 41.988529,Time used 0.007999s\n",
      "batch 14846, train_loss 55.065521,Time used 0.007999s\n",
      "batch 14847, train_loss 56.156029,Time used 0.009002s\n",
      "batch 14848, train_loss 56.619507,Time used 0.008001s\n",
      "batch 14849, train_loss 62.131340,Time used 0.007998s\n",
      "batch 14850, train_loss 37.568810,Time used 0.010000s\n",
      "batch 14851, train_loss 56.104710,Time used 0.008999s\n",
      "batch 14852, train_loss 46.715069,Time used 0.010998s\n",
      "batch 14853, train_loss 50.424389,Time used 0.011000s\n",
      "batch 14854, train_loss 58.654293,Time used 0.009000s\n",
      "batch 14855, train_loss 52.006908,Time used 0.013000s\n",
      "batch 14856, train_loss 52.561489,Time used 0.011000s\n",
      "batch 14857, train_loss 40.329811,Time used 0.007000s\n",
      "batch 14858, train_loss 39.567699,Time used 0.010000s\n",
      "batch 14859, train_loss 54.209747,Time used 0.012002s\n",
      "batch 14860, train_loss 46.064491,Time used 0.011000s\n",
      "batch 14861, train_loss 55.333519,Time used 0.010999s\n",
      "batch 14862, train_loss 52.070656,Time used 0.008001s\n",
      "batch 14863, train_loss 36.077358,Time used 0.010999s\n",
      "batch 14864, train_loss 59.926483,Time used 0.009986s\n",
      "batch 14865, train_loss 55.770851,Time used 0.008000s\n",
      "batch 14866, train_loss 56.335709,Time used 0.008002s\n",
      "batch 14867, train_loss 52.773495,Time used 0.008001s\n",
      "batch 14868, train_loss 50.263588,Time used 0.011999s\n",
      "batch 14869, train_loss 47.519745,Time used 0.013002s\n",
      "batch 14870, train_loss 39.715908,Time used 0.013002s\n",
      "batch 14871, train_loss 53.111069,Time used 0.014998s\n",
      "batch 14872, train_loss 53.218849,Time used 0.013999s\n",
      "batch 14873, train_loss 56.852936,Time used 0.012999s\n",
      "batch 14874, train_loss 48.822121,Time used 0.016998s\n",
      "batch 14875, train_loss 40.426243,Time used 0.015008s\n",
      "batch 14876, train_loss 56.759026,Time used 0.019000s\n",
      "batch 14877, train_loss 49.648781,Time used 0.014992s\n",
      "batch 14878, train_loss 56.420437,Time used 0.022006s\n",
      "batch 14879, train_loss 63.252483,Time used 0.020007s\n",
      "batch 14880, train_loss 61.309376,Time used 0.010990s\n",
      "batch 14881, train_loss 50.484829,Time used 0.016003s\n",
      "batch 14882, train_loss 47.813347,Time used 0.017001s\n",
      "batch 14883, train_loss 53.649490,Time used 0.013996s\n",
      "batch 14884, train_loss 36.762871,Time used 0.017000s\n",
      "batch 14885, train_loss 40.866062,Time used 0.015005s\n",
      "batch 14886, train_loss 44.551697,Time used 0.017003s\n",
      "batch 14887, train_loss 38.905563,Time used 0.016994s\n",
      "batch 14888, train_loss 55.458500,Time used 0.017999s\n",
      "batch 14889, train_loss 59.390877,Time used 0.017001s\n",
      "batch 14890, train_loss 54.453381,Time used 0.017001s\n",
      "batch 14891, train_loss 72.571999,Time used 0.018999s\n",
      "batch 14892, train_loss 44.708801,Time used 0.014998s\n",
      "batch 14893, train_loss 41.409039,Time used 0.014001s\n",
      "batch 14894, train_loss 66.200073,Time used 0.016000s\n",
      "batch 14895, train_loss 44.972683,Time used 0.015005s\n",
      "batch 14896, train_loss 47.506252,Time used 0.009996s\n",
      "batch 14897, train_loss 55.914314,Time used 0.011997s\n",
      "batch 14898, train_loss 49.627121,Time used 0.011001s\n",
      "batch 14899, train_loss 52.389900,Time used 0.010002s\n",
      "batch 14900, train_loss 60.022137,Time used 0.009998s\n",
      "***************************test_batch 14900, test_rmse_loss 8.233289,test_mae_loss 3.388235,test_mape_loss 54.602478,Time used 0.039001s\n",
      "batch 14901, train_loss 42.859470,Time used 0.012002s\n",
      "batch 14902, train_loss 47.486717,Time used 0.010999s\n",
      "batch 14903, train_loss 59.596809,Time used 0.009006s\n",
      "batch 14904, train_loss 55.588612,Time used 0.012992s\n",
      "batch 14905, train_loss 53.166229,Time used 0.008001s\n",
      "batch 14906, train_loss 47.703930,Time used 0.009000s\n",
      "batch 14907, train_loss 64.439438,Time used 0.008000s\n",
      "batch 14908, train_loss 52.955544,Time used 0.007998s\n",
      "batch 14909, train_loss 48.370659,Time used 0.009003s\n",
      "batch 14910, train_loss 52.659252,Time used 0.008998s\n",
      "batch 14911, train_loss 60.125484,Time used 0.010997s\n",
      "batch 14912, train_loss 50.854160,Time used 0.012001s\n",
      "batch 14913, train_loss 57.424782,Time used 0.013001s\n",
      "batch 14914, train_loss 50.531883,Time used 0.010000s\n",
      "batch 14915, train_loss 52.122799,Time used 0.015000s\n",
      "batch 14916, train_loss 68.426285,Time used 0.015004s\n",
      "batch 14917, train_loss 39.349667,Time used 0.017003s\n",
      "batch 14918, train_loss 62.188892,Time used 0.020004s\n",
      "batch 14919, train_loss 46.162903,Time used 0.017992s\n",
      "batch 14920, train_loss 38.798428,Time used 0.017999s\n",
      "batch 14921, train_loss 44.626682,Time used 0.017000s\n",
      "batch 14922, train_loss 39.652622,Time used 0.017003s\n",
      "batch 14923, train_loss 40.492649,Time used 0.013997s\n",
      "batch 14924, train_loss 55.515537,Time used 0.021000s\n",
      "batch 14925, train_loss 43.119202,Time used 0.016997s\n",
      "batch 14926, train_loss 52.710796,Time used 0.018004s\n",
      "batch 14927, train_loss 48.652439,Time used 0.008987s\n",
      "batch 14928, train_loss 50.925247,Time used 0.013001s\n",
      "batch 14929, train_loss 48.087223,Time used 0.011988s\n",
      "batch 14930, train_loss 48.751530,Time used 0.012999s\n",
      "batch 14931, train_loss 43.332066,Time used 0.013000s\n",
      "batch 14932, train_loss 43.356846,Time used 0.013007s\n",
      "batch 14933, train_loss 62.344158,Time used 0.010989s\n",
      "batch 14934, train_loss 57.304321,Time used 0.012003s\n",
      "batch 14935, train_loss 59.775433,Time used 0.013998s\n",
      "batch 14936, train_loss 52.111366,Time used 0.011003s\n",
      "batch 14937, train_loss 46.442226,Time used 0.009995s\n",
      "batch 14938, train_loss 56.915127,Time used 0.014000s\n",
      "batch 14939, train_loss 49.784122,Time used 0.012999s\n",
      "batch 14940, train_loss 50.250664,Time used 0.012007s\n",
      "batch 14941, train_loss 47.187584,Time used 0.009993s\n",
      "batch 14942, train_loss 52.778362,Time used 0.011999s\n",
      "batch 14943, train_loss 64.957909,Time used 0.009008s\n",
      "batch 14944, train_loss 51.895939,Time used 0.007995s\n",
      "batch 14945, train_loss 45.459896,Time used 0.008998s\n",
      "batch 14946, train_loss 43.248505,Time used 0.009002s\n",
      "batch 14947, train_loss 50.630386,Time used 0.008001s\n",
      "batch 14948, train_loss 58.325317,Time used 0.009999s\n",
      "batch 14949, train_loss 46.712250,Time used 0.009001s\n",
      "batch 14950, train_loss 45.665009,Time used 0.010999s\n",
      "batch 14951, train_loss 51.632378,Time used 0.010999s\n",
      "batch 14952, train_loss 41.643223,Time used 0.012001s\n",
      "batch 14953, train_loss 50.493496,Time used 0.007999s\n",
      "batch 14954, train_loss 55.916466,Time used 0.010999s\n",
      "batch 14955, train_loss 50.464561,Time used 0.012003s\n",
      "batch 14956, train_loss 37.087929,Time used 0.010999s\n",
      "batch 14957, train_loss 46.786610,Time used 0.010002s\n",
      "batch 14958, train_loss 42.241795,Time used 0.010999s\n",
      "batch 14959, train_loss 55.804138,Time used 0.011001s\n",
      "batch 14960, train_loss 54.186989,Time used 0.010998s\n",
      "batch 14961, train_loss 47.143024,Time used 0.012000s\n",
      "batch 14962, train_loss 48.521595,Time used 0.008996s\n",
      "batch 14963, train_loss 54.339825,Time used 0.008002s\n",
      "batch 14964, train_loss 46.217999,Time used 0.008003s\n",
      "batch 14965, train_loss 61.925125,Time used 0.007999s\n",
      "batch 14966, train_loss 48.779984,Time used 0.008000s\n",
      "batch 14967, train_loss 44.821613,Time used 0.009001s\n",
      "batch 14968, train_loss 55.925190,Time used 0.010001s\n",
      "batch 14969, train_loss 55.045265,Time used 0.010999s\n",
      "batch 14970, train_loss 51.681076,Time used 0.011000s\n",
      "batch 14971, train_loss 39.871399,Time used 0.012000s\n",
      "batch 14972, train_loss 57.925594,Time used 0.012002s\n",
      "batch 14973, train_loss 57.477089,Time used 0.011998s\n",
      "batch 14974, train_loss 55.570995,Time used 0.013002s\n",
      "batch 14975, train_loss 52.265697,Time used 0.007995s\n",
      "batch 14976, train_loss 46.003365,Time used 0.010002s\n",
      "batch 14977, train_loss 58.872406,Time used 0.010001s\n",
      "batch 14978, train_loss 46.295517,Time used 0.012000s\n",
      "batch 14979, train_loss 53.725906,Time used 0.010998s\n",
      "batch 14980, train_loss 43.967167,Time used 0.007999s\n",
      "batch 14981, train_loss 43.137833,Time used 0.009003s\n",
      "batch 14982, train_loss 43.450912,Time used 0.008999s\n",
      "batch 14983, train_loss 52.431068,Time used 0.008000s\n",
      "batch 14984, train_loss 48.706833,Time used 0.008001s\n",
      "batch 14985, train_loss 54.315460,Time used 0.009000s\n",
      "batch 14986, train_loss 41.519444,Time used 0.009999s\n",
      "batch 14987, train_loss 56.743797,Time used 0.010999s\n",
      "batch 14988, train_loss 50.795185,Time used 0.011000s\n",
      "batch 14989, train_loss 53.346268,Time used 0.011000s\n",
      "batch 14990, train_loss 45.756027,Time used 0.009001s\n",
      "batch 14991, train_loss 54.342606,Time used 0.010999s\n",
      "batch 14992, train_loss 48.637989,Time used 0.014000s\n",
      "batch 14993, train_loss 58.459270,Time used 0.010006s\n",
      "batch 14994, train_loss 43.825306,Time used 0.011995s\n",
      "batch 14995, train_loss 49.753338,Time used 0.012004s\n",
      "batch 14996, train_loss 57.783932,Time used 0.010000s\n",
      "batch 14997, train_loss 51.765194,Time used 0.008995s\n",
      "batch 14998, train_loss 45.510365,Time used 0.012004s\n",
      "batch 14999, train_loss 62.998569,Time used 0.012000s\n",
      "batch 15000, train_loss 47.427818,Time used 0.009996s\n",
      "***************************test_batch 15000, test_rmse_loss 8.208451,test_mae_loss 3.378400,test_mape_loss 54.552646,Time used 0.043000s\n",
      "batch 15001, train_loss 48.936928,Time used 0.010001s\n",
      "batch 15002, train_loss 32.396748,Time used 0.012001s\n",
      "batch 15003, train_loss 59.865135,Time used 0.011999s\n",
      "batch 15004, train_loss 44.581940,Time used 0.009000s\n",
      "batch 15005, train_loss 58.420757,Time used 0.009000s\n",
      "batch 15006, train_loss 50.988808,Time used 0.016002s\n",
      "batch 15007, train_loss 57.770042,Time used 0.007998s\n",
      "batch 15008, train_loss 70.134743,Time used 0.009001s\n",
      "batch 15009, train_loss 41.242195,Time used 0.008001s\n",
      "batch 15010, train_loss 57.139690,Time used 0.010000s\n",
      "batch 15011, train_loss 48.786324,Time used 0.008997s\n",
      "batch 15012, train_loss 45.474743,Time used 0.010003s\n",
      "batch 15013, train_loss 42.845882,Time used 0.012002s\n",
      "batch 15014, train_loss 50.970322,Time used 0.006997s\n",
      "batch 15015, train_loss 51.532097,Time used 0.008004s\n",
      "batch 15016, train_loss 38.217911,Time used 0.010998s\n",
      "batch 15017, train_loss 50.965775,Time used 0.012000s\n",
      "batch 15018, train_loss 55.872581,Time used 0.010998s\n",
      "batch 15019, train_loss 49.604679,Time used 0.011000s\n",
      "batch 15020, train_loss 41.088116,Time used 0.010999s\n",
      "batch 15021, train_loss 62.184803,Time used 0.010001s\n",
      "batch 15022, train_loss 48.638466,Time used 0.010997s\n",
      "batch 15023, train_loss 49.055618,Time used 0.014003s\n",
      "batch 15024, train_loss 54.702511,Time used 0.010999s\n",
      "batch 15025, train_loss 55.596161,Time used 0.011000s\n",
      "batch 15026, train_loss 45.820648,Time used 0.009000s\n",
      "batch 15027, train_loss 41.971241,Time used 0.008000s\n",
      "batch 15028, train_loss 51.439175,Time used 0.007991s\n",
      "batch 15029, train_loss 52.166965,Time used 0.009002s\n",
      "batch 15030, train_loss 56.425598,Time used 0.006999s\n",
      "batch 15031, train_loss 54.071716,Time used 0.010003s\n",
      "batch 15032, train_loss 56.861275,Time used 0.012000s\n",
      "batch 15033, train_loss 45.499893,Time used 0.008001s\n",
      "batch 15034, train_loss 46.017033,Time used 0.008998s\n",
      "batch 15035, train_loss 48.156494,Time used 0.008001s\n",
      "batch 15036, train_loss 41.904697,Time used 0.010998s\n",
      "batch 15037, train_loss 47.552502,Time used 0.012002s\n",
      "batch 15038, train_loss 52.965488,Time used 0.011004s\n",
      "batch 15039, train_loss 40.956898,Time used 0.009997s\n",
      "batch 15040, train_loss 42.246059,Time used 0.011002s\n",
      "batch 15041, train_loss 59.719749,Time used 0.012001s\n",
      "batch 15042, train_loss 56.685806,Time used 0.011998s\n",
      "batch 15043, train_loss 52.372349,Time used 0.011001s\n",
      "batch 15044, train_loss 62.619164,Time used 0.012000s\n",
      "batch 15045, train_loss 54.974586,Time used 0.010998s\n",
      "batch 15046, train_loss 56.107342,Time used 0.007001s\n",
      "batch 15047, train_loss 35.784134,Time used 0.009000s\n",
      "batch 15048, train_loss 51.287086,Time used 0.011001s\n",
      "batch 15049, train_loss 52.609718,Time used 0.011003s\n",
      "batch 15050, train_loss 41.864300,Time used 0.009001s\n",
      "batch 15051, train_loss 36.662071,Time used 0.008000s\n",
      "batch 15052, train_loss 60.633999,Time used 0.009996s\n",
      "batch 15053, train_loss 50.732304,Time used 0.008002s\n",
      "batch 15054, train_loss 65.228317,Time used 0.007999s\n",
      "batch 15055, train_loss 52.106869,Time used 0.008000s\n",
      "batch 15056, train_loss 43.644859,Time used 0.010999s\n",
      "batch 15057, train_loss 48.210911,Time used 0.010000s\n",
      "batch 15058, train_loss 53.878807,Time used 0.010000s\n",
      "batch 15059, train_loss 50.805561,Time used 0.010001s\n",
      "batch 15060, train_loss 51.659435,Time used 0.011999s\n",
      "batch 15061, train_loss 57.916645,Time used 0.012004s\n",
      "batch 15062, train_loss 47.856613,Time used 0.008999s\n",
      "batch 15063, train_loss 40.944656,Time used 0.010999s\n",
      "batch 15064, train_loss 50.132229,Time used 0.010000s\n",
      "batch 15065, train_loss 48.939640,Time used 0.011999s\n",
      "batch 15066, train_loss 47.525013,Time used 0.011000s\n",
      "batch 15067, train_loss 41.177353,Time used 0.012002s\n",
      "batch 15068, train_loss 45.204193,Time used 0.010000s\n",
      "batch 15069, train_loss 52.312149,Time used 0.009999s\n",
      "batch 15070, train_loss 39.140293,Time used 0.009001s\n",
      "batch 15071, train_loss 59.670082,Time used 0.010999s\n",
      "batch 15072, train_loss 68.412560,Time used 0.010002s\n",
      "batch 15073, train_loss 36.684345,Time used 0.008999s\n",
      "batch 15074, train_loss 55.102280,Time used 0.010003s\n",
      "batch 15075, train_loss 47.424847,Time used 0.008001s\n",
      "batch 15076, train_loss 48.052689,Time used 0.009001s\n",
      "batch 15077, train_loss 42.736038,Time used 0.007998s\n",
      "batch 15078, train_loss 51.176479,Time used 0.010002s\n",
      "batch 15079, train_loss 61.434685,Time used 0.009999s\n",
      "batch 15080, train_loss 47.304749,Time used 0.009000s\n",
      "batch 15081, train_loss 49.797798,Time used 0.011999s\n",
      "batch 15082, train_loss 56.272034,Time used 0.011001s\n",
      "batch 15083, train_loss 48.734692,Time used 0.009001s\n",
      "batch 15084, train_loss 54.554947,Time used 0.007998s\n",
      "batch 15085, train_loss 49.415829,Time used 0.007999s\n",
      "batch 15086, train_loss 53.308792,Time used 0.008001s\n",
      "batch 15087, train_loss 62.768387,Time used 0.009003s\n",
      "batch 15088, train_loss 46.657410,Time used 0.011999s\n",
      "batch 15089, train_loss 52.160488,Time used 0.009998s\n",
      "batch 15090, train_loss 60.752892,Time used 0.008000s\n",
      "batch 15091, train_loss 33.617676,Time used 0.011000s\n",
      "batch 15092, train_loss 49.245499,Time used 0.010998s\n",
      "batch 15093, train_loss 50.927505,Time used 0.008001s\n",
      "batch 15094, train_loss 48.258781,Time used 0.008000s\n",
      "batch 15095, train_loss 52.220924,Time used 0.011000s\n",
      "batch 15096, train_loss 45.426212,Time used 0.008001s\n",
      "batch 15097, train_loss 51.032269,Time used 0.009000s\n",
      "batch 15098, train_loss 48.319206,Time used 0.012002s\n",
      "batch 15099, train_loss 47.445820,Time used 0.008999s\n",
      "batch 15100, train_loss 52.152580,Time used 0.011000s\n",
      "***************************test_batch 15100, test_rmse_loss 8.183576,test_mae_loss 3.365324,test_mape_loss 54.117302,Time used 0.044998s\n",
      "batch 15101, train_loss 37.921089,Time used 0.011002s\n",
      "batch 15102, train_loss 44.155876,Time used 0.008001s\n",
      "batch 15103, train_loss 43.877941,Time used 0.009998s\n",
      "batch 15104, train_loss 44.891014,Time used 0.007999s\n",
      "batch 15105, train_loss 49.619713,Time used 0.010001s\n",
      "batch 15106, train_loss 57.393414,Time used 0.010999s\n",
      "batch 15107, train_loss 46.427971,Time used 0.009000s\n",
      "batch 15108, train_loss 55.645184,Time used 0.011001s\n",
      "batch 15109, train_loss 60.205097,Time used 0.010002s\n",
      "batch 15110, train_loss 47.905769,Time used 0.010996s\n",
      "batch 15111, train_loss 45.361488,Time used 0.012002s\n",
      "batch 15112, train_loss 59.491982,Time used 0.008999s\n",
      "batch 15113, train_loss 54.715405,Time used 0.008001s\n",
      "batch 15114, train_loss 48.581234,Time used 0.010999s\n",
      "batch 15115, train_loss 53.406414,Time used 0.012001s\n",
      "batch 15116, train_loss 50.133644,Time used 0.011999s\n",
      "batch 15117, train_loss 51.284740,Time used 0.011000s\n",
      "batch 15118, train_loss 51.222923,Time used 0.009001s\n",
      "batch 15119, train_loss 59.989895,Time used 0.011001s\n",
      "batch 15120, train_loss 40.395267,Time used 0.007999s\n",
      "batch 15121, train_loss 50.292046,Time used 0.012001s\n",
      "batch 15122, train_loss 64.279984,Time used 0.012001s\n",
      "batch 15123, train_loss 48.330101,Time used 0.010999s\n",
      "batch 15124, train_loss 40.032627,Time used 0.011000s\n",
      "batch 15125, train_loss 42.810345,Time used 0.012002s\n",
      "batch 15126, train_loss 57.573708,Time used 0.010997s\n",
      "batch 15127, train_loss 47.678009,Time used 0.009001s\n",
      "batch 15128, train_loss 53.456764,Time used 0.009000s\n",
      "batch 15129, train_loss 55.638405,Time used 0.011001s\n",
      "batch 15130, train_loss 50.943672,Time used 0.010999s\n",
      "batch 15131, train_loss 55.007404,Time used 0.009001s\n",
      "batch 15132, train_loss 40.499081,Time used 0.010000s\n",
      "batch 15133, train_loss 40.725483,Time used 0.010000s\n",
      "batch 15134, train_loss 43.991566,Time used 0.010000s\n",
      "batch 15135, train_loss 54.152317,Time used 0.006998s\n",
      "batch 15136, train_loss 45.170162,Time used 0.011000s\n",
      "batch 15137, train_loss 46.526096,Time used 0.009000s\n",
      "batch 15138, train_loss 51.137432,Time used 0.010001s\n",
      "batch 15139, train_loss 52.731998,Time used 0.011000s\n",
      "batch 15140, train_loss 38.911686,Time used 0.010999s\n",
      "batch 15141, train_loss 46.460907,Time used 0.007003s\n",
      "batch 15142, train_loss 59.445435,Time used 0.010998s\n",
      "batch 15143, train_loss 55.755428,Time used 0.011001s\n",
      "batch 15144, train_loss 58.518131,Time used 0.010000s\n",
      "batch 15145, train_loss 52.539291,Time used 0.010001s\n",
      "batch 15146, train_loss 70.092117,Time used 0.010999s\n",
      "batch 15147, train_loss 48.917736,Time used 0.012000s\n",
      "batch 15148, train_loss 41.389626,Time used 0.012000s\n",
      "batch 15149, train_loss 41.157860,Time used 0.009001s\n",
      "batch 15150, train_loss 59.271095,Time used 0.009998s\n",
      "batch 15151, train_loss 47.476742,Time used 0.012001s\n",
      "batch 15152, train_loss 50.843960,Time used 0.009002s\n",
      "batch 15153, train_loss 45.511475,Time used 0.010001s\n",
      "batch 15154, train_loss 51.812172,Time used 0.007998s\n",
      "batch 15155, train_loss 42.339008,Time used 0.012001s\n",
      "batch 15156, train_loss 51.015087,Time used 0.011999s\n",
      "batch 15157, train_loss 61.440567,Time used 0.011000s\n",
      "batch 15158, train_loss 52.937901,Time used 0.008001s\n",
      "batch 15159, train_loss 58.531002,Time used 0.008001s\n",
      "batch 15160, train_loss 48.730946,Time used 0.008998s\n",
      "batch 15161, train_loss 53.544193,Time used 0.012003s\n",
      "batch 15162, train_loss 49.038208,Time used 0.010998s\n",
      "batch 15163, train_loss 48.113041,Time used 0.010000s\n",
      "batch 15164, train_loss 35.074501,Time used 0.011001s\n",
      "batch 15165, train_loss 36.194885,Time used 0.010001s\n",
      "batch 15166, train_loss 49.502308,Time used 0.010998s\n",
      "batch 15167, train_loss 49.472656,Time used 0.008998s\n",
      "batch 15168, train_loss 52.859604,Time used 0.008009s\n",
      "batch 15169, train_loss 48.857727,Time used 0.010002s\n",
      "batch 15170, train_loss 54.769550,Time used 0.010997s\n",
      "batch 15171, train_loss 34.039261,Time used 0.010000s\n",
      "batch 15172, train_loss 41.366402,Time used 0.009001s\n",
      "batch 15173, train_loss 53.228668,Time used 0.010001s\n",
      "batch 15174, train_loss 49.880836,Time used 0.008996s\n",
      "batch 15175, train_loss 53.031288,Time used 0.008000s\n",
      "batch 15176, train_loss 38.567356,Time used 0.008002s\n",
      "batch 15177, train_loss 50.716312,Time used 0.009999s\n",
      "batch 15178, train_loss 52.091019,Time used 0.007999s\n",
      "batch 15179, train_loss 47.610840,Time used 0.011003s\n",
      "batch 15180, train_loss 51.504757,Time used 0.007998s\n",
      "batch 15181, train_loss 41.218678,Time used 0.008998s\n",
      "batch 15182, train_loss 50.483303,Time used 0.007999s\n",
      "batch 15183, train_loss 65.201332,Time used 0.009001s\n",
      "batch 15184, train_loss 38.642025,Time used 0.010999s\n",
      "batch 15185, train_loss 54.421337,Time used 0.012003s\n",
      "batch 15186, train_loss 49.319252,Time used 0.008999s\n",
      "batch 15187, train_loss 42.564678,Time used 0.009998s\n",
      "batch 15188, train_loss 53.368687,Time used 0.011999s\n",
      "batch 15189, train_loss 58.899395,Time used 0.012002s\n",
      "batch 15190, train_loss 48.808117,Time used 0.009000s\n",
      "batch 15191, train_loss 55.810825,Time used 0.007999s\n",
      "batch 15192, train_loss 61.748478,Time used 0.012002s\n",
      "batch 15193, train_loss 47.191326,Time used 0.010998s\n",
      "batch 15194, train_loss 47.384945,Time used 0.011000s\n",
      "batch 15195, train_loss 53.925625,Time used 0.012001s\n",
      "batch 15196, train_loss 49.958885,Time used 0.011999s\n",
      "batch 15197, train_loss 40.790840,Time used 0.011002s\n",
      "batch 15198, train_loss 36.681198,Time used 0.009001s\n",
      "batch 15199, train_loss 65.104630,Time used 0.012000s\n",
      "batch 15200, train_loss 56.779587,Time used 0.012001s\n",
      "***************************test_batch 15200, test_rmse_loss 8.150459,test_mae_loss 3.358370,test_mape_loss 54.280737,Time used 0.046999s\n",
      "batch 15201, train_loss 54.208641,Time used 0.012997s\n",
      "batch 15202, train_loss 50.858654,Time used 0.009004s\n",
      "batch 15203, train_loss 45.299473,Time used 0.009001s\n",
      "batch 15204, train_loss 42.198956,Time used 0.008997s\n",
      "batch 15205, train_loss 54.064690,Time used 0.008999s\n",
      "batch 15206, train_loss 43.598949,Time used 0.009000s\n",
      "batch 15207, train_loss 51.577820,Time used 0.008002s\n",
      "batch 15208, train_loss 48.439907,Time used 0.010999s\n",
      "batch 15209, train_loss 59.780796,Time used 0.011000s\n",
      "batch 15210, train_loss 51.153339,Time used 0.010999s\n",
      "batch 15211, train_loss 42.909866,Time used 0.011001s\n",
      "batch 15212, train_loss 44.318607,Time used 0.012000s\n",
      "batch 15213, train_loss 55.363136,Time used 0.011999s\n",
      "batch 15214, train_loss 47.666775,Time used 0.011000s\n",
      "batch 15215, train_loss 55.394970,Time used 0.009000s\n",
      "batch 15216, train_loss 48.945896,Time used 0.008001s\n",
      "batch 15217, train_loss 59.457001,Time used 0.011997s\n",
      "batch 15218, train_loss 47.980499,Time used 0.010003s\n",
      "batch 15219, train_loss 45.974960,Time used 0.008999s\n",
      "batch 15220, train_loss 53.041065,Time used 0.011002s\n",
      "batch 15221, train_loss 59.659630,Time used 0.012002s\n",
      "batch 15222, train_loss 53.976879,Time used 0.011998s\n",
      "batch 15223, train_loss 48.281139,Time used 0.008000s\n",
      "batch 15224, train_loss 54.042564,Time used 0.011998s\n",
      "batch 15225, train_loss 39.854988,Time used 0.012002s\n",
      "batch 15226, train_loss 52.567841,Time used 0.010000s\n",
      "batch 15227, train_loss 48.411255,Time used 0.007999s\n",
      "batch 15228, train_loss 43.256275,Time used 0.009000s\n",
      "batch 15229, train_loss 59.490700,Time used 0.010000s\n",
      "batch 15230, train_loss 38.993568,Time used 0.012000s\n",
      "batch 15231, train_loss 47.298504,Time used 0.011000s\n",
      "batch 15232, train_loss 50.937843,Time used 0.012001s\n",
      "batch 15233, train_loss 51.847046,Time used 0.011999s\n",
      "batch 15234, train_loss 45.622784,Time used 0.012001s\n",
      "batch 15235, train_loss 51.618645,Time used 0.011998s\n",
      "batch 15236, train_loss 43.645699,Time used 0.011005s\n",
      "batch 15237, train_loss 49.698555,Time used 0.008998s\n",
      "batch 15238, train_loss 39.840118,Time used 0.009002s\n",
      "batch 15239, train_loss 50.821079,Time used 0.011006s\n",
      "batch 15240, train_loss 55.401997,Time used 0.011998s\n",
      "batch 15241, train_loss 52.144009,Time used 0.012000s\n",
      "batch 15242, train_loss 48.271873,Time used 0.008006s\n",
      "batch 15243, train_loss 40.549934,Time used 0.008999s\n",
      "batch 15244, train_loss 44.371971,Time used 0.009997s\n",
      "batch 15245, train_loss 42.961872,Time used 0.010999s\n",
      "batch 15246, train_loss 53.767849,Time used 0.010004s\n",
      "batch 15247, train_loss 48.915897,Time used 0.010999s\n",
      "batch 15248, train_loss 49.252510,Time used 0.009000s\n",
      "batch 15249, train_loss 49.514164,Time used 0.008000s\n",
      "batch 15250, train_loss 61.539745,Time used 0.012000s\n",
      "batch 15251, train_loss 51.214016,Time used 0.008998s\n",
      "batch 15252, train_loss 53.671936,Time used 0.011999s\n",
      "batch 15253, train_loss 43.977730,Time used 0.011001s\n",
      "batch 15254, train_loss 43.868210,Time used 0.012002s\n",
      "batch 15255, train_loss 50.777992,Time used 0.011999s\n",
      "batch 15256, train_loss 68.024612,Time used 0.011999s\n",
      "batch 15257, train_loss 47.818047,Time used 0.010999s\n",
      "batch 15258, train_loss 59.858917,Time used 0.011002s\n",
      "batch 15259, train_loss 49.745560,Time used 0.010001s\n",
      "batch 15260, train_loss 54.026115,Time used 0.008998s\n",
      "batch 15261, train_loss 40.205833,Time used 0.012000s\n",
      "batch 15262, train_loss 43.200134,Time used 0.011999s\n",
      "batch 15263, train_loss 42.590961,Time used 0.011002s\n",
      "batch 15264, train_loss 49.272743,Time used 0.012001s\n",
      "batch 15265, train_loss 59.874866,Time used 0.011000s\n",
      "batch 15266, train_loss 45.642086,Time used 0.012002s\n",
      "batch 15267, train_loss 53.289841,Time used 0.010998s\n",
      "batch 15268, train_loss 43.276043,Time used 0.009001s\n",
      "batch 15269, train_loss 67.293526,Time used 0.009002s\n",
      "batch 15270, train_loss 52.496456,Time used 0.009996s\n",
      "batch 15271, train_loss 39.869183,Time used 0.008002s\n",
      "batch 15272, train_loss 50.841621,Time used 0.008001s\n",
      "batch 15273, train_loss 48.005524,Time used 0.009000s\n",
      "batch 15274, train_loss 48.718739,Time used 0.008001s\n",
      "batch 15275, train_loss 45.046425,Time used 0.012000s\n",
      "batch 15276, train_loss 43.123226,Time used 0.010998s\n",
      "batch 15277, train_loss 47.709106,Time used 0.013002s\n",
      "batch 15278, train_loss 50.361706,Time used 0.008998s\n",
      "batch 15279, train_loss 50.242817,Time used 0.008000s\n",
      "batch 15280, train_loss 64.923309,Time used 0.009999s\n",
      "batch 15281, train_loss 68.449486,Time used 0.012002s\n",
      "batch 15282, train_loss 46.874882,Time used 0.008000s\n",
      "batch 15283, train_loss 41.639626,Time used 0.009998s\n",
      "batch 15284, train_loss 46.846851,Time used 0.011002s\n",
      "batch 15285, train_loss 49.948586,Time used 0.012000s\n",
      "batch 15286, train_loss 29.542585,Time used 0.010998s\n",
      "batch 15287, train_loss 52.219471,Time used 0.011002s\n",
      "batch 15288, train_loss 40.847652,Time used 0.010001s\n",
      "batch 15289, train_loss 47.279682,Time used 0.012000s\n",
      "batch 15290, train_loss 30.739695,Time used 0.012000s\n",
      "batch 15291, train_loss 54.195007,Time used 0.009999s\n",
      "batch 15292, train_loss 44.500771,Time used 0.011999s\n",
      "batch 15293, train_loss 54.816334,Time used 0.012002s\n",
      "batch 15294, train_loss 42.052681,Time used 0.007000s\n",
      "batch 15295, train_loss 46.458447,Time used 0.010000s\n",
      "batch 15296, train_loss 52.022587,Time used 0.007999s\n",
      "batch 15297, train_loss 52.828506,Time used 0.011001s\n",
      "batch 15298, train_loss 49.690163,Time used 0.010000s\n",
      "batch 15299, train_loss 38.957260,Time used 0.008999s\n",
      "batch 15300, train_loss 53.950577,Time used 0.010002s\n",
      "***************************test_batch 15300, test_rmse_loss 8.126990,test_mae_loss 3.350156,test_mape_loss 54.269642,Time used 0.041000s\n",
      "batch 15301, train_loss 47.962631,Time used 0.012003s\n",
      "batch 15302, train_loss 41.190369,Time used 0.011999s\n",
      "batch 15303, train_loss 44.116375,Time used 0.009999s\n",
      "batch 15304, train_loss 48.366184,Time used 0.010000s\n",
      "batch 15305, train_loss 49.761852,Time used 0.010000s\n",
      "batch 15306, train_loss 52.277756,Time used 0.008000s\n",
      "batch 15307, train_loss 59.810135,Time used 0.009000s\n",
      "batch 15308, train_loss 50.334370,Time used 0.007999s\n",
      "batch 15309, train_loss 55.007507,Time used 0.009997s\n",
      "batch 15310, train_loss 48.174885,Time used 0.007000s\n",
      "batch 15311, train_loss 63.316090,Time used 0.008003s\n",
      "batch 15312, train_loss 58.354374,Time used 0.006998s\n",
      "batch 15313, train_loss 59.212193,Time used 0.007999s\n",
      "batch 15314, train_loss 40.294041,Time used 0.009000s\n",
      "batch 15315, train_loss 56.915501,Time used 0.008001s\n",
      "batch 15316, train_loss 41.927601,Time used 0.007999s\n",
      "batch 15317, train_loss 44.005421,Time used 0.007002s\n",
      "batch 15318, train_loss 46.373291,Time used 0.007998s\n",
      "batch 15319, train_loss 50.592125,Time used 0.008002s\n",
      "batch 15320, train_loss 44.620129,Time used 0.010001s\n",
      "batch 15321, train_loss 43.901142,Time used 0.008999s\n",
      "batch 15322, train_loss 50.445671,Time used 0.008000s\n",
      "batch 15323, train_loss 46.224499,Time used 0.008000s\n",
      "batch 15324, train_loss 52.930599,Time used 0.008034s\n",
      "batch 15325, train_loss 35.825512,Time used 0.007964s\n",
      "batch 15326, train_loss 51.237125,Time used 0.008000s\n",
      "batch 15327, train_loss 49.903877,Time used 0.008001s\n",
      "batch 15328, train_loss 46.551708,Time used 0.008034s\n",
      "batch 15329, train_loss 44.470413,Time used 0.007002s\n",
      "batch 15330, train_loss 43.058285,Time used 0.007036s\n",
      "batch 15331, train_loss 54.728046,Time used 0.008961s\n",
      "batch 15332, train_loss 53.121243,Time used 0.012001s\n",
      "batch 15333, train_loss 56.719181,Time used 0.008002s\n",
      "batch 15334, train_loss 55.377747,Time used 0.008996s\n",
      "batch 15335, train_loss 48.368366,Time used 0.012000s\n",
      "batch 15336, train_loss 67.928787,Time used 0.011037s\n",
      "batch 15337, train_loss 44.873577,Time used 0.008033s\n",
      "batch 15338, train_loss 46.775795,Time used 0.009964s\n",
      "batch 15339, train_loss 56.951805,Time used 0.010999s\n",
      "batch 15340, train_loss 58.354534,Time used 0.008998s\n",
      "batch 15341, train_loss 49.614346,Time used 0.010000s\n",
      "batch 15342, train_loss 42.669727,Time used 0.006998s\n",
      "batch 15343, train_loss 45.076359,Time used 0.008000s\n",
      "batch 15344, train_loss 52.418663,Time used 0.010000s\n",
      "batch 15345, train_loss 52.272697,Time used 0.008037s\n",
      "batch 15346, train_loss 47.225212,Time used 0.007000s\n",
      "batch 15347, train_loss 41.270061,Time used 0.009998s\n",
      "batch 15348, train_loss 42.952938,Time used 0.007962s\n",
      "batch 15349, train_loss 45.069645,Time used 0.008999s\n",
      "batch 15350, train_loss 52.111507,Time used 0.008008s\n",
      "batch 15351, train_loss 46.262722,Time used 0.010994s\n",
      "batch 15352, train_loss 55.775402,Time used 0.009998s\n",
      "batch 15353, train_loss 52.066296,Time used 0.012001s\n",
      "batch 15354, train_loss 47.050877,Time used 0.008034s\n",
      "batch 15355, train_loss 48.859032,Time used 0.007000s\n",
      "batch 15356, train_loss 54.862267,Time used 0.007964s\n",
      "batch 15357, train_loss 49.281208,Time used 0.008999s\n",
      "batch 15358, train_loss 58.991600,Time used 0.010999s\n",
      "batch 15359, train_loss 46.635098,Time used 0.009001s\n",
      "batch 15360, train_loss 44.459957,Time used 0.008000s\n",
      "batch 15361, train_loss 52.735306,Time used 0.007997s\n",
      "batch 15362, train_loss 49.305546,Time used 0.008999s\n",
      "batch 15363, train_loss 51.046738,Time used 0.006999s\n",
      "batch 15364, train_loss 45.188892,Time used 0.007041s\n",
      "batch 15365, train_loss 49.629044,Time used 0.009958s\n",
      "batch 15366, train_loss 58.142269,Time used 0.007002s\n",
      "batch 15367, train_loss 44.260242,Time used 0.008033s\n",
      "batch 15368, train_loss 46.627296,Time used 0.009001s\n",
      "batch 15369, train_loss 55.936066,Time used 0.008966s\n",
      "batch 15370, train_loss 43.856644,Time used 0.007000s\n",
      "batch 15371, train_loss 43.181396,Time used 0.008003s\n",
      "batch 15372, train_loss 53.628525,Time used 0.010000s\n",
      "batch 15373, train_loss 56.195499,Time used 0.010000s\n",
      "batch 15374, train_loss 55.302792,Time used 0.011001s\n",
      "batch 15375, train_loss 49.862892,Time used 0.012034s\n",
      "batch 15376, train_loss 43.519680,Time used 0.007965s\n",
      "batch 15377, train_loss 45.644638,Time used 0.012000s\n",
      "batch 15378, train_loss 38.680119,Time used 0.008003s\n",
      "batch 15379, train_loss 51.470947,Time used 0.010033s\n",
      "batch 15380, train_loss 43.845951,Time used 0.008966s\n",
      "batch 15381, train_loss 50.337360,Time used 0.007998s\n",
      "batch 15382, train_loss 51.788921,Time used 0.008000s\n",
      "batch 15383, train_loss 48.661430,Time used 0.010034s\n",
      "batch 15384, train_loss 50.934784,Time used 0.010966s\n",
      "batch 15385, train_loss 46.879528,Time used 0.008968s\n",
      "batch 15386, train_loss 57.488018,Time used 0.010999s\n",
      "batch 15387, train_loss 45.284245,Time used 0.008999s\n",
      "batch 15388, train_loss 37.699692,Time used 0.009000s\n",
      "batch 15389, train_loss 39.592930,Time used 0.007000s\n",
      "batch 15390, train_loss 48.855362,Time used 0.008002s\n",
      "batch 15391, train_loss 40.207554,Time used 0.007001s\n",
      "batch 15392, train_loss 43.602043,Time used 0.008000s\n",
      "batch 15393, train_loss 56.350056,Time used 0.009000s\n",
      "batch 15394, train_loss 60.666416,Time used 0.011000s\n",
      "batch 15395, train_loss 58.835739,Time used 0.012000s\n",
      "batch 15396, train_loss 40.390301,Time used 0.011000s\n",
      "batch 15397, train_loss 30.093668,Time used 0.009001s\n",
      "batch 15398, train_loss 43.289776,Time used 0.007999s\n",
      "batch 15399, train_loss 58.765152,Time used 0.008000s\n",
      "batch 15400, train_loss 58.587753,Time used 0.010000s\n",
      "***************************test_batch 15400, test_rmse_loss 8.101409,test_mae_loss 3.340055,test_mape_loss 54.042820,Time used 0.031001s\n",
      "batch 15401, train_loss 61.027321,Time used 0.007998s\n",
      "batch 15402, train_loss 60.851856,Time used 0.009001s\n",
      "batch 15403, train_loss 46.214878,Time used 0.008000s\n",
      "batch 15404, train_loss 41.924881,Time used 0.009997s\n",
      "batch 15405, train_loss 58.028454,Time used 0.007001s\n",
      "batch 15406, train_loss 51.752838,Time used 0.008001s\n",
      "batch 15407, train_loss 41.485271,Time used 0.007998s\n",
      "batch 15408, train_loss 50.055035,Time used 0.008002s\n",
      "batch 15409, train_loss 43.355526,Time used 0.008999s\n",
      "batch 15410, train_loss 55.249130,Time used 0.012000s\n",
      "batch 15411, train_loss 41.511181,Time used 0.010998s\n",
      "batch 15412, train_loss 52.457703,Time used 0.012001s\n",
      "batch 15413, train_loss 51.811275,Time used 0.012000s\n",
      "batch 15414, train_loss 54.153694,Time used 0.010000s\n",
      "batch 15415, train_loss 38.285881,Time used 0.008002s\n",
      "batch 15416, train_loss 45.666748,Time used 0.006998s\n",
      "batch 15417, train_loss 61.511257,Time used 0.010001s\n",
      "batch 15418, train_loss 50.907471,Time used 0.009999s\n",
      "batch 15419, train_loss 46.296234,Time used 0.012002s\n",
      "batch 15420, train_loss 44.130863,Time used 0.010000s\n",
      "batch 15421, train_loss 50.132442,Time used 0.008000s\n",
      "batch 15422, train_loss 43.582348,Time used 0.008006s\n",
      "batch 15423, train_loss 42.365322,Time used 0.010994s\n",
      "batch 15424, train_loss 42.134823,Time used 0.007999s\n",
      "batch 15425, train_loss 62.672821,Time used 0.008003s\n",
      "batch 15426, train_loss 41.857780,Time used 0.010998s\n",
      "batch 15427, train_loss 58.771202,Time used 0.011998s\n",
      "batch 15428, train_loss 39.212784,Time used 0.010002s\n",
      "batch 15429, train_loss 43.256302,Time used 0.011999s\n",
      "batch 15430, train_loss 52.014965,Time used 0.010999s\n",
      "batch 15431, train_loss 58.648354,Time used 0.009000s\n",
      "batch 15432, train_loss 56.344307,Time used 0.012000s\n",
      "batch 15433, train_loss 48.806011,Time used 0.011001s\n",
      "batch 15434, train_loss 39.776009,Time used 0.011000s\n",
      "batch 15435, train_loss 40.881680,Time used 0.012003s\n",
      "batch 15436, train_loss 52.655502,Time used 0.008997s\n",
      "batch 15437, train_loss 42.497353,Time used 0.010001s\n",
      "batch 15438, train_loss 64.261345,Time used 0.011004s\n",
      "batch 15439, train_loss 47.168209,Time used 0.008038s\n",
      "batch 15440, train_loss 45.322048,Time used 0.009960s\n",
      "batch 15441, train_loss 52.040283,Time used 0.008001s\n",
      "batch 15442, train_loss 51.541885,Time used 0.007002s\n",
      "batch 15443, train_loss 49.709061,Time used 0.011000s\n",
      "batch 15444, train_loss 53.678959,Time used 0.010000s\n",
      "batch 15445, train_loss 49.256065,Time used 0.008002s\n",
      "batch 15446, train_loss 41.961586,Time used 0.010997s\n",
      "batch 15447, train_loss 49.490749,Time used 0.012001s\n",
      "batch 15448, train_loss 47.144260,Time used 0.011998s\n",
      "batch 15449, train_loss 47.150791,Time used 0.009000s\n",
      "batch 15450, train_loss 48.502785,Time used 0.012000s\n",
      "batch 15451, train_loss 44.698170,Time used 0.012006s\n",
      "batch 15452, train_loss 47.772602,Time used 0.008996s\n",
      "batch 15453, train_loss 57.035820,Time used 0.011001s\n",
      "batch 15454, train_loss 44.960094,Time used 0.010000s\n",
      "batch 15455, train_loss 57.509998,Time used 0.010998s\n",
      "batch 15456, train_loss 50.179096,Time used 0.011000s\n",
      "batch 15457, train_loss 51.487064,Time used 0.008998s\n",
      "batch 15458, train_loss 40.143520,Time used 0.008004s\n",
      "batch 15459, train_loss 47.803471,Time used 0.009001s\n",
      "batch 15460, train_loss 60.701866,Time used 0.008000s\n",
      "batch 15461, train_loss 57.258289,Time used 0.008997s\n",
      "batch 15462, train_loss 49.393230,Time used 0.010005s\n",
      "batch 15463, train_loss 60.442806,Time used 0.011998s\n",
      "batch 15464, train_loss 49.781204,Time used 0.011000s\n",
      "batch 15465, train_loss 41.599915,Time used 0.009002s\n",
      "batch 15466, train_loss 61.884434,Time used 0.010997s\n",
      "batch 15467, train_loss 47.977043,Time used 0.012002s\n",
      "batch 15468, train_loss 40.409550,Time used 0.012002s\n",
      "batch 15469, train_loss 48.660740,Time used 0.010999s\n",
      "batch 15470, train_loss 45.831081,Time used 0.013003s\n",
      "batch 15471, train_loss 42.858887,Time used 0.009999s\n",
      "batch 15472, train_loss 47.263180,Time used 0.008998s\n",
      "batch 15473, train_loss 46.954395,Time used 0.009001s\n",
      "batch 15474, train_loss 44.175560,Time used 0.011002s\n",
      "batch 15475, train_loss 52.328003,Time used 0.008001s\n",
      "batch 15476, train_loss 43.959789,Time used 0.009997s\n",
      "batch 15477, train_loss 48.875412,Time used 0.011003s\n",
      "batch 15478, train_loss 52.589272,Time used 0.009999s\n",
      "batch 15479, train_loss 51.361820,Time used 0.007998s\n",
      "batch 15480, train_loss 37.906384,Time used 0.009998s\n",
      "batch 15481, train_loss 55.789886,Time used 0.008002s\n",
      "batch 15482, train_loss 41.348331,Time used 0.010003s\n",
      "batch 15483, train_loss 64.892204,Time used 0.008998s\n",
      "batch 15484, train_loss 35.958862,Time used 0.008003s\n",
      "batch 15485, train_loss 57.998405,Time used 0.009997s\n",
      "batch 15486, train_loss 53.282990,Time used 0.010999s\n",
      "batch 15487, train_loss 50.760250,Time used 0.011001s\n",
      "batch 15488, train_loss 41.197220,Time used 0.009000s\n",
      "batch 15489, train_loss 44.450069,Time used 0.008000s\n",
      "batch 15490, train_loss 54.776596,Time used 0.011999s\n",
      "batch 15491, train_loss 47.035851,Time used 0.008000s\n",
      "batch 15492, train_loss 55.316467,Time used 0.008003s\n",
      "batch 15493, train_loss 60.572231,Time used 0.010999s\n",
      "batch 15494, train_loss 47.808620,Time used 0.011002s\n",
      "batch 15495, train_loss 45.595615,Time used 0.008002s\n",
      "batch 15496, train_loss 43.589943,Time used 0.009998s\n",
      "batch 15497, train_loss 43.838112,Time used 0.008002s\n",
      "batch 15498, train_loss 45.893276,Time used 0.009999s\n",
      "batch 15499, train_loss 45.432186,Time used 0.010999s\n",
      "batch 15500, train_loss 33.409378,Time used 0.007998s\n",
      "***************************test_batch 15500, test_rmse_loss 8.068246,test_mae_loss 3.336531,test_mape_loss 54.288375,Time used 0.041002s\n",
      "batch 15501, train_loss 66.102104,Time used 0.011998s\n",
      "batch 15502, train_loss 51.049469,Time used 0.009003s\n",
      "batch 15503, train_loss 43.232002,Time used 0.010999s\n",
      "batch 15504, train_loss 40.605572,Time used 0.010998s\n",
      "batch 15505, train_loss 50.509098,Time used 0.010003s\n",
      "batch 15506, train_loss 53.389988,Time used 0.007998s\n",
      "batch 15507, train_loss 45.422657,Time used 0.007999s\n",
      "batch 15508, train_loss 57.076675,Time used 0.008000s\n",
      "batch 15509, train_loss 37.279774,Time used 0.007001s\n",
      "batch 15510, train_loss 45.100948,Time used 0.010005s\n",
      "batch 15511, train_loss 55.497623,Time used 0.008996s\n",
      "batch 15512, train_loss 48.043007,Time used 0.010999s\n",
      "batch 15513, train_loss 54.244778,Time used 0.011002s\n",
      "batch 15514, train_loss 46.286594,Time used 0.011003s\n",
      "batch 15515, train_loss 44.200584,Time used 0.008998s\n",
      "batch 15516, train_loss 47.823853,Time used 0.007999s\n",
      "batch 15517, train_loss 41.037273,Time used 0.008001s\n",
      "batch 15518, train_loss 50.074425,Time used 0.010000s\n",
      "batch 15519, train_loss 51.153568,Time used 0.008003s\n",
      "batch 15520, train_loss 59.407337,Time used 0.011997s\n",
      "batch 15521, train_loss 44.799332,Time used 0.011002s\n",
      "batch 15522, train_loss 49.001114,Time used 0.009002s\n",
      "batch 15523, train_loss 50.469540,Time used 0.011998s\n",
      "batch 15524, train_loss 55.980209,Time used 0.010000s\n",
      "batch 15525, train_loss 44.122112,Time used 0.008999s\n",
      "batch 15526, train_loss 52.168495,Time used 0.012000s\n",
      "batch 15527, train_loss 40.942265,Time used 0.010000s\n",
      "batch 15528, train_loss 43.720631,Time used 0.008000s\n",
      "batch 15529, train_loss 36.554913,Time used 0.007000s\n",
      "batch 15530, train_loss 52.277756,Time used 0.008003s\n",
      "batch 15531, train_loss 50.202702,Time used 0.012000s\n",
      "batch 15532, train_loss 46.051571,Time used 0.012000s\n",
      "batch 15533, train_loss 50.616909,Time used 0.010000s\n",
      "batch 15534, train_loss 55.763664,Time used 0.012000s\n",
      "batch 15535, train_loss 51.368225,Time used 0.010001s\n",
      "batch 15536, train_loss 41.370956,Time used 0.008000s\n",
      "batch 15537, train_loss 54.701927,Time used 0.009001s\n",
      "batch 15538, train_loss 54.525444,Time used 0.010999s\n",
      "batch 15539, train_loss 55.169094,Time used 0.008001s\n",
      "batch 15540, train_loss 40.352905,Time used 0.009998s\n",
      "batch 15541, train_loss 48.528904,Time used 0.010002s\n",
      "batch 15542, train_loss 60.872849,Time used 0.012000s\n",
      "batch 15543, train_loss 57.270603,Time used 0.012002s\n",
      "batch 15544, train_loss 35.938179,Time used 0.011998s\n",
      "batch 15545, train_loss 47.095760,Time used 0.011004s\n",
      "batch 15546, train_loss 54.026581,Time used 0.010999s\n",
      "batch 15547, train_loss 42.777481,Time used 0.008006s\n",
      "batch 15548, train_loss 31.637609,Time used 0.010994s\n",
      "batch 15549, train_loss 48.850536,Time used 0.008998s\n",
      "batch 15550, train_loss 53.146870,Time used 0.007001s\n",
      "batch 15551, train_loss 44.340271,Time used 0.009004s\n",
      "batch 15552, train_loss 52.824436,Time used 0.011001s\n",
      "batch 15553, train_loss 51.548252,Time used 0.010999s\n",
      "batch 15554, train_loss 40.011982,Time used 0.009000s\n",
      "batch 15555, train_loss 49.957882,Time used 0.008000s\n",
      "batch 15556, train_loss 49.172455,Time used 0.007002s\n",
      "batch 15557, train_loss 53.269691,Time used 0.009001s\n",
      "batch 15558, train_loss 54.319344,Time used 0.012002s\n",
      "batch 15559, train_loss 47.932472,Time used 0.010997s\n",
      "batch 15560, train_loss 46.835854,Time used 0.011999s\n",
      "batch 15561, train_loss 55.749531,Time used 0.018002s\n",
      "batch 15562, train_loss 60.111755,Time used 0.011998s\n",
      "batch 15563, train_loss 39.386574,Time used 0.011000s\n",
      "batch 15564, train_loss 49.902119,Time used 0.010002s\n",
      "batch 15565, train_loss 37.244747,Time used 0.008000s\n",
      "batch 15566, train_loss 30.748034,Time used 0.010997s\n",
      "batch 15567, train_loss 50.297100,Time used 0.007999s\n",
      "batch 15568, train_loss 38.712357,Time used 0.009001s\n",
      "batch 15569, train_loss 59.099834,Time used 0.010997s\n",
      "batch 15570, train_loss 41.232052,Time used 0.011001s\n",
      "batch 15571, train_loss 56.246159,Time used 0.011000s\n",
      "batch 15572, train_loss 59.762222,Time used 0.010000s\n",
      "batch 15573, train_loss 37.266788,Time used 0.010998s\n",
      "batch 15574, train_loss 46.509148,Time used 0.011000s\n",
      "batch 15575, train_loss 45.387012,Time used 0.010999s\n",
      "batch 15576, train_loss 64.215378,Time used 0.011999s\n",
      "batch 15577, train_loss 68.964836,Time used 0.011001s\n",
      "batch 15578, train_loss 44.876484,Time used 0.009998s\n",
      "batch 15579, train_loss 45.975788,Time used 0.010002s\n",
      "batch 15580, train_loss 55.301487,Time used 0.009004s\n",
      "batch 15581, train_loss 41.413502,Time used 0.011993s\n",
      "batch 15582, train_loss 44.743141,Time used 0.011004s\n",
      "batch 15583, train_loss 39.964859,Time used 0.011998s\n",
      "batch 15584, train_loss 54.749008,Time used 0.012000s\n",
      "batch 15585, train_loss 56.193691,Time used 0.012002s\n",
      "batch 15586, train_loss 51.446880,Time used 0.008998s\n",
      "batch 15587, train_loss 34.241413,Time used 0.009999s\n",
      "batch 15588, train_loss 45.834763,Time used 0.012002s\n",
      "batch 15589, train_loss 45.492683,Time used 0.009998s\n",
      "batch 15590, train_loss 41.920982,Time used 0.012004s\n",
      "batch 15591, train_loss 44.082630,Time used 0.010999s\n",
      "batch 15592, train_loss 55.583370,Time used 0.008000s\n",
      "batch 15593, train_loss 51.912651,Time used 0.011999s\n",
      "batch 15594, train_loss 42.203205,Time used 0.013000s\n",
      "batch 15595, train_loss 38.768974,Time used 0.012001s\n",
      "batch 15596, train_loss 56.925751,Time used 0.012999s\n",
      "batch 15597, train_loss 58.880733,Time used 0.011001s\n",
      "batch 15598, train_loss 53.319965,Time used 0.007999s\n",
      "batch 15599, train_loss 43.062515,Time used 0.008001s\n",
      "batch 15600, train_loss 46.714310,Time used 0.010000s\n",
      "***************************test_batch 15600, test_rmse_loss 8.045243,test_mae_loss 3.325417,test_mape_loss 54.153470,Time used 0.040998s\n",
      "batch 15601, train_loss 40.936039,Time used 0.008997s\n",
      "batch 15602, train_loss 52.973984,Time used 0.008000s\n",
      "batch 15603, train_loss 55.003994,Time used 0.011001s\n",
      "batch 15604, train_loss 55.390125,Time used 0.009001s\n",
      "batch 15605, train_loss 50.317650,Time used 0.007001s\n",
      "batch 15606, train_loss 40.248398,Time used 0.010000s\n",
      "batch 15607, train_loss 50.851101,Time used 0.011998s\n",
      "batch 15608, train_loss 47.559738,Time used 0.012003s\n",
      "batch 15609, train_loss 49.944275,Time used 0.008996s\n",
      "batch 15610, train_loss 40.216442,Time used 0.008000s\n",
      "batch 15611, train_loss 50.422054,Time used 0.010000s\n",
      "batch 15612, train_loss 49.985119,Time used 0.011002s\n",
      "batch 15613, train_loss 41.552200,Time used 0.007999s\n",
      "batch 15614, train_loss 52.260021,Time used 0.009000s\n",
      "batch 15615, train_loss 49.313786,Time used 0.007001s\n",
      "batch 15616, train_loss 48.625343,Time used 0.007999s\n",
      "batch 15617, train_loss 49.478325,Time used 0.007999s\n",
      "batch 15618, train_loss 58.764553,Time used 0.009001s\n",
      "batch 15619, train_loss 52.029598,Time used 0.010000s\n",
      "batch 15620, train_loss 42.436935,Time used 0.009000s\n",
      "batch 15621, train_loss 50.469784,Time used 0.008000s\n",
      "batch 15622, train_loss 41.661495,Time used 0.008001s\n",
      "batch 15623, train_loss 49.991619,Time used 0.009001s\n",
      "batch 15624, train_loss 39.927151,Time used 0.008001s\n",
      "batch 15625, train_loss 37.323395,Time used 0.008000s\n",
      "batch 15626, train_loss 42.128304,Time used 0.008001s\n",
      "batch 15627, train_loss 41.727623,Time used 0.011000s\n",
      "batch 15628, train_loss 52.345047,Time used 0.010001s\n",
      "batch 15629, train_loss 43.800209,Time used 0.007999s\n",
      "batch 15630, train_loss 46.853970,Time used 0.009000s\n",
      "batch 15631, train_loss 52.338509,Time used 0.010000s\n",
      "batch 15632, train_loss 45.503284,Time used 0.009002s\n",
      "batch 15633, train_loss 60.765724,Time used 0.010999s\n",
      "batch 15634, train_loss 50.387207,Time used 0.012998s\n",
      "batch 15635, train_loss 50.730061,Time used 0.009002s\n",
      "batch 15636, train_loss 53.072491,Time used 0.010998s\n",
      "batch 15637, train_loss 41.926464,Time used 0.010000s\n",
      "batch 15638, train_loss 56.450531,Time used 0.009000s\n",
      "batch 15639, train_loss 41.244183,Time used 0.011002s\n",
      "batch 15640, train_loss 49.788654,Time used 0.009997s\n",
      "batch 15641, train_loss 51.352055,Time used 0.009001s\n",
      "batch 15642, train_loss 52.752995,Time used 0.012000s\n",
      "batch 15643, train_loss 43.428333,Time used 0.012001s\n",
      "batch 15644, train_loss 47.114750,Time used 0.012000s\n",
      "batch 15645, train_loss 55.473354,Time used 0.011999s\n",
      "batch 15646, train_loss 50.354656,Time used 0.008999s\n",
      "batch 15647, train_loss 48.631634,Time used 0.008001s\n",
      "batch 15648, train_loss 43.383862,Time used 0.010001s\n",
      "batch 15649, train_loss 51.957069,Time used 0.011998s\n",
      "batch 15650, train_loss 49.851189,Time used 0.011000s\n",
      "batch 15651, train_loss 41.522221,Time used 0.014000s\n",
      "batch 15652, train_loss 34.230076,Time used 0.007998s\n",
      "batch 15653, train_loss 55.426022,Time used 0.008000s\n",
      "batch 15654, train_loss 40.244415,Time used 0.012009s\n",
      "batch 15655, train_loss 55.220634,Time used 0.008991s\n",
      "batch 15656, train_loss 47.433163,Time used 0.009000s\n",
      "batch 15657, train_loss 63.245174,Time used 0.009001s\n",
      "batch 15658, train_loss 43.964226,Time used 0.010999s\n",
      "batch 15659, train_loss 56.947216,Time used 0.011001s\n",
      "batch 15660, train_loss 51.101421,Time used 0.011000s\n",
      "batch 15661, train_loss 42.443768,Time used 0.008999s\n",
      "batch 15662, train_loss 45.961960,Time used 0.008001s\n",
      "batch 15663, train_loss 46.644253,Time used 0.010998s\n",
      "batch 15664, train_loss 38.951096,Time used 0.011999s\n",
      "batch 15665, train_loss 42.855141,Time used 0.012003s\n",
      "batch 15666, train_loss 55.106869,Time used 0.008999s\n",
      "batch 15667, train_loss 44.396648,Time used 0.010000s\n",
      "batch 15668, train_loss 54.493927,Time used 0.008999s\n",
      "batch 15669, train_loss 48.451630,Time used 0.012000s\n",
      "batch 15670, train_loss 47.548389,Time used 0.010002s\n",
      "batch 15671, train_loss 45.370979,Time used 0.010996s\n",
      "batch 15672, train_loss 53.725815,Time used 0.008000s\n",
      "batch 15673, train_loss 44.705189,Time used 0.007999s\n",
      "batch 15674, train_loss 48.697811,Time used 0.009005s\n",
      "batch 15675, train_loss 44.352982,Time used 0.007997s\n",
      "batch 15676, train_loss 40.026901,Time used 0.009000s\n",
      "batch 15677, train_loss 46.168983,Time used 0.010999s\n",
      "batch 15678, train_loss 54.503872,Time used 0.010000s\n",
      "batch 15679, train_loss 49.487434,Time used 0.011999s\n",
      "batch 15680, train_loss 45.427830,Time used 0.011998s\n",
      "batch 15681, train_loss 42.805134,Time used 0.011001s\n",
      "batch 15682, train_loss 64.265800,Time used 0.011000s\n",
      "batch 15683, train_loss 50.003056,Time used 0.009999s\n",
      "batch 15684, train_loss 46.989902,Time used 0.012000s\n",
      "batch 15685, train_loss 49.552799,Time used 0.008999s\n",
      "batch 15686, train_loss 60.241676,Time used 0.009000s\n",
      "batch 15687, train_loss 56.487770,Time used 0.010999s\n",
      "batch 15688, train_loss 45.541161,Time used 0.011000s\n",
      "batch 15689, train_loss 43.211113,Time used 0.008001s\n",
      "batch 15690, train_loss 46.194870,Time used 0.008998s\n",
      "batch 15691, train_loss 42.307781,Time used 0.008001s\n",
      "batch 15692, train_loss 50.344185,Time used 0.008000s\n",
      "batch 15693, train_loss 54.732719,Time used 0.008001s\n",
      "batch 15694, train_loss 40.432896,Time used 0.010999s\n",
      "batch 15695, train_loss 40.846367,Time used 0.010999s\n",
      "batch 15696, train_loss 47.574722,Time used 0.010002s\n",
      "batch 15697, train_loss 49.112812,Time used 0.011997s\n",
      "batch 15698, train_loss 42.110619,Time used 0.012001s\n",
      "batch 15699, train_loss 45.518383,Time used 0.013002s\n",
      "batch 15700, train_loss 51.281197,Time used 0.011998s\n",
      "***************************test_batch 15700, test_rmse_loss 8.018538,test_mae_loss 3.316351,test_mape_loss 53.939517,Time used 0.038001s\n",
      "batch 15701, train_loss 40.486385,Time used 0.012000s\n",
      "batch 15702, train_loss 41.834366,Time used 0.009001s\n",
      "batch 15703, train_loss 47.964706,Time used 0.009998s\n",
      "batch 15704, train_loss 54.426170,Time used 0.012003s\n",
      "batch 15705, train_loss 56.045170,Time used 0.009998s\n",
      "batch 15706, train_loss 41.915108,Time used 0.009000s\n",
      "batch 15707, train_loss 55.091690,Time used 0.011000s\n",
      "batch 15708, train_loss 43.455173,Time used 0.010999s\n",
      "batch 15709, train_loss 44.496407,Time used 0.011999s\n",
      "batch 15710, train_loss 44.840954,Time used 0.013000s\n",
      "batch 15711, train_loss 50.368202,Time used 0.011001s\n",
      "batch 15712, train_loss 59.872608,Time used 0.012999s\n",
      "batch 15713, train_loss 45.249939,Time used 0.014003s\n",
      "batch 15714, train_loss 47.435593,Time used 0.012003s\n",
      "batch 15715, train_loss 44.602272,Time used 0.013000s\n",
      "batch 15716, train_loss 51.893528,Time used 0.012000s\n",
      "batch 15717, train_loss 48.739784,Time used 0.013003s\n",
      "batch 15718, train_loss 37.781647,Time used 0.012998s\n",
      "batch 15719, train_loss 47.213257,Time used 0.013001s\n",
      "batch 15720, train_loss 61.638325,Time used 0.011999s\n",
      "batch 15721, train_loss 38.831539,Time used 0.012999s\n",
      "batch 15722, train_loss 48.639374,Time used 0.012999s\n",
      "batch 15723, train_loss 42.505348,Time used 0.013003s\n",
      "batch 15724, train_loss 58.693420,Time used 0.010998s\n",
      "batch 15725, train_loss 51.925201,Time used 0.012002s\n",
      "batch 15726, train_loss 49.748425,Time used 0.014998s\n",
      "batch 15727, train_loss 50.389782,Time used 0.022001s\n",
      "batch 15728, train_loss 42.729870,Time used 0.024000s\n",
      "batch 15729, train_loss 37.371994,Time used 0.013999s\n",
      "batch 15730, train_loss 52.685387,Time used 0.017002s\n",
      "batch 15731, train_loss 48.983681,Time used 0.015000s\n",
      "batch 15732, train_loss 46.232914,Time used 0.023997s\n",
      "batch 15733, train_loss 38.870155,Time used 0.014001s\n",
      "batch 15734, train_loss 47.786949,Time used 0.013000s\n",
      "batch 15735, train_loss 53.056114,Time used 0.008999s\n",
      "batch 15736, train_loss 54.756470,Time used 0.013999s\n",
      "batch 15737, train_loss 59.542683,Time used 0.012001s\n",
      "batch 15738, train_loss 54.536633,Time used 0.013000s\n",
      "batch 15739, train_loss 48.702225,Time used 0.016000s\n",
      "batch 15740, train_loss 33.798241,Time used 0.016000s\n",
      "batch 15741, train_loss 54.343739,Time used 0.009999s\n",
      "batch 15742, train_loss 47.775093,Time used 0.008002s\n",
      "batch 15743, train_loss 44.339840,Time used 0.009002s\n",
      "batch 15744, train_loss 44.853081,Time used 0.011998s\n",
      "batch 15745, train_loss 49.839581,Time used 0.010000s\n",
      "batch 15746, train_loss 50.557365,Time used 0.009999s\n",
      "batch 15747, train_loss 70.597397,Time used 0.010000s\n",
      "batch 15748, train_loss 55.673416,Time used 0.011999s\n",
      "batch 15749, train_loss 49.410477,Time used 0.014000s\n",
      "batch 15750, train_loss 56.621422,Time used 0.009001s\n",
      "batch 15751, train_loss 42.754543,Time used 0.012001s\n",
      "batch 15752, train_loss 37.986362,Time used 0.011000s\n",
      "batch 15753, train_loss 31.761129,Time used 0.011999s\n",
      "batch 15754, train_loss 51.957138,Time used 0.011001s\n",
      "batch 15755, train_loss 48.372135,Time used 0.007999s\n",
      "batch 15756, train_loss 48.691654,Time used 0.010001s\n",
      "batch 15757, train_loss 48.565239,Time used 0.009999s\n",
      "batch 15758, train_loss 44.581749,Time used 0.012000s\n",
      "batch 15759, train_loss 46.357433,Time used 0.012000s\n",
      "batch 15760, train_loss 49.785919,Time used 0.009000s\n",
      "batch 15761, train_loss 42.448734,Time used 0.008000s\n",
      "batch 15762, train_loss 43.799271,Time used 0.009000s\n",
      "batch 15763, train_loss 37.883045,Time used 0.007998s\n",
      "batch 15764, train_loss 34.083195,Time used 0.008001s\n",
      "batch 15765, train_loss 52.470463,Time used 0.009001s\n",
      "batch 15766, train_loss 48.499413,Time used 0.009000s\n",
      "batch 15767, train_loss 57.849754,Time used 0.007998s\n",
      "batch 15768, train_loss 49.142162,Time used 0.011997s\n",
      "batch 15769, train_loss 50.185421,Time used 0.010000s\n",
      "batch 15770, train_loss 41.044273,Time used 0.010998s\n",
      "batch 15771, train_loss 46.970348,Time used 0.010004s\n",
      "batch 15772, train_loss 49.255203,Time used 0.007998s\n",
      "batch 15773, train_loss 53.016876,Time used 0.008997s\n",
      "batch 15774, train_loss 58.631519,Time used 0.012001s\n",
      "batch 15775, train_loss 38.991482,Time used 0.009002s\n",
      "batch 15776, train_loss 55.270603,Time used 0.009995s\n",
      "batch 15777, train_loss 43.298904,Time used 0.010998s\n",
      "batch 15778, train_loss 52.206326,Time used 0.011000s\n",
      "batch 15779, train_loss 44.932201,Time used 0.010003s\n",
      "batch 15780, train_loss 52.882568,Time used 0.011999s\n",
      "batch 15781, train_loss 51.554562,Time used 0.011000s\n",
      "batch 15782, train_loss 45.368336,Time used 0.012001s\n",
      "batch 15783, train_loss 46.642944,Time used 0.011998s\n",
      "batch 15784, train_loss 41.302723,Time used 0.012001s\n",
      "batch 15785, train_loss 44.405529,Time used 0.012999s\n",
      "batch 15786, train_loss 43.234615,Time used 0.008998s\n",
      "batch 15787, train_loss 42.422024,Time used 0.007001s\n",
      "batch 15788, train_loss 52.839348,Time used 0.008998s\n",
      "batch 15789, train_loss 55.115204,Time used 0.011001s\n",
      "batch 15790, train_loss 42.821869,Time used 0.009001s\n",
      "batch 15791, train_loss 47.518265,Time used 0.010000s\n",
      "batch 15792, train_loss 47.385078,Time used 0.011000s\n",
      "batch 15793, train_loss 52.529957,Time used 0.009000s\n",
      "batch 15794, train_loss 50.465904,Time used 0.011000s\n",
      "batch 15795, train_loss 45.788403,Time used 0.009000s\n",
      "batch 15796, train_loss 50.504826,Time used 0.008001s\n",
      "batch 15797, train_loss 46.341549,Time used 0.011001s\n",
      "batch 15798, train_loss 57.629974,Time used 0.011001s\n",
      "batch 15799, train_loss 53.077312,Time used 0.007998s\n",
      "batch 15800, train_loss 46.007008,Time used 0.011002s\n",
      "***************************test_batch 15800, test_rmse_loss 7.997675,test_mae_loss 3.304527,test_mape_loss 53.460385,Time used 0.044996s\n",
      "batch 15801, train_loss 48.361885,Time used 0.013000s\n",
      "batch 15802, train_loss 41.344284,Time used 0.012001s\n",
      "batch 15803, train_loss 39.786072,Time used 0.013001s\n",
      "batch 15804, train_loss 52.656574,Time used 0.013000s\n",
      "batch 15805, train_loss 42.194576,Time used 0.013000s\n",
      "batch 15806, train_loss 51.178333,Time used 0.011998s\n",
      "batch 15807, train_loss 44.540958,Time used 0.013001s\n",
      "batch 15808, train_loss 47.195141,Time used 0.012999s\n",
      "batch 15809, train_loss 47.196705,Time used 0.013009s\n",
      "batch 15810, train_loss 50.235687,Time used 0.013993s\n",
      "batch 15811, train_loss 41.283989,Time used 0.014000s\n",
      "batch 15812, train_loss 54.132988,Time used 0.013999s\n",
      "batch 15813, train_loss 44.051079,Time used 0.022002s\n",
      "batch 15814, train_loss 57.128967,Time used 0.014000s\n",
      "batch 15815, train_loss 41.121662,Time used 0.010001s\n",
      "batch 15816, train_loss 40.546818,Time used 0.008999s\n",
      "batch 15817, train_loss 38.306408,Time used 0.010997s\n",
      "batch 15818, train_loss 55.624374,Time used 0.014001s\n",
      "batch 15819, train_loss 44.846722,Time used 0.011999s\n",
      "batch 15820, train_loss 57.930679,Time used 0.015003s\n",
      "batch 15821, train_loss 34.447422,Time used 0.032998s\n",
      "batch 15822, train_loss 44.583050,Time used 0.013000s\n",
      "batch 15823, train_loss 41.558064,Time used 0.012999s\n",
      "batch 15824, train_loss 48.179249,Time used 0.014000s\n",
      "batch 15825, train_loss 59.838116,Time used 0.013001s\n",
      "batch 15826, train_loss 47.900269,Time used 0.014000s\n",
      "batch 15827, train_loss 51.302719,Time used 0.013998s\n",
      "batch 15828, train_loss 48.405418,Time used 0.015001s\n",
      "batch 15829, train_loss 52.991924,Time used 0.012998s\n",
      "batch 15830, train_loss 47.180264,Time used 0.011002s\n",
      "batch 15831, train_loss 48.852528,Time used 0.013000s\n",
      "batch 15832, train_loss 35.724457,Time used 0.013001s\n",
      "batch 15833, train_loss 52.044590,Time used 0.012999s\n",
      "batch 15834, train_loss 52.075382,Time used 0.020004s\n",
      "batch 15835, train_loss 48.167244,Time used 0.010996s\n",
      "batch 15836, train_loss 53.753975,Time used 0.012000s\n",
      "batch 15837, train_loss 43.651531,Time used 0.009998s\n",
      "batch 15838, train_loss 53.267628,Time used 0.009002s\n",
      "batch 15839, train_loss 41.585655,Time used 0.008001s\n",
      "batch 15840, train_loss 41.426273,Time used 0.011998s\n",
      "batch 15841, train_loss 44.416256,Time used 0.010998s\n",
      "batch 15842, train_loss 50.484653,Time used 0.011001s\n",
      "batch 15843, train_loss 51.653500,Time used 0.011999s\n",
      "batch 15844, train_loss 56.523945,Time used 0.008999s\n",
      "batch 15845, train_loss 47.905613,Time used 0.009004s\n",
      "batch 15846, train_loss 52.364662,Time used 0.008003s\n",
      "batch 15847, train_loss 50.847260,Time used 0.011997s\n",
      "batch 15848, train_loss 39.364525,Time used 0.008997s\n",
      "batch 15849, train_loss 65.843613,Time used 0.012004s\n",
      "batch 15850, train_loss 45.833588,Time used 0.010997s\n",
      "batch 15851, train_loss 47.368195,Time used 0.008002s\n",
      "batch 15852, train_loss 51.823692,Time used 0.009001s\n",
      "batch 15853, train_loss 40.372837,Time used 0.011000s\n",
      "batch 15854, train_loss 52.144661,Time used 0.012001s\n",
      "batch 15855, train_loss 40.625637,Time used 0.012000s\n",
      "batch 15856, train_loss 43.603962,Time used 0.011000s\n",
      "batch 15857, train_loss 46.607750,Time used 0.008002s\n",
      "batch 15858, train_loss 37.421627,Time used 0.008000s\n",
      "batch 15859, train_loss 42.940376,Time used 0.010997s\n",
      "batch 15860, train_loss 47.955364,Time used 0.010002s\n",
      "batch 15861, train_loss 47.268673,Time used 0.011001s\n",
      "batch 15862, train_loss 48.995934,Time used 0.011999s\n",
      "batch 15863, train_loss 38.712498,Time used 0.011999s\n",
      "batch 15864, train_loss 51.179081,Time used 0.008003s\n",
      "batch 15865, train_loss 49.337025,Time used 0.011999s\n",
      "batch 15866, train_loss 41.910881,Time used 0.007999s\n",
      "batch 15867, train_loss 47.741562,Time used 0.011000s\n",
      "batch 15868, train_loss 47.680458,Time used 0.011003s\n",
      "batch 15869, train_loss 40.186069,Time used 0.011999s\n",
      "batch 15870, train_loss 41.969139,Time used 0.011008s\n",
      "batch 15871, train_loss 51.780586,Time used 0.010997s\n",
      "batch 15872, train_loss 48.135555,Time used 0.012001s\n",
      "batch 15873, train_loss 49.094128,Time used 0.011999s\n",
      "batch 15874, train_loss 43.044159,Time used 0.010998s\n",
      "batch 15875, train_loss 49.559216,Time used 0.011001s\n",
      "batch 15876, train_loss 46.550636,Time used 0.006999s\n",
      "batch 15877, train_loss 42.307491,Time used 0.012002s\n",
      "batch 15878, train_loss 52.529953,Time used 0.012000s\n",
      "batch 15879, train_loss 57.232903,Time used 0.012001s\n",
      "batch 15880, train_loss 46.471603,Time used 0.010999s\n",
      "batch 15881, train_loss 49.311825,Time used 0.010000s\n",
      "batch 15882, train_loss 47.349762,Time used 0.011002s\n",
      "batch 15883, train_loss 49.106438,Time used 0.007999s\n",
      "batch 15884, train_loss 42.650520,Time used 0.007998s\n",
      "batch 15885, train_loss 48.423492,Time used 0.009003s\n",
      "batch 15886, train_loss 51.910160,Time used 0.007997s\n",
      "batch 15887, train_loss 51.538925,Time used 0.010005s\n",
      "batch 15888, train_loss 44.120419,Time used 0.011001s\n",
      "batch 15889, train_loss 44.827923,Time used 0.014011s\n",
      "batch 15890, train_loss 45.825588,Time used 0.014990s\n",
      "batch 15891, train_loss 48.370979,Time used 0.014001s\n",
      "batch 15892, train_loss 51.448280,Time used 0.016000s\n",
      "batch 15893, train_loss 52.574047,Time used 0.015000s\n",
      "batch 15894, train_loss 49.031326,Time used 0.030000s\n",
      "batch 15895, train_loss 50.274124,Time used 0.014988s\n",
      "batch 15896, train_loss 59.630360,Time used 0.013986s\n",
      "batch 15897, train_loss 41.933563,Time used 0.016000s\n",
      "batch 15898, train_loss 46.014210,Time used 0.015002s\n",
      "batch 15899, train_loss 41.532352,Time used 0.012999s\n",
      "batch 15900, train_loss 46.267681,Time used 0.022000s\n",
      "***************************test_batch 15900, test_rmse_loss 7.970497,test_mae_loss 3.296032,test_mape_loss 53.291567,Time used 0.059005s\n",
      "batch 15901, train_loss 51.023582,Time used 0.012999s\n",
      "batch 15902, train_loss 38.890484,Time used 0.014003s\n",
      "batch 15903, train_loss 42.168285,Time used 0.020001s\n",
      "batch 15904, train_loss 42.980068,Time used 0.016997s\n",
      "batch 15905, train_loss 44.903179,Time used 0.015000s\n",
      "batch 15906, train_loss 49.227345,Time used 0.016000s\n",
      "batch 15907, train_loss 35.426029,Time used 0.016001s\n",
      "batch 15908, train_loss 53.368237,Time used 0.015002s\n",
      "batch 15909, train_loss 51.596905,Time used 0.015996s\n",
      "batch 15910, train_loss 45.168800,Time used 0.017003s\n",
      "batch 15911, train_loss 54.919960,Time used 0.017999s\n",
      "batch 15912, train_loss 51.369411,Time used 0.013999s\n",
      "batch 15913, train_loss 43.740299,Time used 0.010000s\n",
      "batch 15914, train_loss 49.134869,Time used 0.008997s\n",
      "batch 15915, train_loss 41.991245,Time used 0.011002s\n",
      "batch 15916, train_loss 43.013069,Time used 0.009998s\n",
      "batch 15917, train_loss 45.857941,Time used 0.009999s\n",
      "batch 15918, train_loss 47.464638,Time used 0.012003s\n",
      "batch 15919, train_loss 47.009441,Time used 0.012998s\n",
      "batch 15920, train_loss 55.784641,Time used 0.012002s\n",
      "batch 15921, train_loss 43.664608,Time used 0.013003s\n",
      "batch 15922, train_loss 55.601246,Time used 0.007998s\n",
      "batch 15923, train_loss 54.844200,Time used 0.010002s\n",
      "batch 15924, train_loss 41.790173,Time used 0.017001s\n",
      "batch 15925, train_loss 56.619968,Time used 0.013000s\n",
      "batch 15926, train_loss 46.321396,Time used 0.018000s\n",
      "batch 15927, train_loss 57.558784,Time used 0.036007s\n",
      "batch 15928, train_loss 46.210068,Time used 0.016990s\n",
      "batch 15929, train_loss 44.188004,Time used 0.031002s\n",
      "batch 15930, train_loss 50.631577,Time used 0.021999s\n",
      "batch 15931, train_loss 41.158974,Time used 0.032999s\n",
      "batch 15932, train_loss 45.657974,Time used 0.028997s\n",
      "batch 15933, train_loss 44.842884,Time used 0.022000s\n",
      "batch 15934, train_loss 40.035297,Time used 0.033005s\n",
      "batch 15935, train_loss 52.299892,Time used 0.047000s\n",
      "batch 15936, train_loss 40.940361,Time used 0.025005s\n",
      "batch 15937, train_loss 53.823925,Time used 0.023997s\n",
      "batch 15938, train_loss 51.014587,Time used 0.021000s\n",
      "batch 15939, train_loss 43.919262,Time used 0.034998s\n",
      "batch 15940, train_loss 55.038063,Time used 0.019003s\n",
      "batch 15941, train_loss 36.219921,Time used 0.022997s\n",
      "batch 15942, train_loss 48.792511,Time used 0.047001s\n",
      "batch 15943, train_loss 51.662216,Time used 0.015000s\n",
      "batch 15944, train_loss 57.672997,Time used 0.009004s\n",
      "batch 15945, train_loss 57.783012,Time used 0.010989s\n",
      "batch 15946, train_loss 50.418457,Time used 0.013000s\n",
      "batch 15947, train_loss 49.749672,Time used 0.013998s\n",
      "batch 15948, train_loss 41.327869,Time used 0.013003s\n",
      "batch 15949, train_loss 52.278442,Time used 0.010000s\n",
      "batch 15950, train_loss 44.220200,Time used 0.012000s\n",
      "batch 15951, train_loss 51.634247,Time used 0.010001s\n",
      "batch 15952, train_loss 36.525234,Time used 0.011995s\n",
      "batch 15953, train_loss 39.658794,Time used 0.011004s\n",
      "batch 15954, train_loss 45.256542,Time used 0.012000s\n",
      "batch 15955, train_loss 55.506096,Time used 0.011997s\n",
      "batch 15956, train_loss 34.605053,Time used 0.012000s\n",
      "batch 15957, train_loss 34.603588,Time used 0.010000s\n",
      "batch 15958, train_loss 45.742558,Time used 0.009998s\n",
      "batch 15959, train_loss 40.947468,Time used 0.009004s\n",
      "batch 15960, train_loss 56.868793,Time used 0.012996s\n",
      "batch 15961, train_loss 42.425327,Time used 0.008996s\n",
      "batch 15962, train_loss 49.144367,Time used 0.007998s\n",
      "batch 15963, train_loss 49.032192,Time used 0.008998s\n",
      "batch 15964, train_loss 41.059582,Time used 0.008004s\n",
      "batch 15965, train_loss 45.997326,Time used 0.006999s\n",
      "batch 15966, train_loss 41.826786,Time used 0.010003s\n",
      "batch 15967, train_loss 45.602367,Time used 0.011000s\n",
      "batch 15968, train_loss 51.151787,Time used 0.010000s\n",
      "batch 15969, train_loss 41.299664,Time used 0.011004s\n",
      "batch 15970, train_loss 75.253044,Time used 0.010999s\n",
      "batch 15971, train_loss 46.138893,Time used 0.013002s\n",
      "batch 15972, train_loss 47.366558,Time used 0.014998s\n",
      "batch 15973, train_loss 41.009865,Time used 0.016007s\n",
      "batch 15974, train_loss 47.375015,Time used 0.015001s\n",
      "batch 15975, train_loss 55.806053,Time used 0.020994s\n",
      "batch 15976, train_loss 49.334259,Time used 0.019010s\n",
      "batch 15977, train_loss 48.022453,Time used 0.014000s\n",
      "batch 15978, train_loss 38.230774,Time used 0.017997s\n",
      "batch 15979, train_loss 51.220291,Time used 0.016002s\n",
      "batch 15980, train_loss 51.169998,Time used 0.018002s\n",
      "batch 15981, train_loss 39.349930,Time used 0.015997s\n",
      "batch 15982, train_loss 41.842915,Time used 0.017004s\n",
      "batch 15983, train_loss 51.949795,Time used 0.014999s\n",
      "batch 15984, train_loss 41.284462,Time used 0.015000s\n",
      "batch 15985, train_loss 38.435623,Time used 0.017995s\n",
      "batch 15986, train_loss 51.153435,Time used 0.013002s\n",
      "batch 15987, train_loss 53.354080,Time used 0.015994s\n",
      "batch 15988, train_loss 44.770687,Time used 0.019004s\n",
      "batch 15989, train_loss 57.362244,Time used 0.015006s\n",
      "batch 15990, train_loss 42.742943,Time used 0.018986s\n",
      "batch 15991, train_loss 53.107418,Time used 0.019002s\n",
      "batch 15992, train_loss 47.219177,Time used 0.015001s\n",
      "batch 15993, train_loss 37.459209,Time used 0.014999s\n",
      "batch 15994, train_loss 49.511253,Time used 0.017005s\n",
      "batch 15995, train_loss 50.805950,Time used 0.012010s\n",
      "batch 15996, train_loss 42.373035,Time used 0.012997s\n",
      "batch 15997, train_loss 45.093315,Time used 0.011995s\n",
      "batch 15998, train_loss 46.746841,Time used 0.015001s\n",
      "batch 15999, train_loss 60.956799,Time used 0.013000s\n",
      "batch 16000, train_loss 45.447189,Time used 0.014003s\n",
      "***************************test_batch 16000, test_rmse_loss 7.936788,test_mae_loss 3.291241,test_mape_loss 53.669416,Time used 0.056997s\n",
      "batch 16001, train_loss 42.459038,Time used 0.014000s\n",
      "batch 16002, train_loss 46.240520,Time used 0.015000s\n",
      "batch 16003, train_loss 53.010822,Time used 0.013001s\n",
      "batch 16004, train_loss 46.078571,Time used 0.016009s\n",
      "batch 16005, train_loss 50.858761,Time used 0.016006s\n",
      "batch 16006, train_loss 49.495255,Time used 0.022001s\n",
      "batch 16007, train_loss 39.461819,Time used 0.015999s\n",
      "batch 16008, train_loss 36.690605,Time used 0.015001s\n",
      "batch 16009, train_loss 45.621902,Time used 0.014998s\n",
      "batch 16010, train_loss 40.579803,Time used 0.019003s\n",
      "batch 16011, train_loss 52.034401,Time used 0.014001s\n",
      "batch 16012, train_loss 35.773201,Time used 0.021001s\n",
      "batch 16013, train_loss 55.863338,Time used 0.011997s\n",
      "batch 16014, train_loss 41.678604,Time used 0.013005s\n",
      "batch 16015, train_loss 44.689354,Time used 0.010017s\n",
      "batch 16016, train_loss 47.333290,Time used 0.016002s\n",
      "batch 16017, train_loss 48.731091,Time used 0.013990s\n",
      "batch 16018, train_loss 47.267029,Time used 0.014002s\n",
      "batch 16019, train_loss 46.598629,Time used 0.016001s\n",
      "batch 16020, train_loss 45.617695,Time used 0.014998s\n",
      "batch 16021, train_loss 51.535225,Time used 0.016001s\n",
      "batch 16022, train_loss 40.042683,Time used 0.017000s\n",
      "batch 16023, train_loss 49.513100,Time used 0.014999s\n",
      "batch 16024, train_loss 53.883678,Time used 0.015002s\n",
      "batch 16025, train_loss 46.052261,Time used 0.017003s\n",
      "batch 16026, train_loss 50.224403,Time used 0.019996s\n",
      "batch 16027, train_loss 39.409481,Time used 0.012999s\n",
      "batch 16028, train_loss 46.558868,Time used 0.012006s\n",
      "batch 16029, train_loss 45.172810,Time used 0.020001s\n",
      "batch 16030, train_loss 56.778927,Time used 0.017998s\n",
      "batch 16031, train_loss 44.429874,Time used 0.014999s\n",
      "batch 16032, train_loss 53.836037,Time used 0.014995s\n",
      "batch 16033, train_loss 45.270168,Time used 0.013999s\n",
      "batch 16034, train_loss 55.082657,Time used 0.012999s\n",
      "batch 16035, train_loss 32.776085,Time used 0.014000s\n",
      "batch 16036, train_loss 53.752594,Time used 0.018002s\n",
      "batch 16037, train_loss 49.677971,Time used 0.016001s\n",
      "batch 16038, train_loss 44.409096,Time used 0.014996s\n",
      "batch 16039, train_loss 42.949619,Time used 0.016006s\n",
      "batch 16040, train_loss 50.829750,Time used 0.014995s\n",
      "batch 16041, train_loss 51.953606,Time used 0.016999s\n",
      "batch 16042, train_loss 49.197701,Time used 0.018998s\n",
      "batch 16043, train_loss 33.767120,Time used 0.019001s\n",
      "batch 16044, train_loss 53.578327,Time used 0.030999s\n",
      "batch 16045, train_loss 40.491440,Time used 0.017999s\n",
      "batch 16046, train_loss 47.422565,Time used 0.026001s\n",
      "batch 16047, train_loss 43.864185,Time used 0.024000s\n",
      "batch 16048, train_loss 44.441631,Time used 0.023002s\n",
      "batch 16049, train_loss 44.298985,Time used 0.022998s\n",
      "batch 16050, train_loss 44.255665,Time used 0.027015s\n",
      "batch 16051, train_loss 49.560192,Time used 0.038988s\n",
      "batch 16052, train_loss 40.652874,Time used 0.031000s\n",
      "batch 16053, train_loss 50.439224,Time used 0.018001s\n",
      "batch 16054, train_loss 48.465359,Time used 0.030000s\n",
      "batch 16055, train_loss 55.316723,Time used 0.029003s\n",
      "batch 16056, train_loss 55.348328,Time used 0.039997s\n",
      "batch 16057, train_loss 48.989815,Time used 0.017992s\n",
      "batch 16058, train_loss 43.265686,Time used 0.018000s\n",
      "batch 16059, train_loss 55.701256,Time used 0.021002s\n",
      "batch 16060, train_loss 56.570248,Time used 0.012001s\n",
      "batch 16061, train_loss 48.166939,Time used 0.014997s\n",
      "batch 16062, train_loss 50.128174,Time used 0.013002s\n",
      "batch 16063, train_loss 55.312191,Time used 0.012999s\n",
      "batch 16064, train_loss 44.833817,Time used 0.014997s\n",
      "batch 16065, train_loss 33.725014,Time used 0.014002s\n",
      "batch 16066, train_loss 46.391899,Time used 0.013000s\n",
      "batch 16067, train_loss 40.171211,Time used 0.012999s\n",
      "batch 16068, train_loss 45.955563,Time used 0.016998s\n",
      "batch 16069, train_loss 45.983486,Time used 0.012002s\n",
      "batch 16070, train_loss 56.370529,Time used 0.011001s\n",
      "batch 16071, train_loss 40.834522,Time used 0.011998s\n",
      "batch 16072, train_loss 36.142036,Time used 0.010999s\n",
      "batch 16073, train_loss 48.395145,Time used 0.010000s\n",
      "batch 16074, train_loss 44.244923,Time used 0.011002s\n",
      "batch 16075, train_loss 60.849709,Time used 0.012000s\n",
      "batch 16076, train_loss 43.333282,Time used 0.011999s\n",
      "batch 16077, train_loss 41.608959,Time used 0.013001s\n",
      "batch 16078, train_loss 51.283722,Time used 0.010999s\n",
      "batch 16079, train_loss 41.098724,Time used 0.009998s\n",
      "batch 16080, train_loss 46.043537,Time used 0.008001s\n",
      "batch 16081, train_loss 48.338093,Time used 0.011000s\n",
      "batch 16082, train_loss 55.789352,Time used 0.008002s\n",
      "batch 16083, train_loss 55.509415,Time used 0.012001s\n",
      "batch 16084, train_loss 48.186951,Time used 0.012000s\n",
      "batch 16085, train_loss 35.779823,Time used 0.010999s\n",
      "batch 16086, train_loss 43.771755,Time used 0.009000s\n",
      "batch 16087, train_loss 51.222610,Time used 0.008000s\n",
      "batch 16088, train_loss 55.306114,Time used 0.009001s\n",
      "batch 16089, train_loss 44.947464,Time used 0.010001s\n",
      "batch 16090, train_loss 42.795391,Time used 0.011999s\n",
      "batch 16091, train_loss 39.405594,Time used 0.011000s\n",
      "batch 16092, train_loss 45.074543,Time used 0.012002s\n",
      "batch 16093, train_loss 57.989925,Time used 0.009999s\n",
      "batch 16094, train_loss 44.244030,Time used 0.012000s\n",
      "batch 16095, train_loss 40.814728,Time used 0.009000s\n",
      "batch 16096, train_loss 44.148167,Time used 0.007999s\n",
      "batch 16097, train_loss 47.636875,Time used 0.011999s\n",
      "batch 16098, train_loss 40.422409,Time used 0.010998s\n",
      "batch 16099, train_loss 41.751083,Time used 0.010000s\n",
      "batch 16100, train_loss 48.947285,Time used 0.013000s\n",
      "***************************test_batch 16100, test_rmse_loss 7.909460,test_mae_loss 3.283276,test_mape_loss 53.608677,Time used 0.049001s\n",
      "batch 16101, train_loss 51.214798,Time used 0.011001s\n",
      "batch 16102, train_loss 41.385624,Time used 0.008001s\n",
      "batch 16103, train_loss 52.460861,Time used 0.009001s\n",
      "batch 16104, train_loss 46.586628,Time used 0.010999s\n",
      "batch 16105, train_loss 47.983078,Time used 0.010998s\n",
      "batch 16106, train_loss 43.920193,Time used 0.013000s\n",
      "batch 16107, train_loss 35.000725,Time used 0.013001s\n",
      "batch 16108, train_loss 45.905186,Time used 0.013001s\n",
      "batch 16109, train_loss 43.774345,Time used 0.011997s\n",
      "batch 16110, train_loss 42.620037,Time used 0.011997s\n",
      "batch 16111, train_loss 48.190643,Time used 0.014001s\n",
      "batch 16112, train_loss 51.106586,Time used 0.012001s\n",
      "batch 16113, train_loss 36.091385,Time used 0.013001s\n",
      "batch 16114, train_loss 48.239140,Time used 0.014000s\n",
      "batch 16115, train_loss 49.663956,Time used 0.014000s\n",
      "batch 16116, train_loss 48.819557,Time used 0.013998s\n",
      "batch 16117, train_loss 55.468662,Time used 0.013001s\n",
      "batch 16118, train_loss 47.839111,Time used 0.014001s\n",
      "batch 16119, train_loss 47.259991,Time used 0.010996s\n",
      "batch 16120, train_loss 55.140442,Time used 0.010000s\n",
      "batch 16121, train_loss 42.900455,Time used 0.014001s\n",
      "batch 16122, train_loss 49.526260,Time used 0.012003s\n",
      "batch 16123, train_loss 43.021610,Time used 0.012000s\n",
      "batch 16124, train_loss 48.604076,Time used 0.013002s\n",
      "batch 16125, train_loss 54.842648,Time used 0.012998s\n",
      "batch 16126, train_loss 42.684429,Time used 0.013003s\n",
      "batch 16127, train_loss 40.628071,Time used 0.019997s\n",
      "batch 16128, train_loss 52.771107,Time used 0.023999s\n",
      "batch 16129, train_loss 45.450363,Time used 0.023998s\n",
      "batch 16130, train_loss 47.027729,Time used 0.013001s\n",
      "batch 16131, train_loss 47.751759,Time used 0.012999s\n",
      "batch 16132, train_loss 43.724613,Time used 0.014002s\n",
      "batch 16133, train_loss 45.651722,Time used 0.013000s\n",
      "batch 16134, train_loss 51.149109,Time used 0.013001s\n",
      "batch 16135, train_loss 42.442650,Time used 0.014998s\n",
      "batch 16136, train_loss 49.308678,Time used 0.014002s\n",
      "batch 16137, train_loss 49.076290,Time used 0.012000s\n",
      "batch 16138, train_loss 44.361511,Time used 0.012002s\n",
      "batch 16139, train_loss 45.662060,Time used 0.013000s\n",
      "batch 16140, train_loss 34.580849,Time used 0.012998s\n",
      "batch 16141, train_loss 51.497799,Time used 0.012996s\n",
      "batch 16142, train_loss 40.566372,Time used 0.011005s\n",
      "batch 16143, train_loss 38.214256,Time used 0.008998s\n",
      "batch 16144, train_loss 36.960888,Time used 0.010998s\n",
      "batch 16145, train_loss 45.750729,Time used 0.012003s\n",
      "batch 16146, train_loss 51.801857,Time used 0.007998s\n",
      "batch 16147, train_loss 51.703445,Time used 0.011001s\n",
      "batch 16148, train_loss 51.958870,Time used 0.008000s\n",
      "batch 16149, train_loss 50.331837,Time used 0.011002s\n",
      "batch 16150, train_loss 48.319046,Time used 0.012999s\n",
      "batch 16151, train_loss 51.341473,Time used 0.011002s\n",
      "batch 16152, train_loss 55.420918,Time used 0.007998s\n",
      "batch 16153, train_loss 47.965626,Time used 0.009001s\n",
      "batch 16154, train_loss 44.130871,Time used 0.011999s\n",
      "batch 16155, train_loss 31.534159,Time used 0.009002s\n",
      "batch 16156, train_loss 46.686871,Time used 0.007998s\n",
      "batch 16157, train_loss 41.507889,Time used 0.010998s\n",
      "batch 16158, train_loss 57.405094,Time used 0.009002s\n",
      "batch 16159, train_loss 44.399845,Time used 0.010001s\n",
      "batch 16160, train_loss 45.546658,Time used 0.011000s\n",
      "batch 16161, train_loss 45.622860,Time used 0.012001s\n",
      "batch 16162, train_loss 52.479996,Time used 0.008998s\n",
      "batch 16163, train_loss 37.492767,Time used 0.008001s\n",
      "batch 16164, train_loss 46.296513,Time used 0.008997s\n",
      "batch 16165, train_loss 45.025166,Time used 0.011002s\n",
      "batch 16166, train_loss 44.150284,Time used 0.011001s\n",
      "batch 16167, train_loss 39.846413,Time used 0.006998s\n",
      "batch 16168, train_loss 41.487686,Time used 0.008000s\n",
      "batch 16169, train_loss 56.112358,Time used 0.006998s\n",
      "batch 16170, train_loss 55.687672,Time used 0.008000s\n",
      "batch 16171, train_loss 52.478714,Time used 0.008002s\n",
      "batch 16172, train_loss 50.525185,Time used 0.007999s\n",
      "batch 16173, train_loss 45.029087,Time used 0.007999s\n",
      "batch 16174, train_loss 52.027435,Time used 0.008001s\n",
      "batch 16175, train_loss 45.889751,Time used 0.010998s\n",
      "batch 16176, train_loss 48.597534,Time used 0.012000s\n",
      "batch 16177, train_loss 42.639721,Time used 0.008002s\n",
      "batch 16178, train_loss 42.707890,Time used 0.007999s\n",
      "batch 16179, train_loss 47.491013,Time used 0.006999s\n",
      "batch 16180, train_loss 40.601280,Time used 0.008999s\n",
      "batch 16181, train_loss 46.777481,Time used 0.010001s\n",
      "batch 16182, train_loss 53.900593,Time used 0.009001s\n",
      "batch 16183, train_loss 47.240376,Time used 0.007000s\n",
      "batch 16184, train_loss 50.972870,Time used 0.011005s\n",
      "batch 16185, train_loss 40.877228,Time used 0.010998s\n",
      "batch 16186, train_loss 42.213417,Time used 0.010001s\n",
      "batch 16187, train_loss 40.891415,Time used 0.010995s\n",
      "batch 16188, train_loss 55.145210,Time used 0.011999s\n",
      "batch 16189, train_loss 48.440285,Time used 0.011002s\n",
      "batch 16190, train_loss 55.712234,Time used 0.009034s\n",
      "batch 16191, train_loss 29.378136,Time used 0.007965s\n",
      "batch 16192, train_loss 45.453236,Time used 0.007998s\n",
      "batch 16193, train_loss 54.140152,Time used 0.008037s\n",
      "batch 16194, train_loss 55.686253,Time used 0.007003s\n",
      "batch 16195, train_loss 48.175678,Time used 0.007960s\n",
      "batch 16196, train_loss 39.506523,Time used 0.007000s\n",
      "batch 16197, train_loss 44.046856,Time used 0.009007s\n",
      "batch 16198, train_loss 46.940502,Time used 0.008994s\n",
      "batch 16199, train_loss 50.278591,Time used 0.011041s\n",
      "batch 16200, train_loss 47.057896,Time used 0.007965s\n",
      "***************************test_batch 16200, test_rmse_loss 7.876070,test_mae_loss 3.272492,test_mape_loss 53.541340,Time used 0.031995s\n",
      "batch 16201, train_loss 49.042850,Time used 0.009002s\n",
      "batch 16202, train_loss 48.430202,Time used 0.007998s\n",
      "batch 16203, train_loss 50.312378,Time used 0.009002s\n",
      "batch 16204, train_loss 40.825020,Time used 0.006998s\n",
      "batch 16205, train_loss 40.925014,Time used 0.008000s\n",
      "batch 16206, train_loss 45.833828,Time used 0.010001s\n",
      "batch 16207, train_loss 43.553112,Time used 0.007999s\n",
      "batch 16208, train_loss 46.900978,Time used 0.008999s\n",
      "batch 16209, train_loss 46.472210,Time used 0.007999s\n",
      "batch 16210, train_loss 49.999340,Time used 0.007002s\n",
      "batch 16211, train_loss 50.162937,Time used 0.010998s\n",
      "batch 16212, train_loss 40.679512,Time used 0.010011s\n",
      "batch 16213, train_loss 41.952724,Time used 0.023996s\n",
      "batch 16214, train_loss 44.857170,Time used 0.011994s\n",
      "batch 16215, train_loss 51.007256,Time used 0.009000s\n",
      "batch 16216, train_loss 43.888870,Time used 0.008999s\n",
      "batch 16217, train_loss 48.338436,Time used 0.010001s\n",
      "batch 16218, train_loss 38.968578,Time used 0.012000s\n",
      "batch 16219, train_loss 42.079281,Time used 0.013000s\n",
      "batch 16220, train_loss 66.502365,Time used 0.013001s\n",
      "batch 16221, train_loss 39.451721,Time used 0.010999s\n",
      "batch 16222, train_loss 34.887875,Time used 0.010998s\n",
      "batch 16223, train_loss 57.809139,Time used 0.009001s\n",
      "batch 16224, train_loss 51.438671,Time used 0.009001s\n",
      "batch 16225, train_loss 39.447369,Time used 0.009000s\n",
      "batch 16226, train_loss 36.966572,Time used 0.008001s\n",
      "batch 16227, train_loss 43.492512,Time used 0.007998s\n",
      "batch 16228, train_loss 43.571091,Time used 0.008999s\n",
      "batch 16229, train_loss 46.899292,Time used 0.007001s\n",
      "batch 16230, train_loss 56.225929,Time used 0.008000s\n",
      "batch 16231, train_loss 45.447590,Time used 0.006999s\n",
      "batch 16232, train_loss 40.055176,Time used 0.009001s\n",
      "batch 16233, train_loss 43.434883,Time used 0.011000s\n",
      "batch 16234, train_loss 50.237476,Time used 0.008000s\n",
      "batch 16235, train_loss 55.918446,Time used 0.008001s\n",
      "batch 16236, train_loss 41.439777,Time used 0.011000s\n",
      "batch 16237, train_loss 48.040123,Time used 0.010002s\n",
      "batch 16238, train_loss 43.982384,Time used 0.009998s\n",
      "batch 16239, train_loss 56.727486,Time used 0.007001s\n",
      "batch 16240, train_loss 38.830673,Time used 0.008003s\n",
      "batch 16241, train_loss 43.021599,Time used 0.011996s\n",
      "batch 16242, train_loss 53.725853,Time used 0.008002s\n",
      "batch 16243, train_loss 45.807842,Time used 0.007998s\n",
      "batch 16244, train_loss 45.374348,Time used 0.011001s\n",
      "batch 16245, train_loss 47.211815,Time used 0.011000s\n",
      "batch 16246, train_loss 51.059292,Time used 0.009001s\n",
      "batch 16247, train_loss 48.677174,Time used 0.008999s\n",
      "batch 16248, train_loss 46.837177,Time used 0.011001s\n",
      "batch 16249, train_loss 53.452988,Time used 0.009001s\n",
      "batch 16250, train_loss 44.937351,Time used 0.009002s\n",
      "batch 16251, train_loss 51.833172,Time used 0.007998s\n",
      "batch 16252, train_loss 48.254673,Time used 0.009000s\n",
      "batch 16253, train_loss 38.807613,Time used 0.010000s\n",
      "batch 16254, train_loss 43.896828,Time used 0.012000s\n",
      "batch 16255, train_loss 33.071835,Time used 0.011001s\n",
      "batch 16256, train_loss 50.741817,Time used 0.008999s\n",
      "batch 16257, train_loss 39.577305,Time used 0.008002s\n",
      "batch 16258, train_loss 48.102585,Time used 0.009999s\n",
      "batch 16259, train_loss 55.478394,Time used 0.011998s\n",
      "batch 16260, train_loss 52.603008,Time used 0.011002s\n",
      "batch 16261, train_loss 39.614861,Time used 0.009003s\n",
      "batch 16262, train_loss 50.400356,Time used 0.009999s\n",
      "batch 16263, train_loss 42.055672,Time used 0.007002s\n",
      "batch 16264, train_loss 44.610264,Time used 0.008998s\n",
      "batch 16265, train_loss 53.369160,Time used 0.007001s\n",
      "batch 16266, train_loss 41.030548,Time used 0.010999s\n",
      "batch 16267, train_loss 41.147366,Time used 0.009999s\n",
      "batch 16268, train_loss 51.057560,Time used 0.007002s\n",
      "batch 16269, train_loss 47.731152,Time used 0.011000s\n",
      "batch 16270, train_loss 42.277866,Time used 0.011999s\n",
      "batch 16271, train_loss 46.627563,Time used 0.008999s\n",
      "batch 16272, train_loss 50.226337,Time used 0.008002s\n",
      "batch 16273, train_loss 36.721451,Time used 0.011002s\n",
      "batch 16274, train_loss 48.040066,Time used 0.011002s\n",
      "batch 16275, train_loss 43.809574,Time used 0.008996s\n",
      "batch 16276, train_loss 50.008419,Time used 0.011999s\n",
      "batch 16277, train_loss 46.876358,Time used 0.011008s\n",
      "batch 16278, train_loss 50.040035,Time used 0.013997s\n",
      "batch 16279, train_loss 49.412727,Time used 0.008996s\n",
      "batch 16280, train_loss 49.415977,Time used 0.007999s\n",
      "batch 16281, train_loss 47.997932,Time used 0.012003s\n",
      "batch 16282, train_loss 57.338760,Time used 0.010000s\n",
      "batch 16283, train_loss 41.405300,Time used 0.008000s\n",
      "batch 16284, train_loss 48.938084,Time used 0.008003s\n",
      "batch 16285, train_loss 44.160282,Time used 0.008032s\n",
      "batch 16286, train_loss 47.959759,Time used 0.008009s\n",
      "batch 16287, train_loss 40.253693,Time used 0.011001s\n",
      "batch 16288, train_loss 47.534828,Time used 0.012000s\n",
      "batch 16289, train_loss 45.124672,Time used 0.007998s\n",
      "batch 16290, train_loss 38.274784,Time used 0.011006s\n",
      "batch 16291, train_loss 40.081188,Time used 0.010999s\n",
      "batch 16292, train_loss 49.617336,Time used 0.007996s\n",
      "batch 16293, train_loss 47.976959,Time used 0.007998s\n",
      "batch 16294, train_loss 47.420662,Time used 0.009001s\n",
      "batch 16295, train_loss 46.778404,Time used 0.012001s\n",
      "batch 16296, train_loss 43.377281,Time used 0.014002s\n",
      "batch 16297, train_loss 38.967701,Time used 0.016003s\n",
      "batch 16298, train_loss 38.268524,Time used 0.012997s\n",
      "batch 16299, train_loss 55.633160,Time used 0.012002s\n",
      "batch 16300, train_loss 61.267845,Time used 0.011999s\n",
      "***************************test_batch 16300, test_rmse_loss 7.855734,test_mae_loss 3.262434,test_mape_loss 53.255852,Time used 0.046002s\n",
      "batch 16301, train_loss 43.019318,Time used 0.013001s\n",
      "batch 16302, train_loss 39.983677,Time used 0.013000s\n",
      "batch 16303, train_loss 52.963444,Time used 0.012002s\n",
      "batch 16304, train_loss 47.858650,Time used 0.008999s\n",
      "batch 16305, train_loss 49.317959,Time used 0.012998s\n",
      "batch 16306, train_loss 45.063606,Time used 0.012005s\n",
      "batch 16307, train_loss 50.968922,Time used 0.011997s\n",
      "batch 16308, train_loss 46.664494,Time used 0.008999s\n",
      "batch 16309, train_loss 46.788857,Time used 0.012004s\n",
      "batch 16310, train_loss 53.759659,Time used 0.013995s\n",
      "batch 16311, train_loss 40.336803,Time used 0.013002s\n",
      "batch 16312, train_loss 40.074215,Time used 0.012001s\n",
      "batch 16313, train_loss 45.102081,Time used 0.011998s\n",
      "batch 16314, train_loss 50.678123,Time used 0.011998s\n",
      "batch 16315, train_loss 46.974262,Time used 0.008003s\n",
      "batch 16316, train_loss 41.440136,Time used 0.011002s\n",
      "batch 16317, train_loss 37.758968,Time used 0.009000s\n",
      "batch 16318, train_loss 44.293163,Time used 0.008000s\n",
      "batch 16319, train_loss 41.308887,Time used 0.010000s\n",
      "batch 16320, train_loss 48.426567,Time used 0.011010s\n",
      "batch 16321, train_loss 44.352394,Time used 0.010998s\n",
      "batch 16322, train_loss 49.929276,Time used 0.013999s\n",
      "batch 16323, train_loss 50.567928,Time used 0.013000s\n",
      "batch 16324, train_loss 44.771893,Time used 0.013001s\n",
      "batch 16325, train_loss 40.973320,Time used 0.013002s\n",
      "batch 16326, train_loss 38.381939,Time used 0.010998s\n",
      "batch 16327, train_loss 48.216396,Time used 0.012002s\n",
      "batch 16328, train_loss 44.268379,Time used 0.010998s\n",
      "batch 16329, train_loss 43.757156,Time used 0.012001s\n",
      "batch 16330, train_loss 43.022980,Time used 0.008000s\n",
      "batch 16331, train_loss 41.348064,Time used 0.011002s\n",
      "batch 16332, train_loss 51.933998,Time used 0.009000s\n",
      "batch 16333, train_loss 49.979671,Time used 0.010000s\n",
      "batch 16334, train_loss 54.645271,Time used 0.007999s\n",
      "batch 16335, train_loss 45.503696,Time used 0.008000s\n",
      "batch 16336, train_loss 44.631226,Time used 0.008002s\n",
      "batch 16337, train_loss 38.943321,Time used 0.009001s\n",
      "batch 16338, train_loss 46.651360,Time used 0.009995s\n",
      "batch 16339, train_loss 49.277687,Time used 0.010002s\n",
      "batch 16340, train_loss 45.012688,Time used 0.010998s\n",
      "batch 16341, train_loss 48.918423,Time used 0.012002s\n",
      "batch 16342, train_loss 47.188961,Time used 0.010002s\n",
      "batch 16343, train_loss 47.635872,Time used 0.009999s\n",
      "batch 16344, train_loss 45.015167,Time used 0.012002s\n",
      "batch 16345, train_loss 37.282722,Time used 0.011998s\n",
      "batch 16346, train_loss 49.839588,Time used 0.013000s\n",
      "batch 16347, train_loss 58.922153,Time used 0.013000s\n",
      "batch 16348, train_loss 50.140732,Time used 0.013001s\n",
      "batch 16349, train_loss 33.102474,Time used 0.012000s\n",
      "batch 16350, train_loss 46.733215,Time used 0.012999s\n",
      "batch 16351, train_loss 42.660297,Time used 0.009002s\n",
      "batch 16352, train_loss 42.271095,Time used 0.011997s\n",
      "batch 16353, train_loss 41.375340,Time used 0.011003s\n",
      "batch 16354, train_loss 40.174358,Time used 0.011999s\n",
      "batch 16355, train_loss 52.487450,Time used 0.013001s\n",
      "batch 16356, train_loss 53.468254,Time used 0.010999s\n",
      "batch 16357, train_loss 52.965282,Time used 0.011002s\n",
      "batch 16358, train_loss 49.052132,Time used 0.012000s\n",
      "batch 16359, train_loss 35.648575,Time used 0.009999s\n",
      "batch 16360, train_loss 48.223305,Time used 0.010000s\n",
      "batch 16361, train_loss 44.011013,Time used 0.013000s\n",
      "batch 16362, train_loss 40.382687,Time used 0.010998s\n",
      "batch 16363, train_loss 43.285946,Time used 0.012004s\n",
      "batch 16364, train_loss 42.285759,Time used 0.011996s\n",
      "batch 16365, train_loss 49.686737,Time used 0.009001s\n",
      "batch 16366, train_loss 56.848530,Time used 0.009003s\n",
      "batch 16367, train_loss 46.815353,Time used 0.010996s\n",
      "batch 16368, train_loss 45.791122,Time used 0.008999s\n",
      "batch 16369, train_loss 52.506599,Time used 0.010999s\n",
      "batch 16370, train_loss 38.050545,Time used 0.008999s\n",
      "batch 16371, train_loss 41.027977,Time used 0.009004s\n",
      "batch 16372, train_loss 47.402500,Time used 0.011999s\n",
      "batch 16373, train_loss 49.653530,Time used 0.007998s\n",
      "batch 16374, train_loss 49.838184,Time used 0.009001s\n",
      "batch 16375, train_loss 48.385056,Time used 0.007998s\n",
      "batch 16376, train_loss 48.264187,Time used 0.009001s\n",
      "batch 16377, train_loss 41.996574,Time used 0.012999s\n",
      "batch 16378, train_loss 45.824867,Time used 0.010000s\n",
      "batch 16379, train_loss 44.061584,Time used 0.009000s\n",
      "batch 16380, train_loss 45.773399,Time used 0.012002s\n",
      "batch 16381, train_loss 38.913326,Time used 0.011998s\n",
      "batch 16382, train_loss 50.662476,Time used 0.011001s\n",
      "batch 16383, train_loss 46.303223,Time used 0.010000s\n",
      "batch 16384, train_loss 44.393421,Time used 0.008000s\n",
      "batch 16385, train_loss 46.588554,Time used 0.006999s\n",
      "batch 16386, train_loss 45.996223,Time used 0.008001s\n",
      "batch 16387, train_loss 55.767067,Time used 0.011000s\n",
      "batch 16388, train_loss 38.928059,Time used 0.010002s\n",
      "batch 16389, train_loss 39.416748,Time used 0.008000s\n",
      "batch 16390, train_loss 51.313953,Time used 0.007997s\n",
      "batch 16391, train_loss 47.043373,Time used 0.009001s\n",
      "batch 16392, train_loss 43.568611,Time used 0.007999s\n",
      "batch 16393, train_loss 39.521935,Time used 0.008999s\n",
      "batch 16394, train_loss 41.668591,Time used 0.010999s\n",
      "batch 16395, train_loss 40.793835,Time used 0.010001s\n",
      "batch 16396, train_loss 38.578648,Time used 0.009002s\n",
      "batch 16397, train_loss 53.833755,Time used 0.008997s\n",
      "batch 16398, train_loss 47.652317,Time used 0.011001s\n",
      "batch 16399, train_loss 51.900593,Time used 0.014999s\n",
      "batch 16400, train_loss 45.960648,Time used 0.011000s\n",
      "***************************test_batch 16400, test_rmse_loss 7.826289,test_mae_loss 3.258321,test_mape_loss 53.416579,Time used 0.031999s\n",
      "batch 16401, train_loss 43.334049,Time used 0.007999s\n",
      "batch 16402, train_loss 48.082127,Time used 0.009004s\n",
      "batch 16403, train_loss 43.348232,Time used 0.007000s\n",
      "batch 16404, train_loss 46.492435,Time used 0.011997s\n",
      "batch 16405, train_loss 43.293575,Time used 0.010005s\n",
      "batch 16406, train_loss 46.049294,Time used 0.006999s\n",
      "batch 16407, train_loss 54.987492,Time used 0.007999s\n",
      "batch 16408, train_loss 42.242867,Time used 0.007001s\n",
      "batch 16409, train_loss 55.524139,Time used 0.010998s\n",
      "batch 16410, train_loss 47.131409,Time used 0.007006s\n",
      "batch 16411, train_loss 40.844471,Time used 0.007995s\n",
      "batch 16412, train_loss 45.308865,Time used 0.009000s\n",
      "batch 16413, train_loss 51.830658,Time used 0.009012s\n",
      "batch 16414, train_loss 43.501328,Time used 0.012001s\n",
      "batch 16415, train_loss 47.682049,Time used 0.010002s\n",
      "batch 16416, train_loss 40.096348,Time used 0.006999s\n",
      "batch 16417, train_loss 50.072853,Time used 0.010001s\n",
      "batch 16418, train_loss 49.752834,Time used 0.008001s\n",
      "batch 16419, train_loss 39.624859,Time used 0.006998s\n",
      "batch 16420, train_loss 44.333885,Time used 0.007000s\n",
      "batch 16421, train_loss 51.993603,Time used 0.007001s\n",
      "batch 16422, train_loss 48.315685,Time used 0.009000s\n",
      "batch 16423, train_loss 45.694260,Time used 0.008000s\n",
      "batch 16424, train_loss 51.797169,Time used 0.008000s\n",
      "batch 16425, train_loss 43.432289,Time used 0.008000s\n",
      "batch 16426, train_loss 55.515987,Time used 0.009999s\n",
      "batch 16427, train_loss 43.760124,Time used 0.009003s\n",
      "batch 16428, train_loss 43.410118,Time used 0.010000s\n",
      "batch 16429, train_loss 47.409203,Time used 0.009998s\n",
      "batch 16430, train_loss 41.374481,Time used 0.010002s\n",
      "batch 16431, train_loss 36.137657,Time used 0.009001s\n",
      "batch 16432, train_loss 54.624603,Time used 0.007999s\n",
      "batch 16433, train_loss 47.048340,Time used 0.007003s\n",
      "batch 16434, train_loss 44.563393,Time used 0.007001s\n",
      "batch 16435, train_loss 35.616985,Time used 0.011003s\n",
      "batch 16436, train_loss 49.346817,Time used 0.010001s\n",
      "batch 16437, train_loss 31.336226,Time used 0.006999s\n",
      "batch 16438, train_loss 53.332840,Time used 0.011003s\n",
      "batch 16439, train_loss 46.232922,Time used 0.010997s\n",
      "batch 16440, train_loss 43.418095,Time used 0.008000s\n",
      "batch 16441, train_loss 52.260036,Time used 0.012036s\n",
      "batch 16442, train_loss 48.281368,Time used 0.007964s\n",
      "batch 16443, train_loss 40.419079,Time used 0.008000s\n",
      "batch 16444, train_loss 49.906223,Time used 0.009000s\n",
      "batch 16445, train_loss 47.025814,Time used 0.008000s\n",
      "batch 16446, train_loss 38.173126,Time used 0.009000s\n",
      "batch 16447, train_loss 44.407776,Time used 0.008001s\n",
      "batch 16448, train_loss 49.540871,Time used 0.011001s\n",
      "batch 16449, train_loss 38.054874,Time used 0.006999s\n",
      "batch 16450, train_loss 42.285446,Time used 0.007998s\n",
      "batch 16451, train_loss 41.420856,Time used 0.009012s\n",
      "batch 16452, train_loss 41.901443,Time used 0.006990s\n",
      "batch 16453, train_loss 45.738571,Time used 0.008001s\n",
      "batch 16454, train_loss 46.619698,Time used 0.008000s\n",
      "batch 16455, train_loss 46.515106,Time used 0.008000s\n",
      "batch 16456, train_loss 40.517212,Time used 0.010000s\n",
      "batch 16457, train_loss 51.088661,Time used 0.007999s\n",
      "batch 16458, train_loss 46.607372,Time used 0.010001s\n",
      "batch 16459, train_loss 38.203606,Time used 0.011000s\n",
      "batch 16460, train_loss 44.870922,Time used 0.007999s\n",
      "batch 16461, train_loss 47.989491,Time used 0.007998s\n",
      "batch 16462, train_loss 58.695110,Time used 0.007001s\n",
      "batch 16463, train_loss 50.944187,Time used 0.010002s\n",
      "batch 16464, train_loss 44.801785,Time used 0.007999s\n",
      "batch 16465, train_loss 43.339092,Time used 0.011003s\n",
      "batch 16466, train_loss 51.677147,Time used 0.007998s\n",
      "batch 16467, train_loss 43.362602,Time used 0.008003s\n",
      "batch 16468, train_loss 46.045071,Time used 0.007997s\n",
      "batch 16469, train_loss 39.168869,Time used 0.010998s\n",
      "batch 16470, train_loss 50.609760,Time used 0.008002s\n",
      "batch 16471, train_loss 45.393860,Time used 0.008000s\n",
      "batch 16472, train_loss 40.776661,Time used 0.007004s\n",
      "batch 16473, train_loss 37.529026,Time used 0.008000s\n",
      "batch 16474, train_loss 56.174553,Time used 0.009000s\n",
      "batch 16475, train_loss 48.007603,Time used 0.008999s\n",
      "batch 16476, train_loss 44.410294,Time used 0.011001s\n",
      "batch 16477, train_loss 53.228554,Time used 0.007999s\n",
      "batch 16478, train_loss 39.049683,Time used 0.008001s\n",
      "batch 16479, train_loss 51.131222,Time used 0.008000s\n",
      "batch 16480, train_loss 51.401276,Time used 0.008001s\n",
      "batch 16481, train_loss 48.174660,Time used 0.007998s\n",
      "batch 16482, train_loss 40.192928,Time used 0.009002s\n",
      "batch 16483, train_loss 40.469070,Time used 0.012001s\n",
      "batch 16484, train_loss 42.771637,Time used 0.007999s\n",
      "batch 16485, train_loss 49.941319,Time used 0.007999s\n",
      "batch 16486, train_loss 40.146328,Time used 0.010002s\n",
      "batch 16487, train_loss 44.924633,Time used 0.009999s\n",
      "batch 16488, train_loss 47.015923,Time used 0.008001s\n",
      "batch 16489, train_loss 43.553429,Time used 0.010000s\n",
      "batch 16490, train_loss 42.179520,Time used 0.009999s\n",
      "batch 16491, train_loss 41.405842,Time used 0.009001s\n",
      "batch 16492, train_loss 39.139637,Time used 0.007001s\n",
      "batch 16493, train_loss 54.402466,Time used 0.009996s\n",
      "batch 16494, train_loss 33.955551,Time used 0.007002s\n",
      "batch 16495, train_loss 45.029877,Time used 0.012000s\n",
      "batch 16496, train_loss 47.739239,Time used 0.010998s\n",
      "batch 16497, train_loss 39.966839,Time used 0.010003s\n",
      "batch 16498, train_loss 50.455486,Time used 0.011999s\n",
      "batch 16499, train_loss 43.726448,Time used 0.011999s\n",
      "batch 16500, train_loss 40.193024,Time used 0.012001s\n",
      "***************************test_batch 16500, test_rmse_loss 7.806646,test_mae_loss 3.247190,test_mape_loss 53.001090,Time used 0.035999s\n",
      "batch 16501, train_loss 44.778698,Time used 0.010999s\n",
      "batch 16502, train_loss 47.631531,Time used 0.008000s\n",
      "batch 16503, train_loss 45.193211,Time used 0.009001s\n",
      "batch 16504, train_loss 43.021820,Time used 0.011000s\n",
      "batch 16505, train_loss 46.505791,Time used 0.008998s\n",
      "batch 16506, train_loss 53.741623,Time used 0.007001s\n",
      "batch 16507, train_loss 55.504852,Time used 0.006999s\n",
      "batch 16508, train_loss 57.632992,Time used 0.007002s\n",
      "batch 16509, train_loss 35.304104,Time used 0.008997s\n",
      "batch 16510, train_loss 41.446976,Time used 0.009000s\n",
      "batch 16511, train_loss 51.022556,Time used 0.007002s\n",
      "batch 16512, train_loss 49.685680,Time used 0.010000s\n",
      "batch 16513, train_loss 47.533493,Time used 0.009998s\n",
      "batch 16514, train_loss 44.050613,Time used 0.011999s\n",
      "batch 16515, train_loss 52.048904,Time used 0.009001s\n",
      "batch 16516, train_loss 44.028721,Time used 0.008002s\n",
      "batch 16517, train_loss 39.849865,Time used 0.009995s\n",
      "batch 16518, train_loss 46.123207,Time used 0.010999s\n",
      "batch 16519, train_loss 37.272762,Time used 0.008038s\n",
      "batch 16520, train_loss 46.127674,Time used 0.006963s\n",
      "batch 16521, train_loss 46.282795,Time used 0.008001s\n",
      "batch 16522, train_loss 54.580757,Time used 0.008001s\n",
      "batch 16523, train_loss 37.073765,Time used 0.008001s\n",
      "batch 16524, train_loss 51.658752,Time used 0.007999s\n",
      "batch 16525, train_loss 48.065128,Time used 0.007998s\n",
      "batch 16526, train_loss 42.758427,Time used 0.011001s\n",
      "batch 16527, train_loss 41.313374,Time used 0.010000s\n",
      "batch 16528, train_loss 42.146290,Time used 0.008000s\n",
      "batch 16529, train_loss 37.464016,Time used 0.008000s\n",
      "batch 16530, train_loss 46.907612,Time used 0.008001s\n",
      "batch 16531, train_loss 50.826290,Time used 0.006999s\n",
      "batch 16532, train_loss 52.959381,Time used 0.008002s\n",
      "batch 16533, train_loss 49.635521,Time used 0.006997s\n",
      "batch 16534, train_loss 41.078747,Time used 0.008000s\n",
      "batch 16535, train_loss 39.576363,Time used 0.008002s\n",
      "batch 16536, train_loss 52.072041,Time used 0.007000s\n",
      "batch 16537, train_loss 42.717888,Time used 0.010997s\n",
      "batch 16538, train_loss 41.972832,Time used 0.011001s\n",
      "batch 16539, train_loss 49.020035,Time used 0.008002s\n",
      "batch 16540, train_loss 47.805553,Time used 0.008002s\n",
      "batch 16541, train_loss 36.096565,Time used 0.008996s\n",
      "batch 16542, train_loss 43.265560,Time used 0.007001s\n",
      "batch 16543, train_loss 46.793827,Time used 0.009004s\n",
      "batch 16544, train_loss 40.197418,Time used 0.007996s\n",
      "batch 16545, train_loss 59.388065,Time used 0.008998s\n",
      "batch 16546, train_loss 41.807983,Time used 0.009001s\n",
      "batch 16547, train_loss 40.158726,Time used 0.008003s\n",
      "batch 16548, train_loss 52.633320,Time used 0.009995s\n",
      "batch 16549, train_loss 49.981617,Time used 0.009004s\n",
      "batch 16550, train_loss 51.500290,Time used 0.010999s\n",
      "batch 16551, train_loss 48.844452,Time used 0.009998s\n",
      "batch 16552, train_loss 47.117817,Time used 0.007001s\n",
      "batch 16553, train_loss 46.801678,Time used 0.007002s\n",
      "batch 16554, train_loss 46.764603,Time used 0.008002s\n",
      "batch 16555, train_loss 41.972260,Time used 0.007999s\n",
      "batch 16556, train_loss 36.955242,Time used 0.007002s\n",
      "batch 16557, train_loss 46.596775,Time used 0.009997s\n",
      "batch 16558, train_loss 48.296040,Time used 0.008002s\n",
      "batch 16559, train_loss 40.382900,Time used 0.009000s\n",
      "batch 16560, train_loss 42.657211,Time used 0.008998s\n",
      "batch 16561, train_loss 48.645885,Time used 0.011001s\n",
      "batch 16562, train_loss 46.712917,Time used 0.007004s\n",
      "batch 16563, train_loss 38.609558,Time used 0.010998s\n",
      "batch 16564, train_loss 50.897427,Time used 0.008000s\n",
      "batch 16565, train_loss 51.329365,Time used 0.007998s\n",
      "batch 16566, train_loss 43.333546,Time used 0.007001s\n",
      "batch 16567, train_loss 51.659939,Time used 0.007999s\n",
      "batch 16568, train_loss 39.201595,Time used 0.008003s\n",
      "batch 16569, train_loss 47.908863,Time used 0.006997s\n",
      "batch 16570, train_loss 38.178867,Time used 0.013001s\n",
      "batch 16571, train_loss 41.663162,Time used 0.011000s\n",
      "batch 16572, train_loss 51.466625,Time used 0.012001s\n",
      "batch 16573, train_loss 44.801426,Time used 0.011998s\n",
      "batch 16574, train_loss 50.444542,Time used 0.011000s\n",
      "batch 16575, train_loss 46.654556,Time used 0.013001s\n",
      "batch 16576, train_loss 41.072659,Time used 0.009999s\n",
      "batch 16577, train_loss 51.900505,Time used 0.009000s\n",
      "batch 16578, train_loss 54.263687,Time used 0.012001s\n",
      "batch 16579, train_loss 33.153286,Time used 0.014003s\n",
      "batch 16580, train_loss 37.409451,Time used 0.012001s\n",
      "batch 16581, train_loss 50.117527,Time used 0.014000s\n",
      "batch 16582, train_loss 48.065285,Time used 0.010001s\n",
      "batch 16583, train_loss 37.189709,Time used 0.012999s\n",
      "batch 16584, train_loss 43.192287,Time used 0.010998s\n",
      "batch 16585, train_loss 35.499535,Time used 0.011998s\n",
      "batch 16586, train_loss 49.096958,Time used 0.013000s\n",
      "batch 16587, train_loss 48.877800,Time used 0.011001s\n",
      "batch 16588, train_loss 52.963966,Time used 0.011000s\n",
      "batch 16589, train_loss 48.279255,Time used 0.013000s\n",
      "batch 16590, train_loss 37.122623,Time used 0.017000s\n",
      "batch 16591, train_loss 52.020351,Time used 0.024999s\n",
      "batch 16592, train_loss 55.940468,Time used 0.013000s\n",
      "batch 16593, train_loss 42.813030,Time used 0.012001s\n",
      "batch 16594, train_loss 43.066006,Time used 0.015002s\n",
      "batch 16595, train_loss 43.892765,Time used 0.019999s\n",
      "batch 16596, train_loss 48.596169,Time used 0.011998s\n",
      "batch 16597, train_loss 40.600220,Time used 0.013001s\n",
      "batch 16598, train_loss 38.661598,Time used 0.012001s\n",
      "batch 16599, train_loss 49.175995,Time used 0.012998s\n",
      "batch 16600, train_loss 42.522243,Time used 0.011002s\n",
      "***************************test_batch 16600, test_rmse_loss 7.776112,test_mae_loss 3.243783,test_mape_loss 53.438108,Time used 0.055000s\n",
      "batch 16601, train_loss 44.966640,Time used 0.008001s\n",
      "batch 16602, train_loss 36.925934,Time used 0.007997s\n",
      "batch 16603, train_loss 46.419952,Time used 0.008003s\n",
      "batch 16604, train_loss 42.641075,Time used 0.008999s\n",
      "batch 16605, train_loss 44.541290,Time used 0.009001s\n",
      "batch 16606, train_loss 41.700825,Time used 0.007999s\n",
      "batch 16607, train_loss 52.985371,Time used 0.008999s\n",
      "batch 16608, train_loss 47.356178,Time used 0.009001s\n",
      "batch 16609, train_loss 38.513870,Time used 0.007002s\n",
      "batch 16610, train_loss 41.662331,Time used 0.008001s\n",
      "batch 16611, train_loss 50.637367,Time used 0.011001s\n",
      "batch 16612, train_loss 48.089718,Time used 0.010997s\n",
      "batch 16613, train_loss 38.760708,Time used 0.012000s\n",
      "batch 16614, train_loss 54.455669,Time used 0.010001s\n",
      "batch 16615, train_loss 41.750355,Time used 0.008001s\n",
      "batch 16616, train_loss 49.728268,Time used 0.008003s\n",
      "batch 16617, train_loss 54.235367,Time used 0.007998s\n",
      "batch 16618, train_loss 34.222546,Time used 0.007998s\n",
      "batch 16619, train_loss 35.962326,Time used 0.008998s\n",
      "batch 16620, train_loss 42.516495,Time used 0.007004s\n",
      "batch 16621, train_loss 46.078167,Time used 0.007000s\n",
      "batch 16622, train_loss 51.815510,Time used 0.008996s\n",
      "batch 16623, train_loss 46.443474,Time used 0.006999s\n",
      "batch 16624, train_loss 46.217712,Time used 0.010001s\n",
      "batch 16625, train_loss 53.786716,Time used 0.007001s\n",
      "batch 16626, train_loss 38.676304,Time used 0.010999s\n",
      "batch 16627, train_loss 48.328541,Time used 0.012000s\n",
      "batch 16628, train_loss 41.750385,Time used 0.011001s\n",
      "batch 16629, train_loss 51.214947,Time used 0.009000s\n",
      "batch 16630, train_loss 36.164642,Time used 0.008999s\n",
      "batch 16631, train_loss 43.374771,Time used 0.011000s\n",
      "batch 16632, train_loss 50.470745,Time used 0.007999s\n",
      "batch 16633, train_loss 51.075806,Time used 0.008001s\n",
      "batch 16634, train_loss 46.563156,Time used 0.008001s\n",
      "batch 16635, train_loss 41.567715,Time used 0.010999s\n",
      "batch 16636, train_loss 36.202141,Time used 0.010999s\n",
      "batch 16637, train_loss 41.866123,Time used 0.007000s\n",
      "batch 16638, train_loss 53.032963,Time used 0.011002s\n",
      "batch 16639, train_loss 42.153801,Time used 0.010999s\n",
      "batch 16640, train_loss 44.812950,Time used 0.010000s\n",
      "batch 16641, train_loss 41.765392,Time used 0.007002s\n",
      "batch 16642, train_loss 46.289028,Time used 0.008001s\n",
      "batch 16643, train_loss 47.517414,Time used 0.010999s\n",
      "batch 16644, train_loss 41.977898,Time used 0.008999s\n",
      "batch 16645, train_loss 39.727825,Time used 0.008001s\n",
      "batch 16646, train_loss 38.004543,Time used 0.008002s\n",
      "batch 16647, train_loss 50.307926,Time used 0.007998s\n",
      "batch 16648, train_loss 38.891659,Time used 0.010000s\n",
      "batch 16649, train_loss 44.438511,Time used 0.012001s\n",
      "batch 16650, train_loss 59.649101,Time used 0.011999s\n",
      "batch 16651, train_loss 42.099804,Time used 0.009002s\n",
      "batch 16652, train_loss 45.920746,Time used 0.007997s\n",
      "batch 16653, train_loss 49.204655,Time used 0.008002s\n",
      "batch 16654, train_loss 46.041351,Time used 0.007999s\n",
      "batch 16655, train_loss 39.739189,Time used 0.009003s\n",
      "batch 16656, train_loss 54.611309,Time used 0.010999s\n",
      "batch 16657, train_loss 41.711437,Time used 0.010005s\n",
      "batch 16658, train_loss 51.584263,Time used 0.006999s\n",
      "batch 16659, train_loss 49.087101,Time used 0.009996s\n",
      "batch 16660, train_loss 47.734295,Time used 0.010999s\n",
      "batch 16661, train_loss 34.573582,Time used 0.011001s\n",
      "batch 16662, train_loss 37.359455,Time used 0.011000s\n",
      "batch 16663, train_loss 50.015255,Time used 0.007001s\n",
      "batch 16664, train_loss 41.472397,Time used 0.008002s\n",
      "batch 16665, train_loss 47.424942,Time used 0.009000s\n",
      "batch 16666, train_loss 47.214203,Time used 0.008997s\n",
      "batch 16667, train_loss 48.835243,Time used 0.012001s\n",
      "batch 16668, train_loss 42.949291,Time used 0.012000s\n",
      "batch 16669, train_loss 47.245716,Time used 0.011997s\n",
      "batch 16670, train_loss 42.455147,Time used 0.007001s\n",
      "batch 16671, train_loss 48.292381,Time used 0.007999s\n",
      "batch 16672, train_loss 36.586426,Time used 0.007999s\n",
      "batch 16673, train_loss 53.899513,Time used 0.010004s\n",
      "batch 16674, train_loss 42.765564,Time used 0.008999s\n",
      "batch 16675, train_loss 46.042755,Time used 0.011000s\n",
      "batch 16676, train_loss 48.451485,Time used 0.009002s\n",
      "batch 16677, train_loss 39.304405,Time used 0.008996s\n",
      "batch 16678, train_loss 50.449673,Time used 0.010000s\n",
      "batch 16679, train_loss 45.288734,Time used 0.012000s\n",
      "batch 16680, train_loss 40.419102,Time used 0.011998s\n",
      "batch 16681, train_loss 47.947392,Time used 0.008000s\n",
      "batch 16682, train_loss 46.140858,Time used 0.008999s\n",
      "batch 16683, train_loss 45.578758,Time used 0.006999s\n",
      "batch 16684, train_loss 48.991764,Time used 0.008000s\n",
      "batch 16685, train_loss 41.453381,Time used 0.008002s\n",
      "batch 16686, train_loss 42.307453,Time used 0.009999s\n",
      "batch 16687, train_loss 35.027328,Time used 0.012002s\n",
      "batch 16688, train_loss 50.683971,Time used 0.011997s\n",
      "batch 16689, train_loss 35.329872,Time used 0.009001s\n",
      "batch 16690, train_loss 43.754028,Time used 0.008000s\n",
      "batch 16691, train_loss 48.560242,Time used 0.011999s\n",
      "batch 16692, train_loss 52.651730,Time used 0.010000s\n",
      "batch 16693, train_loss 48.732281,Time used 0.008000s\n",
      "batch 16694, train_loss 46.420856,Time used 0.009001s\n",
      "batch 16695, train_loss 40.159187,Time used 0.010004s\n",
      "batch 16696, train_loss 49.992390,Time used 0.011998s\n",
      "batch 16697, train_loss 40.369514,Time used 0.011000s\n",
      "batch 16698, train_loss 50.833385,Time used 0.010001s\n",
      "batch 16699, train_loss 44.526901,Time used 0.008001s\n",
      "batch 16700, train_loss 38.619225,Time used 0.008996s\n",
      "***************************test_batch 16700, test_rmse_loss 7.758094,test_mae_loss 3.234275,test_mape_loss 53.002600,Time used 0.040000s\n",
      "batch 16701, train_loss 43.936749,Time used 0.010003s\n",
      "batch 16702, train_loss 59.765873,Time used 0.009999s\n",
      "batch 16703, train_loss 35.760250,Time used 0.008001s\n",
      "batch 16704, train_loss 41.969543,Time used 0.007003s\n",
      "batch 16705, train_loss 44.620163,Time used 0.007998s\n",
      "batch 16706, train_loss 48.201042,Time used 0.012000s\n",
      "batch 16707, train_loss 45.546829,Time used 0.009999s\n",
      "batch 16708, train_loss 35.989403,Time used 0.007001s\n",
      "batch 16709, train_loss 40.241962,Time used 0.008000s\n",
      "batch 16710, train_loss 49.163258,Time used 0.008002s\n",
      "batch 16711, train_loss 38.162766,Time used 0.008001s\n",
      "batch 16712, train_loss 34.881401,Time used 0.008001s\n",
      "batch 16713, train_loss 45.383640,Time used 0.010998s\n",
      "batch 16714, train_loss 54.726482,Time used 0.008995s\n",
      "batch 16715, train_loss 52.831200,Time used 0.008000s\n",
      "batch 16716, train_loss 51.010792,Time used 0.008000s\n",
      "batch 16717, train_loss 48.750301,Time used 0.007999s\n",
      "batch 16718, train_loss 48.506859,Time used 0.009001s\n",
      "batch 16719, train_loss 46.749809,Time used 0.010037s\n",
      "batch 16720, train_loss 35.210384,Time used 0.009968s\n",
      "batch 16721, train_loss 37.973980,Time used 0.007996s\n",
      "batch 16722, train_loss 52.658798,Time used 0.007036s\n",
      "batch 16723, train_loss 57.088017,Time used 0.007966s\n",
      "batch 16724, train_loss 35.107498,Time used 0.007996s\n",
      "batch 16725, train_loss 44.804157,Time used 0.007002s\n",
      "batch 16726, train_loss 45.105682,Time used 0.009997s\n",
      "batch 16727, train_loss 44.214642,Time used 0.008968s\n",
      "batch 16728, train_loss 41.288380,Time used 0.010998s\n",
      "batch 16729, train_loss 47.967579,Time used 0.009000s\n",
      "batch 16730, train_loss 47.779377,Time used 0.009998s\n",
      "batch 16731, train_loss 37.111874,Time used 0.008004s\n",
      "batch 16732, train_loss 43.658611,Time used 0.006999s\n",
      "batch 16733, train_loss 46.769279,Time used 0.007000s\n",
      "batch 16734, train_loss 47.512428,Time used 0.008999s\n",
      "batch 16735, train_loss 39.617901,Time used 0.012001s\n",
      "batch 16736, train_loss 37.426720,Time used 0.008002s\n",
      "batch 16737, train_loss 45.823185,Time used 0.006999s\n",
      "batch 16738, train_loss 52.589657,Time used 0.009000s\n",
      "batch 16739, train_loss 41.953751,Time used 0.008000s\n",
      "batch 16740, train_loss 41.324863,Time used 0.010999s\n",
      "batch 16741, train_loss 37.481819,Time used 0.009001s\n",
      "batch 16742, train_loss 47.068665,Time used 0.009000s\n",
      "batch 16743, train_loss 35.402283,Time used 0.010000s\n",
      "batch 16744, train_loss 53.031204,Time used 0.007999s\n",
      "batch 16745, train_loss 50.106628,Time used 0.008001s\n",
      "batch 16746, train_loss 56.724808,Time used 0.008000s\n",
      "batch 16747, train_loss 45.393345,Time used 0.008002s\n",
      "batch 16748, train_loss 38.193531,Time used 0.007998s\n",
      "batch 16749, train_loss 45.134262,Time used 0.010000s\n",
      "batch 16750, train_loss 42.043312,Time used 0.007000s\n",
      "batch 16751, train_loss 47.783398,Time used 0.008999s\n",
      "batch 16752, train_loss 48.589539,Time used 0.011002s\n",
      "batch 16753, train_loss 42.477242,Time used 0.010000s\n",
      "batch 16754, train_loss 38.389828,Time used 0.009999s\n",
      "batch 16755, train_loss 36.862457,Time used 0.011001s\n",
      "batch 16756, train_loss 46.615685,Time used 0.011002s\n",
      "batch 16757, train_loss 42.132042,Time used 0.008000s\n",
      "batch 16758, train_loss 50.075199,Time used 0.010000s\n",
      "batch 16759, train_loss 43.741959,Time used 0.009000s\n",
      "batch 16760, train_loss 48.701962,Time used 0.009001s\n",
      "batch 16761, train_loss 45.618530,Time used 0.007998s\n",
      "batch 16762, train_loss 45.388287,Time used 0.007000s\n",
      "batch 16763, train_loss 35.154808,Time used 0.008002s\n",
      "batch 16764, train_loss 39.426525,Time used 0.008000s\n",
      "batch 16765, train_loss 47.388252,Time used 0.009001s\n",
      "batch 16766, train_loss 50.054470,Time used 0.009000s\n",
      "batch 16767, train_loss 37.944386,Time used 0.011000s\n",
      "batch 16768, train_loss 40.937325,Time used 0.011998s\n",
      "batch 16769, train_loss 49.833717,Time used 0.008002s\n",
      "batch 16770, train_loss 53.494480,Time used 0.011000s\n",
      "batch 16771, train_loss 46.279652,Time used 0.007000s\n",
      "batch 16772, train_loss 46.731812,Time used 0.008002s\n",
      "batch 16773, train_loss 41.766315,Time used 0.006999s\n",
      "batch 16774, train_loss 53.350643,Time used 0.011999s\n",
      "batch 16775, train_loss 45.299355,Time used 0.009001s\n",
      "batch 16776, train_loss 47.031067,Time used 0.010998s\n",
      "batch 16777, train_loss 52.549141,Time used 0.010000s\n",
      "batch 16778, train_loss 49.225296,Time used 0.011999s\n",
      "batch 16779, train_loss 53.053570,Time used 0.010001s\n",
      "batch 16780, train_loss 39.921165,Time used 0.007998s\n",
      "batch 16781, train_loss 51.989429,Time used 0.007001s\n",
      "batch 16782, train_loss 45.082592,Time used 0.009001s\n",
      "batch 16783, train_loss 36.506592,Time used 0.007001s\n",
      "batch 16784, train_loss 43.174881,Time used 0.009000s\n",
      "batch 16785, train_loss 56.438690,Time used 0.008000s\n",
      "batch 16786, train_loss 36.218582,Time used 0.010000s\n",
      "batch 16787, train_loss 41.121555,Time used 0.011000s\n",
      "batch 16788, train_loss 50.960648,Time used 0.010000s\n",
      "batch 16789, train_loss 42.093376,Time used 0.012002s\n",
      "batch 16790, train_loss 39.973911,Time used 0.011000s\n",
      "batch 16791, train_loss 38.800686,Time used 0.011000s\n",
      "batch 16792, train_loss 48.334644,Time used 0.011998s\n",
      "batch 16793, train_loss 44.165009,Time used 0.012002s\n",
      "batch 16794, train_loss 46.986038,Time used 0.011000s\n",
      "batch 16795, train_loss 45.630585,Time used 0.009999s\n",
      "batch 16796, train_loss 45.354282,Time used 0.012001s\n",
      "batch 16797, train_loss 48.563545,Time used 0.007000s\n",
      "batch 16798, train_loss 38.621407,Time used 0.009000s\n",
      "batch 16799, train_loss 36.789543,Time used 0.007999s\n",
      "batch 16800, train_loss 41.312866,Time used 0.007999s\n",
      "***************************test_batch 16800, test_rmse_loss 7.730703,test_mae_loss 3.227713,test_mape_loss 53.013677,Time used 0.034005s\n",
      "batch 16801, train_loss 33.675831,Time used 0.006997s\n",
      "batch 16802, train_loss 49.604103,Time used 0.009999s\n",
      "batch 16803, train_loss 45.290096,Time used 0.011001s\n",
      "batch 16804, train_loss 39.465321,Time used 0.011000s\n",
      "batch 16805, train_loss 56.965565,Time used 0.008999s\n",
      "batch 16806, train_loss 58.555775,Time used 0.008001s\n",
      "batch 16807, train_loss 49.048222,Time used 0.010000s\n",
      "batch 16808, train_loss 45.013447,Time used 0.011003s\n",
      "batch 16809, train_loss 42.071320,Time used 0.007998s\n",
      "batch 16810, train_loss 51.574104,Time used 0.008002s\n",
      "batch 16811, train_loss 34.073296,Time used 0.007998s\n",
      "batch 16812, train_loss 42.672104,Time used 0.007002s\n",
      "batch 16813, train_loss 38.213169,Time used 0.009998s\n",
      "batch 16814, train_loss 37.992779,Time used 0.009001s\n",
      "batch 16815, train_loss 47.552444,Time used 0.006998s\n",
      "batch 16816, train_loss 48.455254,Time used 0.009002s\n",
      "batch 16817, train_loss 46.468967,Time used 0.012000s\n",
      "batch 16818, train_loss 40.974129,Time used 0.007998s\n",
      "batch 16819, train_loss 38.409687,Time used 0.007000s\n",
      "batch 16820, train_loss 43.960739,Time used 0.009001s\n",
      "batch 16821, train_loss 42.008881,Time used 0.007001s\n",
      "batch 16822, train_loss 51.503605,Time used 0.008000s\n",
      "batch 16823, train_loss 42.549683,Time used 0.006999s\n",
      "batch 16824, train_loss 45.198925,Time used 0.007000s\n",
      "batch 16825, train_loss 38.369495,Time used 0.011002s\n",
      "batch 16826, train_loss 34.870892,Time used 0.008998s\n",
      "batch 16827, train_loss 49.364941,Time used 0.007000s\n",
      "batch 16828, train_loss 41.768276,Time used 0.008000s\n",
      "batch 16829, train_loss 39.595707,Time used 0.006999s\n",
      "batch 16830, train_loss 52.993553,Time used 0.008000s\n",
      "batch 16831, train_loss 40.552540,Time used 0.008000s\n",
      "batch 16832, train_loss 36.490791,Time used 0.009001s\n",
      "batch 16833, train_loss 51.731495,Time used 0.007999s\n",
      "batch 16834, train_loss 52.735157,Time used 0.007998s\n",
      "batch 16835, train_loss 51.279076,Time used 0.009001s\n",
      "batch 16836, train_loss 38.378681,Time used 0.012001s\n",
      "batch 16837, train_loss 52.194901,Time used 0.011999s\n",
      "batch 16838, train_loss 40.815449,Time used 0.007999s\n",
      "batch 16839, train_loss 47.748154,Time used 0.008002s\n",
      "batch 16840, train_loss 41.807446,Time used 0.012000s\n",
      "batch 16841, train_loss 44.585159,Time used 0.009000s\n",
      "batch 16842, train_loss 39.020477,Time used 0.007999s\n",
      "batch 16843, train_loss 47.648506,Time used 0.008000s\n",
      "batch 16844, train_loss 41.708126,Time used 0.008001s\n",
      "batch 16845, train_loss 43.193665,Time used 0.007998s\n",
      "batch 16846, train_loss 51.945290,Time used 0.008000s\n",
      "batch 16847, train_loss 46.618050,Time used 0.010999s\n",
      "batch 16848, train_loss 44.083984,Time used 0.011001s\n",
      "batch 16849, train_loss 47.444012,Time used 0.007997s\n",
      "batch 16850, train_loss 42.550797,Time used 0.012001s\n",
      "batch 16851, train_loss 40.976791,Time used 0.011000s\n",
      "batch 16852, train_loss 42.548901,Time used 0.008001s\n",
      "batch 16853, train_loss 39.700024,Time used 0.008000s\n",
      "batch 16854, train_loss 38.213799,Time used 0.006999s\n",
      "batch 16855, train_loss 39.241360,Time used 0.010002s\n",
      "batch 16856, train_loss 47.991310,Time used 0.008001s\n",
      "batch 16857, train_loss 47.115692,Time used 0.010000s\n",
      "batch 16858, train_loss 46.746822,Time used 0.008999s\n",
      "batch 16859, train_loss 44.660202,Time used 0.008000s\n",
      "batch 16860, train_loss 45.588917,Time used 0.007999s\n",
      "batch 16861, train_loss 47.395050,Time used 0.010005s\n",
      "batch 16862, train_loss 40.394337,Time used 0.011997s\n",
      "batch 16863, train_loss 46.613197,Time used 0.008000s\n",
      "batch 16864, train_loss 51.883312,Time used 0.007000s\n",
      "batch 16865, train_loss 41.796398,Time used 0.007001s\n",
      "batch 16866, train_loss 37.397705,Time used 0.007998s\n",
      "batch 16867, train_loss 46.704693,Time used 0.008001s\n",
      "batch 16868, train_loss 45.115566,Time used 0.008001s\n",
      "batch 16869, train_loss 46.344830,Time used 0.008000s\n",
      "batch 16870, train_loss 39.514526,Time used 0.010999s\n",
      "batch 16871, train_loss 51.903435,Time used 0.010001s\n",
      "batch 16872, train_loss 50.326462,Time used 0.008000s\n",
      "batch 16873, train_loss 46.471146,Time used 0.008001s\n",
      "batch 16874, train_loss 36.865143,Time used 0.007000s\n",
      "batch 16875, train_loss 36.145351,Time used 0.008999s\n",
      "batch 16876, train_loss 49.391308,Time used 0.009001s\n",
      "batch 16877, train_loss 34.361961,Time used 0.012033s\n",
      "batch 16878, train_loss 49.099739,Time used 0.008001s\n",
      "batch 16879, train_loss 38.654453,Time used 0.007965s\n",
      "batch 16880, train_loss 45.183315,Time used 0.008036s\n",
      "batch 16881, train_loss 47.218567,Time used 0.008000s\n",
      "batch 16882, train_loss 43.012997,Time used 0.006999s\n",
      "batch 16883, train_loss 53.886814,Time used 0.011964s\n",
      "batch 16884, train_loss 47.524292,Time used 0.009038s\n",
      "batch 16885, train_loss 47.750694,Time used 0.007997s\n",
      "batch 16886, train_loss 45.809464,Time used 0.008009s\n",
      "batch 16887, train_loss 49.122383,Time used 0.006994s\n",
      "batch 16888, train_loss 32.680557,Time used 0.007000s\n",
      "batch 16889, train_loss 45.849911,Time used 0.009002s\n",
      "batch 16890, train_loss 45.820877,Time used 0.009997s\n",
      "batch 16891, train_loss 44.573837,Time used 0.007002s\n",
      "batch 16892, train_loss 51.237354,Time used 0.013002s\n",
      "batch 16893, train_loss 36.265900,Time used 0.011999s\n",
      "batch 16894, train_loss 36.786655,Time used 0.006996s\n",
      "batch 16895, train_loss 44.420105,Time used 0.010004s\n",
      "batch 16896, train_loss 58.725582,Time used 0.009998s\n",
      "batch 16897, train_loss 39.204746,Time used 0.008997s\n",
      "batch 16898, train_loss 51.992001,Time used 0.007001s\n",
      "batch 16899, train_loss 44.172729,Time used 0.011003s\n",
      "batch 16900, train_loss 39.070065,Time used 0.010001s\n",
      "***************************test_batch 16900, test_rmse_loss 7.715512,test_mae_loss 3.220091,test_mape_loss 52.805838,Time used 0.034000s\n",
      "batch 16901, train_loss 54.957417,Time used 0.008002s\n",
      "batch 16902, train_loss 48.125324,Time used 0.008997s\n",
      "batch 16903, train_loss 37.954403,Time used 0.007001s\n",
      "batch 16904, train_loss 45.326656,Time used 0.008000s\n",
      "batch 16905, train_loss 39.737331,Time used 0.007000s\n",
      "batch 16906, train_loss 39.125336,Time used 0.007999s\n",
      "batch 16907, train_loss 43.980751,Time used 0.011000s\n",
      "batch 16908, train_loss 35.469093,Time used 0.011000s\n",
      "batch 16909, train_loss 38.498295,Time used 0.010001s\n",
      "batch 16910, train_loss 47.004372,Time used 0.011000s\n",
      "batch 16911, train_loss 45.957558,Time used 0.009998s\n",
      "batch 16912, train_loss 45.149517,Time used 0.011002s\n",
      "batch 16913, train_loss 38.665768,Time used 0.008000s\n",
      "batch 16914, train_loss 39.355373,Time used 0.011000s\n",
      "batch 16915, train_loss 51.663258,Time used 0.008002s\n",
      "batch 16916, train_loss 49.028271,Time used 0.012001s\n",
      "batch 16917, train_loss 46.774937,Time used 0.010005s\n",
      "batch 16918, train_loss 48.127857,Time used 0.008994s\n",
      "batch 16919, train_loss 43.569798,Time used 0.011001s\n",
      "batch 16920, train_loss 52.286861,Time used 0.010002s\n",
      "batch 16921, train_loss 32.437302,Time used 0.006999s\n",
      "batch 16922, train_loss 38.574944,Time used 0.008000s\n",
      "batch 16923, train_loss 47.305424,Time used 0.007000s\n",
      "batch 16924, train_loss 42.752316,Time used 0.007000s\n",
      "batch 16925, train_loss 49.936829,Time used 0.008999s\n",
      "batch 16926, train_loss 45.845604,Time used 0.006998s\n",
      "batch 16927, train_loss 52.852989,Time used 0.008005s\n",
      "batch 16928, train_loss 47.854435,Time used 0.007999s\n",
      "batch 16929, train_loss 36.271564,Time used 0.010997s\n",
      "batch 16930, train_loss 37.207268,Time used 0.009003s\n",
      "batch 16931, train_loss 41.995621,Time used 0.010997s\n",
      "batch 16932, train_loss 44.070316,Time used 0.011998s\n",
      "batch 16933, train_loss 59.702930,Time used 0.009004s\n",
      "batch 16934, train_loss 42.437599,Time used 0.010998s\n",
      "batch 16935, train_loss 42.154121,Time used 0.009000s\n",
      "batch 16936, train_loss 47.904129,Time used 0.010000s\n",
      "batch 16937, train_loss 46.106789,Time used 0.008000s\n",
      "batch 16938, train_loss 45.317856,Time used 0.008001s\n",
      "batch 16939, train_loss 38.812424,Time used 0.006999s\n",
      "batch 16940, train_loss 46.218594,Time used 0.008999s\n",
      "batch 16941, train_loss 49.423573,Time used 0.008000s\n",
      "batch 16942, train_loss 39.780293,Time used 0.008000s\n",
      "batch 16943, train_loss 40.025597,Time used 0.009001s\n",
      "batch 16944, train_loss 48.508198,Time used 0.010040s\n",
      "batch 16945, train_loss 48.646446,Time used 0.007949s\n",
      "batch 16946, train_loss 46.552326,Time used 0.007999s\n",
      "batch 16947, train_loss 37.307674,Time used 0.008039s\n",
      "batch 16948, train_loss 50.897705,Time used 0.008961s\n",
      "batch 16949, train_loss 42.911480,Time used 0.010000s\n",
      "batch 16950, train_loss 49.623833,Time used 0.009999s\n",
      "batch 16951, train_loss 42.798363,Time used 0.010001s\n",
      "batch 16952, train_loss 42.687202,Time used 0.011000s\n",
      "batch 16953, train_loss 33.020214,Time used 0.009001s\n",
      "batch 16954, train_loss 54.652439,Time used 0.006999s\n",
      "batch 16955, train_loss 41.675629,Time used 0.008003s\n",
      "batch 16956, train_loss 37.862335,Time used 0.008007s\n",
      "batch 16957, train_loss 35.641232,Time used 0.008992s\n",
      "batch 16958, train_loss 40.156750,Time used 0.007999s\n",
      "batch 16959, train_loss 48.106976,Time used 0.008008s\n",
      "batch 16960, train_loss 45.863506,Time used 0.006998s\n",
      "batch 16961, train_loss 42.448647,Time used 0.011000s\n",
      "batch 16962, train_loss 51.689285,Time used 0.009998s\n",
      "batch 16963, train_loss 48.107498,Time used 0.009000s\n",
      "batch 16964, train_loss 50.733154,Time used 0.008000s\n",
      "batch 16965, train_loss 38.810925,Time used 0.007000s\n",
      "batch 16966, train_loss 48.995483,Time used 0.008003s\n",
      "batch 16967, train_loss 44.137775,Time used 0.006998s\n",
      "batch 16968, train_loss 37.772869,Time used 0.011000s\n",
      "batch 16969, train_loss 42.085125,Time used 0.008001s\n",
      "batch 16970, train_loss 47.252487,Time used 0.009000s\n",
      "batch 16971, train_loss 45.571060,Time used 0.006999s\n",
      "batch 16972, train_loss 47.854286,Time used 0.008004s\n",
      "batch 16973, train_loss 44.464867,Time used 0.007999s\n",
      "batch 16974, train_loss 51.643169,Time used 0.007997s\n",
      "batch 16975, train_loss 44.124100,Time used 0.008001s\n",
      "batch 16976, train_loss 41.088062,Time used 0.010001s\n",
      "batch 16977, train_loss 48.329445,Time used 0.009001s\n",
      "batch 16978, train_loss 40.730080,Time used 0.007998s\n",
      "batch 16979, train_loss 38.094440,Time used 0.007999s\n",
      "batch 16980, train_loss 37.328075,Time used 0.009001s\n",
      "batch 16981, train_loss 52.040268,Time used 0.011000s\n",
      "batch 16982, train_loss 49.892975,Time used 0.008000s\n",
      "batch 16983, train_loss 39.138180,Time used 0.010002s\n",
      "batch 16984, train_loss 44.591751,Time used 0.009000s\n",
      "batch 16985, train_loss 29.933361,Time used 0.007998s\n",
      "batch 16986, train_loss 43.063232,Time used 0.008001s\n",
      "batch 16987, train_loss 43.749165,Time used 0.008000s\n",
      "batch 16988, train_loss 46.636505,Time used 0.010000s\n",
      "batch 16989, train_loss 37.523998,Time used 0.011000s\n",
      "batch 16990, train_loss 52.466503,Time used 0.011000s\n",
      "batch 16991, train_loss 45.898918,Time used 0.010001s\n",
      "batch 16992, train_loss 46.693996,Time used 0.009001s\n",
      "batch 16993, train_loss 43.656601,Time used 0.011997s\n",
      "batch 16994, train_loss 36.580723,Time used 0.010003s\n",
      "batch 16995, train_loss 40.670959,Time used 0.010996s\n",
      "batch 16996, train_loss 49.180538,Time used 0.010000s\n",
      "batch 16997, train_loss 49.852615,Time used 0.009003s\n",
      "batch 16998, train_loss 44.751526,Time used 0.009998s\n",
      "batch 16999, train_loss 38.492069,Time used 0.009999s\n",
      "batch 17000, train_loss 42.919102,Time used 0.010002s\n",
      "***************************test_batch 17000, test_rmse_loss 7.683099,test_mae_loss 3.215875,test_mape_loss 53.077647,Time used 0.035000s\n",
      "batch 17001, train_loss 45.330105,Time used 0.011000s\n",
      "batch 17002, train_loss 39.225624,Time used 0.008000s\n",
      "batch 17003, train_loss 52.214256,Time used 0.008000s\n",
      "batch 17004, train_loss 43.048367,Time used 0.007999s\n",
      "batch 17005, train_loss 34.724670,Time used 0.012001s\n",
      "batch 17006, train_loss 34.800968,Time used 0.009999s\n",
      "batch 17007, train_loss 39.719017,Time used 0.011002s\n",
      "batch 17008, train_loss 54.006325,Time used 0.011998s\n",
      "batch 17009, train_loss 45.063854,Time used 0.011992s\n",
      "batch 17010, train_loss 53.755283,Time used 0.009003s\n",
      "batch 17011, train_loss 38.083076,Time used 0.009998s\n",
      "batch 17012, train_loss 45.795315,Time used 0.012001s\n",
      "batch 17013, train_loss 50.587585,Time used 0.011999s\n",
      "batch 17014, train_loss 43.961140,Time used 0.012000s\n",
      "batch 17015, train_loss 41.279427,Time used 0.012001s\n",
      "batch 17016, train_loss 51.055939,Time used 0.011000s\n",
      "batch 17017, train_loss 38.905190,Time used 0.012000s\n",
      "batch 17018, train_loss 33.007603,Time used 0.011999s\n",
      "batch 17019, train_loss 40.615349,Time used 0.013000s\n",
      "batch 17020, train_loss 48.925770,Time used 0.009999s\n",
      "batch 17021, train_loss 42.300106,Time used 0.007999s\n",
      "batch 17022, train_loss 30.166582,Time used 0.011003s\n",
      "batch 17023, train_loss 49.598499,Time used 0.008998s\n",
      "batch 17024, train_loss 51.951202,Time used 0.009001s\n",
      "batch 17025, train_loss 50.426895,Time used 0.008999s\n",
      "batch 17026, train_loss 49.954830,Time used 0.010000s\n",
      "batch 17027, train_loss 48.358494,Time used 0.009000s\n",
      "batch 17028, train_loss 45.329720,Time used 0.010001s\n",
      "batch 17029, train_loss 38.595142,Time used 0.011000s\n",
      "batch 17030, train_loss 55.733063,Time used 0.007998s\n",
      "batch 17031, train_loss 40.222946,Time used 0.008000s\n",
      "batch 17032, train_loss 38.760937,Time used 0.011000s\n",
      "batch 17033, train_loss 53.147060,Time used 0.009998s\n",
      "batch 17034, train_loss 49.449207,Time used 0.010001s\n",
      "batch 17035, train_loss 31.568056,Time used 0.011999s\n",
      "batch 17036, train_loss 53.991920,Time used 0.010996s\n",
      "batch 17037, train_loss 39.838348,Time used 0.011001s\n",
      "batch 17038, train_loss 37.592724,Time used 0.012000s\n",
      "batch 17039, train_loss 41.940079,Time used 0.008001s\n",
      "batch 17040, train_loss 46.424274,Time used 0.008000s\n",
      "batch 17041, train_loss 41.711609,Time used 0.011000s\n",
      "batch 17042, train_loss 41.495163,Time used 0.008002s\n",
      "batch 17043, train_loss 43.761559,Time used 0.014000s\n",
      "batch 17044, train_loss 48.894585,Time used 0.011998s\n",
      "batch 17045, train_loss 42.728794,Time used 0.011000s\n",
      "batch 17046, train_loss 41.164200,Time used 0.012001s\n",
      "batch 17047, train_loss 43.925804,Time used 0.011997s\n",
      "batch 17048, train_loss 37.797794,Time used 0.012001s\n",
      "batch 17049, train_loss 43.342461,Time used 0.010000s\n",
      "batch 17050, train_loss 50.968960,Time used 0.012004s\n",
      "batch 17051, train_loss 38.565742,Time used 0.011997s\n",
      "batch 17052, train_loss 45.469250,Time used 0.012003s\n",
      "batch 17053, train_loss 48.244808,Time used 0.012998s\n",
      "batch 17054, train_loss 45.957241,Time used 0.015001s\n",
      "batch 17055, train_loss 42.049484,Time used 0.013001s\n",
      "batch 17056, train_loss 45.562260,Time used 0.011001s\n",
      "batch 17057, train_loss 46.871712,Time used 0.012999s\n",
      "batch 17058, train_loss 44.947739,Time used 0.011000s\n",
      "batch 17059, train_loss 42.451912,Time used 0.011999s\n",
      "batch 17060, train_loss 42.314518,Time used 0.013001s\n",
      "batch 17061, train_loss 39.442970,Time used 0.013003s\n",
      "batch 17062, train_loss 45.408440,Time used 0.012996s\n",
      "batch 17063, train_loss 48.342979,Time used 0.019999s\n",
      "batch 17064, train_loss 43.970936,Time used 0.016003s\n",
      "batch 17065, train_loss 34.674953,Time used 0.015000s\n",
      "batch 17066, train_loss 48.327728,Time used 0.011998s\n",
      "batch 17067, train_loss 40.887512,Time used 0.012000s\n",
      "batch 17068, train_loss 43.672512,Time used 0.012001s\n",
      "batch 17069, train_loss 47.772835,Time used 0.015001s\n",
      "batch 17070, train_loss 38.802612,Time used 0.009999s\n",
      "batch 17071, train_loss 48.894115,Time used 0.012002s\n",
      "batch 17072, train_loss 39.771049,Time used 0.011000s\n",
      "batch 17073, train_loss 39.588009,Time used 0.020000s\n",
      "batch 17074, train_loss 44.108536,Time used 0.014999s\n",
      "batch 17075, train_loss 42.971935,Time used 0.011002s\n",
      "batch 17076, train_loss 35.816376,Time used 0.012000s\n",
      "batch 17077, train_loss 49.879166,Time used 0.012000s\n",
      "batch 17078, train_loss 45.744328,Time used 0.011998s\n",
      "batch 17079, train_loss 38.284073,Time used 0.011000s\n",
      "batch 17080, train_loss 38.226517,Time used 0.011001s\n",
      "batch 17081, train_loss 39.697021,Time used 0.008998s\n",
      "batch 17082, train_loss 41.189587,Time used 0.010001s\n",
      "batch 17083, train_loss 42.985809,Time used 0.008002s\n",
      "batch 17084, train_loss 51.685871,Time used 0.009001s\n",
      "batch 17085, train_loss 51.837914,Time used 0.007998s\n",
      "batch 17086, train_loss 34.766914,Time used 0.008999s\n",
      "batch 17087, train_loss 58.218132,Time used 0.010003s\n",
      "batch 17088, train_loss 56.169781,Time used 0.007996s\n",
      "batch 17089, train_loss 45.018177,Time used 0.009001s\n",
      "batch 17090, train_loss 44.208401,Time used 0.008000s\n",
      "batch 17091, train_loss 53.420162,Time used 0.009000s\n",
      "batch 17092, train_loss 52.033279,Time used 0.007999s\n",
      "batch 17093, train_loss 42.142570,Time used 0.010001s\n",
      "batch 17094, train_loss 36.976566,Time used 0.010999s\n",
      "batch 17095, train_loss 37.910995,Time used 0.008001s\n",
      "batch 17096, train_loss 49.990269,Time used 0.011998s\n",
      "batch 17097, train_loss 32.237312,Time used 0.011000s\n",
      "batch 17098, train_loss 49.778282,Time used 0.009001s\n",
      "batch 17099, train_loss 38.617493,Time used 0.008002s\n",
      "batch 17100, train_loss 44.542900,Time used 0.010001s\n",
      "***************************test_batch 17100, test_rmse_loss 7.667366,test_mae_loss 3.207610,test_mape_loss 52.754169,Time used 0.037000s\n",
      "batch 17101, train_loss 32.297314,Time used 0.010001s\n",
      "batch 17102, train_loss 42.887939,Time used 0.008998s\n",
      "batch 17103, train_loss 49.816036,Time used 0.009000s\n",
      "batch 17104, train_loss 36.973091,Time used 0.009998s\n",
      "batch 17105, train_loss 36.969051,Time used 0.010001s\n",
      "batch 17106, train_loss 42.573265,Time used 0.008001s\n",
      "batch 17107, train_loss 43.032024,Time used 0.012035s\n",
      "batch 17108, train_loss 51.147842,Time used 0.007964s\n",
      "batch 17109, train_loss 47.927269,Time used 0.009002s\n",
      "batch 17110, train_loss 37.937996,Time used 0.008999s\n",
      "batch 17111, train_loss 53.332497,Time used 0.007999s\n",
      "batch 17112, train_loss 50.299328,Time used 0.008000s\n",
      "batch 17113, train_loss 41.525257,Time used 0.009002s\n",
      "batch 17114, train_loss 33.923573,Time used 0.007998s\n",
      "batch 17115, train_loss 50.058968,Time used 0.008001s\n",
      "batch 17116, train_loss 42.434963,Time used 0.009001s\n",
      "batch 17117, train_loss 39.768196,Time used 0.008001s\n",
      "batch 17118, train_loss 44.991447,Time used 0.008999s\n",
      "batch 17119, train_loss 41.179779,Time used 0.008000s\n",
      "batch 17120, train_loss 45.387394,Time used 0.012000s\n",
      "batch 17121, train_loss 44.371189,Time used 0.011000s\n",
      "batch 17122, train_loss 39.626179,Time used 0.007001s\n",
      "batch 17123, train_loss 37.295914,Time used 0.008001s\n",
      "batch 17124, train_loss 47.412819,Time used 0.011000s\n",
      "batch 17125, train_loss 38.612129,Time used 0.007001s\n",
      "batch 17126, train_loss 49.506798,Time used 0.011000s\n",
      "batch 17127, train_loss 46.985462,Time used 0.011998s\n",
      "batch 17128, train_loss 50.866192,Time used 0.010000s\n",
      "batch 17129, train_loss 41.719231,Time used 0.012001s\n",
      "batch 17130, train_loss 48.090443,Time used 0.013000s\n",
      "batch 17131, train_loss 41.771709,Time used 0.009000s\n",
      "batch 17132, train_loss 47.268940,Time used 0.007999s\n",
      "batch 17133, train_loss 44.303501,Time used 0.008000s\n",
      "batch 17134, train_loss 45.946941,Time used 0.009000s\n",
      "batch 17135, train_loss 46.723495,Time used 0.009998s\n",
      "batch 17136, train_loss 40.454872,Time used 0.008000s\n",
      "batch 17137, train_loss 44.114738,Time used 0.009000s\n",
      "batch 17138, train_loss 51.964355,Time used 0.009001s\n",
      "batch 17139, train_loss 45.292000,Time used 0.012999s\n",
      "batch 17140, train_loss 39.714489,Time used 0.012002s\n",
      "batch 17141, train_loss 37.294041,Time used 0.012999s\n",
      "batch 17142, train_loss 37.311863,Time used 0.008997s\n",
      "batch 17143, train_loss 44.226460,Time used 0.008001s\n",
      "batch 17144, train_loss 37.811718,Time used 0.008998s\n",
      "batch 17145, train_loss 46.750839,Time used 0.008001s\n",
      "batch 17146, train_loss 40.206604,Time used 0.009999s\n",
      "batch 17147, train_loss 40.500404,Time used 0.010001s\n",
      "batch 17148, train_loss 50.692165,Time used 0.011000s\n",
      "batch 17149, train_loss 46.444305,Time used 0.010998s\n",
      "batch 17150, train_loss 39.836681,Time used 0.009001s\n",
      "batch 17151, train_loss 43.105530,Time used 0.009003s\n",
      "batch 17152, train_loss 49.054470,Time used 0.009998s\n",
      "batch 17153, train_loss 43.878292,Time used 0.008001s\n",
      "batch 17154, train_loss 48.895481,Time used 0.007998s\n",
      "batch 17155, train_loss 40.933113,Time used 0.011000s\n",
      "batch 17156, train_loss 42.495640,Time used 0.007999s\n",
      "batch 17157, train_loss 46.090607,Time used 0.009001s\n",
      "batch 17158, train_loss 45.777397,Time used 0.009000s\n",
      "batch 17159, train_loss 49.325382,Time used 0.007998s\n",
      "batch 17160, train_loss 37.055332,Time used 0.009003s\n",
      "batch 17161, train_loss 44.994698,Time used 0.011003s\n",
      "batch 17162, train_loss 40.120251,Time used 0.007994s\n",
      "batch 17163, train_loss 47.983257,Time used 0.010002s\n",
      "batch 17164, train_loss 39.645741,Time used 0.007003s\n",
      "batch 17165, train_loss 38.070950,Time used 0.007996s\n",
      "batch 17166, train_loss 51.966972,Time used 0.006999s\n",
      "batch 17167, train_loss 47.701351,Time used 0.010001s\n",
      "batch 17168, train_loss 32.901382,Time used 0.008001s\n",
      "batch 17169, train_loss 38.895206,Time used 0.015001s\n",
      "batch 17170, train_loss 43.174179,Time used 0.012000s\n",
      "batch 17171, train_loss 48.161751,Time used 0.009001s\n",
      "batch 17172, train_loss 47.735363,Time used 0.010000s\n",
      "batch 17173, train_loss 51.211441,Time used 0.012000s\n",
      "batch 17174, train_loss 44.850475,Time used 0.008001s\n",
      "batch 17175, train_loss 31.085871,Time used 0.012001s\n",
      "batch 17176, train_loss 40.130146,Time used 0.007999s\n",
      "batch 17177, train_loss 38.006145,Time used 0.009000s\n",
      "batch 17178, train_loss 46.387035,Time used 0.008002s\n",
      "batch 17179, train_loss 49.956245,Time used 0.011003s\n",
      "batch 17180, train_loss 32.346149,Time used 0.011993s\n",
      "batch 17181, train_loss 41.085468,Time used 0.009001s\n",
      "batch 17182, train_loss 50.284912,Time used 0.007000s\n",
      "batch 17183, train_loss 49.012520,Time used 0.008000s\n",
      "batch 17184, train_loss 51.912003,Time used 0.007999s\n",
      "batch 17185, train_loss 33.670155,Time used 0.009001s\n",
      "batch 17186, train_loss 42.487110,Time used 0.013001s\n",
      "batch 17187, train_loss 44.119610,Time used 0.011998s\n",
      "batch 17188, train_loss 43.238125,Time used 0.012001s\n",
      "batch 17189, train_loss 39.942810,Time used 0.013999s\n",
      "batch 17190, train_loss 35.112957,Time used 0.011000s\n",
      "batch 17191, train_loss 33.043236,Time used 0.010003s\n",
      "batch 17192, train_loss 45.862949,Time used 0.012000s\n",
      "batch 17193, train_loss 46.053570,Time used 0.013000s\n",
      "batch 17194, train_loss 37.607971,Time used 0.012000s\n",
      "batch 17195, train_loss 49.656906,Time used 0.012001s\n",
      "batch 17196, train_loss 47.473484,Time used 0.013000s\n",
      "batch 17197, train_loss 48.987457,Time used 0.013000s\n",
      "batch 17198, train_loss 42.455795,Time used 0.012999s\n",
      "batch 17199, train_loss 55.156471,Time used 0.013004s\n",
      "batch 17200, train_loss 50.250076,Time used 0.010996s\n",
      "***************************test_batch 17200, test_rmse_loss 7.641613,test_mae_loss 3.201669,test_mape_loss 52.873322,Time used 0.049004s\n",
      "batch 17201, train_loss 36.954731,Time used 0.013997s\n",
      "batch 17202, train_loss 41.622700,Time used 0.015000s\n",
      "batch 17203, train_loss 39.289139,Time used 0.023999s\n",
      "batch 17204, train_loss 43.048454,Time used 0.011998s\n",
      "batch 17205, train_loss 41.611053,Time used 0.010999s\n",
      "batch 17206, train_loss 54.084793,Time used 0.011001s\n",
      "batch 17207, train_loss 51.398518,Time used 0.011001s\n",
      "batch 17208, train_loss 42.742935,Time used 0.013001s\n",
      "batch 17209, train_loss 41.826473,Time used 0.010998s\n",
      "batch 17210, train_loss 45.068340,Time used 0.011999s\n",
      "batch 17211, train_loss 48.261356,Time used 0.013001s\n",
      "batch 17212, train_loss 39.190853,Time used 0.011000s\n",
      "batch 17213, train_loss 42.705940,Time used 0.010998s\n",
      "batch 17214, train_loss 38.849731,Time used 0.011003s\n",
      "batch 17215, train_loss 39.580608,Time used 0.012000s\n",
      "batch 17216, train_loss 44.515133,Time used 0.012998s\n",
      "batch 17217, train_loss 52.501472,Time used 0.008998s\n",
      "batch 17218, train_loss 39.483894,Time used 0.011003s\n",
      "batch 17219, train_loss 50.277962,Time used 0.010000s\n",
      "batch 17220, train_loss 50.799175,Time used 0.010001s\n",
      "batch 17221, train_loss 37.910744,Time used 0.010000s\n",
      "batch 17222, train_loss 46.594589,Time used 0.010999s\n",
      "batch 17223, train_loss 45.532806,Time used 0.009001s\n",
      "batch 17224, train_loss 35.523254,Time used 0.012001s\n",
      "batch 17225, train_loss 47.194912,Time used 0.011996s\n",
      "batch 17226, train_loss 35.455734,Time used 0.011003s\n",
      "batch 17227, train_loss 41.890602,Time used 0.010999s\n",
      "batch 17228, train_loss 36.172684,Time used 0.013000s\n",
      "batch 17229, train_loss 52.965385,Time used 0.012999s\n",
      "batch 17230, train_loss 48.544495,Time used 0.011000s\n",
      "batch 17231, train_loss 45.023407,Time used 0.009004s\n",
      "batch 17232, train_loss 38.543877,Time used 0.009996s\n",
      "batch 17233, train_loss 41.550972,Time used 0.008003s\n",
      "batch 17234, train_loss 38.676811,Time used 0.008002s\n",
      "batch 17235, train_loss 32.317810,Time used 0.009996s\n",
      "batch 17236, train_loss 50.021732,Time used 0.010000s\n",
      "batch 17237, train_loss 40.245155,Time used 0.012001s\n",
      "batch 17238, train_loss 46.322765,Time used 0.008999s\n",
      "batch 17239, train_loss 43.869057,Time used 0.007997s\n",
      "batch 17240, train_loss 44.941540,Time used 0.009000s\n",
      "batch 17241, train_loss 40.964848,Time used 0.008001s\n",
      "batch 17242, train_loss 44.894775,Time used 0.012000s\n",
      "batch 17243, train_loss 38.779636,Time used 0.011000s\n",
      "batch 17244, train_loss 44.913105,Time used 0.011999s\n",
      "batch 17245, train_loss 49.422909,Time used 0.008000s\n",
      "batch 17246, train_loss 42.156586,Time used 0.007999s\n",
      "batch 17247, train_loss 46.160004,Time used 0.010996s\n",
      "batch 17248, train_loss 50.440037,Time used 0.008000s\n",
      "batch 17249, train_loss 31.273077,Time used 0.008001s\n",
      "batch 17250, train_loss 45.020855,Time used 0.009000s\n",
      "batch 17251, train_loss 49.115959,Time used 0.012000s\n",
      "batch 17252, train_loss 41.402058,Time used 0.014002s\n",
      "batch 17253, train_loss 48.792946,Time used 0.015998s\n",
      "batch 17254, train_loss 36.532505,Time used 0.010998s\n",
      "batch 17255, train_loss 45.029118,Time used 0.010000s\n",
      "batch 17256, train_loss 50.078869,Time used 0.007999s\n",
      "batch 17257, train_loss 44.849716,Time used 0.009999s\n",
      "batch 17258, train_loss 44.347427,Time used 0.011000s\n",
      "batch 17259, train_loss 43.715027,Time used 0.007999s\n",
      "batch 17260, train_loss 47.101376,Time used 0.012000s\n",
      "batch 17261, train_loss 56.661777,Time used 0.009001s\n",
      "batch 17262, train_loss 46.018444,Time used 0.009001s\n",
      "batch 17263, train_loss 46.319077,Time used 0.013000s\n",
      "batch 17264, train_loss 38.516399,Time used 0.008000s\n",
      "batch 17265, train_loss 35.194588,Time used 0.007000s\n",
      "batch 17266, train_loss 47.926762,Time used 0.009998s\n",
      "batch 17267, train_loss 42.832577,Time used 0.010003s\n",
      "batch 17268, train_loss 42.287037,Time used 0.009002s\n",
      "batch 17269, train_loss 46.421913,Time used 0.008998s\n",
      "batch 17270, train_loss 36.899364,Time used 0.011999s\n",
      "batch 17271, train_loss 47.169029,Time used 0.008003s\n",
      "batch 17272, train_loss 40.975895,Time used 0.009999s\n",
      "batch 17273, train_loss 35.440868,Time used 0.009000s\n",
      "batch 17274, train_loss 44.112724,Time used 0.009002s\n",
      "batch 17275, train_loss 40.006699,Time used 0.006997s\n",
      "batch 17276, train_loss 40.926205,Time used 0.008000s\n",
      "batch 17277, train_loss 38.267818,Time used 0.008000s\n",
      "batch 17278, train_loss 49.695343,Time used 0.008999s\n",
      "batch 17279, train_loss 42.457813,Time used 0.009001s\n",
      "batch 17280, train_loss 42.857193,Time used 0.011998s\n",
      "batch 17281, train_loss 36.579926,Time used 0.007999s\n",
      "batch 17282, train_loss 51.732452,Time used 0.010003s\n",
      "batch 17283, train_loss 42.355492,Time used 0.008997s\n",
      "batch 17284, train_loss 36.029995,Time used 0.013999s\n",
      "batch 17285, train_loss 43.675396,Time used 0.012002s\n",
      "batch 17286, train_loss 40.310364,Time used 0.012001s\n",
      "batch 17287, train_loss 49.221554,Time used 0.011999s\n",
      "batch 17288, train_loss 45.564026,Time used 0.011001s\n",
      "batch 17289, train_loss 45.593353,Time used 0.010997s\n",
      "batch 17290, train_loss 43.486671,Time used 0.012003s\n",
      "batch 17291, train_loss 51.649624,Time used 0.011999s\n",
      "batch 17292, train_loss 40.957954,Time used 0.012003s\n",
      "batch 17293, train_loss 37.537666,Time used 0.011998s\n",
      "batch 17294, train_loss 37.738453,Time used 0.012001s\n",
      "batch 17295, train_loss 44.160973,Time used 0.010999s\n",
      "batch 17296, train_loss 52.545692,Time used 0.010000s\n",
      "batch 17297, train_loss 49.886120,Time used 0.011997s\n",
      "batch 17298, train_loss 46.137142,Time used 0.012001s\n",
      "batch 17299, train_loss 50.598579,Time used 0.012002s\n",
      "batch 17300, train_loss 41.112240,Time used 0.011000s\n",
      "***************************test_batch 17300, test_rmse_loss 7.621720,test_mae_loss 3.191816,test_mape_loss 52.582430,Time used 0.050998s\n",
      "batch 17301, train_loss 29.785566,Time used 0.018008s\n",
      "batch 17302, train_loss 36.483631,Time used 0.023992s\n",
      "batch 17303, train_loss 38.381695,Time used 0.011999s\n",
      "batch 17304, train_loss 48.346439,Time used 0.011002s\n",
      "batch 17305, train_loss 42.320995,Time used 0.010000s\n",
      "batch 17306, train_loss 54.719467,Time used 0.009002s\n",
      "batch 17307, train_loss 36.100990,Time used 0.010998s\n",
      "batch 17308, train_loss 33.877037,Time used 0.012001s\n",
      "batch 17309, train_loss 45.492451,Time used 0.013000s\n",
      "batch 17310, train_loss 46.100258,Time used 0.013000s\n",
      "batch 17311, train_loss 37.551949,Time used 0.011998s\n",
      "batch 17312, train_loss 45.996159,Time used 0.011003s\n",
      "batch 17313, train_loss 44.006237,Time used 0.010993s\n",
      "batch 17314, train_loss 37.230755,Time used 0.014000s\n",
      "batch 17315, train_loss 46.891754,Time used 0.013001s\n",
      "batch 17316, train_loss 38.810184,Time used 0.012998s\n",
      "batch 17317, train_loss 36.693073,Time used 0.012000s\n",
      "batch 17318, train_loss 46.493679,Time used 0.011998s\n",
      "batch 17319, train_loss 44.905670,Time used 0.011000s\n",
      "batch 17320, train_loss 54.383415,Time used 0.008003s\n",
      "batch 17321, train_loss 45.177269,Time used 0.009000s\n",
      "batch 17322, train_loss 44.792263,Time used 0.009999s\n",
      "batch 17323, train_loss 47.869026,Time used 0.008002s\n",
      "batch 17324, train_loss 48.510597,Time used 0.013000s\n",
      "batch 17325, train_loss 40.425243,Time used 0.007998s\n",
      "batch 17326, train_loss 34.835732,Time used 0.008001s\n",
      "batch 17327, train_loss 43.470993,Time used 0.009998s\n",
      "batch 17328, train_loss 41.327614,Time used 0.010001s\n",
      "batch 17329, train_loss 40.940720,Time used 0.009001s\n",
      "batch 17330, train_loss 45.207443,Time used 0.006999s\n",
      "batch 17331, train_loss 47.992271,Time used 0.012000s\n",
      "batch 17332, train_loss 39.216217,Time used 0.010998s\n",
      "batch 17333, train_loss 27.950735,Time used 0.011000s\n",
      "batch 17334, train_loss 38.788216,Time used 0.010000s\n",
      "batch 17335, train_loss 40.287724,Time used 0.011001s\n",
      "batch 17336, train_loss 45.000591,Time used 0.011002s\n",
      "batch 17337, train_loss 40.089878,Time used 0.012999s\n",
      "batch 17338, train_loss 45.438305,Time used 0.012004s\n",
      "batch 17339, train_loss 44.991886,Time used 0.010994s\n",
      "batch 17340, train_loss 39.438038,Time used 0.010006s\n",
      "batch 17341, train_loss 48.506393,Time used 0.010999s\n",
      "batch 17342, train_loss 47.388515,Time used 0.011000s\n",
      "batch 17343, train_loss 46.433556,Time used 0.007998s\n",
      "batch 17344, train_loss 42.282536,Time used 0.008000s\n",
      "batch 17345, train_loss 33.974689,Time used 0.007999s\n",
      "batch 17346, train_loss 47.362312,Time used 0.012000s\n",
      "batch 17347, train_loss 46.918388,Time used 0.012004s\n",
      "batch 17348, train_loss 42.753365,Time used 0.010000s\n",
      "batch 17349, train_loss 48.801250,Time used 0.008000s\n",
      "batch 17350, train_loss 43.879211,Time used 0.008001s\n",
      "batch 17351, train_loss 47.570148,Time used 0.006997s\n",
      "batch 17352, train_loss 45.469326,Time used 0.007995s\n",
      "batch 17353, train_loss 38.684666,Time used 0.007999s\n",
      "batch 17354, train_loss 43.726891,Time used 0.007001s\n",
      "batch 17355, train_loss 52.105194,Time used 0.008999s\n",
      "batch 17356, train_loss 38.587334,Time used 0.008000s\n",
      "batch 17357, train_loss 41.810066,Time used 0.009001s\n",
      "batch 17358, train_loss 44.568645,Time used 0.008001s\n",
      "batch 17359, train_loss 43.256950,Time used 0.008000s\n",
      "batch 17360, train_loss 41.919983,Time used 0.007998s\n",
      "batch 17361, train_loss 44.520607,Time used 0.008003s\n",
      "batch 17362, train_loss 40.996399,Time used 0.008002s\n",
      "batch 17363, train_loss 40.420166,Time used 0.009999s\n",
      "batch 17364, train_loss 46.421650,Time used 0.007998s\n",
      "batch 17365, train_loss 45.783810,Time used 0.008000s\n",
      "batch 17366, train_loss 50.517586,Time used 0.009999s\n",
      "batch 17367, train_loss 44.557297,Time used 0.011002s\n",
      "batch 17368, train_loss 40.579308,Time used 0.009001s\n",
      "batch 17369, train_loss 41.880215,Time used 0.010000s\n",
      "batch 17370, train_loss 50.045387,Time used 0.008000s\n",
      "batch 17371, train_loss 39.620197,Time used 0.009000s\n",
      "batch 17372, train_loss 43.293919,Time used 0.007999s\n",
      "batch 17373, train_loss 35.773994,Time used 0.007001s\n",
      "batch 17374, train_loss 41.868088,Time used 0.007003s\n",
      "batch 17375, train_loss 38.336906,Time used 0.008000s\n",
      "batch 17376, train_loss 46.103111,Time used 0.011000s\n",
      "batch 17377, train_loss 44.934944,Time used 0.006998s\n",
      "batch 17378, train_loss 44.157875,Time used 0.008000s\n",
      "batch 17379, train_loss 40.055050,Time used 0.010999s\n",
      "batch 17380, train_loss 39.029682,Time used 0.010000s\n",
      "batch 17381, train_loss 50.771835,Time used 0.009002s\n",
      "batch 17382, train_loss 49.275883,Time used 0.011997s\n",
      "batch 17383, train_loss 43.012836,Time used 0.010000s\n",
      "batch 17384, train_loss 45.740471,Time used 0.009000s\n",
      "batch 17385, train_loss 42.715290,Time used 0.008000s\n",
      "batch 17386, train_loss 35.028618,Time used 0.007999s\n",
      "batch 17387, train_loss 46.009880,Time used 0.008000s\n",
      "batch 17388, train_loss 34.722984,Time used 0.012000s\n",
      "batch 17389, train_loss 37.178665,Time used 0.010000s\n",
      "batch 17390, train_loss 40.966049,Time used 0.008001s\n",
      "batch 17391, train_loss 40.032845,Time used 0.010999s\n",
      "batch 17392, train_loss 40.833153,Time used 0.009001s\n",
      "batch 17393, train_loss 34.976204,Time used 0.009999s\n",
      "batch 17394, train_loss 44.209274,Time used 0.009000s\n",
      "batch 17395, train_loss 43.727402,Time used 0.011002s\n",
      "batch 17396, train_loss 49.944138,Time used 0.010000s\n",
      "batch 17397, train_loss 50.898285,Time used 0.010001s\n",
      "batch 17398, train_loss 48.926586,Time used 0.007999s\n",
      "batch 17399, train_loss 56.617561,Time used 0.009999s\n",
      "batch 17400, train_loss 29.169291,Time used 0.010002s\n",
      "***************************test_batch 17400, test_rmse_loss 7.600991,test_mae_loss 3.185985,test_mape_loss 52.442828,Time used 0.032000s\n",
      "batch 17401, train_loss 34.910282,Time used 0.009002s\n",
      "batch 17402, train_loss 48.907768,Time used 0.008999s\n",
      "batch 17403, train_loss 33.441437,Time used 0.009001s\n",
      "batch 17404, train_loss 53.213379,Time used 0.010999s\n",
      "batch 17405, train_loss 50.204479,Time used 0.008000s\n",
      "batch 17406, train_loss 43.813179,Time used 0.007998s\n",
      "batch 17407, train_loss 37.416840,Time used 0.008001s\n",
      "batch 17408, train_loss 44.378780,Time used 0.007000s\n",
      "batch 17409, train_loss 42.560741,Time used 0.009000s\n",
      "batch 17410, train_loss 39.597900,Time used 0.010002s\n",
      "batch 17411, train_loss 48.358356,Time used 0.009003s\n",
      "batch 17412, train_loss 36.227573,Time used 0.008996s\n",
      "batch 17413, train_loss 50.155960,Time used 0.008003s\n",
      "batch 17414, train_loss 48.002205,Time used 0.010002s\n",
      "batch 17415, train_loss 41.027538,Time used 0.010997s\n",
      "batch 17416, train_loss 42.312500,Time used 0.009002s\n",
      "batch 17417, train_loss 45.774963,Time used 0.009004s\n",
      "batch 17418, train_loss 52.081375,Time used 0.006998s\n",
      "batch 17419, train_loss 42.045097,Time used 0.008001s\n",
      "batch 17420, train_loss 37.322556,Time used 0.006999s\n",
      "batch 17421, train_loss 42.028065,Time used 0.007999s\n",
      "batch 17422, train_loss 32.039948,Time used 0.007998s\n",
      "batch 17423, train_loss 45.809105,Time used 0.011003s\n",
      "batch 17424, train_loss 40.541451,Time used 0.012998s\n",
      "batch 17425, train_loss 36.690834,Time used 0.011995s\n",
      "batch 17426, train_loss 37.314678,Time used 0.011000s\n",
      "batch 17427, train_loss 34.388855,Time used 0.009998s\n",
      "batch 17428, train_loss 45.638107,Time used 0.012007s\n",
      "batch 17429, train_loss 41.716877,Time used 0.011992s\n",
      "batch 17430, train_loss 54.047539,Time used 0.011001s\n",
      "batch 17431, train_loss 33.038612,Time used 0.012001s\n",
      "batch 17432, train_loss 40.146770,Time used 0.012000s\n",
      "batch 17433, train_loss 42.220486,Time used 0.012000s\n",
      "batch 17434, train_loss 45.428047,Time used 0.012999s\n",
      "batch 17435, train_loss 44.692036,Time used 0.011998s\n",
      "batch 17436, train_loss 41.227188,Time used 0.008002s\n",
      "batch 17437, train_loss 41.623745,Time used 0.008000s\n",
      "batch 17438, train_loss 53.824184,Time used 0.008000s\n",
      "batch 17439, train_loss 43.394184,Time used 0.011002s\n",
      "batch 17440, train_loss 36.626934,Time used 0.010001s\n",
      "batch 17441, train_loss 34.510166,Time used 0.011997s\n",
      "batch 17442, train_loss 51.957008,Time used 0.011001s\n",
      "batch 17443, train_loss 46.840847,Time used 0.008999s\n",
      "batch 17444, train_loss 43.611076,Time used 0.009002s\n",
      "batch 17445, train_loss 36.002125,Time used 0.009999s\n",
      "batch 17446, train_loss 54.902603,Time used 0.009998s\n",
      "batch 17447, train_loss 44.123096,Time used 0.012002s\n",
      "batch 17448, train_loss 46.879841,Time used 0.013999s\n",
      "batch 17449, train_loss 41.733105,Time used 0.006992s\n",
      "batch 17450, train_loss 47.284386,Time used 0.008998s\n",
      "batch 17451, train_loss 44.206371,Time used 0.011001s\n",
      "batch 17452, train_loss 41.562393,Time used 0.008001s\n",
      "batch 17453, train_loss 46.184925,Time used 0.011003s\n",
      "batch 17454, train_loss 40.987625,Time used 0.007998s\n",
      "batch 17455, train_loss 44.087006,Time used 0.012001s\n",
      "batch 17456, train_loss 47.122295,Time used 0.010002s\n",
      "batch 17457, train_loss 42.507812,Time used 0.007999s\n",
      "batch 17458, train_loss 41.780899,Time used 0.008997s\n",
      "batch 17459, train_loss 42.906414,Time used 0.009000s\n",
      "batch 17460, train_loss 52.942886,Time used 0.009001s\n",
      "batch 17461, train_loss 42.353123,Time used 0.008000s\n",
      "batch 17462, train_loss 43.043034,Time used 0.012001s\n",
      "batch 17463, train_loss 45.226616,Time used 0.009999s\n",
      "batch 17464, train_loss 42.277573,Time used 0.012001s\n",
      "batch 17465, train_loss 47.004997,Time used 0.008001s\n",
      "batch 17466, train_loss 41.511986,Time used 0.007999s\n",
      "batch 17467, train_loss 36.310078,Time used 0.008000s\n",
      "batch 17468, train_loss 40.592564,Time used 0.008000s\n",
      "batch 17469, train_loss 37.419895,Time used 0.009001s\n",
      "batch 17470, train_loss 43.076668,Time used 0.008001s\n",
      "batch 17471, train_loss 31.048372,Time used 0.007998s\n",
      "batch 17472, train_loss 46.363892,Time used 0.010000s\n",
      "batch 17473, train_loss 39.076923,Time used 0.008998s\n",
      "batch 17474, train_loss 42.899292,Time used 0.008002s\n",
      "batch 17475, train_loss 42.077644,Time used 0.010001s\n",
      "batch 17476, train_loss 45.524437,Time used 0.007998s\n",
      "batch 17477, train_loss 47.212585,Time used 0.008000s\n",
      "batch 17478, train_loss 44.200451,Time used 0.006999s\n",
      "batch 17479, train_loss 34.875511,Time used 0.007001s\n",
      "batch 17480, train_loss 53.772076,Time used 0.008001s\n",
      "batch 17481, train_loss 43.484135,Time used 0.007998s\n",
      "batch 17482, train_loss 41.981430,Time used 0.008000s\n",
      "batch 17483, train_loss 49.993317,Time used 0.010999s\n",
      "batch 17484, train_loss 41.794201,Time used 0.006999s\n",
      "batch 17485, train_loss 35.809723,Time used 0.008002s\n",
      "batch 17486, train_loss 41.093430,Time used 0.008000s\n",
      "batch 17487, train_loss 44.220932,Time used 0.010003s\n",
      "batch 17488, train_loss 33.746468,Time used 0.008002s\n",
      "batch 17489, train_loss 47.368473,Time used 0.007999s\n",
      "batch 17490, train_loss 55.291512,Time used 0.008001s\n",
      "batch 17491, train_loss 34.837418,Time used 0.009035s\n",
      "batch 17492, train_loss 31.743141,Time used 0.007963s\n",
      "batch 17493, train_loss 45.207432,Time used 0.012035s\n",
      "batch 17494, train_loss 43.616604,Time used 0.008004s\n",
      "batch 17495, train_loss 46.791981,Time used 0.009999s\n",
      "batch 17496, train_loss 41.094463,Time used 0.010995s\n",
      "batch 17497, train_loss 43.113178,Time used 0.008002s\n",
      "batch 17498, train_loss 41.156872,Time used 0.009996s\n",
      "batch 17499, train_loss 38.778812,Time used 0.008001s\n",
      "batch 17500, train_loss 35.227470,Time used 0.010000s\n",
      "***************************test_batch 17500, test_rmse_loss 7.581663,test_mae_loss 3.179415,test_mape_loss 52.422180,Time used 0.033999s\n",
      "batch 17501, train_loss 44.647259,Time used 0.009001s\n",
      "batch 17502, train_loss 47.848595,Time used 0.008000s\n",
      "batch 17503, train_loss 49.047771,Time used 0.007999s\n",
      "batch 17504, train_loss 46.454964,Time used 0.010999s\n",
      "batch 17505, train_loss 41.076130,Time used 0.008003s\n",
      "batch 17506, train_loss 36.689537,Time used 0.009998s\n",
      "batch 17507, train_loss 36.241116,Time used 0.008001s\n",
      "batch 17508, train_loss 44.521748,Time used 0.008000s\n",
      "batch 17509, train_loss 40.251575,Time used 0.011999s\n",
      "batch 17510, train_loss 48.699848,Time used 0.009000s\n",
      "batch 17511, train_loss 45.872337,Time used 0.007999s\n",
      "batch 17512, train_loss 42.662277,Time used 0.008002s\n",
      "batch 17513, train_loss 41.991970,Time used 0.008000s\n",
      "batch 17514, train_loss 42.055939,Time used 0.007999s\n",
      "batch 17515, train_loss 47.404533,Time used 0.008002s\n",
      "batch 17516, train_loss 42.528492,Time used 0.011997s\n",
      "batch 17517, train_loss 42.150242,Time used 0.012000s\n",
      "batch 17518, train_loss 36.382256,Time used 0.010001s\n",
      "batch 17519, train_loss 43.661003,Time used 0.009000s\n",
      "batch 17520, train_loss 48.262886,Time used 0.007999s\n",
      "batch 17521, train_loss 46.659050,Time used 0.008000s\n",
      "batch 17522, train_loss 47.369434,Time used 0.010999s\n",
      "batch 17523, train_loss 45.313038,Time used 0.010002s\n",
      "batch 17524, train_loss 46.855019,Time used 0.007999s\n",
      "batch 17525, train_loss 47.509666,Time used 0.011002s\n",
      "batch 17526, train_loss 36.167030,Time used 0.011003s\n",
      "batch 17527, train_loss 54.628582,Time used 0.010997s\n",
      "batch 17528, train_loss 43.823940,Time used 0.010001s\n",
      "batch 17529, train_loss 36.735950,Time used 0.010000s\n",
      "batch 17530, train_loss 42.694942,Time used 0.012001s\n",
      "batch 17531, train_loss 41.969791,Time used 0.010000s\n",
      "batch 17532, train_loss 47.760548,Time used 0.014001s\n",
      "batch 17533, train_loss 43.486763,Time used 0.012000s\n",
      "batch 17534, train_loss 36.455738,Time used 0.011000s\n",
      "batch 17535, train_loss 41.033504,Time used 0.008998s\n",
      "batch 17536, train_loss 41.763561,Time used 0.008001s\n",
      "batch 17537, train_loss 32.293514,Time used 0.011003s\n",
      "batch 17538, train_loss 41.973125,Time used 0.011000s\n",
      "batch 17539, train_loss 34.326584,Time used 0.008998s\n",
      "batch 17540, train_loss 43.106983,Time used 0.008000s\n",
      "batch 17541, train_loss 39.009140,Time used 0.011000s\n",
      "batch 17542, train_loss 45.401058,Time used 0.009003s\n",
      "batch 17543, train_loss 32.724689,Time used 0.010000s\n",
      "batch 17544, train_loss 56.619476,Time used 0.008001s\n",
      "batch 17545, train_loss 46.537338,Time used 0.009998s\n",
      "batch 17546, train_loss 43.739960,Time used 0.008002s\n",
      "batch 17547, train_loss 44.510506,Time used 0.010007s\n",
      "batch 17548, train_loss 40.452656,Time used 0.009990s\n",
      "batch 17549, train_loss 43.637836,Time used 0.008002s\n",
      "batch 17550, train_loss 46.744656,Time used 0.012001s\n",
      "batch 17551, train_loss 39.990784,Time used 0.007000s\n",
      "batch 17552, train_loss 45.328953,Time used 0.007999s\n",
      "batch 17553, train_loss 47.349018,Time used 0.008000s\n",
      "batch 17554, train_loss 40.584793,Time used 0.008000s\n",
      "batch 17555, train_loss 40.767578,Time used 0.008001s\n",
      "batch 17556, train_loss 41.570438,Time used 0.011000s\n",
      "batch 17557, train_loss 39.612595,Time used 0.012000s\n",
      "batch 17558, train_loss 48.150990,Time used 0.010005s\n",
      "batch 17559, train_loss 45.892998,Time used 0.008995s\n",
      "batch 17560, train_loss 39.438850,Time used 0.010001s\n",
      "batch 17561, train_loss 38.056416,Time used 0.011998s\n",
      "batch 17562, train_loss 40.991398,Time used 0.008002s\n",
      "batch 17563, train_loss 47.967731,Time used 0.011998s\n",
      "batch 17564, train_loss 34.452759,Time used 0.009002s\n",
      "batch 17565, train_loss 46.636639,Time used 0.011998s\n",
      "batch 17566, train_loss 51.813152,Time used 0.011004s\n",
      "batch 17567, train_loss 36.855518,Time used 0.012001s\n",
      "batch 17568, train_loss 32.124058,Time used 0.011997s\n",
      "batch 17569, train_loss 47.511917,Time used 0.007000s\n",
      "batch 17570, train_loss 42.127262,Time used 0.012001s\n",
      "batch 17571, train_loss 44.323532,Time used 0.011036s\n",
      "batch 17572, train_loss 43.596943,Time used 0.007962s\n",
      "batch 17573, train_loss 48.731514,Time used 0.010003s\n",
      "batch 17574, train_loss 40.136822,Time used 0.010006s\n",
      "batch 17575, train_loss 42.170349,Time used 0.007991s\n",
      "batch 17576, train_loss 43.133526,Time used 0.014001s\n",
      "batch 17577, train_loss 43.027702,Time used 0.011999s\n",
      "batch 17578, train_loss 26.329880,Time used 0.010001s\n",
      "batch 17579, train_loss 43.400139,Time used 0.012052s\n",
      "batch 17580, train_loss 51.195808,Time used 0.011955s\n",
      "batch 17581, train_loss 41.394978,Time used 0.013993s\n",
      "batch 17582, train_loss 45.085472,Time used 0.027014s\n",
      "batch 17583, train_loss 31.355600,Time used 0.019996s\n",
      "batch 17584, train_loss 38.363781,Time used 0.029000s\n",
      "batch 17585, train_loss 38.550636,Time used 0.019000s\n",
      "batch 17586, train_loss 39.610218,Time used 0.025013s\n",
      "batch 17587, train_loss 44.060905,Time used 0.017989s\n",
      "batch 17588, train_loss 33.263412,Time used 0.022999s\n",
      "batch 17589, train_loss 41.491219,Time used 0.014999s\n",
      "batch 17590, train_loss 59.309284,Time used 0.019999s\n",
      "batch 17591, train_loss 41.031921,Time used 0.026000s\n",
      "batch 17592, train_loss 53.058613,Time used 0.025001s\n",
      "batch 17593, train_loss 41.391903,Time used 0.027001s\n",
      "batch 17594, train_loss 37.132114,Time used 0.016999s\n",
      "batch 17595, train_loss 43.549149,Time used 0.024000s\n",
      "batch 17596, train_loss 39.749935,Time used 0.024999s\n",
      "batch 17597, train_loss 50.971390,Time used 0.017996s\n",
      "batch 17598, train_loss 41.134766,Time used 0.021001s\n",
      "batch 17599, train_loss 48.382259,Time used 0.015996s\n",
      "batch 17600, train_loss 42.085114,Time used 0.017003s\n",
      "***************************test_batch 17600, test_rmse_loss 7.559876,test_mae_loss 3.175947,test_mape_loss 52.503056,Time used 0.071987s\n",
      "batch 17601, train_loss 40.737316,Time used 0.014999s\n",
      "batch 17602, train_loss 48.467789,Time used 0.008000s\n",
      "batch 17603, train_loss 38.272766,Time used 0.012001s\n",
      "batch 17604, train_loss 42.589775,Time used 0.010002s\n",
      "batch 17605, train_loss 38.291080,Time used 0.009996s\n",
      "batch 17606, train_loss 44.801277,Time used 0.011003s\n",
      "batch 17607, train_loss 48.703182,Time used 0.008001s\n",
      "batch 17608, train_loss 40.188190,Time used 0.011998s\n",
      "batch 17609, train_loss 42.520821,Time used 0.007999s\n",
      "batch 17610, train_loss 37.650463,Time used 0.010003s\n",
      "batch 17611, train_loss 39.263752,Time used 0.010997s\n",
      "batch 17612, train_loss 44.224064,Time used 0.009002s\n",
      "batch 17613, train_loss 36.921276,Time used 0.012001s\n",
      "batch 17614, train_loss 51.508076,Time used 0.009999s\n",
      "batch 17615, train_loss 40.407272,Time used 0.011001s\n",
      "batch 17616, train_loss 41.375885,Time used 0.010998s\n",
      "batch 17617, train_loss 49.984730,Time used 0.011002s\n",
      "batch 17618, train_loss 41.390697,Time used 0.011003s\n",
      "batch 17619, train_loss 37.245014,Time used 0.007998s\n",
      "batch 17620, train_loss 40.489132,Time used 0.007999s\n",
      "batch 17621, train_loss 41.631157,Time used 0.009000s\n",
      "batch 17622, train_loss 42.672729,Time used 0.011997s\n",
      "batch 17623, train_loss 36.290981,Time used 0.010998s\n",
      "batch 17624, train_loss 36.692173,Time used 0.008002s\n",
      "batch 17625, train_loss 50.848789,Time used 0.009999s\n",
      "batch 17626, train_loss 51.431961,Time used 0.008000s\n",
      "batch 17627, train_loss 37.423141,Time used 0.008003s\n",
      "batch 17628, train_loss 48.681259,Time used 0.007998s\n",
      "batch 17629, train_loss 48.155949,Time used 0.008000s\n",
      "batch 17630, train_loss 41.391197,Time used 0.008001s\n",
      "batch 17631, train_loss 38.407104,Time used 0.012001s\n",
      "batch 17632, train_loss 45.944870,Time used 0.009998s\n",
      "batch 17633, train_loss 37.635231,Time used 0.007000s\n",
      "batch 17634, train_loss 43.158928,Time used 0.010002s\n",
      "batch 17635, train_loss 45.153534,Time used 0.009000s\n",
      "batch 17636, train_loss 33.336052,Time used 0.007999s\n",
      "batch 17637, train_loss 44.390495,Time used 0.011001s\n",
      "batch 17638, train_loss 44.247616,Time used 0.012000s\n",
      "batch 17639, train_loss 40.833771,Time used 0.007998s\n",
      "batch 17640, train_loss 41.317028,Time used 0.007999s\n",
      "batch 17641, train_loss 32.856743,Time used 0.011002s\n",
      "batch 17642, train_loss 54.228065,Time used 0.008998s\n",
      "batch 17643, train_loss 47.713955,Time used 0.010001s\n",
      "batch 17644, train_loss 39.006893,Time used 0.008000s\n",
      "batch 17645, train_loss 34.512688,Time used 0.007998s\n",
      "batch 17646, train_loss 39.809345,Time used 0.008001s\n",
      "batch 17647, train_loss 35.260876,Time used 0.011001s\n",
      "batch 17648, train_loss 41.587254,Time used 0.010998s\n",
      "batch 17649, train_loss 39.221313,Time used 0.008001s\n",
      "batch 17650, train_loss 48.896091,Time used 0.010000s\n",
      "batch 17651, train_loss 53.773983,Time used 0.008001s\n",
      "batch 17652, train_loss 48.026772,Time used 0.008001s\n",
      "batch 17653, train_loss 50.687862,Time used 0.007001s\n",
      "batch 17654, train_loss 36.438934,Time used 0.011000s\n",
      "batch 17655, train_loss 44.711449,Time used 0.009000s\n",
      "batch 17656, train_loss 45.570389,Time used 0.012001s\n",
      "batch 17657, train_loss 37.639339,Time used 0.012000s\n",
      "batch 17658, train_loss 39.297588,Time used 0.011998s\n",
      "batch 17659, train_loss 42.726715,Time used 0.009996s\n",
      "batch 17660, train_loss 53.209126,Time used 0.013997s\n",
      "batch 17661, train_loss 40.572376,Time used 0.014998s\n",
      "batch 17662, train_loss 33.766209,Time used 0.015004s\n",
      "batch 17663, train_loss 41.891010,Time used 0.014000s\n",
      "batch 17664, train_loss 35.570354,Time used 0.016999s\n",
      "batch 17665, train_loss 47.127514,Time used 0.016005s\n",
      "batch 17666, train_loss 35.865936,Time used 0.015994s\n",
      "batch 17667, train_loss 46.649929,Time used 0.016998s\n",
      "batch 17668, train_loss 44.366653,Time used 0.015008s\n",
      "batch 17669, train_loss 41.625160,Time used 0.013998s\n",
      "batch 17670, train_loss 37.252617,Time used 0.017997s\n",
      "batch 17671, train_loss 47.888550,Time used 0.019999s\n",
      "batch 17672, train_loss 31.133923,Time used 0.013002s\n",
      "batch 17673, train_loss 48.238289,Time used 0.016007s\n",
      "batch 17674, train_loss 44.558258,Time used 0.014990s\n",
      "batch 17675, train_loss 40.680161,Time used 0.013994s\n",
      "batch 17676, train_loss 44.624519,Time used 0.015998s\n",
      "batch 17677, train_loss 49.759518,Time used 0.013000s\n",
      "batch 17678, train_loss 37.421265,Time used 0.014000s\n",
      "batch 17679, train_loss 34.640602,Time used 0.014002s\n",
      "batch 17680, train_loss 38.108387,Time used 0.012998s\n",
      "batch 17681, train_loss 45.051510,Time used 0.015997s\n",
      "batch 17682, train_loss 39.964172,Time used 0.018008s\n",
      "batch 17683, train_loss 41.617027,Time used 0.009995s\n",
      "batch 17684, train_loss 48.730812,Time used 0.010998s\n",
      "batch 17685, train_loss 36.224937,Time used 0.013000s\n",
      "batch 17686, train_loss 44.732079,Time used 0.008001s\n",
      "batch 17687, train_loss 43.526302,Time used 0.011999s\n",
      "batch 17688, train_loss 46.620922,Time used 0.010003s\n",
      "batch 17689, train_loss 42.396103,Time used 0.012000s\n",
      "batch 17690, train_loss 60.805763,Time used 0.014003s\n",
      "batch 17691, train_loss 37.773617,Time used 0.009000s\n",
      "batch 17692, train_loss 42.822060,Time used 0.012985s\n",
      "batch 17693, train_loss 39.484146,Time used 0.012001s\n",
      "batch 17694, train_loss 46.691383,Time used 0.008004s\n",
      "batch 17695, train_loss 36.832932,Time used 0.010995s\n",
      "batch 17696, train_loss 40.319176,Time used 0.010001s\n",
      "batch 17697, train_loss 38.020580,Time used 0.007999s\n",
      "batch 17698, train_loss 36.443577,Time used 0.012000s\n",
      "batch 17699, train_loss 38.492718,Time used 0.012001s\n",
      "batch 17700, train_loss 44.308075,Time used 0.011002s\n",
      "***************************test_batch 17700, test_rmse_loss 7.542789,test_mae_loss 3.165266,test_mape_loss 52.261335,Time used 0.056997s\n",
      "batch 17701, train_loss 41.442371,Time used 0.012002s\n",
      "batch 17702, train_loss 40.062580,Time used 0.010000s\n",
      "batch 17703, train_loss 38.521732,Time used 0.018013s\n",
      "batch 17704, train_loss 55.317261,Time used 0.012994s\n",
      "batch 17705, train_loss 43.994507,Time used 0.023000s\n",
      "batch 17706, train_loss 27.793016,Time used 0.020994s\n",
      "batch 17707, train_loss 43.945030,Time used 0.015997s\n",
      "batch 17708, train_loss 35.839283,Time used 0.020002s\n",
      "batch 17709, train_loss 42.847347,Time used 0.019003s\n",
      "batch 17710, train_loss 46.061699,Time used 0.013989s\n",
      "batch 17711, train_loss 44.663284,Time used 0.023004s\n",
      "batch 17712, train_loss 50.167362,Time used 0.020998s\n",
      "batch 17713, train_loss 46.778854,Time used 0.026003s\n",
      "batch 17714, train_loss 41.797512,Time used 0.019991s\n",
      "batch 17715, train_loss 44.704498,Time used 0.026010s\n",
      "batch 17716, train_loss 38.252945,Time used 0.015991s\n",
      "batch 17717, train_loss 37.145554,Time used 0.028998s\n",
      "batch 17718, train_loss 46.990974,Time used 0.017999s\n",
      "batch 17719, train_loss 31.756504,Time used 0.039995s\n",
      "batch 17720, train_loss 46.774872,Time used 0.025002s\n",
      "batch 17721, train_loss 39.644455,Time used 0.024001s\n",
      "batch 17722, train_loss 45.961273,Time used 0.017998s\n",
      "batch 17723, train_loss 43.033386,Time used 0.016998s\n",
      "batch 17724, train_loss 36.685745,Time used 0.016999s\n",
      "batch 17725, train_loss 42.565556,Time used 0.014000s\n",
      "batch 17726, train_loss 30.734667,Time used 0.016001s\n",
      "batch 17727, train_loss 45.254230,Time used 0.017003s\n",
      "batch 17728, train_loss 44.590370,Time used 0.014998s\n",
      "batch 17729, train_loss 45.293896,Time used 0.014000s\n",
      "batch 17730, train_loss 42.779766,Time used 0.013000s\n",
      "batch 17731, train_loss 44.787582,Time used 0.012996s\n",
      "batch 17732, train_loss 30.289705,Time used 0.013000s\n",
      "batch 17733, train_loss 52.907272,Time used 0.012002s\n",
      "batch 17734, train_loss 40.157017,Time used 0.011999s\n",
      "batch 17735, train_loss 50.002445,Time used 0.008000s\n",
      "batch 17736, train_loss 44.391750,Time used 0.009000s\n",
      "batch 17737, train_loss 45.635269,Time used 0.008999s\n",
      "batch 17738, train_loss 37.850761,Time used 0.015001s\n",
      "batch 17739, train_loss 31.208296,Time used 0.013001s\n",
      "batch 17740, train_loss 37.862061,Time used 0.010000s\n",
      "batch 17741, train_loss 46.580418,Time used 0.010000s\n",
      "batch 17742, train_loss 30.808826,Time used 0.006999s\n",
      "batch 17743, train_loss 41.146408,Time used 0.008001s\n",
      "batch 17744, train_loss 42.685432,Time used 0.008998s\n",
      "batch 17745, train_loss 49.658566,Time used 0.008999s\n",
      "batch 17746, train_loss 40.849575,Time used 0.009000s\n",
      "batch 17747, train_loss 52.972660,Time used 0.010001s\n",
      "batch 17748, train_loss 42.044880,Time used 0.011000s\n",
      "batch 17749, train_loss 42.581703,Time used 0.008000s\n",
      "batch 17750, train_loss 43.123199,Time used 0.007999s\n",
      "batch 17751, train_loss 45.313446,Time used 0.008002s\n",
      "batch 17752, train_loss 50.750954,Time used 0.009999s\n",
      "batch 17753, train_loss 41.063576,Time used 0.007999s\n",
      "batch 17754, train_loss 45.409008,Time used 0.008000s\n",
      "batch 17755, train_loss 43.073769,Time used 0.006999s\n",
      "batch 17756, train_loss 46.695301,Time used 0.008000s\n",
      "batch 17757, train_loss 36.039482,Time used 0.007999s\n",
      "batch 17758, train_loss 36.830173,Time used 0.009002s\n",
      "batch 17759, train_loss 43.831142,Time used 0.007998s\n",
      "batch 17760, train_loss 37.511150,Time used 0.008009s\n",
      "batch 17761, train_loss 44.229565,Time used 0.008002s\n",
      "batch 17762, train_loss 41.648994,Time used 0.010000s\n",
      "batch 17763, train_loss 34.690174,Time used 0.008002s\n",
      "batch 17764, train_loss 40.610306,Time used 0.007998s\n",
      "batch 17765, train_loss 43.266209,Time used 0.012001s\n",
      "batch 17766, train_loss 31.491240,Time used 0.011000s\n",
      "batch 17767, train_loss 40.166332,Time used 0.009001s\n",
      "batch 17768, train_loss 41.175838,Time used 0.008000s\n",
      "batch 17769, train_loss 44.072563,Time used 0.011001s\n",
      "batch 17770, train_loss 57.325241,Time used 0.007999s\n",
      "batch 17771, train_loss 34.656693,Time used 0.008000s\n",
      "batch 17772, train_loss 54.939198,Time used 0.012001s\n",
      "batch 17773, train_loss 33.088654,Time used 0.008996s\n",
      "batch 17774, train_loss 39.730679,Time used 0.008999s\n",
      "batch 17775, train_loss 48.468697,Time used 0.009002s\n",
      "batch 17776, train_loss 48.996716,Time used 0.012999s\n",
      "batch 17777, train_loss 37.783947,Time used 0.010000s\n",
      "batch 17778, train_loss 41.171280,Time used 0.008000s\n",
      "batch 17779, train_loss 34.523067,Time used 0.009000s\n",
      "batch 17780, train_loss 46.439793,Time used 0.008999s\n",
      "batch 17781, train_loss 45.483376,Time used 0.007999s\n",
      "batch 17782, train_loss 42.374939,Time used 0.008002s\n",
      "batch 17783, train_loss 51.150566,Time used 0.007999s\n",
      "batch 17784, train_loss 32.335701,Time used 0.010002s\n",
      "batch 17785, train_loss 33.459175,Time used 0.012000s\n",
      "batch 17786, train_loss 42.492275,Time used 0.007003s\n",
      "batch 17787, train_loss 31.169260,Time used 0.006992s\n",
      "batch 17788, train_loss 43.230186,Time used 0.009000s\n",
      "batch 17789, train_loss 41.701374,Time used 0.011038s\n",
      "batch 17790, train_loss 38.190475,Time used 0.006999s\n",
      "batch 17791, train_loss 39.005852,Time used 0.011003s\n",
      "batch 17792, train_loss 46.693348,Time used 0.010997s\n",
      "batch 17793, train_loss 31.536310,Time used 0.014000s\n",
      "batch 17794, train_loss 58.818398,Time used 0.015002s\n",
      "batch 17795, train_loss 40.992222,Time used 0.012001s\n",
      "batch 17796, train_loss 43.871273,Time used 0.013997s\n",
      "batch 17797, train_loss 44.108013,Time used 0.015003s\n",
      "batch 17798, train_loss 43.910645,Time used 0.013996s\n",
      "batch 17799, train_loss 47.750042,Time used 0.013010s\n",
      "batch 17800, train_loss 38.987236,Time used 0.010990s\n",
      "***************************test_batch 17800, test_rmse_loss 7.514426,test_mae_loss 3.162752,test_mape_loss 52.443680,Time used 0.064996s\n",
      "batch 17801, train_loss 41.316010,Time used 0.024003s\n",
      "batch 17802, train_loss 45.436134,Time used 0.031999s\n",
      "batch 17803, train_loss 38.175293,Time used 0.018002s\n",
      "batch 17804, train_loss 47.290718,Time used 0.021998s\n",
      "batch 17805, train_loss 45.620815,Time used 0.017998s\n",
      "batch 17806, train_loss 36.008297,Time used 0.025002s\n",
      "batch 17807, train_loss 49.744122,Time used 0.018997s\n",
      "batch 17808, train_loss 39.156448,Time used 0.013000s\n",
      "batch 17809, train_loss 38.920044,Time used 0.011998s\n",
      "batch 17810, train_loss 48.340195,Time used 0.010999s\n",
      "batch 17811, train_loss 47.265984,Time used 0.012000s\n",
      "batch 17812, train_loss 44.129700,Time used 0.012001s\n",
      "batch 17813, train_loss 41.416191,Time used 0.012998s\n",
      "batch 17814, train_loss 36.500149,Time used 0.010999s\n",
      "batch 17815, train_loss 44.558971,Time used 0.013999s\n",
      "batch 17816, train_loss 43.780777,Time used 0.013002s\n",
      "batch 17817, train_loss 42.727520,Time used 0.029000s\n",
      "batch 17818, train_loss 47.409756,Time used 0.013998s\n",
      "batch 17819, train_loss 41.814308,Time used 0.013000s\n",
      "batch 17820, train_loss 44.719910,Time used 0.010999s\n",
      "batch 17821, train_loss 41.949722,Time used 0.013003s\n",
      "batch 17822, train_loss 45.642494,Time used 0.009998s\n",
      "batch 17823, train_loss 49.271954,Time used 0.011003s\n",
      "batch 17824, train_loss 29.937143,Time used 0.012001s\n",
      "batch 17825, train_loss 31.098244,Time used 0.009999s\n",
      "batch 17826, train_loss 45.686050,Time used 0.012998s\n",
      "batch 17827, train_loss 41.869427,Time used 0.012002s\n",
      "batch 17828, train_loss 48.831097,Time used 0.012002s\n",
      "batch 17829, train_loss 43.213776,Time used 0.012002s\n",
      "batch 17830, train_loss 34.179615,Time used 0.011998s\n",
      "batch 17831, train_loss 41.772518,Time used 0.012999s\n",
      "batch 17832, train_loss 32.140377,Time used 0.012000s\n",
      "batch 17833, train_loss 34.919693,Time used 0.008000s\n",
      "batch 17834, train_loss 43.898994,Time used 0.010001s\n",
      "batch 17835, train_loss 51.023632,Time used 0.012998s\n",
      "batch 17836, train_loss 40.211189,Time used 0.012004s\n",
      "batch 17837, train_loss 34.986065,Time used 0.011999s\n",
      "batch 17838, train_loss 40.998669,Time used 0.010998s\n",
      "batch 17839, train_loss 34.837986,Time used 0.008000s\n",
      "batch 17840, train_loss 44.444954,Time used 0.010003s\n",
      "batch 17841, train_loss 35.127636,Time used 0.008001s\n",
      "batch 17842, train_loss 43.253269,Time used 0.009998s\n",
      "batch 17843, train_loss 42.341900,Time used 0.008999s\n",
      "batch 17844, train_loss 43.583126,Time used 0.006998s\n",
      "batch 17845, train_loss 47.890228,Time used 0.010001s\n",
      "batch 17846, train_loss 43.030903,Time used 0.011997s\n",
      "batch 17847, train_loss 49.090569,Time used 0.010001s\n",
      "batch 17848, train_loss 47.649578,Time used 0.008996s\n",
      "batch 17849, train_loss 41.151699,Time used 0.008005s\n",
      "batch 17850, train_loss 45.572121,Time used 0.006999s\n",
      "batch 17851, train_loss 40.716293,Time used 0.007996s\n",
      "batch 17852, train_loss 40.045250,Time used 0.011002s\n",
      "batch 17853, train_loss 42.807735,Time used 0.011002s\n",
      "batch 17854, train_loss 42.139885,Time used 0.007997s\n",
      "batch 17855, train_loss 39.242638,Time used 0.011999s\n",
      "batch 17856, train_loss 37.054993,Time used 0.013002s\n",
      "batch 17857, train_loss 47.173241,Time used 0.012003s\n",
      "batch 17858, train_loss 50.704674,Time used 0.015997s\n",
      "batch 17859, train_loss 47.104908,Time used 0.014007s\n",
      "batch 17860, train_loss 40.486118,Time used 0.013995s\n",
      "batch 17861, train_loss 40.794270,Time used 0.013998s\n",
      "batch 17862, train_loss 44.784695,Time used 0.013986s\n",
      "batch 17863, train_loss 40.908478,Time used 0.014002s\n",
      "batch 17864, train_loss 41.481361,Time used 0.014996s\n",
      "batch 17865, train_loss 44.675995,Time used 0.015006s\n",
      "batch 17866, train_loss 35.319260,Time used 0.014999s\n",
      "batch 17867, train_loss 43.515896,Time used 0.016007s\n",
      "batch 17868, train_loss 40.534809,Time used 0.016003s\n",
      "batch 17869, train_loss 42.714165,Time used 0.016000s\n",
      "batch 17870, train_loss 35.397106,Time used 0.017002s\n",
      "batch 17871, train_loss 36.660511,Time used 0.014013s\n",
      "batch 17872, train_loss 38.169750,Time used 0.009984s\n",
      "batch 17873, train_loss 48.370739,Time used 0.011998s\n",
      "batch 17874, train_loss 42.200024,Time used 0.015999s\n",
      "batch 17875, train_loss 38.838837,Time used 0.015003s\n",
      "batch 17876, train_loss 43.187950,Time used 0.013999s\n",
      "batch 17877, train_loss 30.598099,Time used 0.012016s\n",
      "batch 17878, train_loss 46.876263,Time used 0.010997s\n",
      "batch 17879, train_loss 44.527084,Time used 0.014998s\n",
      "batch 17880, train_loss 39.487961,Time used 0.012001s\n",
      "batch 17881, train_loss 43.654041,Time used 0.013000s\n",
      "batch 17882, train_loss 44.518047,Time used 0.011000s\n",
      "batch 17883, train_loss 39.654724,Time used 0.011001s\n",
      "batch 17884, train_loss 36.683735,Time used 0.011998s\n",
      "batch 17885, train_loss 39.543205,Time used 0.011011s\n",
      "batch 17886, train_loss 42.548496,Time used 0.012006s\n",
      "batch 17887, train_loss 34.054207,Time used 0.011005s\n",
      "batch 17888, train_loss 40.799019,Time used 0.014997s\n",
      "batch 17889, train_loss 38.245090,Time used 0.011999s\n",
      "batch 17890, train_loss 36.623856,Time used 0.016999s\n",
      "batch 17891, train_loss 46.800407,Time used 0.014003s\n",
      "batch 17892, train_loss 41.629524,Time used 0.030005s\n",
      "batch 17893, train_loss 45.851650,Time used 0.020999s\n",
      "batch 17894, train_loss 40.285404,Time used 0.016998s\n",
      "batch 17895, train_loss 49.528519,Time used 0.013999s\n",
      "batch 17896, train_loss 55.267124,Time used 0.017007s\n",
      "batch 17897, train_loss 35.459038,Time used 0.015997s\n",
      "batch 17898, train_loss 34.547733,Time used 0.015002s\n",
      "batch 17899, train_loss 52.373993,Time used 0.012003s\n",
      "batch 17900, train_loss 37.152706,Time used 0.011000s\n",
      "***************************test_batch 17900, test_rmse_loss 7.495687,test_mae_loss 3.156478,test_mape_loss 52.376461,Time used 0.061998s\n",
      "batch 17901, train_loss 46.275085,Time used 0.016002s\n",
      "batch 17902, train_loss 45.732052,Time used 0.014997s\n",
      "batch 17903, train_loss 41.444492,Time used 0.013001s\n",
      "batch 17904, train_loss 34.087952,Time used 0.009999s\n",
      "batch 17905, train_loss 37.170715,Time used 0.012002s\n",
      "batch 17906, train_loss 37.108662,Time used 0.007997s\n",
      "batch 17907, train_loss 36.872345,Time used 0.014001s\n",
      "batch 17908, train_loss 48.704006,Time used 0.012000s\n",
      "batch 17909, train_loss 41.075203,Time used 0.009000s\n",
      "batch 17910, train_loss 42.316422,Time used 0.010002s\n",
      "batch 17911, train_loss 45.388519,Time used 0.009998s\n",
      "batch 17912, train_loss 40.246239,Time used 0.008003s\n",
      "batch 17913, train_loss 45.499805,Time used 0.008000s\n",
      "batch 17914, train_loss 32.229641,Time used 0.009000s\n",
      "batch 17915, train_loss 45.761116,Time used 0.010000s\n",
      "batch 17916, train_loss 41.393936,Time used 0.008999s\n",
      "batch 17917, train_loss 46.640045,Time used 0.011000s\n",
      "batch 17918, train_loss 41.223862,Time used 0.008002s\n",
      "batch 17919, train_loss 44.588238,Time used 0.007999s\n",
      "batch 17920, train_loss 42.212372,Time used 0.009999s\n",
      "batch 17921, train_loss 34.290707,Time used 0.011008s\n",
      "batch 17922, train_loss 48.594612,Time used 0.010994s\n",
      "batch 17923, train_loss 43.253117,Time used 0.008001s\n",
      "batch 17924, train_loss 45.340805,Time used 0.009001s\n",
      "batch 17925, train_loss 46.278774,Time used 0.007991s\n",
      "batch 17926, train_loss 43.506569,Time used 0.007999s\n",
      "batch 17927, train_loss 41.095829,Time used 0.008002s\n",
      "batch 17928, train_loss 30.454208,Time used 0.008998s\n",
      "batch 17929, train_loss 39.106895,Time used 0.007999s\n",
      "batch 17930, train_loss 36.565861,Time used 0.008002s\n",
      "batch 17931, train_loss 39.954262,Time used 0.009000s\n",
      "batch 17932, train_loss 49.465977,Time used 0.008999s\n",
      "batch 17933, train_loss 29.851841,Time used 0.010000s\n",
      "batch 17934, train_loss 35.836803,Time used 0.011001s\n",
      "batch 17935, train_loss 38.251781,Time used 0.012998s\n",
      "batch 17936, train_loss 41.494446,Time used 0.013001s\n",
      "batch 17937, train_loss 36.712379,Time used 0.013000s\n",
      "batch 17938, train_loss 45.417301,Time used 0.012997s\n",
      "batch 17939, train_loss 45.513927,Time used 0.011000s\n",
      "batch 17940, train_loss 41.374931,Time used 0.014000s\n",
      "batch 17941, train_loss 47.441452,Time used 0.015001s\n",
      "batch 17942, train_loss 49.420555,Time used 0.013001s\n",
      "batch 17943, train_loss 45.688610,Time used 0.015998s\n",
      "batch 17944, train_loss 40.161346,Time used 0.013000s\n",
      "batch 17945, train_loss 40.922649,Time used 0.011001s\n",
      "batch 17946, train_loss 40.730503,Time used 0.010000s\n",
      "batch 17947, train_loss 42.156269,Time used 0.011000s\n",
      "batch 17948, train_loss 44.139179,Time used 0.012001s\n",
      "batch 17949, train_loss 49.449036,Time used 0.011000s\n",
      "batch 17950, train_loss 40.676861,Time used 0.012001s\n",
      "batch 17951, train_loss 37.323685,Time used 0.012997s\n",
      "batch 17952, train_loss 42.770103,Time used 0.010000s\n",
      "batch 17953, train_loss 45.700165,Time used 0.011000s\n",
      "batch 17954, train_loss 49.331715,Time used 0.014001s\n",
      "batch 17955, train_loss 51.009361,Time used 0.026004s\n",
      "batch 17956, train_loss 36.674854,Time used 0.013996s\n",
      "batch 17957, train_loss 30.148794,Time used 0.014001s\n",
      "batch 17958, train_loss 34.970013,Time used 0.013999s\n",
      "batch 17959, train_loss 44.707333,Time used 0.011001s\n",
      "batch 17960, train_loss 52.213577,Time used 0.008997s\n",
      "batch 17961, train_loss 33.904530,Time used 0.011001s\n",
      "batch 17962, train_loss 40.886852,Time used 0.015002s\n",
      "batch 17963, train_loss 37.745865,Time used 0.017001s\n",
      "batch 17964, train_loss 30.680231,Time used 0.019002s\n",
      "batch 17965, train_loss 41.537968,Time used 0.015999s\n",
      "batch 17966, train_loss 41.913181,Time used 0.035003s\n",
      "batch 17967, train_loss 42.511585,Time used 0.026006s\n",
      "batch 17968, train_loss 45.087559,Time used 0.015996s\n",
      "batch 17969, train_loss 41.168934,Time used 0.017998s\n",
      "batch 17970, train_loss 38.664009,Time used 0.013000s\n",
      "batch 17971, train_loss 38.152016,Time used 0.015004s\n",
      "batch 17972, train_loss 44.923958,Time used 0.011994s\n",
      "batch 17973, train_loss 46.559166,Time used 0.015996s\n",
      "batch 17974, train_loss 46.231407,Time used 0.013995s\n",
      "batch 17975, train_loss 47.705730,Time used 0.015999s\n",
      "batch 17976, train_loss 36.742519,Time used 0.013999s\n",
      "batch 17977, train_loss 38.738461,Time used 0.014004s\n",
      "batch 17978, train_loss 46.802891,Time used 0.015000s\n",
      "batch 17979, train_loss 34.911205,Time used 0.016994s\n",
      "batch 17980, train_loss 40.502476,Time used 0.013998s\n",
      "batch 17981, train_loss 43.944023,Time used 0.014018s\n",
      "batch 17982, train_loss 46.553879,Time used 0.014986s\n",
      "batch 17983, train_loss 37.631245,Time used 0.010996s\n",
      "batch 17984, train_loss 37.230644,Time used 0.012003s\n",
      "batch 17985, train_loss 49.444046,Time used 0.015002s\n",
      "batch 17986, train_loss 35.162449,Time used 0.013009s\n",
      "batch 17987, train_loss 38.733120,Time used 0.011988s\n",
      "batch 17988, train_loss 40.729019,Time used 0.010999s\n",
      "batch 17989, train_loss 44.508659,Time used 0.012001s\n",
      "batch 17990, train_loss 38.051304,Time used 0.011001s\n",
      "batch 17991, train_loss 36.304920,Time used 0.011996s\n",
      "batch 17992, train_loss 43.086346,Time used 0.011002s\n",
      "batch 17993, train_loss 43.642216,Time used 0.011001s\n",
      "batch 17994, train_loss 52.079227,Time used 0.010999s\n",
      "batch 17995, train_loss 56.607998,Time used 0.010999s\n",
      "batch 17996, train_loss 39.143703,Time used 0.011006s\n",
      "batch 17997, train_loss 41.262955,Time used 0.010991s\n",
      "batch 17998, train_loss 36.190609,Time used 0.010002s\n",
      "batch 17999, train_loss 39.046745,Time used 0.009000s\n",
      "batch 18000, train_loss 37.177483,Time used 0.008000s\n",
      "***************************test_batch 18000, test_rmse_loss 7.486319,test_mae_loss 3.146446,test_mape_loss 51.923662,Time used 0.038998s\n",
      "batch 18001, train_loss 42.927734,Time used 0.012007s\n",
      "batch 18002, train_loss 42.501503,Time used 0.014995s\n",
      "batch 18003, train_loss 37.670284,Time used 0.011000s\n",
      "batch 18004, train_loss 43.918438,Time used 0.016000s\n",
      "batch 18005, train_loss 53.064022,Time used 0.012997s\n",
      "batch 18006, train_loss 37.174976,Time used 0.015003s\n",
      "batch 18007, train_loss 38.348743,Time used 0.011996s\n",
      "batch 18008, train_loss 40.875969,Time used 0.013005s\n",
      "batch 18009, train_loss 48.676117,Time used 0.015996s\n",
      "batch 18010, train_loss 45.504601,Time used 0.016001s\n",
      "batch 18011, train_loss 30.878035,Time used 0.014999s\n",
      "batch 18012, train_loss 35.219124,Time used 0.014998s\n",
      "batch 18013, train_loss 33.455303,Time used 0.014006s\n",
      "batch 18014, train_loss 54.574787,Time used 0.015999s\n",
      "batch 18015, train_loss 39.827335,Time used 0.018997s\n",
      "batch 18016, train_loss 42.831566,Time used 0.016003s\n",
      "batch 18017, train_loss 31.635382,Time used 0.017000s\n",
      "batch 18018, train_loss 47.723236,Time used 0.014997s\n",
      "batch 18019, train_loss 39.390728,Time used 0.012007s\n",
      "batch 18020, train_loss 44.706547,Time used 0.008986s\n",
      "batch 18021, train_loss 52.969566,Time used 0.012999s\n",
      "batch 18022, train_loss 33.034428,Time used 0.016004s\n",
      "batch 18023, train_loss 34.588573,Time used 0.012997s\n",
      "batch 18024, train_loss 44.896938,Time used 0.007996s\n",
      "batch 18025, train_loss 35.978527,Time used 0.013995s\n",
      "batch 18026, train_loss 39.757217,Time used 0.012000s\n",
      "batch 18027, train_loss 39.510208,Time used 0.009999s\n",
      "batch 18028, train_loss 41.444691,Time used 0.012002s\n",
      "batch 18029, train_loss 37.972416,Time used 0.010000s\n",
      "batch 18030, train_loss 36.431274,Time used 0.008003s\n",
      "batch 18031, train_loss 35.536057,Time used 0.009996s\n",
      "batch 18032, train_loss 38.262642,Time used 0.012004s\n",
      "batch 18033, train_loss 34.247070,Time used 0.012996s\n",
      "batch 18034, train_loss 38.011906,Time used 0.012000s\n",
      "batch 18035, train_loss 35.387390,Time used 0.010001s\n",
      "batch 18036, train_loss 58.479752,Time used 0.007002s\n",
      "batch 18037, train_loss 53.040165,Time used 0.008001s\n",
      "batch 18038, train_loss 43.191814,Time used 0.008999s\n",
      "batch 18039, train_loss 37.142921,Time used 0.011000s\n",
      "batch 18040, train_loss 34.398525,Time used 0.008003s\n",
      "batch 18041, train_loss 48.888081,Time used 0.008998s\n",
      "batch 18042, train_loss 35.924000,Time used 0.012002s\n",
      "batch 18043, train_loss 49.181118,Time used 0.008996s\n",
      "batch 18044, train_loss 40.439461,Time used 0.010999s\n",
      "batch 18045, train_loss 46.762157,Time used 0.012002s\n",
      "batch 18046, train_loss 42.704628,Time used 0.010001s\n",
      "batch 18047, train_loss 51.554768,Time used 0.010000s\n",
      "batch 18048, train_loss 40.410133,Time used 0.012003s\n",
      "batch 18049, train_loss 45.173897,Time used 0.014999s\n",
      "batch 18050, train_loss 36.393795,Time used 0.015998s\n",
      "batch 18051, train_loss 40.833652,Time used 0.016003s\n",
      "batch 18052, train_loss 49.925236,Time used 0.018004s\n",
      "batch 18053, train_loss 39.126415,Time used 0.010998s\n",
      "batch 18054, train_loss 36.100780,Time used 0.012997s\n",
      "batch 18055, train_loss 51.137516,Time used 0.009980s\n",
      "batch 18056, train_loss 40.019497,Time used 0.014000s\n",
      "batch 18057, train_loss 42.833191,Time used 0.013002s\n",
      "batch 18058, train_loss 43.685776,Time used 0.016000s\n",
      "batch 18059, train_loss 41.766315,Time used 0.014997s\n",
      "batch 18060, train_loss 39.251675,Time used 0.012004s\n",
      "batch 18061, train_loss 47.691658,Time used 0.015001s\n",
      "batch 18062, train_loss 38.233116,Time used 0.014004s\n",
      "batch 18063, train_loss 41.081108,Time used 0.014994s\n",
      "batch 18064, train_loss 37.812340,Time used 0.014001s\n",
      "batch 18065, train_loss 42.383484,Time used 0.016001s\n",
      "batch 18066, train_loss 34.914951,Time used 0.014999s\n",
      "batch 18067, train_loss 40.208557,Time used 0.012002s\n",
      "batch 18068, train_loss 52.672073,Time used 0.017002s\n",
      "batch 18069, train_loss 33.275345,Time used 0.015996s\n",
      "batch 18070, train_loss 32.752224,Time used 0.015005s\n",
      "batch 18071, train_loss 45.161777,Time used 0.009996s\n",
      "batch 18072, train_loss 40.945312,Time used 0.010989s\n",
      "batch 18073, train_loss 23.110226,Time used 0.012003s\n",
      "batch 18074, train_loss 34.729824,Time used 0.013003s\n",
      "batch 18075, train_loss 42.377285,Time used 0.008997s\n",
      "batch 18076, train_loss 36.638996,Time used 0.011002s\n",
      "batch 18077, train_loss 42.652874,Time used 0.007999s\n",
      "batch 18078, train_loss 42.072048,Time used 0.013999s\n",
      "batch 18079, train_loss 41.595505,Time used 0.013000s\n",
      "batch 18080, train_loss 44.434917,Time used 0.015002s\n",
      "batch 18081, train_loss 42.225132,Time used 0.013998s\n",
      "batch 18082, train_loss 37.016933,Time used 0.013002s\n",
      "batch 18083, train_loss 43.216061,Time used 0.008996s\n",
      "batch 18084, train_loss 38.570663,Time used 0.012003s\n",
      "batch 18085, train_loss 44.966038,Time used 0.008000s\n",
      "batch 18086, train_loss 39.501499,Time used 0.009999s\n",
      "batch 18087, train_loss 49.495682,Time used 0.012002s\n",
      "batch 18088, train_loss 36.087940,Time used 0.007999s\n",
      "batch 18089, train_loss 37.275932,Time used 0.010000s\n",
      "batch 18090, train_loss 51.286880,Time used 0.008001s\n",
      "batch 18091, train_loss 46.409325,Time used 0.010041s\n",
      "batch 18092, train_loss 39.581955,Time used 0.010957s\n",
      "batch 18093, train_loss 55.710934,Time used 0.009002s\n",
      "batch 18094, train_loss 44.198936,Time used 0.008998s\n",
      "batch 18095, train_loss 40.740181,Time used 0.012001s\n",
      "batch 18096, train_loss 37.948524,Time used 0.010036s\n",
      "batch 18097, train_loss 41.958664,Time used 0.008001s\n",
      "batch 18098, train_loss 44.714043,Time used 0.007996s\n",
      "batch 18099, train_loss 49.172733,Time used 0.011003s\n",
      "batch 18100, train_loss 34.685204,Time used 0.010999s\n",
      "***************************test_batch 18100, test_rmse_loss 7.470365,test_mae_loss 3.143967,test_mape_loss 51.844690,Time used 0.039999s\n",
      "batch 18101, train_loss 37.723301,Time used 0.008000s\n",
      "batch 18102, train_loss 39.896534,Time used 0.009003s\n",
      "batch 18103, train_loss 41.428474,Time used 0.011996s\n",
      "batch 18104, train_loss 46.955875,Time used 0.008001s\n",
      "batch 18105, train_loss 43.278328,Time used 0.008999s\n",
      "batch 18106, train_loss 42.342220,Time used 0.011001s\n",
      "batch 18107, train_loss 51.442421,Time used 0.007998s\n",
      "batch 18108, train_loss 46.256989,Time used 0.011000s\n",
      "batch 18109, train_loss 30.172913,Time used 0.010000s\n",
      "batch 18110, train_loss 37.804955,Time used 0.008000s\n",
      "batch 18111, train_loss 48.059914,Time used 0.008000s\n",
      "batch 18112, train_loss 37.852509,Time used 0.008001s\n",
      "batch 18113, train_loss 44.368248,Time used 0.012003s\n",
      "batch 18114, train_loss 38.886139,Time used 0.013008s\n",
      "batch 18115, train_loss 40.884991,Time used 0.011993s\n",
      "batch 18116, train_loss 35.715725,Time used 0.008996s\n",
      "batch 18117, train_loss 42.726826,Time used 0.009999s\n",
      "batch 18118, train_loss 45.172920,Time used 0.008000s\n",
      "batch 18119, train_loss 39.283535,Time used 0.007002s\n",
      "batch 18120, train_loss 29.549953,Time used 0.007999s\n",
      "batch 18121, train_loss 45.804096,Time used 0.007998s\n",
      "batch 18122, train_loss 43.904110,Time used 0.009000s\n",
      "batch 18123, train_loss 34.109974,Time used 0.011003s\n",
      "batch 18124, train_loss 33.002106,Time used 0.009997s\n",
      "batch 18125, train_loss 34.945007,Time used 0.012004s\n",
      "batch 18126, train_loss 40.654568,Time used 0.010996s\n",
      "batch 18127, train_loss 36.744789,Time used 0.011000s\n",
      "batch 18128, train_loss 47.023365,Time used 0.012001s\n",
      "batch 18129, train_loss 49.215450,Time used 0.010004s\n",
      "batch 18130, train_loss 39.974072,Time used 0.007001s\n",
      "batch 18131, train_loss 31.346039,Time used 0.010999s\n",
      "batch 18132, train_loss 35.495735,Time used 0.011001s\n",
      "batch 18133, train_loss 43.666004,Time used 0.009002s\n",
      "batch 18134, train_loss 46.711964,Time used 0.016007s\n",
      "batch 18135, train_loss 43.819313,Time used 0.012992s\n",
      "batch 18136, train_loss 38.324760,Time used 0.015008s\n",
      "batch 18137, train_loss 39.009319,Time used 0.014991s\n",
      "batch 18138, train_loss 39.243481,Time used 0.013001s\n",
      "batch 18139, train_loss 43.988247,Time used 0.017000s\n",
      "batch 18140, train_loss 45.331131,Time used 0.017999s\n",
      "batch 18141, train_loss 46.339355,Time used 0.017001s\n",
      "batch 18142, train_loss 39.300026,Time used 0.015998s\n",
      "batch 18143, train_loss 51.560120,Time used 0.014002s\n",
      "batch 18144, train_loss 39.600414,Time used 0.011001s\n",
      "batch 18145, train_loss 41.774578,Time used 0.014002s\n",
      "batch 18146, train_loss 38.963814,Time used 0.016001s\n",
      "batch 18147, train_loss 32.009102,Time used 0.014997s\n",
      "batch 18148, train_loss 44.634129,Time used 0.016003s\n",
      "batch 18149, train_loss 34.864758,Time used 0.017000s\n",
      "batch 18150, train_loss 52.622105,Time used 0.013009s\n",
      "batch 18151, train_loss 42.337704,Time used 0.009989s\n",
      "batch 18152, train_loss 37.470562,Time used 0.015001s\n",
      "batch 18153, train_loss 41.371124,Time used 0.012003s\n",
      "batch 18154, train_loss 38.535133,Time used 0.013997s\n",
      "batch 18155, train_loss 44.159359,Time used 0.014997s\n",
      "batch 18156, train_loss 38.349236,Time used 0.015000s\n",
      "batch 18157, train_loss 41.117229,Time used 0.007993s\n",
      "batch 18158, train_loss 39.120728,Time used 0.014002s\n",
      "batch 18159, train_loss 43.504772,Time used 0.014002s\n",
      "batch 18160, train_loss 49.940414,Time used 0.013998s\n",
      "batch 18161, train_loss 47.951939,Time used 0.007997s\n",
      "batch 18162, train_loss 46.491199,Time used 0.012000s\n",
      "batch 18163, train_loss 31.050655,Time used 0.011999s\n",
      "batch 18164, train_loss 38.579380,Time used 0.013007s\n",
      "batch 18165, train_loss 44.206196,Time used 0.008001s\n",
      "batch 18166, train_loss 42.016788,Time used 0.008002s\n",
      "batch 18167, train_loss 36.300198,Time used 0.008000s\n",
      "batch 18168, train_loss 40.152985,Time used 0.008999s\n",
      "batch 18169, train_loss 35.612110,Time used 0.008001s\n",
      "batch 18170, train_loss 39.779045,Time used 0.006998s\n",
      "batch 18171, train_loss 39.257030,Time used 0.007999s\n",
      "batch 18172, train_loss 41.955750,Time used 0.009999s\n",
      "batch 18173, train_loss 37.730484,Time used 0.008999s\n",
      "batch 18174, train_loss 41.326126,Time used 0.008003s\n",
      "batch 18175, train_loss 47.866306,Time used 0.007998s\n",
      "batch 18176, train_loss 42.270870,Time used 0.007999s\n",
      "batch 18177, train_loss 48.060974,Time used 0.008000s\n",
      "batch 18178, train_loss 38.821873,Time used 0.007001s\n",
      "batch 18179, train_loss 37.632572,Time used 0.008000s\n",
      "batch 18180, train_loss 30.240562,Time used 0.007999s\n",
      "batch 18181, train_loss 40.984539,Time used 0.008001s\n",
      "batch 18182, train_loss 44.799751,Time used 0.009001s\n",
      "batch 18183, train_loss 46.246109,Time used 0.010999s\n",
      "batch 18184, train_loss 38.033108,Time used 0.010001s\n",
      "batch 18185, train_loss 56.966618,Time used 0.011006s\n",
      "batch 18186, train_loss 34.836857,Time used 0.008001s\n",
      "batch 18187, train_loss 46.843067,Time used 0.008999s\n",
      "batch 18188, train_loss 45.331760,Time used 0.008001s\n",
      "batch 18189, train_loss 35.370541,Time used 0.008006s\n",
      "batch 18190, train_loss 39.234158,Time used 0.008994s\n",
      "batch 18191, train_loss 37.621231,Time used 0.008000s\n",
      "batch 18192, train_loss 39.312611,Time used 0.009001s\n",
      "batch 18193, train_loss 38.659355,Time used 0.008998s\n",
      "batch 18194, train_loss 43.111099,Time used 0.008998s\n",
      "batch 18195, train_loss 44.617184,Time used 0.011011s\n",
      "batch 18196, train_loss 44.013626,Time used 0.009999s\n",
      "batch 18197, train_loss 34.578094,Time used 0.009999s\n",
      "batch 18198, train_loss 45.612320,Time used 0.013000s\n",
      "batch 18199, train_loss 44.191055,Time used 0.010000s\n",
      "batch 18200, train_loss 51.995735,Time used 0.011999s\n",
      "***************************test_batch 18200, test_rmse_loss 7.456071,test_mae_loss 3.138563,test_mape_loss 51.858194,Time used 0.042002s\n",
      "batch 18201, train_loss 35.393803,Time used 0.009000s\n",
      "batch 18202, train_loss 41.058018,Time used 0.011998s\n",
      "batch 18203, train_loss 41.405594,Time used 0.010001s\n",
      "batch 18204, train_loss 47.254696,Time used 0.008000s\n",
      "batch 18205, train_loss 33.602604,Time used 0.010000s\n",
      "batch 18206, train_loss 42.855247,Time used 0.008000s\n",
      "batch 18207, train_loss 51.874023,Time used 0.008000s\n",
      "batch 18208, train_loss 38.521633,Time used 0.009000s\n",
      "batch 18209, train_loss 45.387020,Time used 0.008999s\n",
      "batch 18210, train_loss 28.846956,Time used 0.008000s\n",
      "batch 18211, train_loss 45.691662,Time used 0.009002s\n",
      "batch 18212, train_loss 36.378258,Time used 0.011000s\n",
      "batch 18213, train_loss 35.748947,Time used 0.009002s\n",
      "batch 18214, train_loss 38.260048,Time used 0.010000s\n",
      "batch 18215, train_loss 40.825321,Time used 0.011999s\n",
      "batch 18216, train_loss 35.357609,Time used 0.012006s\n",
      "batch 18217, train_loss 44.855049,Time used 0.011000s\n",
      "batch 18218, train_loss 36.049171,Time used 0.008998s\n",
      "batch 18219, train_loss 38.930607,Time used 0.011001s\n",
      "batch 18220, train_loss 38.704155,Time used 0.008000s\n",
      "batch 18221, train_loss 43.499744,Time used 0.008000s\n",
      "batch 18222, train_loss 46.855995,Time used 0.012000s\n",
      "batch 18223, train_loss 37.613670,Time used 0.010003s\n",
      "batch 18224, train_loss 43.751823,Time used 0.012997s\n",
      "batch 18225, train_loss 38.791084,Time used 0.012004s\n",
      "batch 18226, train_loss 39.921261,Time used 0.012998s\n",
      "batch 18227, train_loss 42.485851,Time used 0.013999s\n",
      "batch 18228, train_loss 35.999531,Time used 0.016000s\n",
      "batch 18229, train_loss 40.972599,Time used 0.017012s\n",
      "batch 18230, train_loss 45.615761,Time used 0.012989s\n",
      "batch 18231, train_loss 36.769730,Time used 0.015004s\n",
      "batch 18232, train_loss 47.609642,Time used 0.015997s\n",
      "batch 18233, train_loss 37.302402,Time used 0.012992s\n",
      "batch 18234, train_loss 41.106846,Time used 0.017012s\n",
      "batch 18235, train_loss 44.767376,Time used 0.015999s\n",
      "batch 18236, train_loss 40.164051,Time used 0.014001s\n",
      "batch 18237, train_loss 42.457485,Time used 0.015002s\n",
      "batch 18238, train_loss 41.365768,Time used 0.014001s\n",
      "batch 18239, train_loss 39.703201,Time used 0.010006s\n",
      "batch 18240, train_loss 38.295078,Time used 0.010998s\n",
      "batch 18241, train_loss 38.335846,Time used 0.014001s\n",
      "batch 18242, train_loss 42.737633,Time used 0.017001s\n",
      "batch 18243, train_loss 39.327354,Time used 0.014002s\n",
      "batch 18244, train_loss 54.339252,Time used 0.016004s\n",
      "batch 18245, train_loss 39.668663,Time used 0.015995s\n",
      "batch 18246, train_loss 36.893997,Time used 0.013997s\n",
      "batch 18247, train_loss 37.755966,Time used 0.013003s\n",
      "batch 18248, train_loss 51.187969,Time used 0.009997s\n",
      "batch 18249, train_loss 43.119503,Time used 0.009000s\n",
      "batch 18250, train_loss 33.484333,Time used 0.006999s\n",
      "batch 18251, train_loss 32.877365,Time used 0.011000s\n",
      "batch 18252, train_loss 34.826542,Time used 0.008001s\n",
      "batch 18253, train_loss 46.932430,Time used 0.008999s\n",
      "batch 18254, train_loss 29.154028,Time used 0.008003s\n",
      "batch 18255, train_loss 46.723553,Time used 0.007998s\n",
      "batch 18256, train_loss 42.574684,Time used 0.006997s\n",
      "batch 18257, train_loss 51.333561,Time used 0.008000s\n",
      "batch 18258, train_loss 37.390667,Time used 0.010001s\n",
      "batch 18259, train_loss 39.463387,Time used 0.008000s\n",
      "batch 18260, train_loss 44.032635,Time used 0.008004s\n",
      "batch 18261, train_loss 45.545513,Time used 0.011995s\n",
      "batch 18262, train_loss 40.925209,Time used 0.012000s\n",
      "batch 18263, train_loss 42.809544,Time used 0.012000s\n",
      "batch 18264, train_loss 30.388664,Time used 0.011002s\n",
      "batch 18265, train_loss 43.314957,Time used 0.012001s\n",
      "batch 18266, train_loss 47.420776,Time used 0.007999s\n",
      "batch 18267, train_loss 42.079079,Time used 0.010001s\n",
      "batch 18268, train_loss 28.785366,Time used 0.010998s\n",
      "batch 18269, train_loss 49.806465,Time used 0.009002s\n",
      "batch 18270, train_loss 44.296780,Time used 0.007998s\n",
      "batch 18271, train_loss 35.893990,Time used 0.007999s\n",
      "batch 18272, train_loss 36.468925,Time used 0.012001s\n",
      "batch 18273, train_loss 44.766487,Time used 0.011005s\n",
      "batch 18274, train_loss 48.905857,Time used 0.011001s\n",
      "batch 18275, train_loss 42.154560,Time used 0.007999s\n",
      "batch 18276, train_loss 34.842133,Time used 0.008000s\n",
      "batch 18277, train_loss 42.476582,Time used 0.007001s\n",
      "batch 18278, train_loss 34.616947,Time used 0.009000s\n",
      "batch 18279, train_loss 40.989296,Time used 0.008001s\n",
      "batch 18280, train_loss 36.513466,Time used 0.011002s\n",
      "batch 18281, train_loss 35.422470,Time used 0.010001s\n",
      "batch 18282, train_loss 47.728516,Time used 0.012000s\n",
      "batch 18283, train_loss 47.074699,Time used 0.009000s\n",
      "batch 18284, train_loss 35.456924,Time used 0.009002s\n",
      "batch 18285, train_loss 38.832233,Time used 0.008998s\n",
      "batch 18286, train_loss 41.218128,Time used 0.011000s\n",
      "batch 18287, train_loss 37.445309,Time used 0.010998s\n",
      "batch 18288, train_loss 44.836601,Time used 0.009002s\n",
      "batch 18289, train_loss 33.915985,Time used 0.011999s\n",
      "batch 18290, train_loss 42.614334,Time used 0.009001s\n",
      "batch 18291, train_loss 40.875179,Time used 0.010001s\n",
      "batch 18292, train_loss 45.805115,Time used 0.010997s\n",
      "batch 18293, train_loss 37.970036,Time used 0.008004s\n",
      "batch 18294, train_loss 34.864246,Time used 0.008998s\n",
      "batch 18295, train_loss 54.786713,Time used 0.012000s\n",
      "batch 18296, train_loss 45.282738,Time used 0.012001s\n",
      "batch 18297, train_loss 46.230198,Time used 0.010998s\n",
      "batch 18298, train_loss 34.911427,Time used 0.010000s\n",
      "batch 18299, train_loss 42.332363,Time used 0.007000s\n",
      "batch 18300, train_loss 45.707047,Time used 0.008002s\n",
      "***************************test_batch 18300, test_rmse_loss 7.418654,test_mae_loss 3.131550,test_mape_loss 52.130877,Time used 0.043999s\n",
      "batch 18301, train_loss 44.478207,Time used 0.009000s\n",
      "batch 18302, train_loss 44.501541,Time used 0.009000s\n",
      "batch 18303, train_loss 34.895958,Time used 0.006999s\n",
      "batch 18304, train_loss 41.152637,Time used 0.008000s\n",
      "batch 18305, train_loss 44.147346,Time used 0.008999s\n",
      "batch 18306, train_loss 35.448193,Time used 0.009001s\n",
      "batch 18307, train_loss 40.038033,Time used 0.012001s\n",
      "batch 18308, train_loss 39.725975,Time used 0.008998s\n",
      "batch 18309, train_loss 40.619652,Time used 0.010000s\n",
      "batch 18310, train_loss 36.415874,Time used 0.008999s\n",
      "batch 18311, train_loss 37.642883,Time used 0.011002s\n",
      "batch 18312, train_loss 35.091854,Time used 0.012001s\n",
      "batch 18313, train_loss 33.208134,Time used 0.010999s\n",
      "batch 18314, train_loss 35.943779,Time used 0.010999s\n",
      "batch 18315, train_loss 34.633041,Time used 0.008000s\n",
      "batch 18316, train_loss 47.961037,Time used 0.010001s\n",
      "batch 18317, train_loss 41.008133,Time used 0.011999s\n",
      "batch 18318, train_loss 39.624069,Time used 0.009002s\n",
      "batch 18319, train_loss 43.475975,Time used 0.008999s\n",
      "batch 18320, train_loss 42.044178,Time used 0.010000s\n",
      "batch 18321, train_loss 41.124485,Time used 0.011000s\n",
      "batch 18322, train_loss 38.174381,Time used 0.009001s\n",
      "batch 18323, train_loss 38.139275,Time used 0.008002s\n",
      "batch 18324, train_loss 50.632179,Time used 0.007998s\n",
      "batch 18325, train_loss 44.623680,Time used 0.007003s\n",
      "batch 18326, train_loss 40.922546,Time used 0.007998s\n",
      "batch 18327, train_loss 47.239559,Time used 0.008003s\n",
      "batch 18328, train_loss 27.895977,Time used 0.010000s\n",
      "batch 18329, train_loss 40.284939,Time used 0.008000s\n",
      "batch 18330, train_loss 42.413651,Time used 0.008000s\n",
      "batch 18331, train_loss 50.009808,Time used 0.009000s\n",
      "batch 18332, train_loss 31.695024,Time used 0.010000s\n",
      "batch 18333, train_loss 42.726376,Time used 0.010000s\n",
      "batch 18334, train_loss 40.072880,Time used 0.011006s\n",
      "batch 18335, train_loss 44.570404,Time used 0.008993s\n",
      "batch 18336, train_loss 39.850040,Time used 0.008000s\n",
      "batch 18337, train_loss 43.466660,Time used 0.009002s\n",
      "batch 18338, train_loss 45.019314,Time used 0.007999s\n",
      "batch 18339, train_loss 34.608704,Time used 0.009000s\n",
      "batch 18340, train_loss 38.380047,Time used 0.008000s\n",
      "batch 18341, train_loss 34.657078,Time used 0.009000s\n",
      "batch 18342, train_loss 40.930161,Time used 0.008000s\n",
      "batch 18343, train_loss 36.670807,Time used 0.009002s\n",
      "batch 18344, train_loss 52.073772,Time used 0.011998s\n",
      "batch 18345, train_loss 38.602093,Time used 0.008001s\n",
      "batch 18346, train_loss 37.268635,Time used 0.007000s\n",
      "batch 18347, train_loss 43.400970,Time used 0.007000s\n",
      "batch 18348, train_loss 34.687714,Time used 0.008000s\n",
      "batch 18349, train_loss 43.788441,Time used 0.007999s\n",
      "batch 18350, train_loss 37.283535,Time used 0.008002s\n",
      "batch 18351, train_loss 39.831459,Time used 0.007997s\n",
      "batch 18352, train_loss 45.473965,Time used 0.008000s\n",
      "batch 18353, train_loss 46.332115,Time used 0.011001s\n",
      "batch 18354, train_loss 41.025776,Time used 0.011002s\n",
      "batch 18355, train_loss 38.544788,Time used 0.008000s\n",
      "batch 18356, train_loss 44.812626,Time used 0.007999s\n",
      "batch 18357, train_loss 41.875019,Time used 0.008000s\n",
      "batch 18358, train_loss 41.913082,Time used 0.009000s\n",
      "batch 18359, train_loss 34.116516,Time used 0.009001s\n",
      "batch 18360, train_loss 42.040722,Time used 0.008002s\n",
      "batch 18361, train_loss 36.173267,Time used 0.007001s\n",
      "batch 18362, train_loss 37.740963,Time used 0.008000s\n",
      "batch 18363, train_loss 38.453003,Time used 0.008002s\n",
      "batch 18364, train_loss 32.727207,Time used 0.010995s\n",
      "batch 18365, train_loss 44.369946,Time used 0.012002s\n",
      "batch 18366, train_loss 47.580261,Time used 0.011999s\n",
      "batch 18367, train_loss 46.460861,Time used 0.011002s\n",
      "batch 18368, train_loss 39.217522,Time used 0.011996s\n",
      "batch 18369, train_loss 36.626053,Time used 0.010996s\n",
      "batch 18370, train_loss 39.540184,Time used 0.011001s\n",
      "batch 18371, train_loss 33.118931,Time used 0.008998s\n",
      "batch 18372, train_loss 38.261967,Time used 0.011001s\n",
      "batch 18373, train_loss 49.743313,Time used 0.008999s\n",
      "batch 18374, train_loss 35.115093,Time used 0.011002s\n",
      "batch 18375, train_loss 42.961658,Time used 0.014002s\n",
      "batch 18376, train_loss 41.849209,Time used 0.021003s\n",
      "batch 18377, train_loss 41.765339,Time used 0.011998s\n",
      "batch 18378, train_loss 39.327423,Time used 0.012999s\n",
      "batch 18379, train_loss 40.104988,Time used 0.012000s\n",
      "batch 18380, train_loss 43.267696,Time used 0.010999s\n",
      "batch 18381, train_loss 49.159492,Time used 0.010998s\n",
      "batch 18382, train_loss 46.156281,Time used 0.012002s\n",
      "batch 18383, train_loss 38.468163,Time used 0.012998s\n",
      "batch 18384, train_loss 37.405903,Time used 0.013002s\n",
      "batch 18385, train_loss 44.490036,Time used 0.015995s\n",
      "batch 18386, train_loss 31.032469,Time used 0.022999s\n",
      "batch 18387, train_loss 27.674704,Time used 0.025001s\n",
      "batch 18388, train_loss 53.640762,Time used 0.012001s\n",
      "batch 18389, train_loss 40.873856,Time used 0.013999s\n",
      "batch 18390, train_loss 41.486591,Time used 0.011998s\n",
      "batch 18391, train_loss 34.472130,Time used 0.011000s\n",
      "batch 18392, train_loss 35.882721,Time used 0.012001s\n",
      "batch 18393, train_loss 42.449772,Time used 0.012999s\n",
      "batch 18394, train_loss 31.550919,Time used 0.011002s\n",
      "batch 18395, train_loss 42.981331,Time used 0.012000s\n",
      "batch 18396, train_loss 37.303455,Time used 0.013000s\n",
      "batch 18397, train_loss 37.879013,Time used 0.011000s\n",
      "batch 18398, train_loss 49.686672,Time used 0.012999s\n",
      "batch 18399, train_loss 46.748257,Time used 0.012000s\n",
      "batch 18400, train_loss 37.236752,Time used 0.011000s\n",
      "***************************test_batch 18400, test_rmse_loss 7.406649,test_mae_loss 3.125742,test_mape_loss 51.777410,Time used 0.041002s\n",
      "batch 18401, train_loss 45.494198,Time used 0.008997s\n",
      "batch 18402, train_loss 43.224850,Time used 0.009001s\n",
      "batch 18403, train_loss 46.846916,Time used 0.012001s\n",
      "batch 18404, train_loss 43.821686,Time used 0.011998s\n",
      "batch 18405, train_loss 48.832066,Time used 0.008002s\n",
      "batch 18406, train_loss 37.880737,Time used 0.006998s\n",
      "batch 18407, train_loss 35.204033,Time used 0.008000s\n",
      "batch 18408, train_loss 37.269665,Time used 0.007000s\n",
      "batch 18409, train_loss 41.784092,Time used 0.010999s\n",
      "batch 18410, train_loss 34.450832,Time used 0.008999s\n",
      "batch 18411, train_loss 34.837505,Time used 0.010005s\n",
      "batch 18412, train_loss 39.299465,Time used 0.008996s\n",
      "batch 18413, train_loss 34.761616,Time used 0.008000s\n",
      "batch 18414, train_loss 40.979504,Time used 0.007000s\n",
      "batch 18415, train_loss 53.321774,Time used 0.008000s\n",
      "batch 18416, train_loss 52.069595,Time used 0.012000s\n",
      "batch 18417, train_loss 44.073135,Time used 0.010000s\n",
      "batch 18418, train_loss 39.833286,Time used 0.009998s\n",
      "batch 18419, train_loss 41.685863,Time used 0.010000s\n",
      "batch 18420, train_loss 39.182049,Time used 0.010002s\n",
      "batch 18421, train_loss 40.864094,Time used 0.010000s\n",
      "batch 18422, train_loss 41.459389,Time used 0.008998s\n",
      "batch 18423, train_loss 35.835949,Time used 0.012001s\n",
      "batch 18424, train_loss 47.521339,Time used 0.012000s\n",
      "batch 18425, train_loss 39.196117,Time used 0.011999s\n",
      "batch 18426, train_loss 44.674244,Time used 0.011001s\n",
      "batch 18427, train_loss 37.318382,Time used 0.011001s\n",
      "batch 18428, train_loss 40.321949,Time used 0.010998s\n",
      "batch 18429, train_loss 32.611221,Time used 0.008000s\n",
      "batch 18430, train_loss 32.508919,Time used 0.008000s\n",
      "batch 18431, train_loss 34.179516,Time used 0.008003s\n",
      "batch 18432, train_loss 50.634560,Time used 0.006999s\n",
      "batch 18433, train_loss 41.254311,Time used 0.009998s\n",
      "batch 18434, train_loss 39.993366,Time used 0.011002s\n",
      "batch 18435, train_loss 40.965313,Time used 0.009997s\n",
      "batch 18436, train_loss 39.368858,Time used 0.008006s\n",
      "batch 18437, train_loss 36.420364,Time used 0.007966s\n",
      "batch 18438, train_loss 41.453278,Time used 0.007999s\n",
      "batch 18439, train_loss 39.283230,Time used 0.010042s\n",
      "batch 18440, train_loss 41.161682,Time used 0.008960s\n",
      "batch 18441, train_loss 40.505020,Time used 0.008000s\n",
      "batch 18442, train_loss 37.617737,Time used 0.011034s\n",
      "batch 18443, train_loss 37.175407,Time used 0.007964s\n",
      "batch 18444, train_loss 43.182632,Time used 0.007999s\n",
      "batch 18445, train_loss 34.842419,Time used 0.008008s\n",
      "batch 18446, train_loss 39.340679,Time used 0.008992s\n",
      "batch 18447, train_loss 38.401836,Time used 0.009002s\n",
      "batch 18448, train_loss 37.856079,Time used 0.007998s\n",
      "batch 18449, train_loss 35.733795,Time used 0.007002s\n",
      "batch 18450, train_loss 34.977985,Time used 0.010999s\n",
      "batch 18451, train_loss 41.182484,Time used 0.008999s\n",
      "batch 18452, train_loss 50.282841,Time used 0.008001s\n",
      "batch 18453, train_loss 53.345890,Time used 0.007999s\n",
      "batch 18454, train_loss 43.077053,Time used 0.006999s\n",
      "batch 18455, train_loss 37.280399,Time used 0.011001s\n",
      "batch 18456, train_loss 46.832455,Time used 0.008001s\n",
      "batch 18457, train_loss 47.421276,Time used 0.009001s\n",
      "batch 18458, train_loss 42.754581,Time used 0.006999s\n",
      "batch 18459, train_loss 45.753471,Time used 0.010002s\n",
      "batch 18460, train_loss 33.499737,Time used 0.010999s\n",
      "batch 18461, train_loss 36.892902,Time used 0.011001s\n",
      "batch 18462, train_loss 36.221779,Time used 0.014003s\n",
      "batch 18463, train_loss 38.963215,Time used 0.009998s\n",
      "batch 18464, train_loss 45.310810,Time used 0.011000s\n",
      "batch 18465, train_loss 44.822235,Time used 0.008998s\n",
      "batch 18466, train_loss 41.631504,Time used 0.008002s\n",
      "batch 18467, train_loss 48.868275,Time used 0.008999s\n",
      "batch 18468, train_loss 41.614704,Time used 0.008999s\n",
      "batch 18469, train_loss 38.723843,Time used 0.008000s\n",
      "batch 18470, train_loss 31.431715,Time used 0.010000s\n",
      "batch 18471, train_loss 39.463753,Time used 0.012001s\n",
      "batch 18472, train_loss 34.863171,Time used 0.007998s\n",
      "batch 18473, train_loss 40.834412,Time used 0.009002s\n",
      "batch 18474, train_loss 40.834782,Time used 0.010002s\n",
      "batch 18475, train_loss 28.219965,Time used 0.007997s\n",
      "batch 18476, train_loss 37.520042,Time used 0.009002s\n",
      "batch 18477, train_loss 45.534050,Time used 0.007000s\n",
      "batch 18478, train_loss 46.191700,Time used 0.008999s\n",
      "batch 18479, train_loss 41.567108,Time used 0.006999s\n",
      "batch 18480, train_loss 40.952045,Time used 0.007999s\n",
      "batch 18481, train_loss 44.091167,Time used 0.008002s\n",
      "batch 18482, train_loss 36.888649,Time used 0.007003s\n",
      "batch 18483, train_loss 39.486439,Time used 0.007999s\n",
      "batch 18484, train_loss 31.260704,Time used 0.008001s\n",
      "batch 18485, train_loss 51.446270,Time used 0.012001s\n",
      "batch 18486, train_loss 46.608814,Time used 0.011001s\n",
      "batch 18487, train_loss 43.323792,Time used 0.008999s\n",
      "batch 18488, train_loss 36.340477,Time used 0.008003s\n",
      "batch 18489, train_loss 37.165646,Time used 0.008001s\n",
      "batch 18490, train_loss 48.058060,Time used 0.010998s\n",
      "batch 18491, train_loss 37.345158,Time used 0.010004s\n",
      "batch 18492, train_loss 39.203526,Time used 0.011998s\n",
      "batch 18493, train_loss 46.252724,Time used 0.008999s\n",
      "batch 18494, train_loss 35.795071,Time used 0.010002s\n",
      "batch 18495, train_loss 43.601002,Time used 0.008999s\n",
      "batch 18496, train_loss 36.563381,Time used 0.011001s\n",
      "batch 18497, train_loss 40.029072,Time used 0.011000s\n",
      "batch 18498, train_loss 41.711597,Time used 0.012001s\n",
      "batch 18499, train_loss 42.052849,Time used 0.008000s\n",
      "batch 18500, train_loss 34.695366,Time used 0.007000s\n",
      "***************************test_batch 18500, test_rmse_loss 7.387017,test_mae_loss 3.119145,test_mape_loss 51.826217,Time used 0.033998s\n",
      "batch 18501, train_loss 38.162899,Time used 0.012001s\n",
      "batch 18502, train_loss 42.163784,Time used 0.008001s\n",
      "batch 18503, train_loss 43.594929,Time used 0.010998s\n",
      "batch 18504, train_loss 33.038647,Time used 0.008001s\n",
      "batch 18505, train_loss 35.770370,Time used 0.006999s\n",
      "batch 18506, train_loss 45.784084,Time used 0.010999s\n",
      "batch 18507, train_loss 45.175961,Time used 0.010001s\n",
      "batch 18508, train_loss 39.444817,Time used 0.007999s\n",
      "batch 18509, train_loss 37.717560,Time used 0.007998s\n",
      "batch 18510, train_loss 33.243137,Time used 0.007000s\n",
      "batch 18511, train_loss 42.819180,Time used 0.012000s\n",
      "batch 18512, train_loss 40.570950,Time used 0.011002s\n",
      "batch 18513, train_loss 44.553509,Time used 0.007999s\n",
      "batch 18514, train_loss 40.496605,Time used 0.009002s\n",
      "batch 18515, train_loss 47.569691,Time used 0.008999s\n",
      "batch 18516, train_loss 38.553135,Time used 0.013001s\n",
      "batch 18517, train_loss 39.287926,Time used 0.009002s\n",
      "batch 18518, train_loss 31.432646,Time used 0.011998s\n",
      "batch 18519, train_loss 31.850395,Time used 0.011998s\n",
      "batch 18520, train_loss 40.287632,Time used 0.012003s\n",
      "batch 18521, train_loss 38.988995,Time used 0.011000s\n",
      "batch 18522, train_loss 43.586773,Time used 0.011998s\n",
      "batch 18523, train_loss 45.057171,Time used 0.008000s\n",
      "batch 18524, train_loss 40.694565,Time used 0.008000s\n",
      "batch 18525, train_loss 43.687363,Time used 0.008000s\n",
      "batch 18526, train_loss 42.154476,Time used 0.009999s\n",
      "batch 18527, train_loss 36.678265,Time used 0.012000s\n",
      "batch 18528, train_loss 41.922947,Time used 0.011001s\n",
      "batch 18529, train_loss 34.128483,Time used 0.008001s\n",
      "batch 18530, train_loss 48.478611,Time used 0.007998s\n",
      "batch 18531, train_loss 35.467178,Time used 0.008000s\n",
      "batch 18532, train_loss 55.722736,Time used 0.008000s\n",
      "batch 18533, train_loss 30.067631,Time used 0.007999s\n",
      "batch 18534, train_loss 36.576385,Time used 0.011000s\n",
      "batch 18535, train_loss 40.747776,Time used 0.012002s\n",
      "batch 18536, train_loss 39.732433,Time used 0.012999s\n",
      "batch 18537, train_loss 35.514729,Time used 0.012001s\n",
      "batch 18538, train_loss 33.726173,Time used 0.007999s\n",
      "batch 18539, train_loss 41.161865,Time used 0.008000s\n",
      "batch 18540, train_loss 43.293560,Time used 0.007998s\n",
      "batch 18541, train_loss 39.636700,Time used 0.007999s\n",
      "batch 18542, train_loss 41.662228,Time used 0.009999s\n",
      "batch 18543, train_loss 42.604324,Time used 0.007001s\n",
      "batch 18544, train_loss 45.304062,Time used 0.008003s\n",
      "batch 18545, train_loss 35.564594,Time used 0.008000s\n",
      "batch 18546, train_loss 40.194309,Time used 0.008000s\n",
      "batch 18547, train_loss 38.324886,Time used 0.007998s\n",
      "batch 18548, train_loss 47.398285,Time used 0.009001s\n",
      "batch 18549, train_loss 45.577652,Time used 0.007000s\n",
      "batch 18550, train_loss 39.237522,Time used 0.009001s\n",
      "batch 18551, train_loss 34.535820,Time used 0.008002s\n",
      "batch 18552, train_loss 41.334785,Time used 0.011998s\n",
      "batch 18553, train_loss 48.971596,Time used 0.007999s\n",
      "batch 18554, train_loss 45.589630,Time used 0.008002s\n",
      "batch 18555, train_loss 43.493858,Time used 0.007998s\n",
      "batch 18556, train_loss 39.158520,Time used 0.011000s\n",
      "batch 18557, train_loss 34.888287,Time used 0.009002s\n",
      "batch 18558, train_loss 39.582851,Time used 0.010000s\n",
      "batch 18559, train_loss 38.317822,Time used 0.011999s\n",
      "batch 18560, train_loss 29.085691,Time used 0.009000s\n",
      "batch 18561, train_loss 42.397423,Time used 0.006999s\n",
      "batch 18562, train_loss 41.738693,Time used 0.011003s\n",
      "batch 18563, train_loss 39.469856,Time used 0.008998s\n",
      "batch 18564, train_loss 46.790966,Time used 0.007998s\n",
      "batch 18565, train_loss 39.557423,Time used 0.008003s\n",
      "batch 18566, train_loss 47.397591,Time used 0.008000s\n",
      "batch 18567, train_loss 47.911766,Time used 0.011999s\n",
      "batch 18568, train_loss 36.057560,Time used 0.012001s\n",
      "batch 18569, train_loss 46.435120,Time used 0.011999s\n",
      "batch 18570, train_loss 42.520000,Time used 0.009001s\n",
      "batch 18571, train_loss 32.687668,Time used 0.007000s\n",
      "batch 18572, train_loss 30.533915,Time used 0.011000s\n",
      "batch 18573, train_loss 41.967525,Time used 0.010999s\n",
      "batch 18574, train_loss 41.229923,Time used 0.009003s\n",
      "batch 18575, train_loss 31.621590,Time used 0.010000s\n",
      "batch 18576, train_loss 37.304287,Time used 0.009998s\n",
      "batch 18577, train_loss 40.815067,Time used 0.008003s\n",
      "batch 18578, train_loss 36.229218,Time used 0.010999s\n",
      "batch 18579, train_loss 43.909077,Time used 0.011002s\n",
      "batch 18580, train_loss 46.532791,Time used 0.006999s\n",
      "batch 18581, train_loss 34.219398,Time used 0.007999s\n",
      "batch 18582, train_loss 33.655449,Time used 0.007001s\n",
      "batch 18583, train_loss 46.229717,Time used 0.012002s\n",
      "batch 18584, train_loss 39.457764,Time used 0.009999s\n",
      "batch 18585, train_loss 28.517324,Time used 0.011000s\n",
      "batch 18586, train_loss 33.438408,Time used 0.008999s\n",
      "batch 18587, train_loss 46.242298,Time used 0.009001s\n",
      "batch 18588, train_loss 43.773975,Time used 0.008997s\n",
      "batch 18589, train_loss 42.435333,Time used 0.008999s\n",
      "batch 18590, train_loss 44.004021,Time used 0.011998s\n",
      "batch 18591, train_loss 34.737637,Time used 0.011001s\n",
      "batch 18592, train_loss 39.192471,Time used 0.008000s\n",
      "batch 18593, train_loss 38.075405,Time used 0.008001s\n",
      "batch 18594, train_loss 37.110760,Time used 0.008001s\n",
      "batch 18595, train_loss 38.054859,Time used 0.010002s\n",
      "batch 18596, train_loss 54.289440,Time used 0.007999s\n",
      "batch 18597, train_loss 40.453682,Time used 0.011998s\n",
      "batch 18598, train_loss 35.824028,Time used 0.010001s\n",
      "batch 18599, train_loss 46.313213,Time used 0.011000s\n",
      "batch 18600, train_loss 39.714001,Time used 0.012998s\n",
      "***************************test_batch 18600, test_rmse_loss 7.366111,test_mae_loss 3.114144,test_mape_loss 51.814437,Time used 0.052004s\n",
      "batch 18601, train_loss 36.646835,Time used 0.018004s\n",
      "batch 18602, train_loss 39.545006,Time used 0.015997s\n",
      "batch 18603, train_loss 44.165096,Time used 0.016001s\n",
      "batch 18604, train_loss 35.632866,Time used 0.013000s\n",
      "batch 18605, train_loss 39.810501,Time used 0.014005s\n",
      "batch 18606, train_loss 47.524601,Time used 0.009995s\n",
      "batch 18607, train_loss 38.625671,Time used 0.018997s\n",
      "batch 18608, train_loss 37.561745,Time used 0.013998s\n",
      "batch 18609, train_loss 33.693321,Time used 0.012996s\n",
      "batch 18610, train_loss 39.778454,Time used 0.012000s\n",
      "batch 18611, train_loss 41.514076,Time used 0.011002s\n",
      "batch 18612, train_loss 38.627407,Time used 0.012997s\n",
      "batch 18613, train_loss 43.549229,Time used 0.008999s\n",
      "batch 18614, train_loss 41.721577,Time used 0.009002s\n",
      "batch 18615, train_loss 45.534710,Time used 0.008000s\n",
      "batch 18616, train_loss 40.154488,Time used 0.007999s\n",
      "batch 18617, train_loss 34.282246,Time used 0.008000s\n",
      "batch 18618, train_loss 43.182022,Time used 0.009001s\n",
      "batch 18619, train_loss 35.980881,Time used 0.009999s\n",
      "batch 18620, train_loss 47.163040,Time used 0.010000s\n",
      "batch 18621, train_loss 40.817703,Time used 0.008003s\n",
      "batch 18622, train_loss 38.418343,Time used 0.007999s\n",
      "batch 18623, train_loss 30.608074,Time used 0.009002s\n",
      "batch 18624, train_loss 48.162083,Time used 0.006998s\n",
      "batch 18625, train_loss 53.376282,Time used 0.008000s\n",
      "batch 18626, train_loss 32.784340,Time used 0.009001s\n",
      "batch 18627, train_loss 47.517014,Time used 0.008998s\n",
      "batch 18628, train_loss 46.167301,Time used 0.009000s\n",
      "batch 18629, train_loss 43.423733,Time used 0.012000s\n",
      "batch 18630, train_loss 41.245232,Time used 0.010000s\n",
      "batch 18631, train_loss 43.399590,Time used 0.008001s\n",
      "batch 18632, train_loss 34.768539,Time used 0.010999s\n",
      "batch 18633, train_loss 26.815727,Time used 0.010999s\n",
      "batch 18634, train_loss 38.209362,Time used 0.009000s\n",
      "batch 18635, train_loss 41.317368,Time used 0.008001s\n",
      "batch 18636, train_loss 31.186188,Time used 0.010000s\n",
      "batch 18637, train_loss 36.898582,Time used 0.011000s\n",
      "batch 18638, train_loss 47.334347,Time used 0.009000s\n",
      "batch 18639, train_loss 42.410561,Time used 0.009002s\n",
      "batch 18640, train_loss 37.666340,Time used 0.011000s\n",
      "batch 18641, train_loss 35.121094,Time used 0.007998s\n",
      "batch 18642, train_loss 50.963741,Time used 0.010999s\n",
      "batch 18643, train_loss 35.397125,Time used 0.012002s\n",
      "batch 18644, train_loss 40.111267,Time used 0.007999s\n",
      "batch 18645, train_loss 36.173893,Time used 0.006999s\n",
      "batch 18646, train_loss 40.202332,Time used 0.008001s\n",
      "batch 18647, train_loss 38.401089,Time used 0.008000s\n",
      "batch 18648, train_loss 39.749359,Time used 0.014002s\n",
      "batch 18649, train_loss 34.799088,Time used 0.010002s\n",
      "batch 18650, train_loss 43.496246,Time used 0.007000s\n",
      "batch 18651, train_loss 42.841885,Time used 0.008001s\n",
      "batch 18652, train_loss 32.025162,Time used 0.010999s\n",
      "batch 18653, train_loss 46.445438,Time used 0.007998s\n",
      "batch 18654, train_loss 39.490395,Time used 0.008000s\n",
      "batch 18655, train_loss 35.126431,Time used 0.011001s\n",
      "batch 18656, train_loss 40.202423,Time used 0.010001s\n",
      "batch 18657, train_loss 44.938255,Time used 0.009999s\n",
      "batch 18658, train_loss 37.121143,Time used 0.010001s\n",
      "batch 18659, train_loss 39.594860,Time used 0.010001s\n",
      "batch 18660, train_loss 43.780533,Time used 0.011002s\n",
      "batch 18661, train_loss 51.968662,Time used 0.011000s\n",
      "batch 18662, train_loss 45.827385,Time used 0.011002s\n",
      "batch 18663, train_loss 40.351643,Time used 0.010998s\n",
      "batch 18664, train_loss 32.126080,Time used 0.008045s\n",
      "batch 18665, train_loss 42.977024,Time used 0.008956s\n",
      "batch 18666, train_loss 39.873173,Time used 0.007997s\n",
      "batch 18667, train_loss 34.668266,Time used 0.007004s\n",
      "batch 18668, train_loss 40.887917,Time used 0.007039s\n",
      "batch 18669, train_loss 44.757729,Time used 0.007962s\n",
      "batch 18670, train_loss 28.887882,Time used 0.007999s\n",
      "batch 18671, train_loss 37.367863,Time used 0.008997s\n",
      "batch 18672, train_loss 39.880356,Time used 0.012002s\n",
      "batch 18673, train_loss 43.209618,Time used 0.016003s\n",
      "batch 18674, train_loss 43.003563,Time used 0.014002s\n",
      "batch 18675, train_loss 34.934708,Time used 0.016997s\n",
      "batch 18676, train_loss 42.369274,Time used 0.012000s\n",
      "batch 18677, train_loss 40.991653,Time used 0.014000s\n",
      "batch 18678, train_loss 39.381290,Time used 0.018000s\n",
      "batch 18679, train_loss 46.398529,Time used 0.018000s\n",
      "batch 18680, train_loss 37.978004,Time used 0.015001s\n",
      "batch 18681, train_loss 39.668293,Time used 0.016000s\n",
      "batch 18682, train_loss 49.351627,Time used 0.016997s\n",
      "batch 18683, train_loss 43.355148,Time used 0.012002s\n",
      "batch 18684, train_loss 32.744766,Time used 0.012011s\n",
      "batch 18685, train_loss 46.653183,Time used 0.014989s\n",
      "batch 18686, train_loss 41.177418,Time used 0.013987s\n",
      "batch 18687, train_loss 37.756546,Time used 0.017001s\n",
      "batch 18688, train_loss 38.451008,Time used 0.016001s\n",
      "batch 18689, train_loss 37.986881,Time used 0.015996s\n",
      "batch 18690, train_loss 34.704502,Time used 0.013005s\n",
      "batch 18691, train_loss 36.753006,Time used 0.015000s\n",
      "batch 18692, train_loss 34.045849,Time used 0.014998s\n",
      "batch 18693, train_loss 40.412678,Time used 0.013006s\n",
      "batch 18694, train_loss 37.561462,Time used 0.013996s\n",
      "batch 18695, train_loss 41.706081,Time used 0.011999s\n",
      "batch 18696, train_loss 37.688747,Time used 0.012998s\n",
      "batch 18697, train_loss 39.817474,Time used 0.008994s\n",
      "batch 18698, train_loss 41.036053,Time used 0.008001s\n",
      "batch 18699, train_loss 40.657047,Time used 0.007001s\n",
      "batch 18700, train_loss 49.455227,Time used 0.009000s\n",
      "***************************test_batch 18700, test_rmse_loss 7.359844,test_mae_loss 3.104234,test_mape_loss 51.332673,Time used 0.043000s\n",
      "batch 18701, train_loss 40.702667,Time used 0.008999s\n",
      "batch 18702, train_loss 38.207237,Time used 0.009002s\n",
      "batch 18703, train_loss 38.764473,Time used 0.008001s\n",
      "batch 18704, train_loss 45.558952,Time used 0.007998s\n",
      "batch 18705, train_loss 37.664917,Time used 0.008000s\n",
      "batch 18706, train_loss 55.077797,Time used 0.009999s\n",
      "batch 18707, train_loss 27.354111,Time used 0.010999s\n",
      "batch 18708, train_loss 33.806049,Time used 0.010001s\n",
      "batch 18709, train_loss 44.484882,Time used 0.007001s\n",
      "batch 18710, train_loss 32.930927,Time used 0.008999s\n",
      "batch 18711, train_loss 36.053635,Time used 0.011002s\n",
      "batch 18712, train_loss 44.554581,Time used 0.008999s\n",
      "batch 18713, train_loss 56.417828,Time used 0.008998s\n",
      "batch 18714, train_loss 41.610847,Time used 0.007001s\n",
      "batch 18715, train_loss 36.524563,Time used 0.007000s\n",
      "batch 18716, train_loss 35.135395,Time used 0.009999s\n",
      "batch 18717, train_loss 39.160805,Time used 0.008001s\n",
      "batch 18718, train_loss 40.955200,Time used 0.008997s\n",
      "batch 18719, train_loss 26.806349,Time used 0.012000s\n",
      "batch 18720, train_loss 34.285072,Time used 0.011001s\n",
      "batch 18721, train_loss 33.342152,Time used 0.010005s\n",
      "batch 18722, train_loss 42.152744,Time used 0.007998s\n",
      "batch 18723, train_loss 39.000999,Time used 0.008003s\n",
      "batch 18724, train_loss 31.461964,Time used 0.008998s\n",
      "batch 18725, train_loss 43.888214,Time used 0.010998s\n",
      "batch 18726, train_loss 38.530956,Time used 0.008003s\n",
      "batch 18727, train_loss 39.696346,Time used 0.009000s\n",
      "batch 18728, train_loss 46.249462,Time used 0.007999s\n",
      "batch 18729, train_loss 46.539276,Time used 0.011036s\n",
      "batch 18730, train_loss 37.966824,Time used 0.011964s\n",
      "batch 18731, train_loss 40.411255,Time used 0.013006s\n",
      "batch 18732, train_loss 47.794491,Time used 0.008993s\n",
      "batch 18733, train_loss 38.667900,Time used 0.009998s\n",
      "batch 18734, train_loss 41.752056,Time used 0.012002s\n",
      "batch 18735, train_loss 40.671829,Time used 0.011000s\n",
      "batch 18736, train_loss 34.981991,Time used 0.012000s\n",
      "batch 18737, train_loss 35.210091,Time used 0.009999s\n",
      "batch 18738, train_loss 37.841507,Time used 0.008001s\n",
      "batch 18739, train_loss 40.603539,Time used 0.010000s\n",
      "batch 18740, train_loss 33.819130,Time used 0.012000s\n",
      "batch 18741, train_loss 42.949234,Time used 0.011000s\n",
      "batch 18742, train_loss 40.916435,Time used 0.011999s\n",
      "batch 18743, train_loss 43.116028,Time used 0.008002s\n",
      "batch 18744, train_loss 37.691231,Time used 0.007001s\n",
      "batch 18745, train_loss 35.682491,Time used 0.010993s\n",
      "batch 18746, train_loss 41.710438,Time used 0.009004s\n",
      "batch 18747, train_loss 36.469585,Time used 0.008998s\n",
      "batch 18748, train_loss 40.366344,Time used 0.009000s\n",
      "batch 18749, train_loss 45.086544,Time used 0.008000s\n",
      "batch 18750, train_loss 30.826553,Time used 0.008005s\n",
      "batch 18751, train_loss 37.834679,Time used 0.009994s\n",
      "batch 18752, train_loss 42.807812,Time used 0.013005s\n",
      "batch 18753, train_loss 39.379280,Time used 0.013996s\n",
      "batch 18754, train_loss 31.883255,Time used 0.010003s\n",
      "batch 18755, train_loss 39.238247,Time used 0.012999s\n",
      "batch 18756, train_loss 40.792904,Time used 0.015998s\n",
      "batch 18757, train_loss 41.373135,Time used 0.013996s\n",
      "batch 18758, train_loss 38.339153,Time used 0.017006s\n",
      "batch 18759, train_loss 44.190914,Time used 0.017000s\n",
      "batch 18760, train_loss 37.495483,Time used 0.017008s\n",
      "batch 18761, train_loss 34.882626,Time used 0.010999s\n",
      "batch 18762, train_loss 41.725933,Time used 0.013000s\n",
      "batch 18763, train_loss 46.786285,Time used 0.010991s\n",
      "batch 18764, train_loss 38.998901,Time used 0.013995s\n",
      "batch 18765, train_loss 38.672764,Time used 0.016003s\n",
      "batch 18766, train_loss 45.610275,Time used 0.015002s\n",
      "batch 18767, train_loss 36.744724,Time used 0.014001s\n",
      "batch 18768, train_loss 47.564926,Time used 0.018997s\n",
      "batch 18769, train_loss 42.829109,Time used 0.011992s\n",
      "batch 18770, train_loss 40.876003,Time used 0.012003s\n",
      "batch 18771, train_loss 43.027424,Time used 0.012998s\n",
      "batch 18772, train_loss 35.176762,Time used 0.009009s\n",
      "batch 18773, train_loss 35.079670,Time used 0.012993s\n",
      "batch 18774, train_loss 44.649693,Time used 0.013006s\n",
      "batch 18775, train_loss 38.618069,Time used 0.011997s\n",
      "batch 18776, train_loss 35.547092,Time used 0.012006s\n",
      "batch 18777, train_loss 42.238934,Time used 0.012993s\n",
      "batch 18778, train_loss 37.540432,Time used 0.012998s\n",
      "batch 18779, train_loss 38.824604,Time used 0.013003s\n",
      "batch 18780, train_loss 43.833450,Time used 0.014001s\n",
      "batch 18781, train_loss 37.548466,Time used 0.007998s\n",
      "batch 18782, train_loss 30.275511,Time used 0.010001s\n",
      "batch 18783, train_loss 47.186760,Time used 0.009001s\n",
      "batch 18784, train_loss 38.647579,Time used 0.007997s\n",
      "batch 18785, train_loss 43.382984,Time used 0.007999s\n",
      "batch 18786, train_loss 35.350727,Time used 0.008001s\n",
      "batch 18787, train_loss 39.400486,Time used 0.009997s\n",
      "batch 18788, train_loss 36.047897,Time used 0.008000s\n",
      "batch 18789, train_loss 48.430584,Time used 0.008999s\n",
      "batch 18790, train_loss 43.299072,Time used 0.008000s\n",
      "batch 18791, train_loss 40.633968,Time used 0.007999s\n",
      "batch 18792, train_loss 34.436848,Time used 0.008000s\n",
      "batch 18793, train_loss 42.528168,Time used 0.012001s\n",
      "batch 18794, train_loss 34.350155,Time used 0.009000s\n",
      "batch 18795, train_loss 31.931089,Time used 0.007001s\n",
      "batch 18796, train_loss 43.111195,Time used 0.011000s\n",
      "batch 18797, train_loss 36.543480,Time used 0.008001s\n",
      "batch 18798, train_loss 42.696453,Time used 0.013001s\n",
      "batch 18799, train_loss 36.172649,Time used 0.011999s\n",
      "batch 18800, train_loss 45.577938,Time used 0.008001s\n",
      "***************************test_batch 18800, test_rmse_loss 7.335719,test_mae_loss 3.102570,test_mape_loss 51.535820,Time used 0.041000s\n",
      "batch 18801, train_loss 35.986439,Time used 0.009000s\n",
      "batch 18802, train_loss 34.887321,Time used 0.008000s\n",
      "batch 18803, train_loss 43.450245,Time used 0.007999s\n",
      "batch 18804, train_loss 43.438164,Time used 0.010000s\n",
      "batch 18805, train_loss 49.293667,Time used 0.011001s\n",
      "batch 18806, train_loss 47.485691,Time used 0.010000s\n",
      "batch 18807, train_loss 44.681126,Time used 0.008000s\n",
      "batch 18808, train_loss 36.806412,Time used 0.007998s\n",
      "batch 18809, train_loss 40.743961,Time used 0.008000s\n",
      "batch 18810, train_loss 37.518341,Time used 0.008001s\n",
      "batch 18811, train_loss 38.615509,Time used 0.009999s\n",
      "batch 18812, train_loss 34.057945,Time used 0.007999s\n",
      "batch 18813, train_loss 34.663448,Time used 0.009000s\n",
      "batch 18814, train_loss 45.915928,Time used 0.009000s\n",
      "batch 18815, train_loss 37.834511,Time used 0.010003s\n",
      "batch 18816, train_loss 33.141441,Time used 0.012999s\n",
      "batch 18817, train_loss 32.917198,Time used 0.008001s\n",
      "batch 18818, train_loss 42.974598,Time used 0.007996s\n",
      "batch 18819, train_loss 44.819214,Time used 0.009999s\n",
      "batch 18820, train_loss 40.517658,Time used 0.011003s\n",
      "batch 18821, train_loss 35.729935,Time used 0.010998s\n",
      "batch 18822, train_loss 43.247051,Time used 0.009003s\n",
      "batch 18823, train_loss 48.073547,Time used 0.010998s\n",
      "batch 18824, train_loss 47.416183,Time used 0.011000s\n",
      "batch 18825, train_loss 36.829395,Time used 0.012000s\n",
      "batch 18826, train_loss 41.089539,Time used 0.014004s\n",
      "batch 18827, train_loss 37.069256,Time used 0.014000s\n",
      "batch 18828, train_loss 39.699524,Time used 0.014997s\n",
      "batch 18829, train_loss 39.700527,Time used 0.013001s\n",
      "batch 18830, train_loss 29.721834,Time used 0.015998s\n",
      "batch 18831, train_loss 38.052181,Time used 0.016005s\n",
      "batch 18832, train_loss 41.667923,Time used 0.018002s\n",
      "batch 18833, train_loss 43.981953,Time used 0.014001s\n",
      "batch 18834, train_loss 43.197479,Time used 0.013000s\n",
      "batch 18835, train_loss 37.271034,Time used 0.017001s\n",
      "batch 18836, train_loss 37.512306,Time used 0.016001s\n",
      "batch 18837, train_loss 35.749928,Time used 0.010011s\n",
      "batch 18838, train_loss 36.609936,Time used 0.012994s\n",
      "batch 18839, train_loss 40.679302,Time used 0.013999s\n",
      "batch 18840, train_loss 35.624046,Time used 0.012002s\n",
      "batch 18841, train_loss 46.040268,Time used 0.014998s\n",
      "batch 18842, train_loss 33.711151,Time used 0.018000s\n",
      "batch 18843, train_loss 39.962528,Time used 0.014011s\n",
      "batch 18844, train_loss 30.651201,Time used 0.014992s\n",
      "batch 18845, train_loss 40.513565,Time used 0.009992s\n",
      "batch 18846, train_loss 35.280346,Time used 0.013003s\n",
      "batch 18847, train_loss 42.555367,Time used 0.014999s\n",
      "batch 18848, train_loss 39.546257,Time used 0.015000s\n",
      "batch 18849, train_loss 34.706219,Time used 0.012999s\n",
      "batch 18850, train_loss 46.534241,Time used 0.013005s\n",
      "batch 18851, train_loss 42.884251,Time used 0.008995s\n",
      "batch 18852, train_loss 37.994804,Time used 0.011001s\n",
      "batch 18853, train_loss 36.517544,Time used 0.008000s\n",
      "batch 18854, train_loss 38.230423,Time used 0.011002s\n",
      "batch 18855, train_loss 39.020702,Time used 0.012001s\n",
      "batch 18856, train_loss 42.770733,Time used 0.012002s\n",
      "batch 18857, train_loss 38.807800,Time used 0.011999s\n",
      "batch 18858, train_loss 36.803474,Time used 0.009000s\n",
      "batch 18859, train_loss 44.413776,Time used 0.009000s\n",
      "batch 18860, train_loss 37.742115,Time used 0.012001s\n",
      "batch 18861, train_loss 43.379593,Time used 0.008002s\n",
      "batch 18862, train_loss 37.455124,Time used 0.010996s\n",
      "batch 18863, train_loss 41.612877,Time used 0.009002s\n",
      "batch 18864, train_loss 42.080063,Time used 0.009001s\n",
      "batch 18865, train_loss 34.176872,Time used 0.007000s\n",
      "batch 18866, train_loss 38.310730,Time used 0.006998s\n",
      "batch 18867, train_loss 38.097317,Time used 0.008000s\n",
      "batch 18868, train_loss 45.928848,Time used 0.009002s\n",
      "batch 18869, train_loss 44.106525,Time used 0.011998s\n",
      "batch 18870, train_loss 43.072918,Time used 0.012010s\n",
      "batch 18871, train_loss 45.029945,Time used 0.011990s\n",
      "batch 18872, train_loss 41.722721,Time used 0.007998s\n",
      "batch 18873, train_loss 40.548801,Time used 0.010998s\n",
      "batch 18874, train_loss 44.325905,Time used 0.010999s\n",
      "batch 18875, train_loss 44.623974,Time used 0.011003s\n",
      "batch 18876, train_loss 36.941563,Time used 0.008000s\n",
      "batch 18877, train_loss 40.775517,Time used 0.008002s\n",
      "batch 18878, train_loss 39.095715,Time used 0.008996s\n",
      "batch 18879, train_loss 37.812477,Time used 0.009003s\n",
      "batch 18880, train_loss 40.849739,Time used 0.007998s\n",
      "batch 18881, train_loss 38.458904,Time used 0.010000s\n",
      "batch 18882, train_loss 40.764027,Time used 0.011000s\n",
      "batch 18883, train_loss 33.387112,Time used 0.008000s\n",
      "batch 18884, train_loss 40.686707,Time used 0.008000s\n",
      "batch 18885, train_loss 38.551243,Time used 0.008999s\n",
      "batch 18886, train_loss 30.703300,Time used 0.009004s\n",
      "batch 18887, train_loss 33.306896,Time used 0.007000s\n",
      "batch 18888, train_loss 36.684155,Time used 0.008001s\n",
      "batch 18889, train_loss 29.157656,Time used 0.009998s\n",
      "batch 18890, train_loss 47.382271,Time used 0.009000s\n",
      "batch 18891, train_loss 43.230022,Time used 0.011000s\n",
      "batch 18892, train_loss 39.210007,Time used 0.011004s\n",
      "batch 18893, train_loss 34.558372,Time used 0.007001s\n",
      "batch 18894, train_loss 38.946407,Time used 0.009996s\n",
      "batch 18895, train_loss 33.697525,Time used 0.011001s\n",
      "batch 18896, train_loss 50.953835,Time used 0.008000s\n",
      "batch 18897, train_loss 38.861702,Time used 0.008000s\n",
      "batch 18898, train_loss 50.042770,Time used 0.007000s\n",
      "batch 18899, train_loss 38.972668,Time used 0.007997s\n",
      "batch 18900, train_loss 29.973246,Time used 0.007001s\n",
      "***************************test_batch 18900, test_rmse_loss 7.322968,test_mae_loss 3.094976,test_mape_loss 51.303723,Time used 0.040003s\n",
      "batch 18901, train_loss 34.638283,Time used 0.008999s\n",
      "batch 18902, train_loss 40.359619,Time used 0.011998s\n",
      "batch 18903, train_loss 30.331591,Time used 0.009002s\n",
      "batch 18904, train_loss 38.935017,Time used 0.011999s\n",
      "batch 18905, train_loss 39.441734,Time used 0.008003s\n",
      "batch 18906, train_loss 41.689034,Time used 0.007996s\n",
      "batch 18907, train_loss 39.932434,Time used 0.007002s\n",
      "batch 18908, train_loss 45.879475,Time used 0.009001s\n",
      "batch 18909, train_loss 44.012089,Time used 0.010997s\n",
      "batch 18910, train_loss 37.335930,Time used 0.010000s\n",
      "batch 18911, train_loss 32.841827,Time used 0.008000s\n",
      "batch 18912, train_loss 46.313461,Time used 0.012002s\n",
      "batch 18913, train_loss 36.569588,Time used 0.009001s\n",
      "batch 18914, train_loss 42.979900,Time used 0.010000s\n",
      "batch 18915, train_loss 38.732544,Time used 0.007001s\n",
      "batch 18916, train_loss 33.486771,Time used 0.010998s\n",
      "batch 18917, train_loss 36.698692,Time used 0.007999s\n",
      "batch 18918, train_loss 36.479362,Time used 0.010999s\n",
      "batch 18919, train_loss 48.333103,Time used 0.010000s\n",
      "batch 18920, train_loss 34.338200,Time used 0.010001s\n",
      "batch 18921, train_loss 38.445797,Time used 0.009999s\n",
      "batch 18922, train_loss 33.820072,Time used 0.008001s\n",
      "batch 18923, train_loss 37.927998,Time used 0.009002s\n",
      "batch 18924, train_loss 50.069881,Time used 0.012000s\n",
      "batch 18925, train_loss 47.132965,Time used 0.009999s\n",
      "batch 18926, train_loss 43.312233,Time used 0.007999s\n",
      "batch 18927, train_loss 38.286987,Time used 0.010002s\n",
      "batch 18928, train_loss 40.923279,Time used 0.007999s\n",
      "batch 18929, train_loss 37.636124,Time used 0.008001s\n",
      "batch 18930, train_loss 36.172920,Time used 0.010001s\n",
      "batch 18931, train_loss 41.735668,Time used 0.007998s\n",
      "batch 18932, train_loss 41.740665,Time used 0.010001s\n",
      "batch 18933, train_loss 40.973240,Time used 0.006999s\n",
      "batch 18934, train_loss 34.775639,Time used 0.011002s\n",
      "batch 18935, train_loss 33.860397,Time used 0.008998s\n",
      "batch 18936, train_loss 41.694756,Time used 0.008003s\n",
      "batch 18937, train_loss 43.294304,Time used 0.007999s\n",
      "batch 18938, train_loss 39.025848,Time used 0.011000s\n",
      "batch 18939, train_loss 45.002991,Time used 0.011002s\n",
      "batch 18940, train_loss 39.461937,Time used 0.008997s\n",
      "batch 18941, train_loss 40.671196,Time used 0.007000s\n",
      "batch 18942, train_loss 36.803410,Time used 0.011001s\n",
      "batch 18943, train_loss 56.422424,Time used 0.009999s\n",
      "batch 18944, train_loss 35.445496,Time used 0.010998s\n",
      "batch 18945, train_loss 32.659653,Time used 0.011002s\n",
      "batch 18946, train_loss 39.527973,Time used 0.009001s\n",
      "batch 18947, train_loss 42.076523,Time used 0.010997s\n",
      "batch 18948, train_loss 35.059708,Time used 0.007999s\n",
      "batch 18949, train_loss 32.462872,Time used 0.011002s\n",
      "batch 18950, train_loss 37.955791,Time used 0.010999s\n",
      "batch 18951, train_loss 36.262562,Time used 0.010004s\n",
      "batch 18952, train_loss 35.931267,Time used 0.006998s\n",
      "batch 18953, train_loss 53.713924,Time used 0.011007s\n",
      "batch 18954, train_loss 38.972729,Time used 0.008992s\n",
      "batch 18955, train_loss 30.125723,Time used 0.010000s\n",
      "batch 18956, train_loss 37.857986,Time used 0.012997s\n",
      "batch 18957, train_loss 37.886253,Time used 0.013001s\n",
      "batch 18958, train_loss 38.793690,Time used 0.011994s\n",
      "batch 18959, train_loss 34.992550,Time used 0.014998s\n",
      "batch 18960, train_loss 43.650406,Time used 0.013997s\n",
      "batch 18961, train_loss 36.543327,Time used 0.014994s\n",
      "batch 18962, train_loss 45.191586,Time used 0.014990s\n",
      "batch 18963, train_loss 37.731449,Time used 0.013013s\n",
      "batch 18964, train_loss 38.607937,Time used 0.015990s\n",
      "batch 18965, train_loss 39.714104,Time used 0.009999s\n",
      "batch 18966, train_loss 31.048264,Time used 0.014999s\n",
      "batch 18967, train_loss 35.489120,Time used 0.014997s\n",
      "batch 18968, train_loss 37.455570,Time used 0.016001s\n",
      "batch 18969, train_loss 36.186874,Time used 0.013003s\n",
      "batch 18970, train_loss 39.973442,Time used 0.011005s\n",
      "batch 18971, train_loss 54.022285,Time used 0.013997s\n",
      "batch 18972, train_loss 41.161743,Time used 0.015994s\n",
      "batch 18973, train_loss 37.928108,Time used 0.016004s\n",
      "batch 18974, train_loss 41.484207,Time used 0.015995s\n",
      "batch 18975, train_loss 30.194374,Time used 0.014991s\n",
      "batch 18976, train_loss 49.776569,Time used 0.015997s\n",
      "batch 18977, train_loss 36.741344,Time used 0.013000s\n",
      "batch 18978, train_loss 36.869736,Time used 0.012002s\n",
      "batch 18979, train_loss 48.594753,Time used 0.008998s\n",
      "batch 18980, train_loss 41.227119,Time used 0.010002s\n",
      "batch 18981, train_loss 34.489342,Time used 0.012999s\n",
      "batch 18982, train_loss 39.801064,Time used 0.008998s\n",
      "batch 18983, train_loss 32.607117,Time used 0.012998s\n",
      "batch 18984, train_loss 40.015430,Time used 0.011001s\n",
      "batch 18985, train_loss 43.647823,Time used 0.011998s\n",
      "batch 18986, train_loss 32.749866,Time used 0.012001s\n",
      "batch 18987, train_loss 40.938297,Time used 0.009003s\n",
      "batch 18988, train_loss 36.374607,Time used 0.014002s\n",
      "batch 18989, train_loss 33.185875,Time used 0.009996s\n",
      "batch 18990, train_loss 39.810825,Time used 0.009001s\n",
      "batch 18991, train_loss 47.982792,Time used 0.009999s\n",
      "batch 18992, train_loss 39.040051,Time used 0.010000s\n",
      "batch 18993, train_loss 31.918251,Time used 0.010001s\n",
      "batch 18994, train_loss 42.121349,Time used 0.009998s\n",
      "batch 18995, train_loss 39.533104,Time used 0.009001s\n",
      "batch 18996, train_loss 43.504589,Time used 0.008003s\n",
      "batch 18997, train_loss 43.349258,Time used 0.007997s\n",
      "batch 18998, train_loss 40.238991,Time used 0.010000s\n",
      "batch 18999, train_loss 33.526566,Time used 0.009001s\n",
      "batch 19000, train_loss 34.486572,Time used 0.008002s\n",
      "***************************test_batch 19000, test_rmse_loss 7.289608,test_mae_loss 3.092039,test_mape_loss 51.598681,Time used 0.038000s\n",
      "batch 19001, train_loss 38.655762,Time used 0.010000s\n",
      "batch 19002, train_loss 41.289406,Time used 0.008997s\n",
      "batch 19003, train_loss 39.721210,Time used 0.008002s\n",
      "batch 19004, train_loss 39.168133,Time used 0.006999s\n",
      "batch 19005, train_loss 38.997208,Time used 0.008001s\n",
      "batch 19006, train_loss 42.244957,Time used 0.013000s\n",
      "batch 19007, train_loss 40.853432,Time used 0.007999s\n",
      "batch 19008, train_loss 38.343456,Time used 0.007998s\n",
      "batch 19009, train_loss 45.549309,Time used 0.012001s\n",
      "batch 19010, train_loss 40.894699,Time used 0.009001s\n",
      "batch 19011, train_loss 44.315514,Time used 0.011000s\n",
      "batch 19012, train_loss 40.880226,Time used 0.011000s\n",
      "batch 19013, train_loss 40.881008,Time used 0.008000s\n",
      "batch 19014, train_loss 34.698288,Time used 0.007998s\n",
      "batch 19015, train_loss 31.936769,Time used 0.008999s\n",
      "batch 19016, train_loss 45.784393,Time used 0.008001s\n",
      "batch 19017, train_loss 42.678825,Time used 0.008000s\n",
      "batch 19018, train_loss 33.396339,Time used 0.008000s\n",
      "batch 19019, train_loss 52.492893,Time used 0.009001s\n",
      "batch 19020, train_loss 39.099243,Time used 0.007997s\n",
      "batch 19021, train_loss 32.361732,Time used 0.011002s\n",
      "batch 19022, train_loss 39.941929,Time used 0.007999s\n",
      "batch 19023, train_loss 30.131014,Time used 0.011001s\n",
      "batch 19024, train_loss 41.062199,Time used 0.010000s\n",
      "batch 19025, train_loss 38.222935,Time used 0.007000s\n",
      "batch 19026, train_loss 43.998058,Time used 0.008002s\n",
      "batch 19027, train_loss 36.593418,Time used 0.007999s\n",
      "batch 19028, train_loss 26.055319,Time used 0.008001s\n",
      "batch 19029, train_loss 38.614422,Time used 0.009000s\n",
      "batch 19030, train_loss 39.089996,Time used 0.009000s\n",
      "batch 19031, train_loss 41.031410,Time used 0.009001s\n",
      "batch 19032, train_loss 40.605869,Time used 0.007999s\n",
      "batch 19033, train_loss 39.127335,Time used 0.009999s\n",
      "batch 19034, train_loss 43.714073,Time used 0.007999s\n",
      "batch 19035, train_loss 44.858727,Time used 0.007999s\n",
      "batch 19036, train_loss 38.182526,Time used 0.008000s\n",
      "batch 19037, train_loss 42.922413,Time used 0.008002s\n",
      "batch 19038, train_loss 39.955696,Time used 0.007999s\n",
      "batch 19039, train_loss 39.666489,Time used 0.009000s\n",
      "batch 19040, train_loss 37.266037,Time used 0.008001s\n",
      "batch 19041, train_loss 41.497070,Time used 0.011000s\n",
      "batch 19042, train_loss 50.290123,Time used 0.012000s\n",
      "batch 19043, train_loss 41.671867,Time used 0.010999s\n",
      "batch 19044, train_loss 36.346119,Time used 0.010001s\n",
      "batch 19045, train_loss 32.685242,Time used 0.010000s\n",
      "batch 19046, train_loss 34.788475,Time used 0.008001s\n",
      "batch 19047, train_loss 37.565243,Time used 0.009000s\n",
      "batch 19048, train_loss 29.783009,Time used 0.007997s\n",
      "batch 19049, train_loss 38.579315,Time used 0.011001s\n",
      "batch 19050, train_loss 51.026459,Time used 0.011003s\n",
      "batch 19051, train_loss 34.183998,Time used 0.010998s\n",
      "batch 19052, train_loss 46.039520,Time used 0.009000s\n",
      "batch 19053, train_loss 30.690294,Time used 0.009003s\n",
      "batch 19054, train_loss 37.617023,Time used 0.010001s\n",
      "batch 19055, train_loss 40.105030,Time used 0.008998s\n",
      "batch 19056, train_loss 30.422110,Time used 0.008000s\n",
      "batch 19057, train_loss 36.688187,Time used 0.009001s\n",
      "batch 19058, train_loss 45.214241,Time used 0.008001s\n",
      "batch 19059, train_loss 42.381210,Time used 0.008001s\n",
      "batch 19060, train_loss 34.180351,Time used 0.008998s\n",
      "batch 19061, train_loss 33.398487,Time used 0.010001s\n",
      "batch 19062, train_loss 40.917774,Time used 0.009998s\n",
      "batch 19063, train_loss 39.515511,Time used 0.012000s\n",
      "batch 19064, train_loss 39.035812,Time used 0.008000s\n",
      "batch 19065, train_loss 36.543766,Time used 0.010000s\n",
      "batch 19066, train_loss 35.519260,Time used 0.008003s\n",
      "batch 19067, train_loss 34.465740,Time used 0.008001s\n",
      "batch 19068, train_loss 38.864918,Time used 0.008998s\n",
      "batch 19069, train_loss 43.400326,Time used 0.009001s\n",
      "batch 19070, train_loss 48.173347,Time used 0.007998s\n",
      "batch 19071, train_loss 36.632690,Time used 0.009005s\n",
      "batch 19072, train_loss 31.008205,Time used 0.007997s\n",
      "batch 19073, train_loss 40.494370,Time used 0.010999s\n",
      "batch 19074, train_loss 32.618023,Time used 0.013000s\n",
      "batch 19075, train_loss 39.724621,Time used 0.012000s\n",
      "batch 19076, train_loss 32.496391,Time used 0.011001s\n",
      "batch 19077, train_loss 49.894756,Time used 0.010001s\n",
      "batch 19078, train_loss 44.785576,Time used 0.008996s\n",
      "batch 19079, train_loss 42.561481,Time used 0.012001s\n",
      "batch 19080, train_loss 39.301434,Time used 0.010001s\n",
      "batch 19081, train_loss 44.600742,Time used 0.015998s\n",
      "batch 19082, train_loss 32.103279,Time used 0.012001s\n",
      "batch 19083, train_loss 27.703489,Time used 0.012002s\n",
      "batch 19084, train_loss 37.938210,Time used 0.010001s\n",
      "batch 19085, train_loss 31.027431,Time used 0.010999s\n",
      "batch 19086, train_loss 45.645817,Time used 0.009999s\n",
      "batch 19087, train_loss 41.478779,Time used 0.009000s\n",
      "batch 19088, train_loss 34.383976,Time used 0.008999s\n",
      "batch 19089, train_loss 33.290562,Time used 0.008004s\n",
      "batch 19090, train_loss 41.378910,Time used 0.011992s\n",
      "batch 19091, train_loss 43.833313,Time used 0.013011s\n",
      "batch 19092, train_loss 32.259510,Time used 0.011998s\n",
      "batch 19093, train_loss 37.227879,Time used 0.015999s\n",
      "batch 19094, train_loss 37.201889,Time used 0.017002s\n",
      "batch 19095, train_loss 39.950127,Time used 0.015003s\n",
      "batch 19096, train_loss 36.546085,Time used 0.015997s\n",
      "batch 19097, train_loss 42.632122,Time used 0.017999s\n",
      "batch 19098, train_loss 30.910061,Time used 0.018999s\n",
      "batch 19099, train_loss 44.575665,Time used 0.016001s\n",
      "batch 19100, train_loss 35.571110,Time used 0.016001s\n",
      "***************************test_batch 19100, test_rmse_loss 7.276156,test_mae_loss 3.082856,test_mape_loss 51.336750,Time used 0.053002s\n",
      "batch 19101, train_loss 47.040672,Time used 0.029998s\n",
      "batch 19102, train_loss 42.339657,Time used 0.020000s\n",
      "batch 19103, train_loss 50.348885,Time used 0.022005s\n",
      "batch 19104, train_loss 46.625107,Time used 0.017008s\n",
      "batch 19105, train_loss 40.445248,Time used 0.027010s\n",
      "batch 19106, train_loss 34.378689,Time used 0.017987s\n",
      "batch 19107, train_loss 46.623394,Time used 0.020000s\n",
      "batch 19108, train_loss 33.717857,Time used 0.026001s\n",
      "batch 19109, train_loss 24.083204,Time used 0.022999s\n",
      "batch 19110, train_loss 51.701790,Time used 0.018002s\n",
      "batch 19111, train_loss 45.267159,Time used 0.027997s\n",
      "batch 19112, train_loss 33.088715,Time used 0.016999s\n",
      "batch 19113, train_loss 34.188484,Time used 0.020999s\n",
      "batch 19114, train_loss 41.221783,Time used 0.023001s\n",
      "batch 19115, train_loss 37.087887,Time used 0.025003s\n",
      "batch 19116, train_loss 49.290661,Time used 0.043993s\n",
      "batch 19117, train_loss 43.402824,Time used 0.033000s\n",
      "batch 19118, train_loss 36.474030,Time used 0.017000s\n",
      "batch 19119, train_loss 32.651043,Time used 0.017999s\n",
      "batch 19120, train_loss 43.085194,Time used 0.018002s\n",
      "batch 19121, train_loss 33.411282,Time used 0.021002s\n",
      "batch 19122, train_loss 34.516499,Time used 0.024993s\n",
      "batch 19123, train_loss 37.334259,Time used 0.018999s\n",
      "batch 19124, train_loss 41.155052,Time used 0.030003s\n",
      "batch 19125, train_loss 40.038372,Time used 0.016996s\n",
      "batch 19126, train_loss 43.880325,Time used 0.036000s\n",
      "batch 19127, train_loss 35.869087,Time used 0.022005s\n",
      "batch 19128, train_loss 42.299431,Time used 0.014002s\n",
      "batch 19129, train_loss 39.366451,Time used 0.016996s\n",
      "batch 19130, train_loss 35.041859,Time used 0.024006s\n",
      "batch 19131, train_loss 34.791916,Time used 0.016998s\n",
      "batch 19132, train_loss 39.920532,Time used 0.015000s\n",
      "batch 19133, train_loss 36.185883,Time used 0.016008s\n",
      "batch 19134, train_loss 41.722321,Time used 0.015992s\n",
      "batch 19135, train_loss 41.456646,Time used 0.016998s\n",
      "batch 19136, train_loss 43.211636,Time used 0.016002s\n",
      "batch 19137, train_loss 32.659393,Time used 0.016992s\n",
      "batch 19138, train_loss 42.416897,Time used 0.016001s\n",
      "batch 19139, train_loss 35.995548,Time used 0.018001s\n",
      "batch 19140, train_loss 30.872780,Time used 0.016996s\n",
      "batch 19141, train_loss 39.153484,Time used 0.014005s\n",
      "batch 19142, train_loss 30.279158,Time used 0.015996s\n",
      "batch 19143, train_loss 42.428982,Time used 0.016003s\n",
      "batch 19144, train_loss 38.887592,Time used 0.016003s\n",
      "batch 19145, train_loss 38.000355,Time used 0.018006s\n",
      "batch 19146, train_loss 48.107876,Time used 0.013990s\n",
      "batch 19147, train_loss 33.977997,Time used 0.007999s\n",
      "batch 19148, train_loss 33.139282,Time used 0.014000s\n",
      "batch 19149, train_loss 40.483105,Time used 0.013000s\n",
      "batch 19150, train_loss 51.487640,Time used 0.017005s\n",
      "batch 19151, train_loss 43.697849,Time used 0.016000s\n",
      "batch 19152, train_loss 40.573303,Time used 0.014997s\n",
      "batch 19153, train_loss 44.722725,Time used 0.011999s\n",
      "batch 19154, train_loss 39.737240,Time used 0.012995s\n",
      "batch 19155, train_loss 46.588890,Time used 0.012997s\n",
      "batch 19156, train_loss 37.508877,Time used 0.015006s\n",
      "batch 19157, train_loss 33.546520,Time used 0.015995s\n",
      "batch 19158, train_loss 33.275974,Time used 0.017012s\n",
      "batch 19159, train_loss 39.662281,Time used 0.013988s\n",
      "batch 19160, train_loss 38.339767,Time used 0.016005s\n",
      "batch 19161, train_loss 45.604668,Time used 0.017998s\n",
      "batch 19162, train_loss 34.573788,Time used 0.011032s\n",
      "batch 19163, train_loss 38.084469,Time used 0.015995s\n",
      "batch 19164, train_loss 41.093643,Time used 0.019997s\n",
      "batch 19165, train_loss 46.389629,Time used 0.008995s\n",
      "batch 19166, train_loss 35.875816,Time used 0.014998s\n",
      "batch 19167, train_loss 37.333927,Time used 0.015998s\n",
      "batch 19168, train_loss 36.250320,Time used 0.013998s\n",
      "batch 19169, train_loss 34.893185,Time used 0.014005s\n",
      "batch 19170, train_loss 33.205643,Time used 0.015000s\n",
      "batch 19171, train_loss 32.243435,Time used 0.015004s\n",
      "batch 19172, train_loss 41.219421,Time used 0.017002s\n",
      "batch 19173, train_loss 41.876667,Time used 0.015993s\n",
      "batch 19174, train_loss 40.806023,Time used 0.014027s\n",
      "batch 19175, train_loss 36.789722,Time used 0.013976s\n",
      "batch 19176, train_loss 43.273880,Time used 0.010997s\n",
      "batch 19177, train_loss 38.828938,Time used 0.013002s\n",
      "batch 19178, train_loss 30.198910,Time used 0.015000s\n",
      "batch 19179, train_loss 40.813671,Time used 0.014000s\n",
      "batch 19180, train_loss 48.455994,Time used 0.009996s\n",
      "batch 19181, train_loss 42.593178,Time used 0.010991s\n",
      "batch 19182, train_loss 39.682507,Time used 0.013999s\n",
      "batch 19183, train_loss 37.713684,Time used 0.014001s\n",
      "batch 19184, train_loss 37.523006,Time used 0.014999s\n",
      "batch 19185, train_loss 36.697289,Time used 0.015995s\n",
      "batch 19186, train_loss 40.573112,Time used 0.016004s\n",
      "batch 19187, train_loss 38.898613,Time used 0.013001s\n",
      "batch 19188, train_loss 41.052574,Time used 0.012995s\n",
      "batch 19189, train_loss 42.925053,Time used 0.013003s\n",
      "batch 19190, train_loss 38.048580,Time used 0.015001s\n",
      "batch 19191, train_loss 37.481304,Time used 0.014998s\n",
      "batch 19192, train_loss 37.166172,Time used 0.015001s\n",
      "batch 19193, train_loss 34.167740,Time used 0.012999s\n",
      "batch 19194, train_loss 39.659725,Time used 0.008002s\n",
      "batch 19195, train_loss 30.646341,Time used 0.011996s\n",
      "batch 19196, train_loss 41.020149,Time used 0.013002s\n",
      "batch 19197, train_loss 52.909565,Time used 0.010001s\n",
      "batch 19198, train_loss 27.804443,Time used 0.013000s\n",
      "batch 19199, train_loss 36.576946,Time used 0.019000s\n",
      "batch 19200, train_loss 40.162388,Time used 0.025002s\n",
      "***************************test_batch 19200, test_rmse_loss 7.260176,test_mae_loss 3.080995,test_mape_loss 51.350720,Time used 0.104996s\n",
      "batch 19201, train_loss 44.366364,Time used 0.020996s\n",
      "batch 19202, train_loss 33.161640,Time used 0.029001s\n",
      "batch 19203, train_loss 36.600861,Time used 0.018996s\n",
      "batch 19204, train_loss 40.125877,Time used 0.017999s\n",
      "batch 19205, train_loss 38.956882,Time used 0.016004s\n",
      "batch 19206, train_loss 45.328232,Time used 0.015998s\n",
      "batch 19207, train_loss 41.401493,Time used 0.022001s\n",
      "batch 19208, train_loss 43.157589,Time used 0.018996s\n",
      "batch 19209, train_loss 43.292755,Time used 0.023998s\n",
      "batch 19210, train_loss 34.846027,Time used 0.036003s\n",
      "batch 19211, train_loss 37.299973,Time used 0.023004s\n",
      "batch 19212, train_loss 35.376503,Time used 0.019001s\n",
      "batch 19213, train_loss 33.564388,Time used 0.028007s\n",
      "batch 19214, train_loss 40.066902,Time used 0.022988s\n",
      "batch 19215, train_loss 48.694733,Time used 0.018000s\n",
      "batch 19216, train_loss 38.929199,Time used 0.019001s\n",
      "batch 19217, train_loss 38.047665,Time used 0.029003s\n",
      "batch 19218, train_loss 39.126286,Time used 0.026008s\n",
      "batch 19219, train_loss 34.781376,Time used 0.020994s\n",
      "batch 19220, train_loss 40.618103,Time used 0.017001s\n",
      "batch 19221, train_loss 34.962242,Time used 0.014999s\n",
      "batch 19222, train_loss 35.173012,Time used 0.016003s\n",
      "batch 19223, train_loss 37.064629,Time used 0.018003s\n",
      "batch 19224, train_loss 35.433743,Time used 0.012995s\n",
      "batch 19225, train_loss 41.337627,Time used 0.016005s\n",
      "batch 19226, train_loss 39.668896,Time used 0.010987s\n",
      "batch 19227, train_loss 31.789526,Time used 0.015002s\n",
      "batch 19228, train_loss 39.987549,Time used 0.011003s\n",
      "batch 19229, train_loss 40.931076,Time used 0.019996s\n",
      "batch 19230, train_loss 42.089153,Time used 0.016001s\n",
      "batch 19231, train_loss 40.201923,Time used 0.016996s\n",
      "batch 19232, train_loss 36.452454,Time used 0.016004s\n",
      "batch 19233, train_loss 39.885948,Time used 0.014998s\n",
      "batch 19234, train_loss 30.744709,Time used 0.015002s\n",
      "batch 19235, train_loss 40.558968,Time used 0.016000s\n",
      "batch 19236, train_loss 40.548485,Time used 0.015003s\n",
      "batch 19237, train_loss 35.281036,Time used 0.015002s\n",
      "batch 19238, train_loss 40.743118,Time used 0.014993s\n",
      "batch 19239, train_loss 40.211178,Time used 0.020001s\n",
      "batch 19240, train_loss 28.241159,Time used 0.019996s\n",
      "batch 19241, train_loss 36.830585,Time used 0.017002s\n",
      "batch 19242, train_loss 44.094093,Time used 0.012012s\n",
      "batch 19243, train_loss 35.355789,Time used 0.014994s\n",
      "batch 19244, train_loss 35.469868,Time used 0.010994s\n",
      "batch 19245, train_loss 43.707993,Time used 0.013977s\n",
      "batch 19246, train_loss 52.421864,Time used 0.014004s\n",
      "batch 19247, train_loss 32.050186,Time used 0.010993s\n",
      "batch 19248, train_loss 40.591236,Time used 0.015007s\n",
      "batch 19249, train_loss 37.383728,Time used 0.014000s\n",
      "batch 19250, train_loss 41.402679,Time used 0.012995s\n",
      "batch 19251, train_loss 38.289429,Time used 0.014997s\n",
      "batch 19252, train_loss 35.511505,Time used 0.016000s\n",
      "batch 19253, train_loss 42.460274,Time used 0.016007s\n",
      "batch 19254, train_loss 32.854156,Time used 0.016003s\n",
      "batch 19255, train_loss 34.817944,Time used 0.019000s\n",
      "batch 19256, train_loss 31.745462,Time used 0.017000s\n",
      "batch 19257, train_loss 38.719601,Time used 0.013999s\n",
      "batch 19258, train_loss 40.085697,Time used 0.013999s\n",
      "batch 19259, train_loss 42.144859,Time used 0.010010s\n",
      "batch 19260, train_loss 45.878574,Time used 0.011998s\n",
      "batch 19261, train_loss 35.388721,Time used 0.011998s\n",
      "batch 19262, train_loss 37.206314,Time used 0.014002s\n",
      "batch 19263, train_loss 37.876110,Time used 0.009001s\n",
      "batch 19264, train_loss 42.876453,Time used 0.009997s\n",
      "batch 19265, train_loss 41.020836,Time used 0.011999s\n",
      "batch 19266, train_loss 34.661308,Time used 0.012005s\n",
      "batch 19267, train_loss 33.493210,Time used 0.008994s\n",
      "batch 19268, train_loss 48.722225,Time used 0.009005s\n",
      "batch 19269, train_loss 38.240147,Time used 0.008996s\n",
      "batch 19270, train_loss 40.520721,Time used 0.011000s\n",
      "batch 19271, train_loss 40.155556,Time used 0.007999s\n",
      "batch 19272, train_loss 36.387348,Time used 0.008001s\n",
      "batch 19273, train_loss 31.823574,Time used 0.007997s\n",
      "batch 19274, train_loss 35.175552,Time used 0.006999s\n",
      "batch 19275, train_loss 33.394230,Time used 0.008002s\n",
      "batch 19276, train_loss 38.280731,Time used 0.008000s\n",
      "batch 19277, train_loss 38.651615,Time used 0.008000s\n",
      "batch 19278, train_loss 28.940300,Time used 0.007000s\n",
      "batch 19279, train_loss 36.429466,Time used 0.009000s\n",
      "batch 19280, train_loss 37.799107,Time used 0.008000s\n",
      "batch 19281, train_loss 43.296734,Time used 0.010004s\n",
      "batch 19282, train_loss 38.205978,Time used 0.009000s\n",
      "batch 19283, train_loss 40.624058,Time used 0.009997s\n",
      "batch 19284, train_loss 44.509716,Time used 0.008998s\n",
      "batch 19285, train_loss 37.296665,Time used 0.008001s\n",
      "batch 19286, train_loss 35.327316,Time used 0.009004s\n",
      "batch 19287, train_loss 46.538425,Time used 0.008998s\n",
      "batch 19288, train_loss 33.684589,Time used 0.006999s\n",
      "batch 19289, train_loss 36.430088,Time used 0.008000s\n",
      "batch 19290, train_loss 41.681160,Time used 0.011002s\n",
      "batch 19291, train_loss 33.529598,Time used 0.006998s\n",
      "batch 19292, train_loss 37.415668,Time used 0.008000s\n",
      "batch 19293, train_loss 37.478992,Time used 0.011001s\n",
      "batch 19294, train_loss 54.166759,Time used 0.010998s\n",
      "batch 19295, train_loss 38.673054,Time used 0.011000s\n",
      "batch 19296, train_loss 47.650650,Time used 0.007999s\n",
      "batch 19297, train_loss 38.745090,Time used 0.007999s\n",
      "batch 19298, train_loss 45.199547,Time used 0.008003s\n",
      "batch 19299, train_loss 40.966618,Time used 0.009001s\n",
      "batch 19300, train_loss 34.841305,Time used 0.007998s\n",
      "***************************test_batch 19300, test_rmse_loss 7.236856,test_mae_loss 3.078459,test_mape_loss 51.601587,Time used 0.038002s\n",
      "batch 19301, train_loss 36.229588,Time used 0.008000s\n",
      "batch 19302, train_loss 36.361000,Time used 0.010998s\n",
      "batch 19303, train_loss 32.822311,Time used 0.010000s\n",
      "batch 19304, train_loss 38.957588,Time used 0.012000s\n",
      "batch 19305, train_loss 38.255665,Time used 0.010998s\n",
      "batch 19306, train_loss 43.758961,Time used 0.011001s\n",
      "batch 19307, train_loss 45.718952,Time used 0.010999s\n",
      "batch 19308, train_loss 41.158352,Time used 0.009001s\n",
      "batch 19309, train_loss 35.420971,Time used 0.008002s\n",
      "batch 19310, train_loss 41.596661,Time used 0.010998s\n",
      "batch 19311, train_loss 27.857435,Time used 0.011999s\n",
      "batch 19312, train_loss 36.672066,Time used 0.009000s\n",
      "batch 19313, train_loss 28.579920,Time used 0.010001s\n",
      "batch 19314, train_loss 43.359486,Time used 0.007002s\n",
      "batch 19315, train_loss 45.540985,Time used 0.007003s\n",
      "batch 19316, train_loss 37.941021,Time used 0.011003s\n",
      "batch 19317, train_loss 30.806715,Time used 0.009998s\n",
      "batch 19318, train_loss 48.960045,Time used 0.008003s\n",
      "batch 19319, train_loss 41.485439,Time used 0.011999s\n",
      "batch 19320, train_loss 34.054604,Time used 0.009000s\n",
      "batch 19321, train_loss 40.587006,Time used 0.010998s\n",
      "batch 19322, train_loss 40.321739,Time used 0.014998s\n",
      "batch 19323, train_loss 39.943539,Time used 0.014004s\n",
      "batch 19324, train_loss 27.334389,Time used 0.012998s\n",
      "batch 19325, train_loss 40.903606,Time used 0.012003s\n",
      "batch 19326, train_loss 43.078613,Time used 0.009000s\n",
      "batch 19327, train_loss 38.016308,Time used 0.012000s\n",
      "batch 19328, train_loss 30.785721,Time used 0.011998s\n",
      "batch 19329, train_loss 38.645729,Time used 0.012000s\n",
      "batch 19330, train_loss 43.047466,Time used 0.011999s\n",
      "batch 19331, train_loss 36.902954,Time used 0.012002s\n",
      "batch 19332, train_loss 30.368372,Time used 0.012000s\n",
      "batch 19333, train_loss 41.078121,Time used 0.010999s\n",
      "batch 19334, train_loss 35.345505,Time used 0.012001s\n",
      "batch 19335, train_loss 41.044876,Time used 0.010998s\n",
      "batch 19336, train_loss 40.430969,Time used 0.010002s\n",
      "batch 19337, train_loss 36.275372,Time used 0.011999s\n",
      "batch 19338, train_loss 42.257553,Time used 0.011999s\n",
      "batch 19339, train_loss 43.202274,Time used 0.011999s\n",
      "batch 19340, train_loss 46.146244,Time used 0.013000s\n",
      "batch 19341, train_loss 45.645573,Time used 0.009000s\n",
      "batch 19342, train_loss 33.514019,Time used 0.013000s\n",
      "batch 19343, train_loss 34.151756,Time used 0.016000s\n",
      "batch 19344, train_loss 34.867325,Time used 0.024000s\n",
      "batch 19345, train_loss 42.701733,Time used 0.012000s\n",
      "batch 19346, train_loss 38.233177,Time used 0.010999s\n",
      "batch 19347, train_loss 39.338821,Time used 0.012001s\n",
      "batch 19348, train_loss 33.594013,Time used 0.012000s\n",
      "batch 19349, train_loss 38.804314,Time used 0.013999s\n",
      "batch 19350, train_loss 46.125675,Time used 0.012000s\n",
      "batch 19351, train_loss 32.664127,Time used 0.013000s\n",
      "batch 19352, train_loss 40.193768,Time used 0.014001s\n",
      "batch 19353, train_loss 40.384472,Time used 0.016001s\n",
      "batch 19354, train_loss 37.446068,Time used 0.012998s\n",
      "batch 19355, train_loss 41.730259,Time used 0.012002s\n",
      "batch 19356, train_loss 38.528637,Time used 0.013998s\n",
      "batch 19357, train_loss 48.579041,Time used 0.012001s\n",
      "batch 19358, train_loss 38.770615,Time used 0.008998s\n",
      "batch 19359, train_loss 32.653118,Time used 0.007999s\n",
      "batch 19360, train_loss 40.009819,Time used 0.009001s\n",
      "batch 19361, train_loss 36.824661,Time used 0.007998s\n",
      "batch 19362, train_loss 32.848267,Time used 0.009000s\n",
      "batch 19363, train_loss 36.022736,Time used 0.011001s\n",
      "batch 19364, train_loss 35.306133,Time used 0.008999s\n",
      "batch 19365, train_loss 39.115444,Time used 0.010001s\n",
      "batch 19366, train_loss 28.595989,Time used 0.006999s\n",
      "batch 19367, train_loss 37.186150,Time used 0.011998s\n",
      "batch 19368, train_loss 47.989010,Time used 0.009003s\n",
      "batch 19369, train_loss 40.299412,Time used 0.009000s\n",
      "batch 19370, train_loss 32.441631,Time used 0.012000s\n",
      "batch 19371, train_loss 38.922421,Time used 0.012000s\n",
      "batch 19372, train_loss 37.022003,Time used 0.010001s\n",
      "batch 19373, train_loss 34.867912,Time used 0.008998s\n",
      "batch 19374, train_loss 34.238022,Time used 0.010002s\n",
      "batch 19375, train_loss 38.501266,Time used 0.009003s\n",
      "batch 19376, train_loss 38.213856,Time used 0.007998s\n",
      "batch 19377, train_loss 37.117386,Time used 0.010999s\n",
      "batch 19378, train_loss 47.310127,Time used 0.010997s\n",
      "batch 19379, train_loss 41.298523,Time used 0.010998s\n",
      "batch 19380, train_loss 34.976791,Time used 0.010001s\n",
      "batch 19381, train_loss 45.794556,Time used 0.008001s\n",
      "batch 19382, train_loss 37.345078,Time used 0.008001s\n",
      "batch 19383, train_loss 40.455650,Time used 0.010998s\n",
      "batch 19384, train_loss 40.700283,Time used 0.009001s\n",
      "batch 19385, train_loss 31.277378,Time used 0.007000s\n",
      "batch 19386, train_loss 31.511738,Time used 0.010001s\n",
      "batch 19387, train_loss 35.811817,Time used 0.010001s\n",
      "batch 19388, train_loss 33.466099,Time used 0.006999s\n",
      "batch 19389, train_loss 40.411549,Time used 0.008002s\n",
      "batch 19390, train_loss 41.368847,Time used 0.007998s\n",
      "batch 19391, train_loss 38.254459,Time used 0.008001s\n",
      "batch 19392, train_loss 50.953571,Time used 0.007998s\n",
      "batch 19393, train_loss 46.193836,Time used 0.008000s\n",
      "batch 19394, train_loss 36.008556,Time used 0.008000s\n",
      "batch 19395, train_loss 42.892193,Time used 0.010999s\n",
      "batch 19396, train_loss 43.117023,Time used 0.008000s\n",
      "batch 19397, train_loss 39.867313,Time used 0.007001s\n",
      "batch 19398, train_loss 39.704704,Time used 0.011999s\n",
      "batch 19399, train_loss 46.955563,Time used 0.009000s\n",
      "batch 19400, train_loss 33.801697,Time used 0.006999s\n",
      "***************************test_batch 19400, test_rmse_loss 7.225265,test_mae_loss 3.067774,test_mape_loss 51.169340,Time used 0.030997s\n",
      "batch 19401, train_loss 30.768385,Time used 0.011001s\n",
      "batch 19402, train_loss 38.903370,Time used 0.009002s\n",
      "batch 19403, train_loss 39.921139,Time used 0.010998s\n",
      "batch 19404, train_loss 37.041008,Time used 0.009001s\n",
      "batch 19405, train_loss 40.119217,Time used 0.008003s\n",
      "batch 19406, train_loss 44.190704,Time used 0.011997s\n",
      "batch 19407, train_loss 46.210552,Time used 0.012002s\n",
      "batch 19408, train_loss 30.446657,Time used 0.012000s\n",
      "batch 19409, train_loss 38.572971,Time used 0.007999s\n",
      "batch 19410, train_loss 38.292580,Time used 0.009002s\n",
      "batch 19411, train_loss 32.095383,Time used 0.011998s\n",
      "batch 19412, train_loss 32.833702,Time used 0.011002s\n",
      "batch 19413, train_loss 32.437084,Time used 0.011997s\n",
      "batch 19414, train_loss 33.171524,Time used 0.008000s\n",
      "batch 19415, train_loss 38.044136,Time used 0.011000s\n",
      "batch 19416, train_loss 39.048271,Time used 0.011000s\n",
      "batch 19417, train_loss 38.227634,Time used 0.011000s\n",
      "batch 19418, train_loss 41.657570,Time used 0.010000s\n",
      "batch 19419, train_loss 36.766396,Time used 0.008000s\n",
      "batch 19420, train_loss 35.985817,Time used 0.009999s\n",
      "batch 19421, train_loss 31.336033,Time used 0.010001s\n",
      "batch 19422, train_loss 43.835953,Time used 0.008001s\n",
      "batch 19423, train_loss 33.711418,Time used 0.009001s\n",
      "batch 19424, train_loss 33.333096,Time used 0.007999s\n",
      "batch 19425, train_loss 35.746677,Time used 0.010000s\n",
      "batch 19426, train_loss 40.847866,Time used 0.007000s\n",
      "batch 19427, train_loss 37.315216,Time used 0.007004s\n",
      "batch 19428, train_loss 38.679367,Time used 0.007998s\n",
      "batch 19429, train_loss 45.823689,Time used 0.009000s\n",
      "batch 19430, train_loss 49.627361,Time used 0.008000s\n",
      "batch 19431, train_loss 34.776440,Time used 0.010997s\n",
      "batch 19432, train_loss 31.580050,Time used 0.009004s\n",
      "batch 19433, train_loss 41.848816,Time used 0.011997s\n",
      "batch 19434, train_loss 38.357231,Time used 0.008000s\n",
      "batch 19435, train_loss 42.903572,Time used 0.008037s\n",
      "batch 19436, train_loss 40.765831,Time used 0.007001s\n",
      "batch 19437, train_loss 32.220341,Time used 0.010001s\n",
      "batch 19438, train_loss 38.733959,Time used 0.011037s\n",
      "batch 19439, train_loss 37.525284,Time used 0.006959s\n",
      "batch 19440, train_loss 37.624538,Time used 0.011000s\n",
      "batch 19441, train_loss 33.740215,Time used 0.009999s\n",
      "batch 19442, train_loss 33.207253,Time used 0.015000s\n",
      "batch 19443, train_loss 41.239262,Time used 0.013003s\n",
      "batch 19444, train_loss 37.003872,Time used 0.010998s\n",
      "batch 19445, train_loss 41.311798,Time used 0.013000s\n",
      "batch 19446, train_loss 38.994350,Time used 0.013000s\n",
      "batch 19447, train_loss 44.114510,Time used 0.012000s\n",
      "batch 19448, train_loss 36.259132,Time used 0.011004s\n",
      "batch 19449, train_loss 39.162605,Time used 0.013000s\n",
      "batch 19450, train_loss 37.106529,Time used 0.026996s\n",
      "batch 19451, train_loss 35.430233,Time used 0.013002s\n",
      "batch 19452, train_loss 41.638920,Time used 0.015001s\n",
      "batch 19453, train_loss 36.333008,Time used 0.012001s\n",
      "batch 19454, train_loss 44.415714,Time used 0.014001s\n",
      "batch 19455, train_loss 37.195488,Time used 0.013998s\n",
      "batch 19456, train_loss 30.038317,Time used 0.015001s\n",
      "batch 19457, train_loss 37.412079,Time used 0.011999s\n",
      "batch 19458, train_loss 39.418465,Time used 0.013001s\n",
      "batch 19459, train_loss 46.262814,Time used 0.013002s\n",
      "batch 19460, train_loss 39.729191,Time used 0.011000s\n",
      "batch 19461, train_loss 30.174610,Time used 0.015001s\n",
      "batch 19462, train_loss 43.109684,Time used 0.026999s\n",
      "batch 19463, train_loss 34.981064,Time used 0.012000s\n",
      "batch 19464, train_loss 40.107780,Time used 0.010001s\n",
      "batch 19465, train_loss 38.130802,Time used 0.012000s\n",
      "batch 19466, train_loss 37.678513,Time used 0.012000s\n",
      "batch 19467, train_loss 34.560879,Time used 0.011999s\n",
      "batch 19468, train_loss 44.230759,Time used 0.014001s\n",
      "batch 19469, train_loss 37.737061,Time used 0.014999s\n",
      "batch 19470, train_loss 44.490959,Time used 0.013000s\n",
      "batch 19471, train_loss 37.746849,Time used 0.012999s\n",
      "batch 19472, train_loss 34.372063,Time used 0.010999s\n",
      "batch 19473, train_loss 43.250996,Time used 0.012000s\n",
      "batch 19474, train_loss 32.625008,Time used 0.013004s\n",
      "batch 19475, train_loss 46.665226,Time used 0.011995s\n",
      "batch 19476, train_loss 38.613537,Time used 0.007999s\n",
      "batch 19477, train_loss 36.222893,Time used 0.009000s\n",
      "batch 19478, train_loss 44.031921,Time used 0.009001s\n",
      "batch 19479, train_loss 33.423325,Time used 0.011999s\n",
      "batch 19480, train_loss 36.425865,Time used 0.012001s\n",
      "batch 19481, train_loss 45.415138,Time used 0.008001s\n",
      "batch 19482, train_loss 46.649189,Time used 0.012001s\n",
      "batch 19483, train_loss 36.770630,Time used 0.009998s\n",
      "batch 19484, train_loss 33.841141,Time used 0.006998s\n",
      "batch 19485, train_loss 34.470726,Time used 0.008999s\n",
      "batch 19486, train_loss 32.725033,Time used 0.008003s\n",
      "batch 19487, train_loss 32.164093,Time used 0.008999s\n",
      "batch 19488, train_loss 34.700573,Time used 0.008003s\n",
      "batch 19489, train_loss 37.396301,Time used 0.007999s\n",
      "batch 19490, train_loss 38.965561,Time used 0.006999s\n",
      "batch 19491, train_loss 43.305504,Time used 0.010002s\n",
      "batch 19492, train_loss 36.996532,Time used 0.011996s\n",
      "batch 19493, train_loss 32.122200,Time used 0.010001s\n",
      "batch 19494, train_loss 47.686207,Time used 0.008001s\n",
      "batch 19495, train_loss 34.939865,Time used 0.008001s\n",
      "batch 19496, train_loss 33.585392,Time used 0.010999s\n",
      "batch 19497, train_loss 38.885017,Time used 0.012000s\n",
      "batch 19498, train_loss 35.214882,Time used 0.011000s\n",
      "batch 19499, train_loss 37.247215,Time used 0.009003s\n",
      "batch 19500, train_loss 40.627636,Time used 0.012996s\n",
      "***************************test_batch 19500, test_rmse_loss 7.204259,test_mae_loss 3.063757,test_mape_loss 51.303796,Time used 0.039037s\n",
      "batch 19501, train_loss 45.846169,Time used 0.007965s\n",
      "batch 19502, train_loss 41.524052,Time used 0.007999s\n",
      "batch 19503, train_loss 34.564095,Time used 0.009008s\n",
      "batch 19504, train_loss 36.262512,Time used 0.010996s\n",
      "batch 19505, train_loss 35.418324,Time used 0.009996s\n",
      "batch 19506, train_loss 31.018744,Time used 0.010000s\n",
      "batch 19507, train_loss 28.877052,Time used 0.011001s\n",
      "batch 19508, train_loss 34.628593,Time used 0.008999s\n",
      "batch 19509, train_loss 41.896446,Time used 0.007999s\n",
      "batch 19510, train_loss 42.949169,Time used 0.009000s\n",
      "batch 19511, train_loss 48.684055,Time used 0.007999s\n",
      "batch 19512, train_loss 37.157993,Time used 0.009000s\n",
      "batch 19513, train_loss 43.383610,Time used 0.008999s\n",
      "batch 19514, train_loss 37.604435,Time used 0.011005s\n",
      "batch 19515, train_loss 42.604122,Time used 0.008998s\n",
      "batch 19516, train_loss 31.256866,Time used 0.007998s\n",
      "batch 19517, train_loss 41.458916,Time used 0.008999s\n",
      "batch 19518, train_loss 31.615778,Time used 0.008000s\n",
      "batch 19519, train_loss 35.030651,Time used 0.011998s\n",
      "batch 19520, train_loss 38.413620,Time used 0.010002s\n",
      "batch 19521, train_loss 36.702171,Time used 0.008000s\n",
      "batch 19522, train_loss 31.691065,Time used 0.010998s\n",
      "batch 19523, train_loss 39.093315,Time used 0.010000s\n",
      "batch 19524, train_loss 43.374737,Time used 0.009000s\n",
      "batch 19525, train_loss 35.127579,Time used 0.011001s\n",
      "batch 19526, train_loss 32.425282,Time used 0.011998s\n",
      "batch 19527, train_loss 45.054188,Time used 0.011003s\n",
      "batch 19528, train_loss 43.459721,Time used 0.011999s\n",
      "batch 19529, train_loss 44.498730,Time used 0.008999s\n",
      "batch 19530, train_loss 36.843872,Time used 0.010000s\n",
      "batch 19531, train_loss 38.772377,Time used 0.008000s\n",
      "batch 19532, train_loss 35.569923,Time used 0.008000s\n",
      "batch 19533, train_loss 37.508919,Time used 0.010000s\n",
      "batch 19534, train_loss 35.955353,Time used 0.007999s\n",
      "batch 19535, train_loss 48.056915,Time used 0.006999s\n",
      "batch 19536, train_loss 29.159487,Time used 0.008000s\n",
      "batch 19537, train_loss 33.403633,Time used 0.011001s\n",
      "batch 19538, train_loss 48.723282,Time used 0.007999s\n",
      "batch 19539, train_loss 38.280857,Time used 0.010001s\n",
      "batch 19540, train_loss 34.005478,Time used 0.009001s\n",
      "batch 19541, train_loss 42.687752,Time used 0.008000s\n",
      "batch 19542, train_loss 33.103264,Time used 0.010998s\n",
      "batch 19543, train_loss 41.413628,Time used 0.009002s\n",
      "batch 19544, train_loss 40.316013,Time used 0.007999s\n",
      "batch 19545, train_loss 42.823956,Time used 0.009000s\n",
      "batch 19546, train_loss 43.866985,Time used 0.009004s\n",
      "batch 19547, train_loss 36.355755,Time used 0.007997s\n",
      "batch 19548, train_loss 34.389477,Time used 0.007002s\n",
      "batch 19549, train_loss 40.792381,Time used 0.011999s\n",
      "batch 19550, train_loss 30.861435,Time used 0.010000s\n",
      "batch 19551, train_loss 44.360481,Time used 0.008999s\n",
      "batch 19552, train_loss 35.006367,Time used 0.009003s\n",
      "batch 19553, train_loss 34.264835,Time used 0.013999s\n",
      "batch 19554, train_loss 36.192757,Time used 0.009998s\n",
      "batch 19555, train_loss 40.928921,Time used 0.012998s\n",
      "batch 19556, train_loss 36.919373,Time used 0.013008s\n",
      "batch 19557, train_loss 37.642254,Time used 0.012994s\n",
      "batch 19558, train_loss 36.953537,Time used 0.011999s\n",
      "batch 19559, train_loss 31.800282,Time used 0.009000s\n",
      "batch 19560, train_loss 38.452141,Time used 0.011003s\n",
      "batch 19561, train_loss 33.243847,Time used 0.011999s\n",
      "batch 19562, train_loss 38.280262,Time used 0.010998s\n",
      "batch 19563, train_loss 37.165337,Time used 0.012002s\n",
      "batch 19564, train_loss 44.555225,Time used 0.011002s\n",
      "batch 19565, train_loss 45.506920,Time used 0.012999s\n",
      "batch 19566, train_loss 35.210743,Time used 0.013002s\n",
      "batch 19567, train_loss 38.852840,Time used 0.012000s\n",
      "batch 19568, train_loss 38.413803,Time used 0.013000s\n",
      "batch 19569, train_loss 34.011471,Time used 0.012998s\n",
      "batch 19570, train_loss 37.743305,Time used 0.013003s\n",
      "batch 19571, train_loss 38.490410,Time used 0.012000s\n",
      "batch 19572, train_loss 35.817307,Time used 0.011999s\n",
      "batch 19573, train_loss 28.641432,Time used 0.015000s\n",
      "batch 19574, train_loss 38.519806,Time used 0.035003s\n",
      "batch 19575, train_loss 38.800632,Time used 0.023997s\n",
      "batch 19576, train_loss 47.042233,Time used 0.012001s\n",
      "batch 19577, train_loss 39.939980,Time used 0.012002s\n",
      "batch 19578, train_loss 30.513866,Time used 0.022997s\n",
      "batch 19579, train_loss 46.873096,Time used 0.015000s\n",
      "batch 19580, train_loss 34.340496,Time used 0.016002s\n",
      "batch 19581, train_loss 36.358772,Time used 0.014999s\n",
      "batch 19582, train_loss 35.346054,Time used 0.015999s\n",
      "batch 19583, train_loss 42.711658,Time used 0.017001s\n",
      "batch 19584, train_loss 35.810085,Time used 0.012001s\n",
      "batch 19585, train_loss 40.157745,Time used 0.016998s\n",
      "batch 19586, train_loss 31.554565,Time used 0.017000s\n",
      "batch 19587, train_loss 38.155212,Time used 0.015001s\n",
      "batch 19588, train_loss 40.294178,Time used 0.014998s\n",
      "batch 19589, train_loss 31.617111,Time used 0.012001s\n",
      "batch 19590, train_loss 44.168266,Time used 0.008000s\n",
      "batch 19591, train_loss 29.584244,Time used 0.011000s\n",
      "batch 19592, train_loss 42.969051,Time used 0.011999s\n",
      "batch 19593, train_loss 41.106487,Time used 0.011001s\n",
      "batch 19594, train_loss 41.731823,Time used 0.009000s\n",
      "batch 19595, train_loss 26.482294,Time used 0.009002s\n",
      "batch 19596, train_loss 40.864376,Time used 0.015997s\n",
      "batch 19597, train_loss 37.320347,Time used 0.009998s\n",
      "batch 19598, train_loss 40.392563,Time used 0.013001s\n",
      "batch 19599, train_loss 35.163597,Time used 0.013003s\n",
      "batch 19600, train_loss 36.932369,Time used 0.012001s\n",
      "***************************test_batch 19600, test_rmse_loss 7.191997,test_mae_loss 3.060195,test_mape_loss 51.324088,Time used 0.042999s\n",
      "batch 19601, train_loss 37.733475,Time used 0.009001s\n",
      "batch 19602, train_loss 34.419613,Time used 0.011000s\n",
      "batch 19603, train_loss 40.546982,Time used 0.010000s\n",
      "batch 19604, train_loss 50.637573,Time used 0.010001s\n",
      "batch 19605, train_loss 41.519646,Time used 0.013002s\n",
      "batch 19606, train_loss 37.695919,Time used 0.009999s\n",
      "batch 19607, train_loss 34.609623,Time used 0.012001s\n",
      "batch 19608, train_loss 35.485413,Time used 0.010998s\n",
      "batch 19609, train_loss 42.606373,Time used 0.010001s\n",
      "batch 19610, train_loss 35.083637,Time used 0.010001s\n",
      "batch 19611, train_loss 31.630407,Time used 0.012001s\n",
      "batch 19612, train_loss 44.194588,Time used 0.012000s\n",
      "batch 19613, train_loss 42.578693,Time used 0.009002s\n",
      "batch 19614, train_loss 34.689392,Time used 0.011000s\n",
      "batch 19615, train_loss 39.436119,Time used 0.008997s\n",
      "batch 19616, train_loss 49.700153,Time used 0.011001s\n",
      "batch 19617, train_loss 31.220425,Time used 0.010001s\n",
      "batch 19618, train_loss 33.550953,Time used 0.012000s\n",
      "batch 19619, train_loss 32.104824,Time used 0.014001s\n",
      "batch 19620, train_loss 36.901611,Time used 0.011000s\n",
      "batch 19621, train_loss 37.582542,Time used 0.008998s\n",
      "batch 19622, train_loss 33.800507,Time used 0.009000s\n",
      "batch 19623, train_loss 35.723980,Time used 0.009003s\n",
      "batch 19624, train_loss 36.598946,Time used 0.010999s\n",
      "batch 19625, train_loss 40.870079,Time used 0.011000s\n",
      "batch 19626, train_loss 40.528362,Time used 0.010004s\n",
      "batch 19627, train_loss 37.124413,Time used 0.011996s\n",
      "batch 19628, train_loss 38.902390,Time used 0.010000s\n",
      "batch 19629, train_loss 39.868698,Time used 0.009000s\n",
      "batch 19630, train_loss 42.223995,Time used 0.010999s\n",
      "batch 19631, train_loss 34.954391,Time used 0.010000s\n",
      "batch 19632, train_loss 38.337215,Time used 0.007999s\n",
      "batch 19633, train_loss 43.487587,Time used 0.012998s\n",
      "batch 19634, train_loss 36.940609,Time used 0.009000s\n",
      "batch 19635, train_loss 43.117992,Time used 0.009000s\n",
      "batch 19636, train_loss 41.659069,Time used 0.009000s\n",
      "batch 19637, train_loss 46.896778,Time used 0.009002s\n",
      "batch 19638, train_loss 39.247807,Time used 0.011999s\n",
      "batch 19639, train_loss 42.752678,Time used 0.008998s\n",
      "batch 19640, train_loss 40.002445,Time used 0.008002s\n",
      "batch 19641, train_loss 35.346043,Time used 0.010000s\n",
      "batch 19642, train_loss 34.313316,Time used 0.008000s\n",
      "batch 19643, train_loss 29.973322,Time used 0.007999s\n",
      "batch 19644, train_loss 29.555862,Time used 0.008000s\n",
      "batch 19645, train_loss 33.214691,Time used 0.007999s\n",
      "batch 19646, train_loss 37.248772,Time used 0.008001s\n",
      "batch 19647, train_loss 33.650486,Time used 0.007998s\n",
      "batch 19648, train_loss 40.880802,Time used 0.009003s\n",
      "batch 19649, train_loss 44.298775,Time used 0.009001s\n",
      "batch 19650, train_loss 40.323490,Time used 0.010999s\n",
      "batch 19651, train_loss 37.490444,Time used 0.007999s\n",
      "batch 19652, train_loss 30.967360,Time used 0.008000s\n",
      "batch 19653, train_loss 32.522659,Time used 0.008000s\n",
      "batch 19654, train_loss 39.847305,Time used 0.011000s\n",
      "batch 19655, train_loss 45.146908,Time used 0.011002s\n",
      "batch 19656, train_loss 29.610458,Time used 0.009998s\n",
      "batch 19657, train_loss 44.281708,Time used 0.010001s\n",
      "batch 19658, train_loss 35.524532,Time used 0.008998s\n",
      "batch 19659, train_loss 42.086449,Time used 0.014001s\n",
      "batch 19660, train_loss 30.491762,Time used 0.011996s\n",
      "batch 19661, train_loss 46.536697,Time used 0.010002s\n",
      "batch 19662, train_loss 36.901585,Time used 0.008002s\n",
      "batch 19663, train_loss 41.552105,Time used 0.007997s\n",
      "batch 19664, train_loss 32.292747,Time used 0.008003s\n",
      "batch 19665, train_loss 46.593262,Time used 0.012002s\n",
      "batch 19666, train_loss 37.847042,Time used 0.010998s\n",
      "batch 19667, train_loss 30.365377,Time used 0.006998s\n",
      "batch 19668, train_loss 33.978722,Time used 0.010005s\n",
      "batch 19669, train_loss 27.150173,Time used 0.010998s\n",
      "batch 19670, train_loss 35.773369,Time used 0.007001s\n",
      "batch 19671, train_loss 37.659878,Time used 0.008004s\n",
      "batch 19672, train_loss 32.069061,Time used 0.010999s\n",
      "batch 19673, train_loss 47.305908,Time used 0.008000s\n",
      "batch 19674, train_loss 34.181427,Time used 0.007003s\n",
      "batch 19675, train_loss 52.205254,Time used 0.008998s\n",
      "batch 19676, train_loss 38.347282,Time used 0.007997s\n",
      "batch 19677, train_loss 44.347412,Time used 0.008003s\n",
      "batch 19678, train_loss 36.881374,Time used 0.007999s\n",
      "batch 19679, train_loss 33.080364,Time used 0.012000s\n",
      "batch 19680, train_loss 30.188860,Time used 0.011998s\n",
      "batch 19681, train_loss 38.523315,Time used 0.009001s\n",
      "batch 19682, train_loss 44.527264,Time used 0.008003s\n",
      "batch 19683, train_loss 42.892937,Time used 0.008997s\n",
      "batch 19684, train_loss 32.025131,Time used 0.010000s\n",
      "batch 19685, train_loss 36.397228,Time used 0.010000s\n",
      "batch 19686, train_loss 36.728935,Time used 0.009999s\n",
      "batch 19687, train_loss 44.409843,Time used 0.007000s\n",
      "batch 19688, train_loss 40.957420,Time used 0.013003s\n",
      "batch 19689, train_loss 31.863970,Time used 0.009000s\n",
      "batch 19690, train_loss 26.223209,Time used 0.010997s\n",
      "batch 19691, train_loss 33.884766,Time used 0.010002s\n",
      "batch 19692, train_loss 41.292362,Time used 0.009000s\n",
      "batch 19693, train_loss 45.573277,Time used 0.009999s\n",
      "batch 19694, train_loss 35.695850,Time used 0.010000s\n",
      "batch 19695, train_loss 44.234432,Time used 0.011000s\n",
      "batch 19696, train_loss 34.954174,Time used 0.008999s\n",
      "batch 19697, train_loss 37.950920,Time used 0.009001s\n",
      "batch 19698, train_loss 42.466038,Time used 0.011001s\n",
      "batch 19699, train_loss 33.268036,Time used 0.011001s\n",
      "batch 19700, train_loss 42.656590,Time used 0.010996s\n",
      "***************************test_batch 19700, test_rmse_loss 7.169013,test_mae_loss 3.053559,test_mape_loss 51.212648,Time used 0.049003s\n",
      "batch 19701, train_loss 38.060734,Time used 0.011001s\n",
      "batch 19702, train_loss 32.868652,Time used 0.009999s\n",
      "batch 19703, train_loss 35.816231,Time used 0.009001s\n",
      "batch 19704, train_loss 33.232098,Time used 0.006999s\n",
      "batch 19705, train_loss 38.885403,Time used 0.008000s\n",
      "batch 19706, train_loss 30.737335,Time used 0.010000s\n",
      "batch 19707, train_loss 39.557373,Time used 0.011001s\n",
      "batch 19708, train_loss 40.877785,Time used 0.007999s\n",
      "batch 19709, train_loss 32.525833,Time used 0.008998s\n",
      "batch 19710, train_loss 27.947369,Time used 0.012001s\n",
      "batch 19711, train_loss 42.463131,Time used 0.009001s\n",
      "batch 19712, train_loss 40.320343,Time used 0.010001s\n",
      "batch 19713, train_loss 35.489819,Time used 0.011999s\n",
      "batch 19714, train_loss 32.607338,Time used 0.009000s\n",
      "batch 19715, train_loss 43.737225,Time used 0.008002s\n",
      "batch 19716, train_loss 37.520603,Time used 0.010998s\n",
      "batch 19717, train_loss 34.062469,Time used 0.011000s\n",
      "batch 19718, train_loss 34.542580,Time used 0.011999s\n",
      "batch 19719, train_loss 39.082249,Time used 0.012003s\n",
      "batch 19720, train_loss 49.922031,Time used 0.010000s\n",
      "batch 19721, train_loss 43.559807,Time used 0.008002s\n",
      "batch 19722, train_loss 37.909531,Time used 0.006999s\n",
      "batch 19723, train_loss 38.529011,Time used 0.007000s\n",
      "batch 19724, train_loss 35.248684,Time used 0.007998s\n",
      "batch 19725, train_loss 41.530540,Time used 0.008004s\n",
      "batch 19726, train_loss 37.262306,Time used 0.010997s\n",
      "batch 19727, train_loss 31.047239,Time used 0.010004s\n",
      "batch 19728, train_loss 40.183144,Time used 0.010998s\n",
      "batch 19729, train_loss 34.289246,Time used 0.007998s\n",
      "batch 19730, train_loss 32.339706,Time used 0.008001s\n",
      "batch 19731, train_loss 44.352695,Time used 0.010003s\n",
      "batch 19732, train_loss 36.738617,Time used 0.009001s\n",
      "batch 19733, train_loss 45.079742,Time used 0.011997s\n",
      "batch 19734, train_loss 25.830935,Time used 0.011001s\n",
      "batch 19735, train_loss 38.642136,Time used 0.011997s\n",
      "batch 19736, train_loss 39.014732,Time used 0.008000s\n",
      "batch 19737, train_loss 40.401623,Time used 0.010001s\n",
      "batch 19738, train_loss 40.908825,Time used 0.011004s\n",
      "batch 19739, train_loss 40.618187,Time used 0.010002s\n",
      "batch 19740, train_loss 42.979389,Time used 0.010001s\n",
      "batch 19741, train_loss 34.083321,Time used 0.007999s\n",
      "batch 19742, train_loss 33.474663,Time used 0.007998s\n",
      "batch 19743, train_loss 38.802063,Time used 0.009002s\n",
      "batch 19744, train_loss 38.581894,Time used 0.009999s\n",
      "batch 19745, train_loss 37.721561,Time used 0.008002s\n",
      "batch 19746, train_loss 40.304646,Time used 0.008999s\n",
      "batch 19747, train_loss 37.733837,Time used 0.008999s\n",
      "batch 19748, train_loss 35.805340,Time used 0.008001s\n",
      "batch 19749, train_loss 38.518852,Time used 0.009998s\n",
      "batch 19750, train_loss 36.534191,Time used 0.012001s\n",
      "batch 19751, train_loss 37.582298,Time used 0.011998s\n",
      "batch 19752, train_loss 34.151558,Time used 0.011000s\n",
      "batch 19753, train_loss 37.491947,Time used 0.011998s\n",
      "batch 19754, train_loss 27.293930,Time used 0.009002s\n",
      "batch 19755, train_loss 36.848690,Time used 0.009999s\n",
      "batch 19756, train_loss 37.607735,Time used 0.011999s\n",
      "batch 19757, train_loss 35.380161,Time used 0.012001s\n",
      "batch 19758, train_loss 32.035011,Time used 0.010999s\n",
      "batch 19759, train_loss 40.114864,Time used 0.008000s\n",
      "batch 19760, train_loss 43.405727,Time used 0.007000s\n",
      "batch 19761, train_loss 41.245399,Time used 0.007999s\n",
      "batch 19762, train_loss 40.309292,Time used 0.007001s\n",
      "batch 19763, train_loss 34.193237,Time used 0.010002s\n",
      "batch 19764, train_loss 36.804298,Time used 0.010999s\n",
      "batch 19765, train_loss 38.969967,Time used 0.009998s\n",
      "batch 19766, train_loss 40.240421,Time used 0.010002s\n",
      "batch 19767, train_loss 43.738060,Time used 0.011000s\n",
      "batch 19768, train_loss 28.790787,Time used 0.008003s\n",
      "batch 19769, train_loss 39.071594,Time used 0.007998s\n",
      "batch 19770, train_loss 43.321285,Time used 0.012000s\n",
      "batch 19771, train_loss 29.733660,Time used 0.008000s\n",
      "batch 19772, train_loss 40.508484,Time used 0.007999s\n",
      "batch 19773, train_loss 41.129768,Time used 0.007997s\n",
      "batch 19774, train_loss 30.651106,Time used 0.011003s\n",
      "batch 19775, train_loss 42.385784,Time used 0.007996s\n",
      "batch 19776, train_loss 42.374283,Time used 0.008004s\n",
      "batch 19777, train_loss 42.407681,Time used 0.008000s\n",
      "batch 19778, train_loss 33.138920,Time used 0.007999s\n",
      "batch 19779, train_loss 48.082298,Time used 0.010000s\n",
      "batch 19780, train_loss 31.183779,Time used 0.008001s\n",
      "batch 19781, train_loss 34.466557,Time used 0.007000s\n",
      "batch 19782, train_loss 34.690842,Time used 0.008002s\n",
      "batch 19783, train_loss 36.798496,Time used 0.008998s\n",
      "batch 19784, train_loss 46.062584,Time used 0.010002s\n",
      "batch 19785, train_loss 30.520147,Time used 0.007000s\n",
      "batch 19786, train_loss 41.474915,Time used 0.007999s\n",
      "batch 19787, train_loss 43.748520,Time used 0.012003s\n",
      "batch 19788, train_loss 31.159353,Time used 0.007998s\n",
      "batch 19789, train_loss 33.757122,Time used 0.008000s\n",
      "batch 19790, train_loss 37.243801,Time used 0.009001s\n",
      "batch 19791, train_loss 37.606800,Time used 0.010001s\n",
      "batch 19792, train_loss 35.745293,Time used 0.009000s\n",
      "batch 19793, train_loss 41.248337,Time used 0.009001s\n",
      "batch 19794, train_loss 39.470619,Time used 0.007001s\n",
      "batch 19795, train_loss 35.761551,Time used 0.009999s\n",
      "batch 19796, train_loss 35.613300,Time used 0.008000s\n",
      "batch 19797, train_loss 34.064587,Time used 0.010002s\n",
      "batch 19798, train_loss 38.433846,Time used 0.010001s\n",
      "batch 19799, train_loss 35.929752,Time used 0.010001s\n",
      "batch 19800, train_loss 43.980141,Time used 0.007001s\n",
      "***************************test_batch 19800, test_rmse_loss 7.160214,test_mae_loss 3.054571,test_mape_loss 51.335765,Time used 0.037999s\n",
      "batch 19801, train_loss 38.005493,Time used 0.008002s\n",
      "batch 19802, train_loss 39.329937,Time used 0.010004s\n",
      "batch 19803, train_loss 39.885841,Time used 0.007999s\n",
      "batch 19804, train_loss 29.557901,Time used 0.008999s\n",
      "batch 19805, train_loss 37.529079,Time used 0.008000s\n",
      "batch 19806, train_loss 43.230263,Time used 0.011001s\n",
      "batch 19807, train_loss 38.022961,Time used 0.011001s\n",
      "batch 19808, train_loss 39.830868,Time used 0.010007s\n",
      "batch 19809, train_loss 53.346272,Time used 0.008995s\n",
      "batch 19810, train_loss 32.226631,Time used 0.008000s\n",
      "batch 19811, train_loss 44.481289,Time used 0.007998s\n",
      "batch 19812, train_loss 34.543362,Time used 0.007999s\n",
      "batch 19813, train_loss 32.021969,Time used 0.011002s\n",
      "batch 19814, train_loss 42.548225,Time used 0.007998s\n",
      "batch 19815, train_loss 34.737232,Time used 0.008000s\n",
      "batch 19816, train_loss 37.180721,Time used 0.008002s\n",
      "batch 19817, train_loss 25.597958,Time used 0.008001s\n",
      "batch 19818, train_loss 35.933090,Time used 0.011999s\n",
      "batch 19819, train_loss 46.575233,Time used 0.008001s\n",
      "batch 19820, train_loss 36.981911,Time used 0.011002s\n",
      "batch 19821, train_loss 31.108284,Time used 0.011000s\n",
      "batch 19822, train_loss 41.519081,Time used 0.007999s\n",
      "batch 19823, train_loss 32.892750,Time used 0.007001s\n",
      "batch 19824, train_loss 34.126797,Time used 0.010998s\n",
      "batch 19825, train_loss 34.190193,Time used 0.010999s\n",
      "batch 19826, train_loss 34.126968,Time used 0.011999s\n",
      "batch 19827, train_loss 33.481510,Time used 0.011001s\n",
      "batch 19828, train_loss 34.576744,Time used 0.010001s\n",
      "batch 19829, train_loss 32.377640,Time used 0.012000s\n",
      "batch 19830, train_loss 41.802467,Time used 0.010998s\n",
      "batch 19831, train_loss 42.103401,Time used 0.010999s\n",
      "batch 19832, train_loss 44.255878,Time used 0.009000s\n",
      "batch 19833, train_loss 34.122597,Time used 0.012002s\n",
      "batch 19834, train_loss 37.689999,Time used 0.012999s\n",
      "batch 19835, train_loss 40.897511,Time used 0.012001s\n",
      "batch 19836, train_loss 33.866447,Time used 0.011998s\n",
      "batch 19837, train_loss 42.320572,Time used 0.012001s\n",
      "batch 19838, train_loss 35.468857,Time used 0.010000s\n",
      "batch 19839, train_loss 36.258949,Time used 0.009998s\n",
      "batch 19840, train_loss 41.386208,Time used 0.008002s\n",
      "batch 19841, train_loss 40.799515,Time used 0.011001s\n",
      "batch 19842, train_loss 43.864353,Time used 0.010000s\n",
      "batch 19843, train_loss 36.570904,Time used 0.008000s\n",
      "batch 19844, train_loss 33.308907,Time used 0.009002s\n",
      "batch 19845, train_loss 37.996407,Time used 0.012000s\n",
      "batch 19846, train_loss 36.063583,Time used 0.010000s\n",
      "batch 19847, train_loss 32.463326,Time used 0.011000s\n",
      "batch 19848, train_loss 40.237343,Time used 0.012998s\n",
      "batch 19849, train_loss 42.124462,Time used 0.011000s\n",
      "batch 19850, train_loss 37.628849,Time used 0.014000s\n",
      "batch 19851, train_loss 42.265545,Time used 0.012001s\n",
      "batch 19852, train_loss 40.721138,Time used 0.011002s\n",
      "batch 19853, train_loss 36.801281,Time used 0.012997s\n",
      "batch 19854, train_loss 33.405476,Time used 0.011001s\n",
      "batch 19855, train_loss 37.589458,Time used 0.011998s\n",
      "batch 19856, train_loss 36.434544,Time used 0.010999s\n",
      "batch 19857, train_loss 31.641764,Time used 0.012002s\n",
      "batch 19858, train_loss 38.221931,Time used 0.010998s\n",
      "batch 19859, train_loss 38.033916,Time used 0.011002s\n",
      "batch 19860, train_loss 41.933083,Time used 0.012000s\n",
      "batch 19861, train_loss 36.539303,Time used 0.011999s\n",
      "batch 19862, train_loss 47.803333,Time used 0.013001s\n",
      "batch 19863, train_loss 35.978313,Time used 0.011999s\n",
      "batch 19864, train_loss 33.302212,Time used 0.010999s\n",
      "batch 19865, train_loss 36.400120,Time used 0.010998s\n",
      "batch 19866, train_loss 36.102238,Time used 0.009999s\n",
      "batch 19867, train_loss 39.378952,Time used 0.012000s\n",
      "batch 19868, train_loss 39.920868,Time used 0.010001s\n",
      "batch 19869, train_loss 32.033127,Time used 0.012000s\n",
      "batch 19870, train_loss 32.475758,Time used 0.013000s\n",
      "batch 19871, train_loss 39.896523,Time used 0.013000s\n",
      "batch 19872, train_loss 32.251331,Time used 0.017002s\n",
      "batch 19873, train_loss 41.114841,Time used 0.011999s\n",
      "batch 19874, train_loss 44.962337,Time used 0.011002s\n",
      "batch 19875, train_loss 38.406017,Time used 0.013000s\n",
      "batch 19876, train_loss 39.139450,Time used 0.011000s\n",
      "batch 19877, train_loss 38.182316,Time used 0.010999s\n",
      "batch 19878, train_loss 44.975128,Time used 0.011997s\n",
      "batch 19879, train_loss 34.166039,Time used 0.012003s\n",
      "batch 19880, train_loss 33.480194,Time used 0.011997s\n",
      "batch 19881, train_loss 36.767857,Time used 0.012002s\n",
      "batch 19882, train_loss 32.944790,Time used 0.012998s\n",
      "batch 19883, train_loss 30.964386,Time used 0.012002s\n",
      "batch 19884, train_loss 37.579288,Time used 0.014997s\n",
      "batch 19885, train_loss 39.425781,Time used 0.012002s\n",
      "batch 19886, train_loss 32.473572,Time used 0.012999s\n",
      "batch 19887, train_loss 36.327019,Time used 0.008999s\n",
      "batch 19888, train_loss 29.261702,Time used 0.008001s\n",
      "batch 19889, train_loss 43.687702,Time used 0.009999s\n",
      "batch 19890, train_loss 32.580097,Time used 0.011003s\n",
      "batch 19891, train_loss 33.071640,Time used 0.010997s\n",
      "batch 19892, train_loss 40.385475,Time used 0.010002s\n",
      "batch 19893, train_loss 36.098629,Time used 0.008998s\n",
      "batch 19894, train_loss 38.893280,Time used 0.009001s\n",
      "batch 19895, train_loss 34.496655,Time used 0.009001s\n",
      "batch 19896, train_loss 48.753799,Time used 0.008999s\n",
      "batch 19897, train_loss 40.331444,Time used 0.012002s\n",
      "batch 19898, train_loss 48.722481,Time used 0.009001s\n",
      "batch 19899, train_loss 29.825958,Time used 0.011999s\n",
      "batch 19900, train_loss 41.764462,Time used 0.011001s\n",
      "***************************test_batch 19900, test_rmse_loss 7.134867,test_mae_loss 3.045849,test_mape_loss 51.167156,Time used 0.046999s\n",
      "batch 19901, train_loss 31.430319,Time used 0.010999s\n",
      "batch 19902, train_loss 36.971546,Time used 0.007999s\n",
      "batch 19903, train_loss 37.855381,Time used 0.008002s\n",
      "batch 19904, train_loss 36.435520,Time used 0.007003s\n",
      "batch 19905, train_loss 49.923134,Time used 0.006997s\n",
      "batch 19906, train_loss 44.056957,Time used 0.009999s\n",
      "batch 19907, train_loss 29.538702,Time used 0.008004s\n",
      "batch 19908, train_loss 32.389168,Time used 0.009997s\n",
      "batch 19909, train_loss 34.177967,Time used 0.007999s\n",
      "batch 19910, train_loss 36.532078,Time used 0.008003s\n",
      "batch 19911, train_loss 43.638660,Time used 0.007001s\n",
      "batch 19912, train_loss 39.497677,Time used 0.008961s\n",
      "batch 19913, train_loss 35.194798,Time used 0.006999s\n",
      "batch 19914, train_loss 45.273193,Time used 0.006998s\n",
      "batch 19915, train_loss 34.196102,Time used 0.009001s\n",
      "batch 19916, train_loss 30.351925,Time used 0.009005s\n",
      "batch 19917, train_loss 36.138168,Time used 0.007998s\n",
      "batch 19918, train_loss 35.929790,Time used 0.009998s\n",
      "batch 19919, train_loss 30.407631,Time used 0.008039s\n",
      "batch 19920, train_loss 36.296738,Time used 0.007962s\n",
      "batch 19921, train_loss 37.476650,Time used 0.010999s\n",
      "batch 19922, train_loss 38.164200,Time used 0.008002s\n",
      "batch 19923, train_loss 41.996883,Time used 0.007998s\n",
      "batch 19924, train_loss 35.350952,Time used 0.010000s\n",
      "batch 19925, train_loss 35.518608,Time used 0.008998s\n",
      "batch 19926, train_loss 35.193443,Time used 0.010001s\n",
      "batch 19927, train_loss 50.638241,Time used 0.012003s\n",
      "batch 19928, train_loss 39.196682,Time used 0.011001s\n",
      "batch 19929, train_loss 35.229637,Time used 0.011997s\n",
      "batch 19930, train_loss 37.710739,Time used 0.010001s\n",
      "batch 19931, train_loss 36.712082,Time used 0.013000s\n",
      "batch 19932, train_loss 33.608089,Time used 0.008998s\n",
      "batch 19933, train_loss 31.198351,Time used 0.007002s\n",
      "batch 19934, train_loss 41.985600,Time used 0.013999s\n",
      "batch 19935, train_loss 33.819912,Time used 0.012999s\n",
      "batch 19936, train_loss 33.668629,Time used 0.011003s\n",
      "batch 19937, train_loss 38.681599,Time used 0.009997s\n",
      "batch 19938, train_loss 39.786625,Time used 0.011002s\n",
      "batch 19939, train_loss 32.360992,Time used 0.010001s\n",
      "batch 19940, train_loss 31.457087,Time used 0.009000s\n",
      "batch 19941, train_loss 38.347050,Time used 0.009998s\n",
      "batch 19942, train_loss 43.676857,Time used 0.008002s\n",
      "batch 19943, train_loss 34.271206,Time used 0.007999s\n",
      "batch 19944, train_loss 39.715698,Time used 0.007999s\n",
      "batch 19945, train_loss 37.461525,Time used 0.008001s\n",
      "batch 19946, train_loss 39.880962,Time used 0.010000s\n",
      "batch 19947, train_loss 28.689299,Time used 0.009003s\n",
      "batch 19948, train_loss 32.057892,Time used 0.011996s\n",
      "batch 19949, train_loss 37.975990,Time used 0.009005s\n",
      "batch 19950, train_loss 39.896217,Time used 0.007997s\n",
      "batch 19951, train_loss 35.779705,Time used 0.008043s\n",
      "batch 19952, train_loss 34.385448,Time used 0.008956s\n",
      "batch 19953, train_loss 32.672188,Time used 0.007999s\n",
      "batch 19954, train_loss 37.498516,Time used 0.010009s\n",
      "batch 19955, train_loss 44.575150,Time used 0.007992s\n",
      "batch 19956, train_loss 42.920464,Time used 0.008001s\n",
      "batch 19957, train_loss 43.421413,Time used 0.007999s\n",
      "batch 19958, train_loss 44.356285,Time used 0.009000s\n",
      "batch 19959, train_loss 36.165150,Time used 0.013000s\n",
      "batch 19960, train_loss 43.024101,Time used 0.011000s\n",
      "batch 19961, train_loss 31.285469,Time used 0.011999s\n",
      "batch 19962, train_loss 33.177399,Time used 0.012000s\n",
      "batch 19963, train_loss 43.790062,Time used 0.011002s\n",
      "batch 19964, train_loss 23.685902,Time used 0.008999s\n",
      "batch 19965, train_loss 37.743904,Time used 0.012000s\n",
      "batch 19966, train_loss 35.540787,Time used 0.012003s\n",
      "batch 19967, train_loss 42.937752,Time used 0.012002s\n",
      "batch 19968, train_loss 35.537537,Time used 0.013001s\n",
      "batch 19969, train_loss 38.081509,Time used 0.010999s\n",
      "batch 19970, train_loss 47.009129,Time used 0.011002s\n",
      "batch 19971, train_loss 37.508018,Time used 0.012001s\n",
      "batch 19972, train_loss 32.867146,Time used 0.011998s\n",
      "batch 19973, train_loss 38.542038,Time used 0.012003s\n",
      "batch 19974, train_loss 36.344883,Time used 0.009999s\n",
      "batch 19975, train_loss 45.289829,Time used 0.013002s\n",
      "batch 19976, train_loss 35.052868,Time used 0.011997s\n",
      "batch 19977, train_loss 30.367485,Time used 0.012000s\n",
      "batch 19978, train_loss 41.661926,Time used 0.012001s\n",
      "batch 19979, train_loss 46.105057,Time used 0.012000s\n",
      "batch 19980, train_loss 30.017073,Time used 0.015000s\n",
      "batch 19981, train_loss 32.045437,Time used 0.022001s\n",
      "batch 19982, train_loss 37.179092,Time used 0.014999s\n",
      "batch 19983, train_loss 42.033314,Time used 0.013000s\n",
      "batch 19984, train_loss 47.366798,Time used 0.010000s\n",
      "batch 19985, train_loss 27.570681,Time used 0.011002s\n",
      "batch 19986, train_loss 35.660755,Time used 0.012001s\n",
      "batch 19987, train_loss 35.522095,Time used 0.011998s\n",
      "batch 19988, train_loss 32.996231,Time used 0.013001s\n",
      "batch 19989, train_loss 37.149590,Time used 0.010999s\n",
      "batch 19990, train_loss 39.767113,Time used 0.011999s\n",
      "batch 19991, train_loss 32.308960,Time used 0.013003s\n",
      "batch 19992, train_loss 35.126488,Time used 0.011999s\n",
      "batch 19993, train_loss 40.532738,Time used 0.011000s\n",
      "batch 19994, train_loss 29.464130,Time used 0.013000s\n",
      "batch 19995, train_loss 32.470692,Time used 0.009001s\n",
      "batch 19996, train_loss 42.429165,Time used 0.008999s\n",
      "batch 19997, train_loss 42.285793,Time used 0.008000s\n",
      "batch 19998, train_loss 38.597095,Time used 0.009003s\n",
      "batch 19999, train_loss 39.012379,Time used 0.009999s\n",
      "batch 20000, train_loss 42.763763,Time used 0.010000s\n",
      "***************************test_batch 20000, test_rmse_loss 7.129457,test_mae_loss 3.047051,test_mape_loss 51.382923,Time used 0.033998s\n",
      "batch 20001, train_loss 40.093018,Time used 0.008002s\n",
      "batch 20002, train_loss 35.895206,Time used 0.008035s\n",
      "batch 20003, train_loss 39.151279,Time used 0.007964s\n",
      "batch 20004, train_loss 31.084152,Time used 0.012007s\n",
      "batch 20005, train_loss 29.457279,Time used 0.008994s\n",
      "batch 20006, train_loss 32.874660,Time used 0.010002s\n",
      "batch 20007, train_loss 36.202198,Time used 0.008997s\n",
      "batch 20008, train_loss 33.828297,Time used 0.009002s\n",
      "batch 20009, train_loss 32.957462,Time used 0.009000s\n",
      "batch 20010, train_loss 38.821377,Time used 0.007999s\n",
      "batch 20011, train_loss 39.230656,Time used 0.012000s\n",
      "batch 20012, train_loss 40.415867,Time used 0.008000s\n",
      "batch 20013, train_loss 36.354393,Time used 0.006999s\n",
      "batch 20014, train_loss 41.629166,Time used 0.006998s\n",
      "batch 20015, train_loss 40.429096,Time used 0.008003s\n",
      "batch 20016, train_loss 36.564957,Time used 0.006999s\n",
      "batch 20017, train_loss 28.037134,Time used 0.009998s\n",
      "batch 20018, train_loss 35.951080,Time used 0.013001s\n",
      "batch 20019, train_loss 35.298389,Time used 0.012000s\n",
      "batch 20020, train_loss 38.921165,Time used 0.013000s\n",
      "batch 20021, train_loss 46.403278,Time used 0.010997s\n",
      "batch 20022, train_loss 37.377220,Time used 0.009002s\n",
      "batch 20023, train_loss 35.982700,Time used 0.006999s\n",
      "batch 20024, train_loss 36.987034,Time used 0.010997s\n",
      "batch 20025, train_loss 37.401981,Time used 0.010002s\n",
      "batch 20026, train_loss 34.186317,Time used 0.008999s\n",
      "batch 20027, train_loss 30.297871,Time used 0.009999s\n",
      "batch 20028, train_loss 40.217648,Time used 0.008000s\n",
      "batch 20029, train_loss 32.414238,Time used 0.009001s\n",
      "batch 20030, train_loss 38.487328,Time used 0.011999s\n",
      "batch 20031, train_loss 35.537498,Time used 0.012000s\n",
      "batch 20032, train_loss 28.882383,Time used 0.011998s\n",
      "batch 20033, train_loss 38.649181,Time used 0.009001s\n",
      "batch 20034, train_loss 39.904934,Time used 0.007999s\n",
      "batch 20035, train_loss 47.641273,Time used 0.010999s\n",
      "batch 20036, train_loss 40.176315,Time used 0.011001s\n",
      "batch 20037, train_loss 44.730671,Time used 0.009000s\n",
      "batch 20038, train_loss 31.462601,Time used 0.011000s\n",
      "batch 20039, train_loss 37.343861,Time used 0.008999s\n",
      "batch 20040, train_loss 39.239700,Time used 0.010000s\n",
      "batch 20041, train_loss 25.827707,Time used 0.009998s\n",
      "batch 20042, train_loss 43.053459,Time used 0.008000s\n",
      "batch 20043, train_loss 37.237953,Time used 0.008000s\n",
      "batch 20044, train_loss 31.006088,Time used 0.008000s\n",
      "batch 20045, train_loss 32.891819,Time used 0.011000s\n",
      "batch 20046, train_loss 32.173176,Time used 0.009001s\n",
      "batch 20047, train_loss 36.826038,Time used 0.007997s\n",
      "batch 20048, train_loss 34.342258,Time used 0.008001s\n",
      "batch 20049, train_loss 40.476627,Time used 0.011000s\n",
      "batch 20050, train_loss 44.708843,Time used 0.010999s\n",
      "batch 20051, train_loss 30.794800,Time used 0.011000s\n",
      "batch 20052, train_loss 39.314568,Time used 0.007999s\n",
      "batch 20053, train_loss 38.198444,Time used 0.008005s\n",
      "batch 20054, train_loss 43.179531,Time used 0.007997s\n",
      "batch 20055, train_loss 39.656754,Time used 0.010001s\n",
      "batch 20056, train_loss 30.651365,Time used 0.010999s\n",
      "batch 20057, train_loss 35.723461,Time used 0.008000s\n",
      "batch 20058, train_loss 38.935463,Time used 0.009000s\n",
      "batch 20059, train_loss 31.626963,Time used 0.010998s\n",
      "batch 20060, train_loss 42.478912,Time used 0.009002s\n",
      "batch 20061, train_loss 32.569172,Time used 0.008001s\n",
      "batch 20062, train_loss 45.772804,Time used 0.010999s\n",
      "batch 20063, train_loss 41.841553,Time used 0.009001s\n",
      "batch 20064, train_loss 41.112926,Time used 0.009001s\n",
      "batch 20065, train_loss 34.965435,Time used 0.007999s\n",
      "batch 20066, train_loss 36.713245,Time used 0.011000s\n",
      "batch 20067, train_loss 29.464479,Time used 0.011999s\n",
      "batch 20068, train_loss 38.540955,Time used 0.008000s\n",
      "batch 20069, train_loss 40.672405,Time used 0.010004s\n",
      "batch 20070, train_loss 34.205486,Time used 0.007996s\n",
      "batch 20071, train_loss 44.306255,Time used 0.009036s\n",
      "batch 20072, train_loss 34.387817,Time used 0.008965s\n",
      "batch 20073, train_loss 44.755829,Time used 0.011002s\n",
      "batch 20074, train_loss 29.821087,Time used 0.012000s\n",
      "batch 20075, train_loss 34.843502,Time used 0.008999s\n",
      "batch 20076, train_loss 43.162766,Time used 0.011001s\n",
      "batch 20077, train_loss 36.329872,Time used 0.010999s\n",
      "batch 20078, train_loss 32.928883,Time used 0.011006s\n",
      "batch 20079, train_loss 35.523090,Time used 0.011998s\n",
      "batch 20080, train_loss 39.044544,Time used 0.011998s\n",
      "batch 20081, train_loss 40.208710,Time used 0.011998s\n",
      "batch 20082, train_loss 34.538647,Time used 0.012002s\n",
      "batch 20083, train_loss 28.980547,Time used 0.011002s\n",
      "batch 20084, train_loss 48.883335,Time used 0.011001s\n",
      "batch 20085, train_loss 34.805637,Time used 0.010999s\n",
      "batch 20086, train_loss 29.368938,Time used 0.013000s\n",
      "batch 20087, train_loss 46.065163,Time used 0.012002s\n",
      "batch 20088, train_loss 36.730194,Time used 0.011995s\n",
      "batch 20089, train_loss 35.326950,Time used 0.011999s\n",
      "batch 20090, train_loss 40.005566,Time used 0.011001s\n",
      "batch 20091, train_loss 31.764540,Time used 0.013000s\n",
      "batch 20092, train_loss 35.849094,Time used 0.012999s\n",
      "batch 20093, train_loss 38.340874,Time used 0.011000s\n",
      "batch 20094, train_loss 38.857574,Time used 0.009001s\n",
      "batch 20095, train_loss 37.575737,Time used 0.015002s\n",
      "batch 20096, train_loss 36.513378,Time used 0.013997s\n",
      "batch 20097, train_loss 37.245983,Time used 0.022000s\n",
      "batch 20098, train_loss 30.652225,Time used 0.012998s\n",
      "batch 20099, train_loss 36.629665,Time used 0.010999s\n",
      "batch 20100, train_loss 29.852734,Time used 0.012002s\n",
      "***************************test_batch 20100, test_rmse_loss 7.113887,test_mae_loss 3.036089,test_mape_loss 50.902126,Time used 0.043999s\n",
      "batch 20101, train_loss 41.433620,Time used 0.014000s\n",
      "batch 20102, train_loss 35.818386,Time used 0.011002s\n",
      "batch 20103, train_loss 38.009521,Time used 0.014000s\n",
      "batch 20104, train_loss 39.397972,Time used 0.019003s\n",
      "batch 20105, train_loss 32.562656,Time used 0.010000s\n",
      "batch 20106, train_loss 38.307350,Time used 0.010998s\n",
      "batch 20107, train_loss 44.144215,Time used 0.012001s\n",
      "batch 20108, train_loss 36.188656,Time used 0.011001s\n",
      "batch 20109, train_loss 47.394047,Time used 0.010001s\n",
      "batch 20110, train_loss 35.609058,Time used 0.013000s\n",
      "batch 20111, train_loss 37.176788,Time used 0.007999s\n",
      "batch 20112, train_loss 33.335300,Time used 0.008999s\n",
      "batch 20113, train_loss 32.643406,Time used 0.010996s\n",
      "batch 20114, train_loss 37.671131,Time used 0.008007s\n",
      "batch 20115, train_loss 41.791737,Time used 0.007995s\n",
      "batch 20116, train_loss 37.041462,Time used 0.008002s\n",
      "batch 20117, train_loss 36.910889,Time used 0.007998s\n",
      "batch 20118, train_loss 41.747066,Time used 0.012001s\n",
      "batch 20119, train_loss 29.807997,Time used 0.007999s\n",
      "batch 20120, train_loss 43.176804,Time used 0.010998s\n",
      "batch 20121, train_loss 37.026058,Time used 0.011001s\n",
      "batch 20122, train_loss 32.600399,Time used 0.008001s\n",
      "batch 20123, train_loss 34.415516,Time used 0.010999s\n",
      "batch 20124, train_loss 38.198830,Time used 0.008999s\n",
      "batch 20125, train_loss 36.889828,Time used 0.007000s\n",
      "batch 20126, train_loss 34.420040,Time used 0.010002s\n",
      "batch 20127, train_loss 35.755627,Time used 0.011996s\n",
      "batch 20128, train_loss 37.027790,Time used 0.007999s\n",
      "batch 20129, train_loss 44.281219,Time used 0.012000s\n",
      "batch 20130, train_loss 30.878029,Time used 0.011001s\n",
      "batch 20131, train_loss 30.327133,Time used 0.011000s\n",
      "batch 20132, train_loss 41.677433,Time used 0.011002s\n",
      "batch 20133, train_loss 32.886181,Time used 0.010000s\n",
      "batch 20134, train_loss 38.911182,Time used 0.008000s\n",
      "batch 20135, train_loss 40.731190,Time used 0.008998s\n",
      "batch 20136, train_loss 40.142738,Time used 0.009000s\n",
      "batch 20137, train_loss 33.083965,Time used 0.008000s\n",
      "batch 20138, train_loss 28.476570,Time used 0.007999s\n",
      "batch 20139, train_loss 43.649334,Time used 0.020001s\n",
      "batch 20140, train_loss 39.178009,Time used 0.009000s\n",
      "batch 20141, train_loss 43.198071,Time used 0.007000s\n",
      "batch 20142, train_loss 34.212162,Time used 0.008997s\n",
      "batch 20143, train_loss 40.627926,Time used 0.008004s\n",
      "batch 20144, train_loss 36.199421,Time used 0.008997s\n",
      "batch 20145, train_loss 30.273035,Time used 0.010000s\n",
      "batch 20146, train_loss 41.832993,Time used 0.007003s\n",
      "batch 20147, train_loss 34.777622,Time used 0.008998s\n",
      "batch 20148, train_loss 30.972511,Time used 0.008004s\n",
      "batch 20149, train_loss 39.118446,Time used 0.011000s\n",
      "batch 20150, train_loss 34.212486,Time used 0.007997s\n",
      "batch 20151, train_loss 36.691612,Time used 0.007999s\n",
      "batch 20152, train_loss 39.511082,Time used 0.009001s\n",
      "batch 20153, train_loss 42.170105,Time used 0.008000s\n",
      "batch 20154, train_loss 37.282528,Time used 0.010000s\n",
      "batch 20155, train_loss 32.810207,Time used 0.008000s\n",
      "batch 20156, train_loss 37.995045,Time used 0.011001s\n",
      "batch 20157, train_loss 40.459049,Time used 0.010999s\n",
      "batch 20158, train_loss 35.758209,Time used 0.007999s\n",
      "batch 20159, train_loss 36.046413,Time used 0.010000s\n",
      "batch 20160, train_loss 37.402008,Time used 0.009001s\n",
      "batch 20161, train_loss 30.117104,Time used 0.010997s\n",
      "batch 20162, train_loss 31.756918,Time used 0.009004s\n",
      "batch 20163, train_loss 37.121010,Time used 0.010998s\n",
      "batch 20164, train_loss 33.327045,Time used 0.009002s\n",
      "batch 20165, train_loss 36.398472,Time used 0.007998s\n",
      "batch 20166, train_loss 47.311180,Time used 0.010000s\n",
      "batch 20167, train_loss 36.605999,Time used 0.007001s\n",
      "batch 20168, train_loss 33.342159,Time used 0.008999s\n",
      "batch 20169, train_loss 36.167854,Time used 0.007000s\n",
      "batch 20170, train_loss 40.440006,Time used 0.009000s\n",
      "batch 20171, train_loss 34.227192,Time used 0.009002s\n",
      "batch 20172, train_loss 39.684357,Time used 0.011997s\n",
      "batch 20173, train_loss 38.970802,Time used 0.007999s\n",
      "batch 20174, train_loss 43.290844,Time used 0.011002s\n",
      "batch 20175, train_loss 36.705925,Time used 0.011006s\n",
      "batch 20176, train_loss 34.493748,Time used 0.008995s\n",
      "batch 20177, train_loss 36.175751,Time used 0.007998s\n",
      "batch 20178, train_loss 42.740051,Time used 0.008002s\n",
      "batch 20179, train_loss 32.185272,Time used 0.007998s\n",
      "batch 20180, train_loss 37.143295,Time used 0.009002s\n",
      "batch 20181, train_loss 34.076218,Time used 0.006997s\n",
      "batch 20182, train_loss 33.644188,Time used 0.011000s\n",
      "batch 20183, train_loss 44.346218,Time used 0.009001s\n",
      "batch 20184, train_loss 34.485428,Time used 0.008003s\n",
      "batch 20185, train_loss 42.328403,Time used 0.009999s\n",
      "batch 20186, train_loss 41.702839,Time used 0.013001s\n",
      "batch 20187, train_loss 38.161522,Time used 0.010999s\n",
      "batch 20188, train_loss 36.011425,Time used 0.011003s\n",
      "batch 20189, train_loss 36.560787,Time used 0.007999s\n",
      "batch 20190, train_loss 39.419941,Time used 0.011998s\n",
      "batch 20191, train_loss 33.501316,Time used 0.012002s\n",
      "batch 20192, train_loss 38.308674,Time used 0.011998s\n",
      "batch 20193, train_loss 33.772209,Time used 0.010005s\n",
      "batch 20194, train_loss 30.868843,Time used 0.012996s\n",
      "batch 20195, train_loss 36.822598,Time used 0.013002s\n",
      "batch 20196, train_loss 31.423828,Time used 0.013000s\n",
      "batch 20197, train_loss 36.877621,Time used 0.011998s\n",
      "batch 20198, train_loss 35.473209,Time used 0.013001s\n",
      "batch 20199, train_loss 42.590466,Time used 0.013001s\n",
      "batch 20200, train_loss 40.444912,Time used 0.018001s\n",
      "***************************test_batch 20200, test_rmse_loss 7.092962,test_mae_loss 3.029386,test_mape_loss 50.888438,Time used 0.047999s\n",
      "batch 20201, train_loss 31.251860,Time used 0.009001s\n",
      "batch 20202, train_loss 37.166218,Time used 0.012000s\n",
      "batch 20203, train_loss 31.796570,Time used 0.017001s\n",
      "batch 20204, train_loss 37.853271,Time used 0.017000s\n",
      "batch 20205, train_loss 40.021965,Time used 0.016998s\n",
      "batch 20206, train_loss 39.385448,Time used 0.012000s\n",
      "batch 20207, train_loss 32.736992,Time used 0.010999s\n",
      "batch 20208, train_loss 39.310535,Time used 0.011998s\n",
      "batch 20209, train_loss 34.760071,Time used 0.013999s\n",
      "batch 20210, train_loss 34.815807,Time used 0.010999s\n",
      "batch 20211, train_loss 35.410610,Time used 0.011006s\n",
      "batch 20212, train_loss 43.638645,Time used 0.012995s\n",
      "batch 20213, train_loss 37.362728,Time used 0.013001s\n",
      "batch 20214, train_loss 37.504299,Time used 0.011999s\n",
      "batch 20215, train_loss 38.971458,Time used 0.010999s\n",
      "batch 20216, train_loss 42.491283,Time used 0.013000s\n",
      "batch 20217, train_loss 34.185497,Time used 0.014002s\n",
      "batch 20218, train_loss 31.151920,Time used 0.011998s\n",
      "batch 20219, train_loss 38.199215,Time used 0.010000s\n",
      "batch 20220, train_loss 35.733418,Time used 0.012998s\n",
      "batch 20221, train_loss 43.080254,Time used 0.012000s\n",
      "batch 20222, train_loss 37.756699,Time used 0.011997s\n",
      "batch 20223, train_loss 36.385380,Time used 0.008001s\n",
      "batch 20224, train_loss 38.402184,Time used 0.010998s\n",
      "batch 20225, train_loss 30.886116,Time used 0.012002s\n",
      "batch 20226, train_loss 33.344238,Time used 0.012001s\n",
      "batch 20227, train_loss 34.732033,Time used 0.007998s\n",
      "batch 20228, train_loss 40.846760,Time used 0.009000s\n",
      "batch 20229, train_loss 41.130394,Time used 0.011000s\n",
      "batch 20230, train_loss 37.219845,Time used 0.012001s\n",
      "batch 20231, train_loss 28.402916,Time used 0.009999s\n",
      "batch 20232, train_loss 36.519299,Time used 0.009002s\n",
      "batch 20233, train_loss 35.427692,Time used 0.008998s\n",
      "batch 20234, train_loss 24.602823,Time used 0.008001s\n",
      "batch 20235, train_loss 34.573460,Time used 0.009999s\n",
      "batch 20236, train_loss 40.942532,Time used 0.010001s\n",
      "batch 20237, train_loss 32.832069,Time used 0.011998s\n",
      "batch 20238, train_loss 38.798061,Time used 0.008001s\n",
      "batch 20239, train_loss 57.659054,Time used 0.008001s\n",
      "batch 20240, train_loss 31.740976,Time used 0.009005s\n",
      "batch 20241, train_loss 31.030056,Time used 0.011996s\n",
      "batch 20242, train_loss 37.787495,Time used 0.011000s\n",
      "batch 20243, train_loss 36.560467,Time used 0.010995s\n",
      "batch 20244, train_loss 33.940105,Time used 0.011005s\n",
      "batch 20245, train_loss 31.519413,Time used 0.011995s\n",
      "batch 20246, train_loss 36.426594,Time used 0.009005s\n",
      "batch 20247, train_loss 46.738010,Time used 0.008996s\n",
      "batch 20248, train_loss 38.868793,Time used 0.011000s\n",
      "batch 20249, train_loss 41.200886,Time used 0.011000s\n",
      "batch 20250, train_loss 41.325676,Time used 0.007516s\n",
      "batch 20251, train_loss 42.816837,Time used 0.010999s\n",
      "batch 20252, train_loss 28.944548,Time used 0.008001s\n",
      "batch 20253, train_loss 34.217049,Time used 0.007999s\n",
      "batch 20254, train_loss 34.470348,Time used 0.008998s\n",
      "batch 20255, train_loss 34.612823,Time used 0.009001s\n",
      "batch 20256, train_loss 35.210430,Time used 0.010001s\n",
      "batch 20257, train_loss 38.218243,Time used 0.011998s\n",
      "batch 20258, train_loss 38.216335,Time used 0.008004s\n",
      "batch 20259, train_loss 28.353706,Time used 0.008998s\n",
      "batch 20260, train_loss 35.137932,Time used 0.011000s\n",
      "batch 20261, train_loss 45.202213,Time used 0.007999s\n",
      "batch 20262, train_loss 34.148247,Time used 0.008003s\n",
      "batch 20263, train_loss 35.346973,Time used 0.009000s\n",
      "batch 20264, train_loss 41.715191,Time used 0.008999s\n",
      "batch 20265, train_loss 38.559223,Time used 0.009009s\n",
      "batch 20266, train_loss 30.630392,Time used 0.010992s\n",
      "batch 20267, train_loss 39.559975,Time used 0.007999s\n",
      "batch 20268, train_loss 40.557327,Time used 0.010001s\n",
      "batch 20269, train_loss 35.027897,Time used 0.009000s\n",
      "batch 20270, train_loss 39.077812,Time used 0.007998s\n",
      "batch 20271, train_loss 38.382793,Time used 0.008001s\n",
      "batch 20272, train_loss 35.132530,Time used 0.008998s\n",
      "batch 20273, train_loss 34.694511,Time used 0.012001s\n",
      "batch 20274, train_loss 37.395546,Time used 0.009000s\n",
      "batch 20275, train_loss 35.382015,Time used 0.008999s\n",
      "batch 20276, train_loss 28.257160,Time used 0.008001s\n",
      "batch 20277, train_loss 34.050808,Time used 0.011000s\n",
      "batch 20278, train_loss 41.375011,Time used 0.008001s\n",
      "batch 20279, train_loss 32.900661,Time used 0.012000s\n",
      "batch 20280, train_loss 43.481819,Time used 0.010000s\n",
      "batch 20281, train_loss 38.429516,Time used 0.013999s\n",
      "batch 20282, train_loss 36.243580,Time used 0.011001s\n",
      "batch 20283, train_loss 35.548157,Time used 0.011001s\n",
      "batch 20284, train_loss 30.729645,Time used 0.011001s\n",
      "batch 20285, train_loss 33.873096,Time used 0.019000s\n",
      "batch 20286, train_loss 28.091429,Time used 0.009999s\n",
      "batch 20287, train_loss 38.209309,Time used 0.013003s\n",
      "batch 20288, train_loss 33.995895,Time used 0.010998s\n",
      "batch 20289, train_loss 48.580956,Time used 0.013002s\n",
      "batch 20290, train_loss 34.273876,Time used 0.012002s\n",
      "batch 20291, train_loss 31.816652,Time used 0.012998s\n",
      "batch 20292, train_loss 35.195942,Time used 0.011000s\n",
      "batch 20293, train_loss 40.394787,Time used 0.014000s\n",
      "batch 20294, train_loss 32.443115,Time used 0.014001s\n",
      "batch 20295, train_loss 35.214077,Time used 0.011998s\n",
      "batch 20296, train_loss 38.143986,Time used 0.013001s\n",
      "batch 20297, train_loss 39.090420,Time used 0.011000s\n",
      "batch 20298, train_loss 32.199398,Time used 0.010001s\n",
      "batch 20299, train_loss 38.376091,Time used 0.011998s\n",
      "batch 20300, train_loss 45.410023,Time used 0.013002s\n",
      "***************************test_batch 20300, test_rmse_loss 7.083973,test_mae_loss 3.029734,test_mape_loss 50.885668,Time used 0.067000s\n",
      "batch 20301, train_loss 33.904007,Time used 0.011998s\n",
      "batch 20302, train_loss 38.847218,Time used 0.012000s\n",
      "batch 20303, train_loss 40.050465,Time used 0.012000s\n",
      "batch 20304, train_loss 40.777382,Time used 0.011999s\n",
      "batch 20305, train_loss 39.538868,Time used 0.015002s\n",
      "batch 20306, train_loss 38.748142,Time used 0.011999s\n",
      "batch 20307, train_loss 42.786633,Time used 0.012999s\n",
      "batch 20308, train_loss 38.116985,Time used 0.012001s\n",
      "batch 20309, train_loss 37.568253,Time used 0.013000s\n",
      "batch 20310, train_loss 36.589188,Time used 0.017000s\n",
      "batch 20311, train_loss 39.468258,Time used 0.021002s\n",
      "batch 20312, train_loss 35.541401,Time used 0.012992s\n",
      "batch 20313, train_loss 38.124466,Time used 0.014998s\n",
      "batch 20314, train_loss 38.567383,Time used 0.014002s\n",
      "batch 20315, train_loss 41.099167,Time used 0.011002s\n",
      "batch 20316, train_loss 31.559883,Time used 0.014000s\n",
      "batch 20317, train_loss 34.797703,Time used 0.013002s\n",
      "batch 20318, train_loss 44.241493,Time used 0.012001s\n",
      "batch 20319, train_loss 32.828823,Time used 0.013000s\n",
      "batch 20320, train_loss 37.314423,Time used 0.013001s\n",
      "batch 20321, train_loss 32.904388,Time used 0.011999s\n",
      "batch 20322, train_loss 32.341496,Time used 0.014002s\n",
      "batch 20323, train_loss 26.004143,Time used 0.020002s\n",
      "batch 20324, train_loss 41.225143,Time used 0.020000s\n",
      "batch 20325, train_loss 31.498835,Time used 0.022006s\n",
      "batch 20326, train_loss 35.067799,Time used 0.020995s\n",
      "batch 20327, train_loss 32.227455,Time used 0.026997s\n",
      "batch 20328, train_loss 40.368443,Time used 0.022006s\n",
      "batch 20329, train_loss 28.678673,Time used 0.020993s\n",
      "batch 20330, train_loss 36.065422,Time used 0.043007s\n",
      "batch 20331, train_loss 37.787010,Time used 0.022999s\n",
      "batch 20332, train_loss 41.250599,Time used 0.020002s\n",
      "batch 20333, train_loss 30.166613,Time used 0.015001s\n",
      "batch 20334, train_loss 37.643478,Time used 0.016999s\n",
      "batch 20335, train_loss 44.033180,Time used 0.021002s\n",
      "batch 20336, train_loss 35.460545,Time used 0.020000s\n",
      "batch 20337, train_loss 34.541664,Time used 0.018998s\n",
      "batch 20338, train_loss 39.425140,Time used 0.020001s\n",
      "batch 20339, train_loss 33.917812,Time used 0.014998s\n",
      "batch 20340, train_loss 34.598034,Time used 0.014999s\n",
      "batch 20341, train_loss 36.873955,Time used 0.018004s\n",
      "batch 20342, train_loss 40.093815,Time used 0.016001s\n",
      "batch 20343, train_loss 40.050850,Time used 0.010998s\n",
      "batch 20344, train_loss 36.653992,Time used 0.012002s\n",
      "batch 20345, train_loss 30.972357,Time used 0.011000s\n",
      "batch 20346, train_loss 33.652077,Time used 0.011999s\n",
      "batch 20347, train_loss 35.268333,Time used 0.012000s\n",
      "batch 20348, train_loss 38.605568,Time used 0.008002s\n",
      "batch 20349, train_loss 32.802551,Time used 0.009002s\n",
      "batch 20350, train_loss 40.613541,Time used 0.009998s\n",
      "batch 20351, train_loss 40.103477,Time used 0.010999s\n",
      "batch 20352, train_loss 38.193619,Time used 0.011001s\n",
      "batch 20353, train_loss 45.332966,Time used 0.008998s\n",
      "batch 20354, train_loss 37.621452,Time used 0.008038s\n",
      "batch 20355, train_loss 27.297195,Time used 0.007001s\n",
      "batch 20356, train_loss 39.913883,Time used 0.008961s\n",
      "batch 20357, train_loss 32.670883,Time used 0.008036s\n",
      "batch 20358, train_loss 37.146935,Time used 0.009964s\n",
      "batch 20359, train_loss 44.914013,Time used 0.007966s\n",
      "batch 20360, train_loss 35.911591,Time used 0.012033s\n",
      "batch 20361, train_loss 30.555857,Time used 0.006963s\n",
      "batch 20362, train_loss 38.219120,Time used 0.011000s\n",
      "batch 20363, train_loss 37.381977,Time used 0.007999s\n",
      "batch 20364, train_loss 31.529520,Time used 0.008001s\n",
      "batch 20365, train_loss 31.882233,Time used 0.007997s\n",
      "batch 20366, train_loss 49.531147,Time used 0.007000s\n",
      "batch 20367, train_loss 34.731030,Time used 0.008002s\n",
      "batch 20368, train_loss 39.149170,Time used 0.010998s\n",
      "batch 20369, train_loss 38.771923,Time used 0.011000s\n",
      "batch 20370, train_loss 39.139168,Time used 0.010001s\n",
      "batch 20371, train_loss 37.303959,Time used 0.009003s\n",
      "batch 20372, train_loss 42.016254,Time used 0.007998s\n",
      "batch 20373, train_loss 31.213936,Time used 0.010002s\n",
      "batch 20374, train_loss 33.849583,Time used 0.011999s\n",
      "batch 20375, train_loss 27.693659,Time used 0.008002s\n",
      "batch 20376, train_loss 32.142193,Time used 0.010996s\n",
      "batch 20377, train_loss 36.255463,Time used 0.007998s\n",
      "batch 20378, train_loss 27.584854,Time used 0.008001s\n",
      "batch 20379, train_loss 34.045288,Time used 0.012000s\n",
      "batch 20380, train_loss 42.849880,Time used 0.013001s\n",
      "batch 20381, train_loss 44.713360,Time used 0.011999s\n",
      "batch 20382, train_loss 47.390873,Time used 0.011001s\n",
      "batch 20383, train_loss 35.018604,Time used 0.012999s\n",
      "batch 20384, train_loss 46.721092,Time used 0.012000s\n",
      "batch 20385, train_loss 38.446014,Time used 0.011001s\n",
      "batch 20386, train_loss 36.291191,Time used 0.011003s\n",
      "batch 20387, train_loss 33.810658,Time used 0.010999s\n",
      "batch 20388, train_loss 48.084435,Time used 0.013000s\n",
      "batch 20389, train_loss 39.260525,Time used 0.013000s\n",
      "batch 20390, train_loss 35.802731,Time used 0.012002s\n",
      "batch 20391, train_loss 33.368481,Time used 0.011999s\n",
      "batch 20392, train_loss 26.279160,Time used 0.013999s\n",
      "batch 20393, train_loss 32.308102,Time used 0.013001s\n",
      "batch 20394, train_loss 28.488525,Time used 0.021000s\n",
      "batch 20395, train_loss 33.608765,Time used 0.014000s\n",
      "batch 20396, train_loss 30.976753,Time used 0.017999s\n",
      "batch 20397, train_loss 42.161263,Time used 0.013000s\n",
      "batch 20398, train_loss 25.855341,Time used 0.015001s\n",
      "batch 20399, train_loss 38.114391,Time used 0.015002s\n",
      "batch 20400, train_loss 37.816566,Time used 0.021999s\n",
      "***************************test_batch 20400, test_rmse_loss 7.062918,test_mae_loss 3.023823,test_mape_loss 50.915389,Time used 0.047999s\n",
      "batch 20401, train_loss 34.043732,Time used 0.011998s\n",
      "batch 20402, train_loss 37.796757,Time used 0.011001s\n",
      "batch 20403, train_loss 42.550991,Time used 0.012000s\n",
      "batch 20404, train_loss 40.048653,Time used 0.011000s\n",
      "batch 20405, train_loss 36.190582,Time used 0.013004s\n",
      "batch 20406, train_loss 43.617577,Time used 0.011997s\n",
      "batch 20407, train_loss 36.965916,Time used 0.011003s\n",
      "batch 20408, train_loss 34.099777,Time used 0.009998s\n",
      "batch 20409, train_loss 33.861408,Time used 0.012002s\n",
      "batch 20410, train_loss 41.041405,Time used 0.012999s\n",
      "batch 20411, train_loss 30.365046,Time used 0.009000s\n",
      "batch 20412, train_loss 48.294952,Time used 0.008000s\n",
      "batch 20413, train_loss 35.079639,Time used 0.008000s\n",
      "batch 20414, train_loss 37.076817,Time used 0.010000s\n",
      "batch 20415, train_loss 28.322426,Time used 0.010003s\n",
      "batch 20416, train_loss 33.370705,Time used 0.008999s\n",
      "batch 20417, train_loss 31.719393,Time used 0.013000s\n",
      "batch 20418, train_loss 31.975634,Time used 0.010997s\n",
      "batch 20419, train_loss 39.823883,Time used 0.008003s\n",
      "batch 20420, train_loss 33.315346,Time used 0.008000s\n",
      "batch 20421, train_loss 40.347267,Time used 0.008001s\n",
      "batch 20422, train_loss 35.271931,Time used 0.007998s\n",
      "batch 20423, train_loss 37.151863,Time used 0.008002s\n",
      "batch 20424, train_loss 32.051140,Time used 0.011999s\n",
      "batch 20425, train_loss 27.404016,Time used 0.012000s\n",
      "batch 20426, train_loss 48.286983,Time used 0.012000s\n",
      "batch 20427, train_loss 30.435200,Time used 0.012001s\n",
      "batch 20428, train_loss 36.005135,Time used 0.012001s\n",
      "batch 20429, train_loss 32.066116,Time used 0.010999s\n",
      "batch 20430, train_loss 34.467281,Time used 0.012000s\n",
      "batch 20431, train_loss 36.390751,Time used 0.012000s\n",
      "batch 20432, train_loss 35.570534,Time used 0.011999s\n",
      "batch 20433, train_loss 37.333004,Time used 0.012000s\n",
      "batch 20434, train_loss 41.633072,Time used 0.013004s\n",
      "batch 20435, train_loss 38.251034,Time used 0.012997s\n",
      "batch 20436, train_loss 31.119301,Time used 0.013004s\n",
      "batch 20437, train_loss 40.947788,Time used 0.011998s\n",
      "batch 20438, train_loss 39.804943,Time used 0.013001s\n",
      "batch 20439, train_loss 32.424706,Time used 0.011003s\n",
      "batch 20440, train_loss 38.862190,Time used 0.012004s\n",
      "batch 20441, train_loss 35.333385,Time used 0.010998s\n",
      "batch 20442, train_loss 37.204136,Time used 0.014002s\n",
      "batch 20443, train_loss 36.415962,Time used 0.011999s\n",
      "batch 20444, train_loss 29.266827,Time used 0.012001s\n",
      "batch 20445, train_loss 42.037636,Time used 0.012000s\n",
      "batch 20446, train_loss 38.760883,Time used 0.011999s\n",
      "batch 20447, train_loss 40.626892,Time used 0.010999s\n",
      "batch 20448, train_loss 32.696171,Time used 0.014004s\n",
      "batch 20449, train_loss 30.917618,Time used 0.022003s\n",
      "batch 20450, train_loss 31.693731,Time used 0.015000s\n",
      "batch 20451, train_loss 36.473427,Time used 0.011002s\n",
      "batch 20452, train_loss 36.609322,Time used 0.010001s\n",
      "batch 20453, train_loss 34.342125,Time used 0.012001s\n",
      "batch 20454, train_loss 32.614407,Time used 0.012001s\n",
      "batch 20455, train_loss 28.602346,Time used 0.009998s\n",
      "batch 20456, train_loss 33.324783,Time used 0.011999s\n",
      "batch 20457, train_loss 41.688046,Time used 0.013002s\n",
      "batch 20458, train_loss 40.320141,Time used 0.010997s\n",
      "batch 20459, train_loss 47.876411,Time used 0.011003s\n",
      "batch 20460, train_loss 35.280247,Time used 0.012999s\n",
      "batch 20461, train_loss 36.550968,Time used 0.013000s\n",
      "batch 20462, train_loss 36.423309,Time used 0.009999s\n",
      "batch 20463, train_loss 41.189671,Time used 0.008999s\n",
      "batch 20464, train_loss 36.230209,Time used 0.013999s\n",
      "batch 20465, train_loss 37.234123,Time used 0.011000s\n",
      "batch 20466, train_loss 41.771370,Time used 0.012001s\n",
      "batch 20467, train_loss 34.299339,Time used 0.008999s\n",
      "batch 20468, train_loss 34.490379,Time used 0.012000s\n",
      "batch 20469, train_loss 33.834541,Time used 0.010000s\n",
      "batch 20470, train_loss 29.284019,Time used 0.012000s\n",
      "batch 20471, train_loss 36.081509,Time used 0.009001s\n",
      "batch 20472, train_loss 45.644424,Time used 0.008998s\n",
      "batch 20473, train_loss 49.264816,Time used 0.008000s\n",
      "batch 20474, train_loss 36.957348,Time used 0.010005s\n",
      "batch 20475, train_loss 35.615910,Time used 0.008000s\n",
      "batch 20476, train_loss 31.035130,Time used 0.007998s\n",
      "batch 20477, train_loss 40.884159,Time used 0.009005s\n",
      "batch 20478, train_loss 37.847122,Time used 0.010997s\n",
      "batch 20479, train_loss 39.085831,Time used 0.012000s\n",
      "batch 20480, train_loss 44.358486,Time used 0.007999s\n",
      "batch 20481, train_loss 40.456211,Time used 0.009006s\n",
      "batch 20482, train_loss 31.130911,Time used 0.008002s\n",
      "batch 20483, train_loss 38.868797,Time used 0.010998s\n",
      "batch 20484, train_loss 33.962189,Time used 0.009000s\n",
      "batch 20485, train_loss 28.615986,Time used 0.015000s\n",
      "batch 20486, train_loss 31.913479,Time used 0.014001s\n",
      "batch 20487, train_loss 23.835939,Time used 0.012998s\n",
      "batch 20488, train_loss 45.401291,Time used 0.013000s\n",
      "batch 20489, train_loss 28.973764,Time used 0.014000s\n",
      "batch 20490, train_loss 38.924263,Time used 0.013000s\n",
      "batch 20491, train_loss 35.673069,Time used 0.009000s\n",
      "batch 20492, train_loss 34.470425,Time used 0.012000s\n",
      "batch 20493, train_loss 41.389027,Time used 0.012000s\n",
      "batch 20494, train_loss 39.470531,Time used 0.012000s\n",
      "batch 20495, train_loss 36.069817,Time used 0.011000s\n",
      "batch 20496, train_loss 26.440935,Time used 0.011000s\n",
      "batch 20497, train_loss 42.573483,Time used 0.013001s\n",
      "batch 20498, train_loss 32.305069,Time used 0.011998s\n",
      "batch 20499, train_loss 30.266371,Time used 0.013001s\n",
      "batch 20500, train_loss 40.119831,Time used 0.010998s\n",
      "***************************test_batch 20500, test_rmse_loss 7.055376,test_mae_loss 3.020087,test_mape_loss 50.770359,Time used 0.058002s\n",
      "batch 20501, train_loss 34.505394,Time used 0.027000s\n",
      "batch 20502, train_loss 38.608524,Time used 0.012999s\n",
      "batch 20503, train_loss 34.423748,Time used 0.012002s\n",
      "batch 20504, train_loss 38.040150,Time used 0.011004s\n",
      "batch 20505, train_loss 33.836044,Time used 0.011999s\n",
      "batch 20506, train_loss 33.091358,Time used 0.011998s\n",
      "batch 20507, train_loss 32.279045,Time used 0.013001s\n",
      "batch 20508, train_loss 45.971390,Time used 0.013001s\n",
      "batch 20509, train_loss 31.066088,Time used 0.013002s\n",
      "batch 20510, train_loss 39.003986,Time used 0.007999s\n",
      "batch 20511, train_loss 31.016230,Time used 0.010001s\n",
      "batch 20512, train_loss 37.315544,Time used 0.013001s\n",
      "batch 20513, train_loss 34.222843,Time used 0.011000s\n",
      "batch 20514, train_loss 40.861973,Time used 0.013000s\n",
      "batch 20515, train_loss 44.271980,Time used 0.013999s\n",
      "batch 20516, train_loss 39.444660,Time used 0.012001s\n",
      "batch 20517, train_loss 36.683266,Time used 0.010998s\n",
      "batch 20518, train_loss 32.944099,Time used 0.008999s\n",
      "batch 20519, train_loss 35.620899,Time used 0.008002s\n",
      "batch 20520, train_loss 31.462954,Time used 0.008000s\n",
      "batch 20521, train_loss 48.433578,Time used 0.008003s\n",
      "batch 20522, train_loss 44.313908,Time used 0.008002s\n",
      "batch 20523, train_loss 35.784912,Time used 0.007998s\n",
      "batch 20524, train_loss 37.268024,Time used 0.007998s\n",
      "batch 20525, train_loss 29.213297,Time used 0.008002s\n",
      "batch 20526, train_loss 29.644688,Time used 0.012000s\n",
      "batch 20527, train_loss 32.485672,Time used 0.008998s\n",
      "batch 20528, train_loss 31.007462,Time used 0.010008s\n",
      "batch 20529, train_loss 36.412262,Time used 0.013992s\n",
      "batch 20530, train_loss 33.383713,Time used 0.014998s\n",
      "batch 20531, train_loss 38.934212,Time used 0.016002s\n",
      "batch 20532, train_loss 34.529858,Time used 0.014001s\n",
      "batch 20533, train_loss 38.547802,Time used 0.015999s\n",
      "batch 20534, train_loss 41.785732,Time used 0.014002s\n",
      "batch 20535, train_loss 41.495090,Time used 0.015999s\n",
      "batch 20536, train_loss 39.872051,Time used 0.018998s\n",
      "batch 20537, train_loss 46.223541,Time used 0.018001s\n",
      "batch 20538, train_loss 37.619186,Time used 0.027008s\n",
      "batch 20539, train_loss 36.408375,Time used 0.021999s\n",
      "batch 20540, train_loss 28.764269,Time used 0.014998s\n",
      "batch 20541, train_loss 28.588266,Time used 0.013000s\n",
      "batch 20542, train_loss 32.926662,Time used 0.013000s\n",
      "batch 20543, train_loss 30.428690,Time used 0.012998s\n",
      "batch 20544, train_loss 35.093071,Time used 0.012002s\n",
      "batch 20545, train_loss 35.415092,Time used 0.013000s\n",
      "batch 20546, train_loss 31.620893,Time used 0.013002s\n",
      "batch 20547, train_loss 38.048016,Time used 0.011997s\n",
      "batch 20548, train_loss 35.119907,Time used 0.011999s\n",
      "batch 20549, train_loss 29.891226,Time used 0.012000s\n",
      "batch 20550, train_loss 37.793262,Time used 0.011001s\n",
      "batch 20551, train_loss 40.813034,Time used 0.014001s\n",
      "batch 20552, train_loss 42.205872,Time used 0.012999s\n",
      "batch 20553, train_loss 34.554218,Time used 0.014000s\n",
      "batch 20554, train_loss 32.654556,Time used 0.013000s\n",
      "batch 20555, train_loss 37.827339,Time used 0.016002s\n",
      "batch 20556, train_loss 28.458603,Time used 0.021999s\n",
      "batch 20557, train_loss 40.803535,Time used 0.016001s\n",
      "batch 20558, train_loss 31.739004,Time used 0.014000s\n",
      "batch 20559, train_loss 33.999115,Time used 0.016999s\n",
      "batch 20560, train_loss 35.143063,Time used 0.014001s\n",
      "batch 20561, train_loss 43.374981,Time used 0.014001s\n",
      "batch 20562, train_loss 37.212395,Time used 0.012997s\n",
      "batch 20563, train_loss 43.328983,Time used 0.014001s\n",
      "batch 20564, train_loss 46.106983,Time used 0.012002s\n",
      "batch 20565, train_loss 34.413189,Time used 0.011999s\n",
      "batch 20566, train_loss 31.134060,Time used 0.013002s\n",
      "batch 20567, train_loss 29.254745,Time used 0.013000s\n",
      "batch 20568, train_loss 37.214474,Time used 0.012000s\n",
      "batch 20569, train_loss 36.691582,Time used 0.009996s\n",
      "batch 20570, train_loss 39.114594,Time used 0.008001s\n",
      "batch 20571, train_loss 34.956020,Time used 0.008998s\n",
      "batch 20572, train_loss 40.986717,Time used 0.010001s\n",
      "batch 20573, train_loss 30.774303,Time used 0.016001s\n",
      "batch 20574, train_loss 48.243225,Time used 0.010003s\n",
      "batch 20575, train_loss 28.667278,Time used 0.011999s\n",
      "batch 20576, train_loss 37.359486,Time used 0.012000s\n",
      "batch 20577, train_loss 40.693848,Time used 0.012001s\n",
      "batch 20578, train_loss 29.730835,Time used 0.011000s\n",
      "batch 20579, train_loss 36.899834,Time used 0.012999s\n",
      "batch 20580, train_loss 33.418392,Time used 0.012004s\n",
      "batch 20581, train_loss 31.521023,Time used 0.011998s\n",
      "batch 20582, train_loss 42.545765,Time used 0.014001s\n",
      "batch 20583, train_loss 36.292950,Time used 0.012999s\n",
      "batch 20584, train_loss 30.440796,Time used 0.013000s\n",
      "batch 20585, train_loss 27.800228,Time used 0.012001s\n",
      "batch 20586, train_loss 30.336111,Time used 0.009998s\n",
      "batch 20587, train_loss 49.640293,Time used 0.010997s\n",
      "batch 20588, train_loss 27.454762,Time used 0.011002s\n",
      "batch 20589, train_loss 39.130688,Time used 0.013002s\n",
      "batch 20590, train_loss 35.901817,Time used 0.012003s\n",
      "batch 20591, train_loss 38.867313,Time used 0.012995s\n",
      "batch 20592, train_loss 39.561413,Time used 0.013004s\n",
      "batch 20593, train_loss 31.980433,Time used 0.014998s\n",
      "batch 20594, train_loss 40.875042,Time used 0.014004s\n",
      "batch 20595, train_loss 35.393658,Time used 0.022000s\n",
      "batch 20596, train_loss 38.096066,Time used 0.011997s\n",
      "batch 20597, train_loss 34.525665,Time used 0.012000s\n",
      "batch 20598, train_loss 33.799221,Time used 0.012001s\n",
      "batch 20599, train_loss 31.728456,Time used 0.011998s\n",
      "batch 20600, train_loss 33.019733,Time used 0.011001s\n",
      "***************************test_batch 20600, test_rmse_loss 7.035747,test_mae_loss 3.016685,test_mape_loss 50.943864,Time used 0.049002s\n",
      "batch 20601, train_loss 37.658783,Time used 0.010998s\n",
      "batch 20602, train_loss 34.173874,Time used 0.011996s\n",
      "batch 20603, train_loss 35.807167,Time used 0.012002s\n",
      "batch 20604, train_loss 31.431337,Time used 0.010997s\n",
      "batch 20605, train_loss 36.268803,Time used 0.012006s\n",
      "batch 20606, train_loss 32.590881,Time used 0.008995s\n",
      "batch 20607, train_loss 39.447407,Time used 0.007999s\n",
      "batch 20608, train_loss 36.345448,Time used 0.009000s\n",
      "batch 20609, train_loss 37.972771,Time used 0.009000s\n",
      "batch 20610, train_loss 36.119926,Time used 0.010999s\n",
      "batch 20611, train_loss 38.201672,Time used 0.008003s\n",
      "batch 20612, train_loss 36.158356,Time used 0.009002s\n",
      "batch 20613, train_loss 31.882286,Time used 0.010996s\n",
      "batch 20614, train_loss 42.889675,Time used 0.012002s\n",
      "batch 20615, train_loss 34.690681,Time used 0.007999s\n",
      "batch 20616, train_loss 45.145306,Time used 0.008997s\n",
      "batch 20617, train_loss 38.243465,Time used 0.007999s\n",
      "batch 20618, train_loss 36.067375,Time used 0.008000s\n",
      "batch 20619, train_loss 34.327793,Time used 0.007997s\n",
      "batch 20620, train_loss 38.707058,Time used 0.012003s\n",
      "batch 20621, train_loss 35.368053,Time used 0.008997s\n",
      "batch 20622, train_loss 31.263140,Time used 0.009003s\n",
      "batch 20623, train_loss 36.220314,Time used 0.011001s\n",
      "batch 20624, train_loss 34.622032,Time used 0.011999s\n",
      "batch 20625, train_loss 34.305634,Time used 0.011002s\n",
      "batch 20626, train_loss 41.710461,Time used 0.010999s\n",
      "batch 20627, train_loss 39.472805,Time used 0.011000s\n",
      "batch 20628, train_loss 37.626209,Time used 0.012001s\n",
      "batch 20629, train_loss 36.835732,Time used 0.013000s\n",
      "batch 20630, train_loss 38.917980,Time used 0.011998s\n",
      "batch 20631, train_loss 33.651295,Time used 0.013000s\n",
      "batch 20632, train_loss 41.198154,Time used 0.010999s\n",
      "batch 20633, train_loss 31.808535,Time used 0.010002s\n",
      "batch 20634, train_loss 30.549742,Time used 0.011000s\n",
      "batch 20635, train_loss 38.636425,Time used 0.013000s\n",
      "batch 20636, train_loss 34.160545,Time used 0.011000s\n",
      "batch 20637, train_loss 31.878141,Time used 0.013000s\n",
      "batch 20638, train_loss 39.105957,Time used 0.010000s\n",
      "batch 20639, train_loss 32.384895,Time used 0.011012s\n",
      "batch 20640, train_loss 38.066479,Time used 0.011988s\n",
      "batch 20641, train_loss 43.387909,Time used 0.012002s\n",
      "batch 20642, train_loss 34.871876,Time used 0.013999s\n",
      "batch 20643, train_loss 44.333893,Time used 0.011000s\n",
      "batch 20644, train_loss 28.780329,Time used 0.013005s\n",
      "batch 20645, train_loss 30.238840,Time used 0.013999s\n",
      "batch 20646, train_loss 32.549683,Time used 0.012998s\n",
      "batch 20647, train_loss 29.663147,Time used 0.017002s\n",
      "batch 20648, train_loss 38.210476,Time used 0.030000s\n",
      "batch 20649, train_loss 27.769424,Time used 0.015999s\n",
      "batch 20650, train_loss 31.448101,Time used 0.015000s\n",
      "batch 20651, train_loss 39.526592,Time used 0.013001s\n",
      "batch 20652, train_loss 37.599701,Time used 0.013000s\n",
      "batch 20653, train_loss 41.588024,Time used 0.013000s\n",
      "batch 20654, train_loss 39.618584,Time used 0.012999s\n",
      "batch 20655, train_loss 31.211422,Time used 0.012002s\n",
      "batch 20656, train_loss 35.014721,Time used 0.012001s\n",
      "batch 20657, train_loss 33.876915,Time used 0.013000s\n",
      "batch 20658, train_loss 36.538685,Time used 0.015002s\n",
      "batch 20659, train_loss 32.589241,Time used 0.011998s\n",
      "batch 20660, train_loss 42.958221,Time used 0.011999s\n",
      "batch 20661, train_loss 37.243893,Time used 0.012001s\n",
      "batch 20662, train_loss 35.432667,Time used 0.011998s\n",
      "batch 20663, train_loss 38.752472,Time used 0.008001s\n",
      "batch 20664, train_loss 40.621426,Time used 0.007999s\n",
      "batch 20665, train_loss 42.472553,Time used 0.010998s\n",
      "batch 20666, train_loss 34.951942,Time used 0.010008s\n",
      "batch 20667, train_loss 38.841686,Time used 0.010999s\n",
      "batch 20668, train_loss 34.213547,Time used 0.010003s\n",
      "batch 20669, train_loss 32.344223,Time used 0.011000s\n",
      "batch 20670, train_loss 41.778461,Time used 0.011000s\n",
      "batch 20671, train_loss 32.576637,Time used 0.010999s\n",
      "batch 20672, train_loss 32.670177,Time used 0.011001s\n",
      "batch 20673, train_loss 30.469097,Time used 0.012000s\n",
      "batch 20674, train_loss 38.046040,Time used 0.011000s\n",
      "batch 20675, train_loss 38.439327,Time used 0.012000s\n",
      "batch 20676, train_loss 37.626713,Time used 0.010001s\n",
      "batch 20677, train_loss 31.374516,Time used 0.011997s\n",
      "batch 20678, train_loss 33.905006,Time used 0.010001s\n",
      "batch 20679, train_loss 38.800064,Time used 0.012000s\n",
      "batch 20680, train_loss 35.211922,Time used 0.011003s\n",
      "batch 20681, train_loss 40.418705,Time used 0.014998s\n",
      "batch 20682, train_loss 36.412617,Time used 0.013001s\n",
      "batch 20683, train_loss 41.987125,Time used 0.011999s\n",
      "batch 20684, train_loss 32.762257,Time used 0.013999s\n",
      "batch 20685, train_loss 35.233318,Time used 0.012002s\n",
      "batch 20686, train_loss 31.002455,Time used 0.011001s\n",
      "batch 20687, train_loss 33.755165,Time used 0.013000s\n",
      "batch 20688, train_loss 37.767479,Time used 0.015000s\n",
      "batch 20689, train_loss 34.071789,Time used 0.018000s\n",
      "batch 20690, train_loss 36.033161,Time used 0.011998s\n",
      "batch 20691, train_loss 36.900314,Time used 0.011999s\n",
      "batch 20692, train_loss 39.485340,Time used 0.012000s\n",
      "batch 20693, train_loss 31.142368,Time used 0.009999s\n",
      "batch 20694, train_loss 34.777237,Time used 0.010002s\n",
      "batch 20695, train_loss 36.613869,Time used 0.012002s\n",
      "batch 20696, train_loss 37.329063,Time used 0.012999s\n",
      "batch 20697, train_loss 34.981842,Time used 0.013000s\n",
      "batch 20698, train_loss 35.048908,Time used 0.012001s\n",
      "batch 20699, train_loss 27.850595,Time used 0.010999s\n",
      "batch 20700, train_loss 37.812401,Time used 0.011001s\n",
      "***************************test_batch 20700, test_rmse_loss 7.032471,test_mae_loss 3.010427,test_mape_loss 50.695023,Time used 0.047002s\n",
      "batch 20701, train_loss 38.777912,Time used 0.011000s\n",
      "batch 20702, train_loss 41.133408,Time used 0.010000s\n",
      "batch 20703, train_loss 36.044189,Time used 0.008998s\n",
      "batch 20704, train_loss 32.882027,Time used 0.008000s\n",
      "batch 20705, train_loss 26.822571,Time used 0.009000s\n",
      "batch 20706, train_loss 34.574593,Time used 0.006999s\n",
      "batch 20707, train_loss 30.729174,Time used 0.007000s\n",
      "batch 20708, train_loss 34.410011,Time used 0.011001s\n",
      "batch 20709, train_loss 37.574623,Time used 0.009000s\n",
      "batch 20710, train_loss 36.298958,Time used 0.008002s\n",
      "batch 20711, train_loss 47.739708,Time used 0.007001s\n",
      "batch 20712, train_loss 42.958710,Time used 0.010000s\n",
      "batch 20713, train_loss 36.735340,Time used 0.009997s\n",
      "batch 20714, train_loss 32.050163,Time used 0.009999s\n",
      "batch 20715, train_loss 37.342770,Time used 0.008000s\n",
      "batch 20716, train_loss 39.690563,Time used 0.011001s\n",
      "batch 20717, train_loss 45.494572,Time used 0.008999s\n",
      "batch 20718, train_loss 39.810207,Time used 0.008000s\n",
      "batch 20719, train_loss 33.281731,Time used 0.008001s\n",
      "batch 20720, train_loss 35.115269,Time used 0.010004s\n",
      "batch 20721, train_loss 33.120262,Time used 0.010993s\n",
      "batch 20722, train_loss 33.020187,Time used 0.010004s\n",
      "batch 20723, train_loss 32.259628,Time used 0.012002s\n",
      "batch 20724, train_loss 40.492561,Time used 0.008995s\n",
      "batch 20725, train_loss 33.865246,Time used 0.009001s\n",
      "batch 20726, train_loss 30.428087,Time used 0.006998s\n",
      "batch 20727, train_loss 30.673798,Time used 0.007001s\n",
      "batch 20728, train_loss 40.597729,Time used 0.007999s\n",
      "batch 20729, train_loss 45.279900,Time used 0.009004s\n",
      "batch 20730, train_loss 35.814480,Time used 0.013997s\n",
      "batch 20731, train_loss 29.089445,Time used 0.011000s\n",
      "batch 20732, train_loss 34.316990,Time used 0.010998s\n",
      "batch 20733, train_loss 35.777576,Time used 0.013001s\n",
      "batch 20734, train_loss 32.799335,Time used 0.011998s\n",
      "batch 20735, train_loss 41.399406,Time used 0.011998s\n",
      "batch 20736, train_loss 32.060665,Time used 0.010004s\n",
      "batch 20737, train_loss 29.293070,Time used 0.008000s\n",
      "batch 20738, train_loss 34.014889,Time used 0.011000s\n",
      "batch 20739, train_loss 31.607224,Time used 0.012002s\n",
      "batch 20740, train_loss 38.352345,Time used 0.011997s\n",
      "batch 20741, train_loss 40.373962,Time used 0.008002s\n",
      "batch 20742, train_loss 31.638582,Time used 0.006999s\n",
      "batch 20743, train_loss 30.713890,Time used 0.008001s\n",
      "batch 20744, train_loss 40.446049,Time used 0.009000s\n",
      "batch 20745, train_loss 29.438692,Time used 0.007999s\n",
      "batch 20746, train_loss 29.270151,Time used 0.007000s\n",
      "batch 20747, train_loss 43.854546,Time used 0.008000s\n",
      "batch 20748, train_loss 35.774246,Time used 0.009998s\n",
      "batch 20749, train_loss 27.246412,Time used 0.008002s\n",
      "batch 20750, train_loss 38.088585,Time used 0.011998s\n",
      "batch 20751, train_loss 36.583744,Time used 0.011000s\n",
      "batch 20752, train_loss 45.000946,Time used 0.008000s\n",
      "batch 20753, train_loss 34.669895,Time used 0.010001s\n",
      "batch 20754, train_loss 34.650211,Time used 0.007998s\n",
      "batch 20755, train_loss 40.778580,Time used 0.011000s\n",
      "batch 20756, train_loss 34.816406,Time used 0.008001s\n",
      "batch 20757, train_loss 33.795490,Time used 0.008999s\n",
      "batch 20758, train_loss 38.804737,Time used 0.008001s\n",
      "batch 20759, train_loss 46.902885,Time used 0.007999s\n",
      "batch 20760, train_loss 33.051037,Time used 0.009000s\n",
      "batch 20761, train_loss 37.634968,Time used 0.007998s\n",
      "batch 20762, train_loss 35.730682,Time used 0.008001s\n",
      "batch 20763, train_loss 33.666634,Time used 0.007998s\n",
      "batch 20764, train_loss 34.211182,Time used 0.008002s\n",
      "batch 20765, train_loss 32.262081,Time used 0.008999s\n",
      "batch 20766, train_loss 35.541214,Time used 0.008000s\n",
      "batch 20767, train_loss 34.083324,Time used 0.010998s\n",
      "batch 20768, train_loss 37.903778,Time used 0.010002s\n",
      "batch 20769, train_loss 38.508625,Time used 0.008999s\n",
      "batch 20770, train_loss 32.802322,Time used 0.006999s\n",
      "batch 20771, train_loss 37.936203,Time used 0.007000s\n",
      "batch 20772, train_loss 38.266014,Time used 0.009998s\n",
      "batch 20773, train_loss 37.250931,Time used 0.010001s\n",
      "batch 20774, train_loss 38.142067,Time used 0.007999s\n",
      "batch 20775, train_loss 33.326851,Time used 0.008000s\n",
      "batch 20776, train_loss 36.954777,Time used 0.008000s\n",
      "batch 20777, train_loss 34.403378,Time used 0.008000s\n",
      "batch 20778, train_loss 32.201317,Time used 0.010999s\n",
      "batch 20779, train_loss 41.779549,Time used 0.011003s\n",
      "batch 20780, train_loss 30.951277,Time used 0.010000s\n",
      "batch 20781, train_loss 40.207993,Time used 0.007999s\n",
      "batch 20782, train_loss 35.791779,Time used 0.008000s\n",
      "batch 20783, train_loss 32.703262,Time used 0.009999s\n",
      "batch 20784, train_loss 36.348579,Time used 0.007001s\n",
      "batch 20785, train_loss 31.816517,Time used 0.009000s\n",
      "batch 20786, train_loss 33.898342,Time used 0.007999s\n",
      "batch 20787, train_loss 34.343689,Time used 0.010000s\n",
      "batch 20788, train_loss 30.782755,Time used 0.008000s\n",
      "batch 20789, train_loss 38.402290,Time used 0.008001s\n",
      "batch 20790, train_loss 35.780148,Time used 0.011999s\n",
      "batch 20791, train_loss 33.334988,Time used 0.012000s\n",
      "batch 20792, train_loss 44.853577,Time used 0.011001s\n",
      "batch 20793, train_loss 35.985966,Time used 0.009000s\n",
      "batch 20794, train_loss 41.454323,Time used 0.008001s\n",
      "batch 20795, train_loss 32.433975,Time used 0.014000s\n",
      "batch 20796, train_loss 36.231113,Time used 0.011002s\n",
      "batch 20797, train_loss 30.249355,Time used 0.011001s\n",
      "batch 20798, train_loss 37.548611,Time used 0.012999s\n",
      "batch 20799, train_loss 36.252415,Time used 0.015001s\n",
      "batch 20800, train_loss 42.569675,Time used 0.013999s\n",
      "***************************test_batch 20800, test_rmse_loss 7.009766,test_mae_loss 3.008497,test_mape_loss 51.002348,Time used 0.063005s\n",
      "batch 20801, train_loss 32.153866,Time used 0.009995s\n",
      "batch 20802, train_loss 40.497326,Time used 0.014001s\n",
      "batch 20803, train_loss 33.678612,Time used 0.012998s\n",
      "batch 20804, train_loss 37.249043,Time used 0.016000s\n",
      "batch 20805, train_loss 35.317196,Time used 0.015001s\n",
      "batch 20806, train_loss 37.707512,Time used 0.011998s\n",
      "batch 20807, train_loss 28.216763,Time used 0.015001s\n",
      "batch 20808, train_loss 36.704773,Time used 0.012012s\n",
      "batch 20809, train_loss 28.188543,Time used 0.017000s\n",
      "batch 20810, train_loss 31.075415,Time used 0.015003s\n",
      "batch 20811, train_loss 39.948109,Time used 0.014991s\n",
      "batch 20812, train_loss 39.815495,Time used 0.013008s\n",
      "batch 20813, train_loss 38.032516,Time used 0.012987s\n",
      "batch 20814, train_loss 35.942856,Time used 0.011002s\n",
      "batch 20815, train_loss 39.706741,Time used 0.012998s\n",
      "batch 20816, train_loss 30.929447,Time used 0.016999s\n",
      "batch 20817, train_loss 39.146118,Time used 0.010999s\n",
      "batch 20818, train_loss 40.039616,Time used 0.016000s\n",
      "batch 20819, train_loss 35.847767,Time used 0.015004s\n",
      "batch 20820, train_loss 44.143421,Time used 0.008997s\n",
      "batch 20821, train_loss 30.675888,Time used 0.012001s\n",
      "batch 20822, train_loss 36.846611,Time used 0.008000s\n",
      "batch 20823, train_loss 30.498142,Time used 0.011996s\n",
      "batch 20824, train_loss 32.919281,Time used 0.012002s\n",
      "batch 20825, train_loss 37.058434,Time used 0.012002s\n",
      "batch 20826, train_loss 40.037628,Time used 0.013997s\n",
      "batch 20827, train_loss 33.323257,Time used 0.013004s\n",
      "batch 20828, train_loss 37.168797,Time used 0.012996s\n",
      "batch 20829, train_loss 36.177650,Time used 0.014002s\n",
      "batch 20830, train_loss 38.711281,Time used 0.012997s\n",
      "batch 20831, train_loss 29.996132,Time used 0.009002s\n",
      "batch 20832, train_loss 29.752192,Time used 0.012000s\n",
      "batch 20833, train_loss 31.530985,Time used 0.011998s\n",
      "batch 20834, train_loss 31.357555,Time used 0.012002s\n",
      "batch 20835, train_loss 33.611187,Time used 0.007999s\n",
      "batch 20836, train_loss 40.669094,Time used 0.011004s\n",
      "batch 20837, train_loss 30.674955,Time used 0.008003s\n",
      "batch 20838, train_loss 34.638153,Time used 0.011994s\n",
      "batch 20839, train_loss 37.152012,Time used 0.011000s\n",
      "batch 20840, train_loss 44.939026,Time used 0.007000s\n",
      "batch 20841, train_loss 29.681681,Time used 0.010000s\n",
      "batch 20842, train_loss 40.480698,Time used 0.008000s\n",
      "batch 20843, train_loss 47.421890,Time used 0.010000s\n",
      "batch 20844, train_loss 37.051739,Time used 0.011000s\n",
      "batch 20845, train_loss 35.110916,Time used 0.008001s\n",
      "batch 20846, train_loss 33.459396,Time used 0.010000s\n",
      "batch 20847, train_loss 35.169979,Time used 0.012999s\n",
      "batch 20848, train_loss 33.480743,Time used 0.009999s\n",
      "batch 20849, train_loss 33.608906,Time used 0.010000s\n",
      "batch 20850, train_loss 35.705383,Time used 0.009002s\n",
      "batch 20851, train_loss 41.990974,Time used 0.006998s\n",
      "batch 20852, train_loss 34.962692,Time used 0.008000s\n",
      "batch 20853, train_loss 29.027374,Time used 0.011002s\n",
      "batch 20854, train_loss 38.872334,Time used 0.009999s\n",
      "batch 20855, train_loss 33.805225,Time used 0.012000s\n",
      "batch 20856, train_loss 30.548111,Time used 0.007999s\n",
      "batch 20857, train_loss 42.589825,Time used 0.012002s\n",
      "batch 20858, train_loss 39.590935,Time used 0.011998s\n",
      "batch 20859, train_loss 32.100632,Time used 0.007001s\n",
      "batch 20860, train_loss 30.767323,Time used 0.007001s\n",
      "batch 20861, train_loss 33.317558,Time used 0.008000s\n",
      "batch 20862, train_loss 34.518932,Time used 0.011001s\n",
      "batch 20863, train_loss 36.082386,Time used 0.011000s\n",
      "batch 20864, train_loss 36.166672,Time used 0.011002s\n",
      "batch 20865, train_loss 28.327806,Time used 0.010998s\n",
      "batch 20866, train_loss 35.621696,Time used 0.012003s\n",
      "batch 20867, train_loss 40.911270,Time used 0.011998s\n",
      "batch 20868, train_loss 41.754898,Time used 0.011003s\n",
      "batch 20869, train_loss 40.221703,Time used 0.007998s\n",
      "batch 20870, train_loss 34.645092,Time used 0.009001s\n",
      "batch 20871, train_loss 34.693394,Time used 0.009998s\n",
      "batch 20872, train_loss 31.428036,Time used 0.010001s\n",
      "batch 20873, train_loss 31.968061,Time used 0.011002s\n",
      "batch 20874, train_loss 34.148254,Time used 0.009001s\n",
      "batch 20875, train_loss 30.038126,Time used 0.007998s\n",
      "batch 20876, train_loss 35.545235,Time used 0.010997s\n",
      "batch 20877, train_loss 38.630703,Time used 0.007999s\n",
      "batch 20878, train_loss 34.226181,Time used 0.008000s\n",
      "batch 20879, train_loss 40.152763,Time used 0.009000s\n",
      "batch 20880, train_loss 36.576618,Time used 0.007000s\n",
      "batch 20881, train_loss 34.330940,Time used 0.010000s\n",
      "batch 20882, train_loss 34.337379,Time used 0.008002s\n",
      "batch 20883, train_loss 30.722137,Time used 0.007998s\n",
      "batch 20884, train_loss 27.840246,Time used 0.008001s\n",
      "batch 20885, train_loss 37.365410,Time used 0.010001s\n",
      "batch 20886, train_loss 35.656227,Time used 0.009000s\n",
      "batch 20887, train_loss 34.573345,Time used 0.008999s\n",
      "batch 20888, train_loss 30.299776,Time used 0.006999s\n",
      "batch 20889, train_loss 40.363899,Time used 0.008003s\n",
      "batch 20890, train_loss 32.643551,Time used 0.011999s\n",
      "batch 20891, train_loss 30.020702,Time used 0.008000s\n",
      "batch 20892, train_loss 28.883938,Time used 0.009002s\n",
      "batch 20893, train_loss 38.735241,Time used 0.007999s\n",
      "batch 20894, train_loss 45.250404,Time used 0.009000s\n",
      "batch 20895, train_loss 35.316441,Time used 0.007998s\n",
      "batch 20896, train_loss 35.993542,Time used 0.008000s\n",
      "batch 20897, train_loss 37.760986,Time used 0.009002s\n",
      "batch 20898, train_loss 47.514317,Time used 0.010999s\n",
      "batch 20899, train_loss 32.559101,Time used 0.010999s\n",
      "batch 20900, train_loss 38.555935,Time used 0.006999s\n",
      "***************************test_batch 20900, test_rmse_loss 6.990352,test_mae_loss 3.003095,test_mape_loss 50.872067,Time used 0.033005s\n",
      "batch 20901, train_loss 38.148506,Time used 0.009033s\n",
      "batch 20902, train_loss 37.457855,Time used 0.007970s\n",
      "batch 20903, train_loss 33.337730,Time used 0.010993s\n",
      "batch 20904, train_loss 35.413033,Time used 0.011998s\n",
      "batch 20905, train_loss 35.207893,Time used 0.010999s\n",
      "batch 20906, train_loss 31.785774,Time used 0.013001s\n",
      "batch 20907, train_loss 26.110929,Time used 0.010998s\n",
      "batch 20908, train_loss 42.621521,Time used 0.007999s\n",
      "batch 20909, train_loss 36.958286,Time used 0.010001s\n",
      "batch 20910, train_loss 35.029648,Time used 0.009001s\n",
      "batch 20911, train_loss 39.345726,Time used 0.008002s\n",
      "batch 20912, train_loss 38.099724,Time used 0.009997s\n",
      "batch 20913, train_loss 29.564693,Time used 0.008000s\n",
      "batch 20914, train_loss 38.213932,Time used 0.010000s\n",
      "batch 20915, train_loss 42.268494,Time used 0.011003s\n",
      "batch 20916, train_loss 31.409533,Time used 0.011000s\n",
      "batch 20917, train_loss 34.172501,Time used 0.009999s\n",
      "batch 20918, train_loss 35.686375,Time used 0.008000s\n",
      "batch 20919, train_loss 35.743073,Time used 0.012002s\n",
      "batch 20920, train_loss 34.153408,Time used 0.009999s\n",
      "batch 20921, train_loss 38.188499,Time used 0.009001s\n",
      "batch 20922, train_loss 32.048786,Time used 0.007999s\n",
      "batch 20923, train_loss 34.859894,Time used 0.008001s\n",
      "batch 20924, train_loss 36.650406,Time used 0.007997s\n",
      "batch 20925, train_loss 31.861721,Time used 0.010001s\n",
      "batch 20926, train_loss 46.773003,Time used 0.008000s\n",
      "batch 20927, train_loss 27.715132,Time used 0.010000s\n",
      "batch 20928, train_loss 37.707905,Time used 0.007998s\n",
      "batch 20929, train_loss 38.889954,Time used 0.010000s\n",
      "batch 20930, train_loss 29.158939,Time used 0.008005s\n",
      "batch 20931, train_loss 34.800465,Time used 0.011994s\n",
      "batch 20932, train_loss 33.510265,Time used 0.010998s\n",
      "batch 20933, train_loss 33.705887,Time used 0.011002s\n",
      "batch 20934, train_loss 36.757473,Time used 0.011001s\n",
      "batch 20935, train_loss 39.624821,Time used 0.011000s\n",
      "batch 20936, train_loss 33.712132,Time used 0.011000s\n",
      "batch 20937, train_loss 40.036404,Time used 0.009000s\n",
      "batch 20938, train_loss 33.144863,Time used 0.009000s\n",
      "batch 20939, train_loss 38.911797,Time used 0.009001s\n",
      "batch 20940, train_loss 29.302937,Time used 0.007999s\n",
      "batch 20941, train_loss 43.566166,Time used 0.010999s\n",
      "batch 20942, train_loss 43.050583,Time used 0.009003s\n",
      "batch 20943, train_loss 32.026985,Time used 0.007998s\n",
      "batch 20944, train_loss 42.925537,Time used 0.009002s\n",
      "batch 20945, train_loss 30.578003,Time used 0.008000s\n",
      "batch 20946, train_loss 33.038746,Time used 0.007998s\n",
      "batch 20947, train_loss 36.994881,Time used 0.008003s\n",
      "batch 20948, train_loss 34.556808,Time used 0.009996s\n",
      "batch 20949, train_loss 35.487778,Time used 0.011999s\n",
      "batch 20950, train_loss 36.725906,Time used 0.009003s\n",
      "batch 20951, train_loss 29.199757,Time used 0.011000s\n",
      "batch 20952, train_loss 31.210094,Time used 0.009001s\n",
      "batch 20953, train_loss 31.420921,Time used 0.008998s\n",
      "batch 20954, train_loss 38.060074,Time used 0.012001s\n",
      "batch 20955, train_loss 37.752415,Time used 0.009000s\n",
      "batch 20956, train_loss 38.917892,Time used 0.009001s\n",
      "batch 20957, train_loss 39.754890,Time used 0.008002s\n",
      "batch 20958, train_loss 30.017899,Time used 0.012000s\n",
      "batch 20959, train_loss 37.876366,Time used 0.010000s\n",
      "batch 20960, train_loss 39.122974,Time used 0.008000s\n",
      "batch 20961, train_loss 36.732975,Time used 0.012002s\n",
      "batch 20962, train_loss 35.765118,Time used 0.010000s\n",
      "batch 20963, train_loss 29.438557,Time used 0.009000s\n",
      "batch 20964, train_loss 36.481991,Time used 0.011000s\n",
      "batch 20965, train_loss 31.816002,Time used 0.008002s\n",
      "batch 20966, train_loss 29.193657,Time used 0.007999s\n",
      "batch 20967, train_loss 38.006042,Time used 0.007001s\n",
      "batch 20968, train_loss 40.350838,Time used 0.006999s\n",
      "batch 20969, train_loss 36.133396,Time used 0.008002s\n",
      "batch 20970, train_loss 29.361835,Time used 0.010997s\n",
      "batch 20971, train_loss 40.546181,Time used 0.011001s\n",
      "batch 20972, train_loss 33.180267,Time used 0.009003s\n",
      "batch 20973, train_loss 28.162735,Time used 0.007999s\n",
      "batch 20974, train_loss 31.078503,Time used 0.009999s\n",
      "batch 20975, train_loss 38.882504,Time used 0.012000s\n",
      "batch 20976, train_loss 42.133419,Time used 0.011000s\n",
      "batch 20977, train_loss 38.242161,Time used 0.008000s\n",
      "batch 20978, train_loss 33.246845,Time used 0.011999s\n",
      "batch 20979, train_loss 37.545151,Time used 0.007999s\n",
      "batch 20980, train_loss 33.309921,Time used 0.008001s\n",
      "batch 20981, train_loss 30.610769,Time used 0.008001s\n",
      "batch 20982, train_loss 33.982021,Time used 0.007998s\n",
      "batch 20983, train_loss 42.802841,Time used 0.009001s\n",
      "batch 20984, train_loss 44.625759,Time used 0.007998s\n",
      "batch 20985, train_loss 35.696751,Time used 0.007000s\n",
      "batch 20986, train_loss 32.271950,Time used 0.007997s\n",
      "batch 20987, train_loss 44.157578,Time used 0.011003s\n",
      "batch 20988, train_loss 34.207993,Time used 0.010999s\n",
      "batch 20989, train_loss 30.985544,Time used 0.011999s\n",
      "batch 20990, train_loss 27.897488,Time used 0.011003s\n",
      "batch 20991, train_loss 38.462017,Time used 0.012000s\n",
      "batch 20992, train_loss 36.074493,Time used 0.011997s\n",
      "batch 20993, train_loss 35.325233,Time used 0.006999s\n",
      "batch 20994, train_loss 32.621952,Time used 0.008001s\n",
      "batch 20995, train_loss 29.040663,Time used 0.007999s\n",
      "batch 20996, train_loss 38.470921,Time used 0.008000s\n",
      "batch 20997, train_loss 37.941673,Time used 0.006999s\n",
      "batch 20998, train_loss 32.658272,Time used 0.010000s\n",
      "batch 20999, train_loss 38.893047,Time used 0.011001s\n",
      "batch 21000, train_loss 29.783939,Time used 0.010999s\n",
      "***************************test_batch 21000, test_rmse_loss 6.977163,test_mae_loss 3.001354,test_mape_loss 51.018054,Time used 0.032000s\n",
      "batch 21001, train_loss 35.876225,Time used 0.007997s\n",
      "batch 21002, train_loss 32.272343,Time used 0.012001s\n",
      "batch 21003, train_loss 42.097672,Time used 0.008999s\n",
      "batch 21004, train_loss 35.299934,Time used 0.008005s\n",
      "batch 21005, train_loss 34.557758,Time used 0.007994s\n",
      "batch 21006, train_loss 35.460415,Time used 0.011000s\n",
      "batch 21007, train_loss 32.596233,Time used 0.010002s\n",
      "batch 21008, train_loss 31.903913,Time used 0.008001s\n",
      "batch 21009, train_loss 30.918076,Time used 0.007997s\n",
      "batch 21010, train_loss 40.107952,Time used 0.008004s\n",
      "batch 21011, train_loss 35.267414,Time used 0.007999s\n",
      "batch 21012, train_loss 35.621571,Time used 0.011000s\n",
      "batch 21013, train_loss 34.810104,Time used 0.011998s\n",
      "batch 21014, train_loss 44.512589,Time used 0.012000s\n",
      "batch 21015, train_loss 25.892717,Time used 0.011003s\n",
      "batch 21016, train_loss 28.109737,Time used 0.011001s\n",
      "batch 21017, train_loss 35.373650,Time used 0.007999s\n",
      "batch 21018, train_loss 37.292313,Time used 0.012002s\n",
      "batch 21019, train_loss 32.504234,Time used 0.007997s\n",
      "batch 21020, train_loss 35.333923,Time used 0.007999s\n",
      "batch 21021, train_loss 39.502834,Time used 0.009000s\n",
      "batch 21022, train_loss 35.772362,Time used 0.007000s\n",
      "batch 21023, train_loss 36.087433,Time used 0.010000s\n",
      "batch 21024, train_loss 41.063362,Time used 0.010001s\n",
      "batch 21025, train_loss 35.775009,Time used 0.012000s\n",
      "batch 21026, train_loss 28.688354,Time used 0.010000s\n",
      "batch 21027, train_loss 33.736938,Time used 0.010001s\n",
      "batch 21028, train_loss 30.730560,Time used 0.010004s\n",
      "batch 21029, train_loss 35.959930,Time used 0.007997s\n",
      "batch 21030, train_loss 34.717503,Time used 0.009998s\n",
      "batch 21031, train_loss 30.099194,Time used 0.008000s\n",
      "batch 21032, train_loss 35.944626,Time used 0.008000s\n",
      "batch 21033, train_loss 36.828991,Time used 0.008000s\n",
      "batch 21034, train_loss 23.622311,Time used 0.008998s\n",
      "batch 21035, train_loss 34.002449,Time used 0.008002s\n",
      "batch 21036, train_loss 31.692368,Time used 0.009000s\n",
      "batch 21037, train_loss 35.863827,Time used 0.010001s\n",
      "batch 21038, train_loss 45.491150,Time used 0.010000s\n",
      "batch 21039, train_loss 29.901684,Time used 0.010998s\n",
      "batch 21040, train_loss 34.971008,Time used 0.011001s\n",
      "batch 21041, train_loss 34.247330,Time used 0.008001s\n",
      "batch 21042, train_loss 42.382999,Time used 0.010997s\n",
      "batch 21043, train_loss 36.774136,Time used 0.011003s\n",
      "batch 21044, train_loss 41.760124,Time used 0.008999s\n",
      "batch 21045, train_loss 39.668316,Time used 0.010000s\n",
      "batch 21046, train_loss 35.019878,Time used 0.011000s\n",
      "batch 21047, train_loss 42.235535,Time used 0.008002s\n",
      "batch 21048, train_loss 36.984566,Time used 0.009997s\n",
      "batch 21049, train_loss 35.232906,Time used 0.010001s\n",
      "batch 21050, train_loss 36.011036,Time used 0.007999s\n",
      "batch 21051, train_loss 35.784348,Time used 0.010001s\n",
      "batch 21052, train_loss 42.313519,Time used 0.009001s\n",
      "batch 21053, train_loss 31.077406,Time used 0.012000s\n",
      "batch 21054, train_loss 27.404022,Time used 0.012000s\n",
      "batch 21055, train_loss 32.250195,Time used 0.009999s\n",
      "batch 21056, train_loss 31.348793,Time used 0.009999s\n",
      "batch 21057, train_loss 30.115646,Time used 0.010000s\n",
      "batch 21058, train_loss 35.689835,Time used 0.011000s\n",
      "batch 21059, train_loss 37.160450,Time used 0.010001s\n",
      "batch 21060, train_loss 33.056217,Time used 0.011998s\n",
      "batch 21061, train_loss 41.679989,Time used 0.007999s\n",
      "batch 21062, train_loss 35.366100,Time used 0.007999s\n",
      "batch 21063, train_loss 34.892597,Time used 0.007004s\n",
      "batch 21064, train_loss 39.814602,Time used 0.007000s\n",
      "batch 21065, train_loss 32.103508,Time used 0.008002s\n",
      "batch 21066, train_loss 42.559139,Time used 0.009997s\n",
      "batch 21067, train_loss 37.229145,Time used 0.009000s\n",
      "batch 21068, train_loss 31.315496,Time used 0.012001s\n",
      "batch 21069, train_loss 37.368141,Time used 0.008000s\n",
      "batch 21070, train_loss 35.865364,Time used 0.008997s\n",
      "batch 21071, train_loss 33.098221,Time used 0.009001s\n",
      "batch 21072, train_loss 37.272232,Time used 0.008002s\n",
      "batch 21073, train_loss 38.955231,Time used 0.008000s\n",
      "batch 21074, train_loss 34.633183,Time used 0.008001s\n",
      "batch 21075, train_loss 32.912334,Time used 0.010000s\n",
      "batch 21076, train_loss 37.375549,Time used 0.008001s\n",
      "batch 21077, train_loss 35.714199,Time used 0.008998s\n",
      "batch 21078, train_loss 31.020365,Time used 0.008000s\n",
      "batch 21079, train_loss 33.412052,Time used 0.009001s\n",
      "batch 21080, train_loss 35.797398,Time used 0.008000s\n",
      "batch 21081, train_loss 34.375977,Time used 0.008000s\n",
      "batch 21082, train_loss 30.745163,Time used 0.008001s\n",
      "batch 21083, train_loss 37.572277,Time used 0.011002s\n",
      "batch 21084, train_loss 42.443958,Time used 0.010003s\n",
      "batch 21085, train_loss 41.620407,Time used 0.010996s\n",
      "batch 21086, train_loss 40.453823,Time used 0.007000s\n",
      "batch 21087, train_loss 35.858894,Time used 0.007002s\n",
      "batch 21088, train_loss 28.587482,Time used 0.007000s\n",
      "batch 21089, train_loss 32.118694,Time used 0.011001s\n",
      "batch 21090, train_loss 28.158293,Time used 0.012001s\n",
      "batch 21091, train_loss 34.100380,Time used 0.007997s\n",
      "batch 21092, train_loss 28.755486,Time used 0.008004s\n",
      "batch 21093, train_loss 32.671238,Time used 0.011000s\n",
      "batch 21094, train_loss 38.386040,Time used 0.010998s\n",
      "batch 21095, train_loss 40.747025,Time used 0.011002s\n",
      "batch 21096, train_loss 38.727581,Time used 0.008997s\n",
      "batch 21097, train_loss 34.111698,Time used 0.008000s\n",
      "batch 21098, train_loss 38.181107,Time used 0.008001s\n",
      "batch 21099, train_loss 40.368279,Time used 0.006999s\n",
      "batch 21100, train_loss 28.219309,Time used 0.008000s\n",
      "***************************test_batch 21100, test_rmse_loss 6.962626,test_mae_loss 2.993397,test_mape_loss 50.807661,Time used 0.038998s\n",
      "batch 21101, train_loss 34.693119,Time used 0.008000s\n",
      "batch 21102, train_loss 41.110821,Time used 0.010000s\n",
      "batch 21103, train_loss 34.862457,Time used 0.007001s\n",
      "batch 21104, train_loss 37.488163,Time used 0.008000s\n",
      "batch 21105, train_loss 33.777653,Time used 0.008000s\n",
      "batch 21106, train_loss 28.044413,Time used 0.009999s\n",
      "batch 21107, train_loss 32.836597,Time used 0.011000s\n",
      "batch 21108, train_loss 33.609509,Time used 0.009001s\n",
      "batch 21109, train_loss 34.705494,Time used 0.007999s\n",
      "batch 21110, train_loss 36.158394,Time used 0.009001s\n",
      "batch 21111, train_loss 40.679466,Time used 0.009000s\n",
      "batch 21112, train_loss 37.661560,Time used 0.011003s\n",
      "batch 21113, train_loss 36.832253,Time used 0.011998s\n",
      "batch 21114, train_loss 37.567177,Time used 0.007998s\n",
      "batch 21115, train_loss 33.681431,Time used 0.010999s\n",
      "batch 21116, train_loss 37.906235,Time used 0.008002s\n",
      "batch 21117, train_loss 32.721386,Time used 0.008997s\n",
      "batch 21118, train_loss 32.643524,Time used 0.010002s\n",
      "batch 21119, train_loss 30.955868,Time used 0.007002s\n",
      "batch 21120, train_loss 35.298645,Time used 0.009000s\n",
      "batch 21121, train_loss 41.946522,Time used 0.011001s\n",
      "batch 21122, train_loss 36.883762,Time used 0.010999s\n",
      "batch 21123, train_loss 33.733059,Time used 0.012001s\n",
      "batch 21124, train_loss 33.334385,Time used 0.012000s\n",
      "batch 21125, train_loss 36.689507,Time used 0.012999s\n",
      "batch 21126, train_loss 36.137630,Time used 0.013002s\n",
      "batch 21127, train_loss 29.305962,Time used 0.011999s\n",
      "batch 21128, train_loss 32.341705,Time used 0.009001s\n",
      "batch 21129, train_loss 35.203392,Time used 0.010999s\n",
      "batch 21130, train_loss 35.317333,Time used 0.011003s\n",
      "batch 21131, train_loss 33.078609,Time used 0.012999s\n",
      "batch 21132, train_loss 37.817993,Time used 0.012000s\n",
      "batch 21133, train_loss 25.438128,Time used 0.011000s\n",
      "batch 21134, train_loss 36.180420,Time used 0.015001s\n",
      "batch 21135, train_loss 27.886475,Time used 0.013000s\n",
      "batch 21136, train_loss 36.426540,Time used 0.013001s\n",
      "batch 21137, train_loss 36.189945,Time used 0.012998s\n",
      "batch 21138, train_loss 43.020588,Time used 0.013001s\n",
      "batch 21139, train_loss 36.644779,Time used 0.010000s\n",
      "batch 21140, train_loss 41.550667,Time used 0.014000s\n",
      "batch 21141, train_loss 39.280876,Time used 0.017004s\n",
      "batch 21142, train_loss 27.393997,Time used 0.026000s\n",
      "batch 21143, train_loss 34.911701,Time used 0.013999s\n",
      "batch 21144, train_loss 36.112289,Time used 0.012000s\n",
      "batch 21145, train_loss 28.268337,Time used 0.012996s\n",
      "batch 21146, train_loss 40.320175,Time used 0.013000s\n",
      "batch 21147, train_loss 31.728453,Time used 0.013000s\n",
      "batch 21148, train_loss 36.924065,Time used 0.014002s\n",
      "batch 21149, train_loss 39.369537,Time used 0.007998s\n",
      "batch 21150, train_loss 32.170479,Time used 0.013002s\n",
      "batch 21151, train_loss 32.927723,Time used 0.011001s\n",
      "batch 21152, train_loss 38.116177,Time used 0.011000s\n",
      "batch 21153, train_loss 39.394951,Time used 0.012001s\n",
      "batch 21154, train_loss 37.877552,Time used 0.011999s\n",
      "batch 21155, train_loss 29.891363,Time used 0.012001s\n",
      "batch 21156, train_loss 35.936794,Time used 0.012999s\n",
      "batch 21157, train_loss 33.369823,Time used 0.011999s\n",
      "batch 21158, train_loss 36.987816,Time used 0.008000s\n",
      "batch 21159, train_loss 36.893696,Time used 0.009001s\n",
      "batch 21160, train_loss 37.870804,Time used 0.008000s\n",
      "batch 21161, train_loss 31.375101,Time used 0.007999s\n",
      "batch 21162, train_loss 43.327187,Time used 0.009001s\n",
      "batch 21163, train_loss 37.587574,Time used 0.011001s\n",
      "batch 21164, train_loss 35.061104,Time used 0.010000s\n",
      "batch 21165, train_loss 29.468018,Time used 0.007999s\n",
      "batch 21166, train_loss 32.294659,Time used 0.008999s\n",
      "batch 21167, train_loss 33.053581,Time used 0.011002s\n",
      "batch 21168, train_loss 31.655434,Time used 0.010000s\n",
      "batch 21169, train_loss 29.156607,Time used 0.010999s\n",
      "batch 21170, train_loss 44.304722,Time used 0.009002s\n",
      "batch 21171, train_loss 32.671963,Time used 0.007999s\n",
      "batch 21172, train_loss 35.869747,Time used 0.009999s\n",
      "batch 21173, train_loss 28.741280,Time used 0.011001s\n",
      "batch 21174, train_loss 33.135811,Time used 0.008003s\n",
      "batch 21175, train_loss 38.572517,Time used 0.010000s\n",
      "batch 21176, train_loss 41.740807,Time used 0.010999s\n",
      "batch 21177, train_loss 43.975563,Time used 0.010998s\n",
      "batch 21178, train_loss 30.845144,Time used 0.008003s\n",
      "batch 21179, train_loss 35.821636,Time used 0.011996s\n",
      "batch 21180, train_loss 35.406292,Time used 0.011002s\n",
      "batch 21181, train_loss 39.399704,Time used 0.008999s\n",
      "batch 21182, train_loss 38.242264,Time used 0.010999s\n",
      "batch 21183, train_loss 34.173267,Time used 0.012000s\n",
      "batch 21184, train_loss 30.527870,Time used 0.007000s\n",
      "batch 21185, train_loss 36.889435,Time used 0.008001s\n",
      "batch 21186, train_loss 39.674801,Time used 0.012000s\n",
      "batch 21187, train_loss 29.266220,Time used 0.011001s\n",
      "batch 21188, train_loss 33.534969,Time used 0.012003s\n",
      "batch 21189, train_loss 33.723667,Time used 0.007995s\n",
      "batch 21190, train_loss 33.421394,Time used 0.009000s\n",
      "batch 21191, train_loss 27.559462,Time used 0.007000s\n",
      "batch 21192, train_loss 34.248238,Time used 0.011000s\n",
      "batch 21193, train_loss 27.794151,Time used 0.009997s\n",
      "batch 21194, train_loss 36.090088,Time used 0.009000s\n",
      "batch 21195, train_loss 35.222141,Time used 0.008000s\n",
      "batch 21196, train_loss 31.515532,Time used 0.008999s\n",
      "batch 21197, train_loss 39.187260,Time used 0.006999s\n",
      "batch 21198, train_loss 38.146446,Time used 0.008001s\n",
      "batch 21199, train_loss 39.547291,Time used 0.008999s\n",
      "batch 21200, train_loss 27.680775,Time used 0.010998s\n",
      "***************************test_batch 21200, test_rmse_loss 6.947768,test_mae_loss 2.990622,test_mape_loss 50.797202,Time used 0.038000s\n",
      "batch 21201, train_loss 43.483967,Time used 0.011004s\n",
      "batch 21202, train_loss 28.515081,Time used 0.007999s\n",
      "batch 21203, train_loss 31.378727,Time used 0.011999s\n",
      "batch 21204, train_loss 42.173561,Time used 0.008003s\n",
      "batch 21205, train_loss 30.564436,Time used 0.010999s\n",
      "batch 21206, train_loss 33.859417,Time used 0.011001s\n",
      "batch 21207, train_loss 34.525948,Time used 0.008998s\n",
      "batch 21208, train_loss 40.332981,Time used 0.007999s\n",
      "batch 21209, train_loss 31.432150,Time used 0.012000s\n",
      "batch 21210, train_loss 33.118206,Time used 0.008001s\n",
      "batch 21211, train_loss 36.856243,Time used 0.009000s\n",
      "batch 21212, train_loss 38.388573,Time used 0.010001s\n",
      "batch 21213, train_loss 31.536324,Time used 0.009000s\n",
      "batch 21214, train_loss 34.358799,Time used 0.007998s\n",
      "batch 21215, train_loss 38.564350,Time used 0.008998s\n",
      "batch 21216, train_loss 35.593761,Time used 0.008000s\n",
      "batch 21217, train_loss 33.381512,Time used 0.011003s\n",
      "batch 21218, train_loss 31.585732,Time used 0.007998s\n",
      "batch 21219, train_loss 49.540535,Time used 0.010999s\n",
      "batch 21220, train_loss 37.732258,Time used 0.010000s\n",
      "batch 21221, train_loss 33.011868,Time used 0.010003s\n",
      "batch 21222, train_loss 32.806286,Time used 0.011001s\n",
      "batch 21223, train_loss 40.481083,Time used 0.007998s\n",
      "batch 21224, train_loss 41.057880,Time used 0.009000s\n",
      "batch 21225, train_loss 28.987373,Time used 0.006998s\n",
      "batch 21226, train_loss 29.506355,Time used 0.012002s\n",
      "batch 21227, train_loss 34.642593,Time used 0.006999s\n",
      "batch 21228, train_loss 25.586927,Time used 0.010999s\n",
      "batch 21229, train_loss 37.752468,Time used 0.015001s\n",
      "batch 21230, train_loss 37.679436,Time used 0.013001s\n",
      "batch 21231, train_loss 31.623356,Time used 0.012001s\n",
      "batch 21232, train_loss 34.683849,Time used 0.012999s\n",
      "batch 21233, train_loss 39.827641,Time used 0.014000s\n",
      "batch 21234, train_loss 28.496828,Time used 0.013000s\n",
      "batch 21235, train_loss 34.298855,Time used 0.014001s\n",
      "batch 21236, train_loss 32.904076,Time used 0.015001s\n",
      "batch 21237, train_loss 35.546082,Time used 0.012997s\n",
      "batch 21238, train_loss 36.541946,Time used 0.015001s\n",
      "batch 21239, train_loss 35.570236,Time used 0.020999s\n",
      "batch 21240, train_loss 35.833752,Time used 0.012000s\n",
      "batch 21241, train_loss 35.988956,Time used 0.013001s\n",
      "batch 21242, train_loss 34.281357,Time used 0.012000s\n",
      "batch 21243, train_loss 29.235214,Time used 0.011998s\n",
      "batch 21244, train_loss 33.903023,Time used 0.011001s\n",
      "batch 21245, train_loss 25.659422,Time used 0.011002s\n",
      "batch 21246, train_loss 32.605976,Time used 0.011997s\n",
      "batch 21247, train_loss 33.734692,Time used 0.012002s\n",
      "batch 21248, train_loss 40.683483,Time used 0.022002s\n",
      "batch 21249, train_loss 36.130020,Time used 0.033999s\n",
      "batch 21250, train_loss 38.439644,Time used 0.015000s\n",
      "batch 21251, train_loss 37.960403,Time used 0.013999s\n",
      "batch 21252, train_loss 31.317362,Time used 0.014000s\n",
      "batch 21253, train_loss 38.395725,Time used 0.015000s\n",
      "batch 21254, train_loss 35.002209,Time used 0.017000s\n",
      "batch 21255, train_loss 34.111595,Time used 0.043002s\n",
      "batch 21256, train_loss 48.325901,Time used 0.036994s\n",
      "batch 21257, train_loss 30.327562,Time used 0.046011s\n",
      "batch 21258, train_loss 41.995869,Time used 0.013987s\n",
      "batch 21259, train_loss 31.443298,Time used 0.019006s\n",
      "batch 21260, train_loss 40.357979,Time used 0.015002s\n",
      "batch 21261, train_loss 33.618797,Time used 0.009993s\n",
      "batch 21262, train_loss 29.033535,Time used 0.011999s\n",
      "batch 21263, train_loss 34.770462,Time used 0.009999s\n",
      "batch 21264, train_loss 30.594025,Time used 0.012999s\n",
      "batch 21265, train_loss 27.808010,Time used 0.013000s\n",
      "batch 21266, train_loss 29.283537,Time used 0.012002s\n",
      "batch 21267, train_loss 32.508278,Time used 0.011001s\n",
      "batch 21268, train_loss 39.633812,Time used 0.010002s\n",
      "batch 21269, train_loss 33.796036,Time used 0.007999s\n",
      "batch 21270, train_loss 38.225861,Time used 0.012002s\n",
      "batch 21271, train_loss 38.509285,Time used 0.010999s\n",
      "batch 21272, train_loss 38.926186,Time used 0.010999s\n",
      "batch 21273, train_loss 36.299770,Time used 0.008000s\n",
      "batch 21274, train_loss 31.402853,Time used 0.011001s\n",
      "batch 21275, train_loss 41.395302,Time used 0.007998s\n",
      "batch 21276, train_loss 38.722557,Time used 0.009000s\n",
      "batch 21277, train_loss 36.529778,Time used 0.012000s\n",
      "batch 21278, train_loss 38.303413,Time used 0.010000s\n",
      "batch 21279, train_loss 30.012325,Time used 0.010001s\n",
      "batch 21280, train_loss 27.236376,Time used 0.010002s\n",
      "batch 21281, train_loss 32.447342,Time used 0.010998s\n",
      "batch 21282, train_loss 31.779621,Time used 0.011001s\n",
      "batch 21283, train_loss 46.135555,Time used 0.009000s\n",
      "batch 21284, train_loss 39.696285,Time used 0.008001s\n",
      "batch 21285, train_loss 33.326088,Time used 0.012000s\n",
      "batch 21286, train_loss 37.400478,Time used 0.010999s\n",
      "batch 21287, train_loss 28.762968,Time used 0.012005s\n",
      "batch 21288, train_loss 28.690216,Time used 0.011997s\n",
      "batch 21289, train_loss 26.326738,Time used 0.010003s\n",
      "batch 21290, train_loss 31.348175,Time used 0.008002s\n",
      "batch 21291, train_loss 32.269146,Time used 0.010002s\n",
      "batch 21292, train_loss 41.607937,Time used 0.007996s\n",
      "batch 21293, train_loss 30.084190,Time used 0.010004s\n",
      "batch 21294, train_loss 30.169928,Time used 0.012004s\n",
      "batch 21295, train_loss 40.934223,Time used 0.011996s\n",
      "batch 21296, train_loss 33.165707,Time used 0.012001s\n",
      "batch 21297, train_loss 44.791985,Time used 0.011001s\n",
      "batch 21298, train_loss 32.962475,Time used 0.010999s\n",
      "batch 21299, train_loss 28.077709,Time used 0.009000s\n",
      "batch 21300, train_loss 27.122234,Time used 0.012001s\n",
      "***************************test_batch 21300, test_rmse_loss 6.946026,test_mae_loss 2.985937,test_mape_loss 50.532301,Time used 0.038001s\n",
      "batch 21301, train_loss 38.412449,Time used 0.008998s\n",
      "batch 21302, train_loss 43.596741,Time used 0.012001s\n",
      "batch 21303, train_loss 37.909275,Time used 0.007999s\n",
      "batch 21304, train_loss 33.578766,Time used 0.009004s\n",
      "batch 21305, train_loss 20.980043,Time used 0.008996s\n",
      "batch 21306, train_loss 39.255547,Time used 0.008002s\n",
      "batch 21307, train_loss 33.149841,Time used 0.008998s\n",
      "batch 21308, train_loss 39.738605,Time used 0.010999s\n",
      "batch 21309, train_loss 40.369972,Time used 0.010000s\n",
      "batch 21310, train_loss 41.188736,Time used 0.008005s\n",
      "batch 21311, train_loss 31.503502,Time used 0.010997s\n",
      "batch 21312, train_loss 37.561226,Time used 0.008000s\n",
      "batch 21313, train_loss 35.099342,Time used 0.008996s\n",
      "batch 21314, train_loss 31.072683,Time used 0.008000s\n",
      "batch 21315, train_loss 34.496143,Time used 0.009000s\n",
      "batch 21316, train_loss 34.934994,Time used 0.011000s\n",
      "batch 21317, train_loss 38.458656,Time used 0.012001s\n",
      "batch 21318, train_loss 32.041725,Time used 0.010999s\n",
      "batch 21319, train_loss 30.683279,Time used 0.012000s\n",
      "batch 21320, train_loss 33.155712,Time used 0.014000s\n",
      "batch 21321, train_loss 36.707123,Time used 0.013996s\n",
      "batch 21322, train_loss 35.278004,Time used 0.013998s\n",
      "batch 21323, train_loss 28.406178,Time used 0.011001s\n",
      "batch 21324, train_loss 35.000755,Time used 0.010000s\n",
      "batch 21325, train_loss 41.619457,Time used 0.009999s\n",
      "batch 21326, train_loss 43.848507,Time used 0.012002s\n",
      "batch 21327, train_loss 31.466274,Time used 0.011002s\n",
      "batch 21328, train_loss 35.090897,Time used 0.010000s\n",
      "batch 21329, train_loss 32.664223,Time used 0.011999s\n",
      "batch 21330, train_loss 32.765060,Time used 0.011002s\n",
      "batch 21331, train_loss 34.906284,Time used 0.015000s\n",
      "batch 21332, train_loss 31.309340,Time used 0.018999s\n",
      "batch 21333, train_loss 31.944002,Time used 0.013998s\n",
      "batch 21334, train_loss 40.498505,Time used 0.012000s\n",
      "batch 21335, train_loss 35.174408,Time used 0.015002s\n",
      "batch 21336, train_loss 38.708698,Time used 0.013012s\n",
      "batch 21337, train_loss 31.131090,Time used 0.013000s\n",
      "batch 21338, train_loss 39.021301,Time used 0.011001s\n",
      "batch 21339, train_loss 34.803379,Time used 0.012017s\n",
      "batch 21340, train_loss 33.667889,Time used 0.013001s\n",
      "batch 21341, train_loss 34.207169,Time used 0.014999s\n",
      "batch 21342, train_loss 33.134220,Time used 0.012001s\n",
      "batch 21343, train_loss 31.116936,Time used 0.011996s\n",
      "batch 21344, train_loss 29.529171,Time used 0.012006s\n",
      "batch 21345, train_loss 40.742367,Time used 0.007995s\n",
      "batch 21346, train_loss 31.277821,Time used 0.010006s\n",
      "batch 21347, train_loss 36.609268,Time used 0.011994s\n",
      "batch 21348, train_loss 37.381561,Time used 0.013001s\n",
      "batch 21349, train_loss 33.440460,Time used 0.009998s\n",
      "batch 21350, train_loss 34.480526,Time used 0.008999s\n",
      "batch 21351, train_loss 37.790020,Time used 0.009002s\n",
      "batch 21352, train_loss 32.597225,Time used 0.009001s\n",
      "batch 21353, train_loss 37.451649,Time used 0.008999s\n",
      "batch 21354, train_loss 33.976288,Time used 0.008000s\n",
      "batch 21355, train_loss 35.989754,Time used 0.008000s\n",
      "batch 21356, train_loss 37.106888,Time used 0.010001s\n",
      "batch 21357, train_loss 35.968090,Time used 0.008001s\n",
      "batch 21358, train_loss 32.341774,Time used 0.010999s\n",
      "batch 21359, train_loss 33.747368,Time used 0.015998s\n",
      "batch 21360, train_loss 36.650478,Time used 0.013002s\n",
      "batch 21361, train_loss 36.995007,Time used 0.011998s\n",
      "batch 21362, train_loss 30.625435,Time used 0.013003s\n",
      "batch 21363, train_loss 36.417397,Time used 0.012997s\n",
      "batch 21364, train_loss 31.400206,Time used 0.013000s\n",
      "batch 21365, train_loss 34.106956,Time used 0.013000s\n",
      "batch 21366, train_loss 34.472027,Time used 0.012999s\n",
      "batch 21367, train_loss 40.088207,Time used 0.012001s\n",
      "batch 21368, train_loss 39.019604,Time used 0.014000s\n",
      "batch 21369, train_loss 35.463257,Time used 0.012997s\n",
      "batch 21370, train_loss 37.247093,Time used 0.012000s\n",
      "batch 21371, train_loss 37.320499,Time used 0.011002s\n",
      "batch 21372, train_loss 37.668640,Time used 0.011000s\n",
      "batch 21373, train_loss 36.013630,Time used 0.010998s\n",
      "batch 21374, train_loss 28.136358,Time used 0.012003s\n",
      "batch 21375, train_loss 41.256382,Time used 0.013001s\n",
      "batch 21376, train_loss 34.062714,Time used 0.013002s\n",
      "batch 21377, train_loss 35.017662,Time used 0.010999s\n",
      "batch 21378, train_loss 31.680969,Time used 0.013001s\n",
      "batch 21379, train_loss 28.214279,Time used 0.013998s\n",
      "batch 21380, train_loss 31.511158,Time used 0.015000s\n",
      "batch 21381, train_loss 37.163086,Time used 0.022999s\n",
      "batch 21382, train_loss 38.278538,Time used 0.013999s\n",
      "batch 21383, train_loss 30.809620,Time used 0.012999s\n",
      "batch 21384, train_loss 29.979792,Time used 0.012001s\n",
      "batch 21385, train_loss 43.948280,Time used 0.010998s\n",
      "batch 21386, train_loss 28.492813,Time used 0.009003s\n",
      "batch 21387, train_loss 42.983059,Time used 0.013005s\n",
      "batch 21388, train_loss 35.431942,Time used 0.010999s\n",
      "batch 21389, train_loss 34.570232,Time used 0.013000s\n",
      "batch 21390, train_loss 32.305916,Time used 0.014002s\n",
      "batch 21391, train_loss 35.875599,Time used 0.011000s\n",
      "batch 21392, train_loss 40.435249,Time used 0.013001s\n",
      "batch 21393, train_loss 33.406410,Time used 0.014001s\n",
      "batch 21394, train_loss 44.507381,Time used 0.010998s\n",
      "batch 21395, train_loss 29.065258,Time used 0.010001s\n",
      "batch 21396, train_loss 27.148630,Time used 0.011998s\n",
      "batch 21397, train_loss 39.706772,Time used 0.013001s\n",
      "batch 21398, train_loss 30.498852,Time used 0.009002s\n",
      "batch 21399, train_loss 31.702221,Time used 0.012998s\n",
      "batch 21400, train_loss 34.899605,Time used 0.008000s\n",
      "***************************test_batch 21400, test_rmse_loss 6.933637,test_mae_loss 2.979845,test_mape_loss 50.415342,Time used 0.044001s\n",
      "batch 21401, train_loss 36.692188,Time used 0.008997s\n",
      "batch 21402, train_loss 38.624187,Time used 0.013000s\n",
      "batch 21403, train_loss 29.270330,Time used 0.009999s\n",
      "batch 21404, train_loss 27.491085,Time used 0.010001s\n",
      "batch 21405, train_loss 30.299629,Time used 0.011002s\n",
      "batch 21406, train_loss 37.134533,Time used 0.010002s\n",
      "batch 21407, train_loss 34.980793,Time used 0.010003s\n",
      "batch 21408, train_loss 32.818913,Time used 0.008996s\n",
      "batch 21409, train_loss 38.105373,Time used 0.007998s\n",
      "batch 21410, train_loss 31.811680,Time used 0.012000s\n",
      "batch 21411, train_loss 27.739868,Time used 0.010002s\n",
      "batch 21412, train_loss 36.936432,Time used 0.011999s\n",
      "batch 21413, train_loss 35.500595,Time used 0.012000s\n",
      "batch 21414, train_loss 36.390919,Time used 0.010998s\n",
      "batch 21415, train_loss 33.379704,Time used 0.008001s\n",
      "batch 21416, train_loss 40.165298,Time used 0.008008s\n",
      "batch 21417, train_loss 34.557011,Time used 0.011993s\n",
      "batch 21418, train_loss 27.807867,Time used 0.010999s\n",
      "batch 21419, train_loss 35.828438,Time used 0.011000s\n",
      "batch 21420, train_loss 38.313065,Time used 0.010000s\n",
      "batch 21421, train_loss 34.345581,Time used 0.011999s\n",
      "batch 21422, train_loss 35.239063,Time used 0.010002s\n",
      "batch 21423, train_loss 32.672600,Time used 0.009999s\n",
      "batch 21424, train_loss 35.954380,Time used 0.011000s\n",
      "batch 21425, train_loss 32.532471,Time used 0.012000s\n",
      "batch 21426, train_loss 39.545155,Time used 0.012001s\n",
      "batch 21427, train_loss 37.433449,Time used 0.012002s\n",
      "batch 21428, train_loss 35.538929,Time used 0.007997s\n",
      "batch 21429, train_loss 28.430048,Time used 0.008000s\n",
      "batch 21430, train_loss 32.670696,Time used 0.008000s\n",
      "batch 21431, train_loss 32.238438,Time used 0.009997s\n",
      "batch 21432, train_loss 38.132256,Time used 0.008002s\n",
      "batch 21433, train_loss 38.430126,Time used 0.009000s\n",
      "batch 21434, train_loss 29.658970,Time used 0.008999s\n",
      "batch 21435, train_loss 31.169945,Time used 0.009001s\n",
      "batch 21436, train_loss 30.581467,Time used 0.012001s\n",
      "batch 21437, train_loss 31.365227,Time used 0.008001s\n",
      "batch 21438, train_loss 35.888813,Time used 0.007998s\n",
      "batch 21439, train_loss 35.686478,Time used 0.008001s\n",
      "batch 21440, train_loss 37.766979,Time used 0.011998s\n",
      "batch 21441, train_loss 30.952549,Time used 0.012002s\n",
      "batch 21442, train_loss 32.715805,Time used 0.009001s\n",
      "batch 21443, train_loss 41.004070,Time used 0.009999s\n",
      "batch 21444, train_loss 35.770813,Time used 0.009000s\n",
      "batch 21445, train_loss 30.130863,Time used 0.009998s\n",
      "batch 21446, train_loss 28.508724,Time used 0.011002s\n",
      "batch 21447, train_loss 31.712553,Time used 0.011001s\n",
      "batch 21448, train_loss 36.963867,Time used 0.007998s\n",
      "batch 21449, train_loss 35.039776,Time used 0.012999s\n",
      "batch 21450, train_loss 34.298344,Time used 0.011999s\n",
      "batch 21451, train_loss 35.938805,Time used 0.008003s\n",
      "batch 21452, train_loss 41.489483,Time used 0.008000s\n",
      "batch 21453, train_loss 32.971523,Time used 0.010000s\n",
      "batch 21454, train_loss 34.154018,Time used 0.007002s\n",
      "batch 21455, train_loss 39.263233,Time used 0.006996s\n",
      "batch 21456, train_loss 38.926258,Time used 0.012001s\n",
      "batch 21457, train_loss 39.629486,Time used 0.009000s\n",
      "batch 21458, train_loss 39.999832,Time used 0.008000s\n",
      "batch 21459, train_loss 33.600502,Time used 0.009001s\n",
      "batch 21460, train_loss 29.821096,Time used 0.008000s\n",
      "batch 21461, train_loss 29.005438,Time used 0.008999s\n",
      "batch 21462, train_loss 35.998737,Time used 0.013002s\n",
      "batch 21463, train_loss 31.121988,Time used 0.011998s\n",
      "batch 21464, train_loss 35.322155,Time used 0.011999s\n",
      "batch 21465, train_loss 30.668697,Time used 0.009000s\n",
      "batch 21466, train_loss 36.379486,Time used 0.009991s\n",
      "batch 21467, train_loss 37.781204,Time used 0.014003s\n",
      "batch 21468, train_loss 29.503241,Time used 0.008999s\n",
      "batch 21469, train_loss 26.771715,Time used 0.009998s\n",
      "batch 21470, train_loss 33.786888,Time used 0.010999s\n",
      "batch 21471, train_loss 26.815388,Time used 0.011001s\n",
      "batch 21472, train_loss 36.521027,Time used 0.012002s\n",
      "batch 21473, train_loss 36.546383,Time used 0.011000s\n",
      "batch 21474, train_loss 35.978710,Time used 0.017998s\n",
      "batch 21475, train_loss 35.018394,Time used 0.013000s\n",
      "batch 21476, train_loss 36.814892,Time used 0.013001s\n",
      "batch 21477, train_loss 38.449009,Time used 0.011003s\n",
      "batch 21478, train_loss 42.500080,Time used 0.014998s\n",
      "batch 21479, train_loss 36.495819,Time used 0.013000s\n",
      "batch 21480, train_loss 34.738140,Time used 0.012002s\n",
      "batch 21481, train_loss 29.170288,Time used 0.014002s\n",
      "batch 21482, train_loss 30.458826,Time used 0.015999s\n",
      "batch 21483, train_loss 40.330082,Time used 0.022999s\n",
      "batch 21484, train_loss 44.763016,Time used 0.012000s\n",
      "batch 21485, train_loss 31.530872,Time used 0.011000s\n",
      "batch 21486, train_loss 29.886549,Time used 0.008999s\n",
      "batch 21487, train_loss 29.371540,Time used 0.013002s\n",
      "batch 21488, train_loss 35.568745,Time used 0.012999s\n",
      "batch 21489, train_loss 28.957684,Time used 0.013000s\n",
      "batch 21490, train_loss 27.902134,Time used 0.013001s\n",
      "batch 21491, train_loss 29.065231,Time used 0.009997s\n",
      "batch 21492, train_loss 44.436478,Time used 0.011003s\n",
      "batch 21493, train_loss 39.729282,Time used 0.012000s\n",
      "batch 21494, train_loss 32.779686,Time used 0.008002s\n",
      "batch 21495, train_loss 36.319988,Time used 0.010997s\n",
      "batch 21496, train_loss 31.323568,Time used 0.014002s\n",
      "batch 21497, train_loss 39.526062,Time used 0.012002s\n",
      "batch 21498, train_loss 35.718449,Time used 0.012998s\n",
      "batch 21499, train_loss 36.933109,Time used 0.012999s\n",
      "batch 21500, train_loss 34.129295,Time used 0.010002s\n",
      "***************************test_batch 21500, test_rmse_loss 6.911179,test_mae_loss 2.976868,test_mape_loss 50.549486,Time used 0.042001s\n",
      "batch 21501, train_loss 28.251945,Time used 0.010000s\n",
      "batch 21502, train_loss 35.074749,Time used 0.011999s\n",
      "batch 21503, train_loss 38.838928,Time used 0.013003s\n",
      "batch 21504, train_loss 38.488071,Time used 0.009990s\n",
      "batch 21505, train_loss 29.856663,Time used 0.010000s\n",
      "batch 21506, train_loss 30.268185,Time used 0.007999s\n",
      "batch 21507, train_loss 33.672485,Time used 0.010999s\n",
      "batch 21508, train_loss 35.373314,Time used 0.011001s\n",
      "batch 21509, train_loss 33.836494,Time used 0.008001s\n",
      "batch 21510, train_loss 33.019333,Time used 0.010001s\n",
      "batch 21511, train_loss 44.567852,Time used 0.011002s\n",
      "batch 21512, train_loss 35.889126,Time used 0.006999s\n",
      "batch 21513, train_loss 31.809473,Time used 0.010001s\n",
      "batch 21514, train_loss 38.410206,Time used 0.010000s\n",
      "batch 21515, train_loss 38.852589,Time used 0.008000s\n",
      "batch 21516, train_loss 31.667114,Time used 0.007001s\n",
      "batch 21517, train_loss 33.422577,Time used 0.007998s\n",
      "batch 21518, train_loss 37.088852,Time used 0.008002s\n",
      "batch 21519, train_loss 31.000664,Time used 0.007999s\n",
      "batch 21520, train_loss 29.750141,Time used 0.008000s\n",
      "batch 21521, train_loss 33.342438,Time used 0.012001s\n",
      "batch 21522, train_loss 34.397717,Time used 0.009998s\n",
      "batch 21523, train_loss 29.651066,Time used 0.011002s\n",
      "batch 21524, train_loss 35.231239,Time used 0.011000s\n",
      "batch 21525, train_loss 36.998127,Time used 0.009999s\n",
      "batch 21526, train_loss 41.216755,Time used 0.009001s\n",
      "batch 21527, train_loss 32.202644,Time used 0.008999s\n",
      "batch 21528, train_loss 35.812271,Time used 0.008001s\n",
      "batch 21529, train_loss 38.112724,Time used 0.008001s\n",
      "batch 21530, train_loss 40.165352,Time used 0.008000s\n",
      "batch 21531, train_loss 32.820080,Time used 0.008998s\n",
      "batch 21532, train_loss 36.419758,Time used 0.007001s\n",
      "batch 21533, train_loss 28.645350,Time used 0.007000s\n",
      "batch 21534, train_loss 30.941236,Time used 0.007007s\n",
      "batch 21535, train_loss 38.293507,Time used 0.008001s\n",
      "batch 21536, train_loss 34.360058,Time used 0.008000s\n",
      "batch 21537, train_loss 35.491695,Time used 0.010000s\n",
      "batch 21538, train_loss 37.342495,Time used 0.008000s\n",
      "batch 21539, train_loss 32.276260,Time used 0.008000s\n",
      "batch 21540, train_loss 33.721565,Time used 0.008001s\n",
      "batch 21541, train_loss 33.218750,Time used 0.008999s\n",
      "batch 21542, train_loss 32.909157,Time used 0.010000s\n",
      "batch 21543, train_loss 36.990852,Time used 0.007998s\n",
      "batch 21544, train_loss 32.410763,Time used 0.009998s\n",
      "batch 21545, train_loss 40.385323,Time used 0.008000s\n",
      "batch 21546, train_loss 38.019741,Time used 0.008000s\n",
      "batch 21547, train_loss 33.086666,Time used 0.008002s\n",
      "batch 21548, train_loss 23.331129,Time used 0.009000s\n",
      "batch 21549, train_loss 31.081785,Time used 0.008999s\n",
      "batch 21550, train_loss 31.277325,Time used 0.010000s\n",
      "batch 21551, train_loss 32.831905,Time used 0.009003s\n",
      "batch 21552, train_loss 42.571968,Time used 0.012997s\n",
      "batch 21553, train_loss 35.636822,Time used 0.011000s\n",
      "batch 21554, train_loss 33.509666,Time used 0.008000s\n",
      "batch 21555, train_loss 32.497719,Time used 0.010000s\n",
      "batch 21556, train_loss 33.138638,Time used 0.012001s\n",
      "batch 21557, train_loss 36.071411,Time used 0.011999s\n",
      "batch 21558, train_loss 35.207405,Time used 0.011999s\n",
      "batch 21559, train_loss 31.552578,Time used 0.013001s\n",
      "batch 21560, train_loss 30.599834,Time used 0.012001s\n",
      "batch 21561, train_loss 40.312870,Time used 0.013000s\n",
      "batch 21562, train_loss 30.066729,Time used 0.012001s\n",
      "batch 21563, train_loss 34.885998,Time used 0.009000s\n",
      "batch 21564, train_loss 35.170166,Time used 0.014001s\n",
      "batch 21565, train_loss 36.094017,Time used 0.011998s\n",
      "batch 21566, train_loss 28.988592,Time used 0.012000s\n",
      "batch 21567, train_loss 37.515305,Time used 0.013001s\n",
      "batch 21568, train_loss 33.540474,Time used 0.012997s\n",
      "batch 21569, train_loss 43.353928,Time used 0.011000s\n",
      "batch 21570, train_loss 30.122011,Time used 0.012002s\n",
      "batch 21571, train_loss 33.438713,Time used 0.012000s\n",
      "batch 21572, train_loss 31.527653,Time used 0.011998s\n",
      "batch 21573, train_loss 30.915371,Time used 0.015002s\n",
      "batch 21574, train_loss 32.822212,Time used 0.025000s\n",
      "batch 21575, train_loss 41.436989,Time used 0.015002s\n",
      "batch 21576, train_loss 36.908821,Time used 0.015998s\n",
      "batch 21577, train_loss 29.781298,Time used 0.010999s\n",
      "batch 21578, train_loss 29.997438,Time used 0.011001s\n",
      "batch 21579, train_loss 31.879908,Time used 0.013000s\n",
      "batch 21580, train_loss 35.367592,Time used 0.012999s\n",
      "batch 21581, train_loss 34.241962,Time used 0.013000s\n",
      "batch 21582, train_loss 35.005745,Time used 0.013000s\n",
      "batch 21583, train_loss 34.045380,Time used 0.013001s\n",
      "batch 21584, train_loss 29.668814,Time used 0.011999s\n",
      "batch 21585, train_loss 40.699142,Time used 0.012003s\n",
      "batch 21586, train_loss 34.146511,Time used 0.011001s\n",
      "batch 21587, train_loss 36.549644,Time used 0.012998s\n",
      "batch 21588, train_loss 37.716270,Time used 0.010999s\n",
      "batch 21589, train_loss 32.732338,Time used 0.010001s\n",
      "batch 21590, train_loss 30.938421,Time used 0.012000s\n",
      "batch 21591, train_loss 35.400715,Time used 0.010000s\n",
      "batch 21592, train_loss 32.249657,Time used 0.011001s\n",
      "batch 21593, train_loss 33.328060,Time used 0.010002s\n",
      "batch 21594, train_loss 32.523117,Time used 0.010997s\n",
      "batch 21595, train_loss 37.735043,Time used 0.011002s\n",
      "batch 21596, train_loss 40.238865,Time used 0.007998s\n",
      "batch 21597, train_loss 34.381824,Time used 0.013001s\n",
      "batch 21598, train_loss 33.895947,Time used 0.012000s\n",
      "batch 21599, train_loss 35.628117,Time used 0.012001s\n",
      "batch 21600, train_loss 36.225384,Time used 0.009000s\n",
      "***************************test_batch 21600, test_rmse_loss 6.902313,test_mae_loss 2.976249,test_mape_loss 50.622783,Time used 0.033000s\n",
      "batch 21601, train_loss 26.260750,Time used 0.007999s\n",
      "batch 21602, train_loss 34.512505,Time used 0.008999s\n",
      "batch 21603, train_loss 30.327011,Time used 0.009001s\n",
      "batch 21604, train_loss 35.570805,Time used 0.007999s\n",
      "batch 21605, train_loss 27.960917,Time used 0.007004s\n",
      "batch 21606, train_loss 39.559181,Time used 0.007998s\n",
      "batch 21607, train_loss 36.532734,Time used 0.008999s\n",
      "batch 21608, train_loss 35.394478,Time used 0.008000s\n",
      "batch 21609, train_loss 37.251373,Time used 0.008000s\n",
      "batch 21610, train_loss 31.174244,Time used 0.008000s\n",
      "batch 21611, train_loss 27.805593,Time used 0.009000s\n",
      "batch 21612, train_loss 32.554588,Time used 0.008000s\n",
      "batch 21613, train_loss 39.516602,Time used 0.010001s\n",
      "batch 21614, train_loss 34.423710,Time used 0.011998s\n",
      "batch 21615, train_loss 31.100847,Time used 0.012000s\n",
      "batch 21616, train_loss 41.967606,Time used 0.007000s\n",
      "batch 21617, train_loss 31.539822,Time used 0.009001s\n",
      "batch 21618, train_loss 40.322975,Time used 0.007999s\n",
      "batch 21619, train_loss 35.574043,Time used 0.011999s\n",
      "batch 21620, train_loss 36.341366,Time used 0.011001s\n",
      "batch 21621, train_loss 31.146238,Time used 0.009000s\n",
      "batch 21622, train_loss 40.509186,Time used 0.009001s\n",
      "batch 21623, train_loss 34.841862,Time used 0.011999s\n",
      "batch 21624, train_loss 30.957603,Time used 0.009000s\n",
      "batch 21625, train_loss 31.266893,Time used 0.008999s\n",
      "batch 21626, train_loss 25.119535,Time used 0.008000s\n",
      "batch 21627, train_loss 36.231808,Time used 0.008002s\n",
      "batch 21628, train_loss 35.326801,Time used 0.007998s\n",
      "batch 21629, train_loss 33.561226,Time used 0.007998s\n",
      "batch 21630, train_loss 38.228771,Time used 0.008001s\n",
      "batch 21631, train_loss 32.895435,Time used 0.011001s\n",
      "batch 21632, train_loss 34.893559,Time used 0.011001s\n",
      "batch 21633, train_loss 31.469526,Time used 0.012001s\n",
      "batch 21634, train_loss 28.527611,Time used 0.010998s\n",
      "batch 21635, train_loss 31.296228,Time used 0.011001s\n",
      "batch 21636, train_loss 39.077114,Time used 0.011001s\n",
      "batch 21637, train_loss 35.747940,Time used 0.011000s\n",
      "batch 21638, train_loss 41.595409,Time used 0.013001s\n",
      "batch 21639, train_loss 33.784100,Time used 0.010998s\n",
      "batch 21640, train_loss 27.820368,Time used 0.012001s\n",
      "batch 21641, train_loss 35.006184,Time used 0.010000s\n",
      "batch 21642, train_loss 27.384119,Time used 0.012003s\n",
      "batch 21643, train_loss 37.181404,Time used 0.013000s\n",
      "batch 21644, train_loss 33.666073,Time used 0.011998s\n",
      "batch 21645, train_loss 38.856926,Time used 0.012001s\n",
      "batch 21646, train_loss 36.834164,Time used 0.016999s\n",
      "batch 21647, train_loss 37.248417,Time used 0.013001s\n",
      "batch 21648, train_loss 39.819714,Time used 0.012002s\n",
      "batch 21649, train_loss 37.897575,Time used 0.012998s\n",
      "batch 21650, train_loss 31.609652,Time used 0.010999s\n",
      "batch 21651, train_loss 29.521452,Time used 0.014003s\n",
      "batch 21652, train_loss 34.988373,Time used 0.025999s\n",
      "batch 21653, train_loss 36.335701,Time used 0.012999s\n",
      "batch 21654, train_loss 44.360939,Time used 0.012999s\n",
      "batch 21655, train_loss 29.121302,Time used 0.012001s\n",
      "batch 21656, train_loss 33.547176,Time used 0.011999s\n",
      "batch 21657, train_loss 30.006079,Time used 0.011000s\n",
      "batch 21658, train_loss 48.385174,Time used 0.010001s\n",
      "batch 21659, train_loss 38.504719,Time used 0.014001s\n",
      "batch 21660, train_loss 36.434330,Time used 0.013002s\n",
      "batch 21661, train_loss 33.067081,Time used 0.011996s\n",
      "batch 21662, train_loss 37.985954,Time used 0.012002s\n",
      "batch 21663, train_loss 33.510387,Time used 0.012998s\n",
      "batch 21664, train_loss 28.127752,Time used 0.013002s\n",
      "batch 21665, train_loss 38.534554,Time used 0.016998s\n",
      "batch 21666, train_loss 32.817074,Time used 0.011001s\n",
      "batch 21667, train_loss 32.763737,Time used 0.010998s\n",
      "batch 21668, train_loss 31.570103,Time used 0.013000s\n",
      "batch 21669, train_loss 32.206146,Time used 0.009000s\n",
      "batch 21670, train_loss 32.937588,Time used 0.009001s\n",
      "batch 21671, train_loss 29.702614,Time used 0.008001s\n",
      "batch 21672, train_loss 27.251205,Time used 0.010997s\n",
      "batch 21673, train_loss 35.480293,Time used 0.007999s\n",
      "batch 21674, train_loss 32.097034,Time used 0.008002s\n",
      "batch 21675, train_loss 33.122169,Time used 0.007999s\n",
      "batch 21676, train_loss 42.670227,Time used 0.009001s\n",
      "batch 21677, train_loss 37.498528,Time used 0.011997s\n",
      "batch 21678, train_loss 29.164328,Time used 0.012001s\n",
      "batch 21679, train_loss 25.854616,Time used 0.013000s\n",
      "batch 21680, train_loss 31.616417,Time used 0.009002s\n",
      "batch 21681, train_loss 33.312340,Time used 0.007998s\n",
      "batch 21682, train_loss 36.451275,Time used 0.007998s\n",
      "batch 21683, train_loss 33.923244,Time used 0.007002s\n",
      "batch 21684, train_loss 38.304337,Time used 0.009999s\n",
      "batch 21685, train_loss 28.514187,Time used 0.010997s\n",
      "batch 21686, train_loss 33.657669,Time used 0.010000s\n",
      "batch 21687, train_loss 30.569456,Time used 0.010001s\n",
      "batch 21688, train_loss 30.094473,Time used 0.008999s\n",
      "batch 21689, train_loss 31.515686,Time used 0.011000s\n",
      "batch 21690, train_loss 31.379610,Time used 0.010002s\n",
      "batch 21691, train_loss 30.573730,Time used 0.007999s\n",
      "batch 21692, train_loss 36.304455,Time used 0.007999s\n",
      "batch 21693, train_loss 37.079460,Time used 0.010001s\n",
      "batch 21694, train_loss 34.738228,Time used 0.010001s\n",
      "batch 21695, train_loss 37.066570,Time used 0.010001s\n",
      "batch 21696, train_loss 50.158566,Time used 0.013000s\n",
      "batch 21697, train_loss 34.154369,Time used 0.012999s\n",
      "batch 21698, train_loss 28.571163,Time used 0.009000s\n",
      "batch 21699, train_loss 39.581333,Time used 0.009001s\n",
      "batch 21700, train_loss 34.433804,Time used 0.009998s\n",
      "***************************test_batch 21700, test_rmse_loss 6.899686,test_mae_loss 2.973310,test_mape_loss 50.285398,Time used 0.036036s\n",
      "batch 21701, train_loss 35.014854,Time used 0.011003s\n",
      "batch 21702, train_loss 31.455584,Time used 0.009964s\n",
      "batch 21703, train_loss 29.934885,Time used 0.009006s\n",
      "batch 21704, train_loss 32.225651,Time used 0.009995s\n",
      "batch 21705, train_loss 34.867508,Time used 0.010001s\n",
      "batch 21706, train_loss 33.780441,Time used 0.008039s\n",
      "batch 21707, train_loss 32.332867,Time used 0.008994s\n",
      "batch 21708, train_loss 30.639250,Time used 0.007966s\n",
      "batch 21709, train_loss 32.308624,Time used 0.009999s\n",
      "batch 21710, train_loss 33.014507,Time used 0.010003s\n",
      "batch 21711, train_loss 41.812237,Time used 0.007999s\n",
      "batch 21712, train_loss 36.905518,Time used 0.008000s\n",
      "batch 21713, train_loss 26.246937,Time used 0.011997s\n",
      "batch 21714, train_loss 38.031258,Time used 0.009000s\n",
      "batch 21715, train_loss 40.479000,Time used 0.009001s\n",
      "batch 21716, train_loss 33.094452,Time used 0.010001s\n",
      "batch 21717, train_loss 42.448814,Time used 0.011004s\n",
      "batch 21718, train_loss 34.565193,Time used 0.011001s\n",
      "batch 21719, train_loss 25.730768,Time used 0.007997s\n",
      "batch 21720, train_loss 38.047630,Time used 0.008001s\n",
      "batch 21721, train_loss 34.977322,Time used 0.008001s\n",
      "batch 21722, train_loss 38.793526,Time used 0.009996s\n",
      "batch 21723, train_loss 36.419159,Time used 0.007003s\n",
      "batch 21724, train_loss 31.983206,Time used 0.008001s\n",
      "batch 21725, train_loss 33.916065,Time used 0.010000s\n",
      "batch 21726, train_loss 35.645706,Time used 0.011999s\n",
      "batch 21727, train_loss 38.293858,Time used 0.007996s\n",
      "batch 21728, train_loss 28.737972,Time used 0.008001s\n",
      "batch 21729, train_loss 26.222319,Time used 0.008004s\n",
      "batch 21730, train_loss 34.886688,Time used 0.008999s\n",
      "batch 21731, train_loss 41.174603,Time used 0.008001s\n",
      "batch 21732, train_loss 41.991623,Time used 0.008001s\n",
      "batch 21733, train_loss 25.804337,Time used 0.007995s\n",
      "batch 21734, train_loss 28.502728,Time used 0.011002s\n",
      "batch 21735, train_loss 41.401760,Time used 0.008998s\n",
      "batch 21736, train_loss 29.860359,Time used 0.011004s\n",
      "batch 21737, train_loss 33.191353,Time used 0.009997s\n",
      "batch 21738, train_loss 35.965355,Time used 0.008000s\n",
      "batch 21739, train_loss 33.764103,Time used 0.009002s\n",
      "batch 21740, train_loss 29.913198,Time used 0.010996s\n",
      "batch 21741, train_loss 36.743626,Time used 0.011001s\n",
      "batch 21742, train_loss 36.704689,Time used 0.008998s\n",
      "batch 21743, train_loss 28.804409,Time used 0.011004s\n",
      "batch 21744, train_loss 34.556637,Time used 0.007998s\n",
      "batch 21745, train_loss 37.886028,Time used 0.007993s\n",
      "batch 21746, train_loss 35.352425,Time used 0.008999s\n",
      "batch 21747, train_loss 33.336750,Time used 0.011000s\n",
      "batch 21748, train_loss 29.587818,Time used 0.011999s\n",
      "batch 21749, train_loss 34.186096,Time used 0.012001s\n",
      "batch 21750, train_loss 29.547201,Time used 0.011002s\n",
      "batch 21751, train_loss 42.174595,Time used 0.007998s\n",
      "batch 21752, train_loss 36.636337,Time used 0.008999s\n",
      "batch 21753, train_loss 31.490873,Time used 0.012002s\n",
      "batch 21754, train_loss 32.809105,Time used 0.007999s\n",
      "batch 21755, train_loss 38.067036,Time used 0.012000s\n",
      "batch 21756, train_loss 37.977581,Time used 0.008001s\n",
      "batch 21757, train_loss 32.734493,Time used 0.009000s\n",
      "batch 21758, train_loss 31.868687,Time used 0.007999s\n",
      "batch 21759, train_loss 33.481190,Time used 0.010000s\n",
      "batch 21760, train_loss 34.066124,Time used 0.011001s\n",
      "batch 21761, train_loss 40.102856,Time used 0.007998s\n",
      "batch 21762, train_loss 29.554388,Time used 0.008001s\n",
      "batch 21763, train_loss 34.853939,Time used 0.008000s\n",
      "batch 21764, train_loss 37.743637,Time used 0.010000s\n",
      "batch 21765, train_loss 25.372263,Time used 0.011001s\n",
      "batch 21766, train_loss 38.224762,Time used 0.006998s\n",
      "batch 21767, train_loss 29.988522,Time used 0.012003s\n",
      "batch 21768, train_loss 30.448116,Time used 0.010998s\n",
      "batch 21769, train_loss 40.957249,Time used 0.010999s\n",
      "batch 21770, train_loss 37.978828,Time used 0.008002s\n",
      "batch 21771, train_loss 43.410400,Time used 0.008999s\n",
      "batch 21772, train_loss 33.498299,Time used 0.009006s\n",
      "batch 21773, train_loss 26.954540,Time used 0.013994s\n",
      "batch 21774, train_loss 30.263506,Time used 0.012004s\n",
      "batch 21775, train_loss 29.687901,Time used 0.008997s\n",
      "batch 21776, train_loss 29.210909,Time used 0.007000s\n",
      "batch 21777, train_loss 33.957314,Time used 0.009001s\n",
      "batch 21778, train_loss 33.247040,Time used 0.010003s\n",
      "batch 21779, train_loss 36.930725,Time used 0.008998s\n",
      "batch 21780, train_loss 31.305208,Time used 0.010999s\n",
      "batch 21781, train_loss 37.499752,Time used 0.009000s\n",
      "batch 21782, train_loss 29.577536,Time used 0.007999s\n",
      "batch 21783, train_loss 32.579750,Time used 0.009001s\n",
      "batch 21784, train_loss 38.379787,Time used 0.007999s\n",
      "batch 21785, train_loss 37.537251,Time used 0.008000s\n",
      "batch 21786, train_loss 27.114376,Time used 0.011000s\n",
      "batch 21787, train_loss 38.310520,Time used 0.012997s\n",
      "batch 21788, train_loss 35.528744,Time used 0.010000s\n",
      "batch 21789, train_loss 32.795597,Time used 0.012002s\n",
      "batch 21790, train_loss 32.710308,Time used 0.009999s\n",
      "batch 21791, train_loss 34.211315,Time used 0.011003s\n",
      "batch 21792, train_loss 32.633526,Time used 0.008999s\n",
      "batch 21793, train_loss 28.070297,Time used 0.008998s\n",
      "batch 21794, train_loss 27.859966,Time used 0.007999s\n",
      "batch 21795, train_loss 32.789257,Time used 0.010001s\n",
      "batch 21796, train_loss 28.862539,Time used 0.011001s\n",
      "batch 21797, train_loss 28.065569,Time used 0.013000s\n",
      "batch 21798, train_loss 27.277771,Time used 0.010001s\n",
      "batch 21799, train_loss 36.110348,Time used 0.013002s\n",
      "batch 21800, train_loss 40.100834,Time used 0.011995s\n",
      "***************************test_batch 21800, test_rmse_loss 6.875587,test_mae_loss 2.964722,test_mape_loss 50.450819,Time used 0.044002s\n",
      "batch 21801, train_loss 38.046860,Time used 0.007998s\n",
      "batch 21802, train_loss 26.355652,Time used 0.011003s\n",
      "batch 21803, train_loss 39.745983,Time used 0.009000s\n",
      "batch 21804, train_loss 32.813564,Time used 0.010000s\n",
      "batch 21805, train_loss 41.635101,Time used 0.010998s\n",
      "batch 21806, train_loss 32.747612,Time used 0.009001s\n",
      "batch 21807, train_loss 33.622692,Time used 0.010001s\n",
      "batch 21808, train_loss 31.458467,Time used 0.007000s\n",
      "batch 21809, train_loss 40.457264,Time used 0.010001s\n",
      "batch 21810, train_loss 37.096912,Time used 0.009999s\n",
      "batch 21811, train_loss 37.122242,Time used 0.010998s\n",
      "batch 21812, train_loss 36.258743,Time used 0.009002s\n",
      "batch 21813, train_loss 29.113081,Time used 0.009000s\n",
      "batch 21814, train_loss 42.496323,Time used 0.007999s\n",
      "batch 21815, train_loss 37.718155,Time used 0.008999s\n",
      "batch 21816, train_loss 29.811396,Time used 0.011000s\n",
      "batch 21817, train_loss 35.886993,Time used 0.007999s\n",
      "batch 21818, train_loss 33.328632,Time used 0.012002s\n",
      "batch 21819, train_loss 31.808323,Time used 0.009001s\n",
      "batch 21820, train_loss 26.734827,Time used 0.011997s\n",
      "batch 21821, train_loss 35.852039,Time used 0.010000s\n",
      "batch 21822, train_loss 31.979326,Time used 0.011003s\n",
      "batch 21823, train_loss 32.918377,Time used 0.008998s\n",
      "batch 21824, train_loss 35.286148,Time used 0.008002s\n",
      "batch 21825, train_loss 34.970325,Time used 0.010997s\n",
      "batch 21826, train_loss 33.549465,Time used 0.010002s\n",
      "batch 21827, train_loss 23.724672,Time used 0.008998s\n",
      "batch 21828, train_loss 31.308262,Time used 0.008001s\n",
      "batch 21829, train_loss 31.606447,Time used 0.008999s\n",
      "batch 21830, train_loss 39.493263,Time used 0.010999s\n",
      "batch 21831, train_loss 40.001945,Time used 0.011002s\n",
      "batch 21832, train_loss 32.367592,Time used 0.006999s\n",
      "batch 21833, train_loss 36.452816,Time used 0.011002s\n",
      "batch 21834, train_loss 43.523598,Time used 0.011000s\n",
      "batch 21835, train_loss 35.988953,Time used 0.012000s\n",
      "batch 21836, train_loss 37.520229,Time used 0.010000s\n",
      "batch 21837, train_loss 33.724064,Time used 0.011002s\n",
      "batch 21838, train_loss 33.663105,Time used 0.010999s\n",
      "batch 21839, train_loss 31.144514,Time used 0.008000s\n",
      "batch 21840, train_loss 31.674366,Time used 0.007999s\n",
      "batch 21841, train_loss 33.009129,Time used 0.007999s\n",
      "batch 21842, train_loss 48.909878,Time used 0.009000s\n",
      "batch 21843, train_loss 32.446259,Time used 0.008000s\n",
      "batch 21844, train_loss 21.233206,Time used 0.006998s\n",
      "batch 21845, train_loss 39.669575,Time used 0.008001s\n",
      "batch 21846, train_loss 31.093853,Time used 0.008001s\n",
      "batch 21847, train_loss 31.182871,Time used 0.011002s\n",
      "batch 21848, train_loss 27.493435,Time used 0.007997s\n",
      "batch 21849, train_loss 38.487438,Time used 0.008000s\n",
      "batch 21850, train_loss 37.627220,Time used 0.008000s\n",
      "batch 21851, train_loss 30.451147,Time used 0.009998s\n",
      "batch 21852, train_loss 35.262344,Time used 0.010001s\n",
      "batch 21853, train_loss 28.431667,Time used 0.006999s\n",
      "batch 21854, train_loss 38.673622,Time used 0.009035s\n",
      "batch 21855, train_loss 35.240429,Time used 0.010002s\n",
      "batch 21856, train_loss 35.309868,Time used 0.008999s\n",
      "batch 21857, train_loss 37.870167,Time used 0.008003s\n",
      "batch 21858, train_loss 32.781471,Time used 0.010962s\n",
      "batch 21859, train_loss 36.880524,Time used 0.007999s\n",
      "batch 21860, train_loss 34.503986,Time used 0.012002s\n",
      "batch 21861, train_loss 30.533278,Time used 0.012998s\n",
      "batch 21862, train_loss 36.497059,Time used 0.018003s\n",
      "batch 21863, train_loss 28.875612,Time used 0.018989s\n",
      "batch 21864, train_loss 30.977932,Time used 0.013003s\n",
      "batch 21865, train_loss 28.255653,Time used 0.026997s\n",
      "batch 21866, train_loss 42.702957,Time used 0.013000s\n",
      "batch 21867, train_loss 30.737768,Time used 0.016001s\n",
      "batch 21868, train_loss 36.857147,Time used 0.013998s\n",
      "batch 21869, train_loss 32.514118,Time used 0.014000s\n",
      "batch 21870, train_loss 26.264393,Time used 0.013003s\n",
      "batch 21871, train_loss 34.368443,Time used 0.011996s\n",
      "batch 21872, train_loss 38.815990,Time used 0.010999s\n",
      "batch 21873, train_loss 34.865772,Time used 0.011001s\n",
      "batch 21874, train_loss 34.217331,Time used 0.011998s\n",
      "batch 21875, train_loss 38.807858,Time used 0.012001s\n",
      "batch 21876, train_loss 36.029228,Time used 0.011997s\n",
      "batch 21877, train_loss 26.328949,Time used 0.012002s\n",
      "batch 21878, train_loss 31.397974,Time used 0.008000s\n",
      "batch 21879, train_loss 32.243793,Time used 0.010999s\n",
      "batch 21880, train_loss 29.780100,Time used 0.011000s\n",
      "batch 21881, train_loss 31.746723,Time used 0.010000s\n",
      "batch 21882, train_loss 41.823959,Time used 0.012001s\n",
      "batch 21883, train_loss 26.467491,Time used 0.012000s\n",
      "batch 21884, train_loss 37.191235,Time used 0.010002s\n",
      "batch 21885, train_loss 24.117748,Time used 0.012997s\n",
      "batch 21886, train_loss 39.227032,Time used 0.010004s\n",
      "batch 21887, train_loss 48.932240,Time used 0.010995s\n",
      "batch 21888, train_loss 29.091108,Time used 0.010999s\n",
      "batch 21889, train_loss 39.481686,Time used 0.010995s\n",
      "batch 21890, train_loss 35.480297,Time used 0.012001s\n",
      "batch 21891, train_loss 35.441570,Time used 0.010999s\n",
      "batch 21892, train_loss 32.975368,Time used 0.012000s\n",
      "batch 21893, train_loss 36.148357,Time used 0.015001s\n",
      "batch 21894, train_loss 34.103134,Time used 0.014000s\n",
      "batch 21895, train_loss 30.661423,Time used 0.011999s\n",
      "batch 21896, train_loss 32.275642,Time used 0.012002s\n",
      "batch 21897, train_loss 35.170395,Time used 0.010000s\n",
      "batch 21898, train_loss 29.371042,Time used 0.010999s\n",
      "batch 21899, train_loss 29.119083,Time used 0.013000s\n",
      "batch 21900, train_loss 33.454578,Time used 0.012001s\n",
      "***************************test_batch 21900, test_rmse_loss 6.870187,test_mae_loss 2.964856,test_mape_loss 50.354456,Time used 0.045002s\n",
      "batch 21901, train_loss 33.510330,Time used 0.010998s\n",
      "batch 21902, train_loss 33.843189,Time used 0.012002s\n",
      "batch 21903, train_loss 38.256027,Time used 0.010998s\n",
      "batch 21904, train_loss 37.464211,Time used 0.012001s\n",
      "batch 21905, train_loss 40.870983,Time used 0.009998s\n",
      "batch 21906, train_loss 33.684166,Time used 0.011002s\n",
      "batch 21907, train_loss 30.457502,Time used 0.008999s\n",
      "batch 21908, train_loss 31.361126,Time used 0.009001s\n",
      "batch 21909, train_loss 29.161680,Time used 0.009999s\n",
      "batch 21910, train_loss 27.850222,Time used 0.008002s\n",
      "batch 21911, train_loss 35.816101,Time used 0.011999s\n",
      "batch 21912, train_loss 36.049175,Time used 0.012001s\n",
      "batch 21913, train_loss 36.470623,Time used 0.009999s\n",
      "batch 21914, train_loss 35.453262,Time used 0.012000s\n",
      "batch 21915, train_loss 38.696213,Time used 0.012002s\n",
      "batch 21916, train_loss 30.402323,Time used 0.012999s\n",
      "batch 21917, train_loss 33.817425,Time used 0.012996s\n",
      "batch 21918, train_loss 38.422832,Time used 0.010002s\n",
      "batch 21919, train_loss 33.074680,Time used 0.008998s\n",
      "batch 21920, train_loss 26.289604,Time used 0.008002s\n",
      "batch 21921, train_loss 38.964371,Time used 0.012001s\n",
      "batch 21922, train_loss 35.739048,Time used 0.012002s\n",
      "batch 21923, train_loss 33.724556,Time used 0.011999s\n",
      "batch 21924, train_loss 29.212631,Time used 0.011998s\n",
      "batch 21925, train_loss 34.676533,Time used 0.007998s\n",
      "batch 21926, train_loss 33.361343,Time used 0.011000s\n",
      "batch 21927, train_loss 35.763565,Time used 0.012000s\n",
      "batch 21928, train_loss 30.331581,Time used 0.012000s\n",
      "batch 21929, train_loss 34.620373,Time used 0.007999s\n",
      "batch 21930, train_loss 31.977249,Time used 0.011999s\n",
      "batch 21931, train_loss 33.203594,Time used 0.011003s\n",
      "batch 21932, train_loss 33.368862,Time used 0.011999s\n",
      "batch 21933, train_loss 29.605448,Time used 0.012000s\n",
      "batch 21934, train_loss 35.598152,Time used 0.012000s\n",
      "batch 21935, train_loss 32.053986,Time used 0.009000s\n",
      "batch 21936, train_loss 36.070381,Time used 0.013003s\n",
      "batch 21937, train_loss 34.348778,Time used 0.011993s\n",
      "batch 21938, train_loss 30.440351,Time used 0.013999s\n",
      "batch 21939, train_loss 27.195755,Time used 0.019002s\n",
      "batch 21940, train_loss 31.754681,Time used 0.013997s\n",
      "batch 21941, train_loss 34.634357,Time used 0.012002s\n",
      "batch 21942, train_loss 31.659130,Time used 0.014998s\n",
      "batch 21943, train_loss 36.401100,Time used 0.009999s\n",
      "batch 21944, train_loss 40.333031,Time used 0.010999s\n",
      "batch 21945, train_loss 41.994965,Time used 0.012999s\n",
      "batch 21946, train_loss 36.039284,Time used 0.010004s\n",
      "batch 21947, train_loss 38.277950,Time used 0.008999s\n",
      "batch 21948, train_loss 37.580891,Time used 0.009999s\n",
      "batch 21949, train_loss 27.464071,Time used 0.011001s\n",
      "batch 21950, train_loss 33.906124,Time used 0.011999s\n",
      "batch 21951, train_loss 36.410713,Time used 0.011002s\n",
      "batch 21952, train_loss 37.929928,Time used 0.010002s\n",
      "batch 21953, train_loss 32.448708,Time used 0.009997s\n",
      "batch 21954, train_loss 28.703323,Time used 0.010001s\n",
      "batch 21955, train_loss 32.902187,Time used 0.009001s\n",
      "batch 21956, train_loss 23.199347,Time used 0.012000s\n",
      "batch 21957, train_loss 38.354244,Time used 0.011001s\n",
      "batch 21958, train_loss 34.888618,Time used 0.009001s\n",
      "batch 21959, train_loss 32.124790,Time used 0.010997s\n",
      "batch 21960, train_loss 30.728958,Time used 0.008000s\n",
      "batch 21961, train_loss 34.249142,Time used 0.013998s\n",
      "batch 21962, train_loss 31.114197,Time used 0.012003s\n",
      "batch 21963, train_loss 26.842241,Time used 0.010999s\n",
      "batch 21964, train_loss 29.942278,Time used 0.008001s\n",
      "batch 21965, train_loss 35.418285,Time used 0.011000s\n",
      "batch 21966, train_loss 34.580379,Time used 0.011997s\n",
      "batch 21967, train_loss 35.501598,Time used 0.011003s\n",
      "batch 21968, train_loss 33.480038,Time used 0.013000s\n",
      "batch 21969, train_loss 38.624760,Time used 0.011001s\n",
      "batch 21970, train_loss 31.242573,Time used 0.011997s\n",
      "batch 21971, train_loss 43.581829,Time used 0.010003s\n",
      "batch 21972, train_loss 31.834618,Time used 0.011997s\n",
      "batch 21973, train_loss 32.347046,Time used 0.011998s\n",
      "batch 21974, train_loss 39.836338,Time used 0.012000s\n",
      "batch 21975, train_loss 33.721127,Time used 0.010999s\n",
      "batch 21976, train_loss 30.101021,Time used 0.007998s\n",
      "batch 21977, train_loss 31.432642,Time used 0.009001s\n",
      "batch 21978, train_loss 39.856384,Time used 0.010000s\n",
      "batch 21979, train_loss 25.190546,Time used 0.010000s\n",
      "batch 21980, train_loss 27.851494,Time used 0.011002s\n",
      "batch 21981, train_loss 32.167492,Time used 0.011000s\n",
      "batch 21982, train_loss 33.644382,Time used 0.010999s\n",
      "batch 21983, train_loss 31.493380,Time used 0.012001s\n",
      "batch 21984, train_loss 45.556656,Time used 0.010996s\n",
      "batch 21985, train_loss 33.973045,Time used 0.011999s\n",
      "batch 21986, train_loss 32.961079,Time used 0.012001s\n",
      "batch 21987, train_loss 33.242874,Time used 0.009999s\n",
      "batch 21988, train_loss 28.883789,Time used 0.011001s\n",
      "batch 21989, train_loss 34.952175,Time used 0.011999s\n",
      "batch 21990, train_loss 26.702709,Time used 0.009000s\n",
      "batch 21991, train_loss 23.290670,Time used 0.011001s\n",
      "batch 21992, train_loss 33.042992,Time used 0.011002s\n",
      "batch 21993, train_loss 42.111046,Time used 0.010000s\n",
      "batch 21994, train_loss 28.167585,Time used 0.011998s\n",
      "batch 21995, train_loss 38.075344,Time used 0.012000s\n",
      "batch 21996, train_loss 40.682968,Time used 0.008000s\n",
      "batch 21997, train_loss 37.185818,Time used 0.010004s\n",
      "batch 21998, train_loss 39.955799,Time used 0.011998s\n",
      "batch 21999, train_loss 31.436281,Time used 0.012001s\n",
      "batch 22000, train_loss 43.115688,Time used 0.010998s\n",
      "***************************test_batch 22000, test_rmse_loss 6.852870,test_mae_loss 2.959492,test_mape_loss 50.394232,Time used 0.039001s\n",
      "batch 22001, train_loss 36.233673,Time used 0.010000s\n",
      "batch 22002, train_loss 30.551399,Time used 0.008999s\n",
      "batch 22003, train_loss 35.331062,Time used 0.008001s\n",
      "batch 22004, train_loss 30.651491,Time used 0.009000s\n",
      "batch 22005, train_loss 36.834915,Time used 0.010000s\n",
      "batch 22006, train_loss 33.110806,Time used 0.011001s\n",
      "batch 22007, train_loss 29.763943,Time used 0.010000s\n",
      "batch 22008, train_loss 27.467329,Time used 0.009997s\n",
      "batch 22009, train_loss 35.025185,Time used 0.011998s\n",
      "batch 22010, train_loss 27.354366,Time used 0.010003s\n",
      "batch 22011, train_loss 34.805088,Time used 0.007996s\n",
      "batch 22012, train_loss 33.397472,Time used 0.006999s\n",
      "batch 22013, train_loss 33.867809,Time used 0.008000s\n",
      "batch 22014, train_loss 37.134499,Time used 0.009002s\n",
      "batch 22015, train_loss 28.741365,Time used 0.009000s\n",
      "batch 22016, train_loss 27.305475,Time used 0.009001s\n",
      "batch 22017, train_loss 35.168655,Time used 0.010999s\n",
      "batch 22018, train_loss 33.862648,Time used 0.009999s\n",
      "batch 22019, train_loss 29.779734,Time used 0.008003s\n",
      "batch 22020, train_loss 33.717964,Time used 0.010000s\n",
      "batch 22021, train_loss 30.993374,Time used 0.009999s\n",
      "batch 22022, train_loss 38.166031,Time used 0.008001s\n",
      "batch 22023, train_loss 36.161526,Time used 0.008000s\n",
      "batch 22024, train_loss 35.663834,Time used 0.008999s\n",
      "batch 22025, train_loss 31.758009,Time used 0.007999s\n",
      "batch 22026, train_loss 39.757175,Time used 0.011003s\n",
      "batch 22027, train_loss 33.982300,Time used 0.011999s\n",
      "batch 22028, train_loss 31.622646,Time used 0.010999s\n",
      "batch 22029, train_loss 33.159031,Time used 0.009002s\n",
      "batch 22030, train_loss 34.258068,Time used 0.015001s\n",
      "batch 22031, train_loss 35.335205,Time used 0.010000s\n",
      "batch 22032, train_loss 36.450661,Time used 0.007000s\n",
      "batch 22033, train_loss 32.267284,Time used 0.012000s\n",
      "batch 22034, train_loss 39.726608,Time used 0.012001s\n",
      "batch 22035, train_loss 22.405760,Time used 0.009001s\n",
      "batch 22036, train_loss 40.509064,Time used 0.007999s\n",
      "batch 22037, train_loss 34.983971,Time used 0.008000s\n",
      "batch 22038, train_loss 32.637936,Time used 0.007998s\n",
      "batch 22039, train_loss 27.500113,Time used 0.010001s\n",
      "batch 22040, train_loss 33.550365,Time used 0.009001s\n",
      "batch 22041, train_loss 27.401897,Time used 0.008000s\n",
      "batch 22042, train_loss 28.359703,Time used 0.010001s\n",
      "batch 22043, train_loss 31.812553,Time used 0.008000s\n",
      "batch 22044, train_loss 32.871937,Time used 0.007000s\n",
      "batch 22045, train_loss 47.546394,Time used 0.008000s\n",
      "batch 22046, train_loss 30.614534,Time used 0.009001s\n",
      "batch 22047, train_loss 33.794514,Time used 0.010999s\n",
      "batch 22048, train_loss 37.371010,Time used 0.008002s\n",
      "batch 22049, train_loss 39.768360,Time used 0.010001s\n",
      "batch 22050, train_loss 30.869610,Time used 0.011005s\n",
      "batch 22051, train_loss 31.570509,Time used 0.009998s\n",
      "batch 22052, train_loss 37.535225,Time used 0.011997s\n",
      "batch 22053, train_loss 37.556808,Time used 0.010999s\n",
      "batch 22054, train_loss 32.064205,Time used 0.006999s\n",
      "batch 22055, train_loss 39.579407,Time used 0.009001s\n",
      "batch 22056, train_loss 23.772314,Time used 0.010000s\n",
      "batch 22057, train_loss 33.032249,Time used 0.010001s\n",
      "batch 22058, train_loss 30.483664,Time used 0.009999s\n",
      "batch 22059, train_loss 32.442375,Time used 0.010000s\n",
      "batch 22060, train_loss 36.929516,Time used 0.007001s\n",
      "batch 22061, train_loss 31.930996,Time used 0.009999s\n",
      "batch 22062, train_loss 29.648724,Time used 0.011001s\n",
      "batch 22063, train_loss 35.731819,Time used 0.010999s\n",
      "batch 22064, train_loss 36.524853,Time used 0.011000s\n",
      "batch 22065, train_loss 37.182575,Time used 0.008001s\n",
      "batch 22066, train_loss 32.764450,Time used 0.008000s\n",
      "batch 22067, train_loss 40.968807,Time used 0.012000s\n",
      "batch 22068, train_loss 24.148746,Time used 0.011997s\n",
      "batch 22069, train_loss 39.882580,Time used 0.012995s\n",
      "batch 22070, train_loss 41.683861,Time used 0.012003s\n",
      "batch 22071, train_loss 29.327345,Time used 0.010997s\n",
      "batch 22072, train_loss 24.091505,Time used 0.011004s\n",
      "batch 22073, train_loss 33.031460,Time used 0.007999s\n",
      "batch 22074, train_loss 25.783871,Time used 0.008002s\n",
      "batch 22075, train_loss 34.383976,Time used 0.009999s\n",
      "batch 22076, train_loss 34.889774,Time used 0.011002s\n",
      "batch 22077, train_loss 33.986988,Time used 0.011001s\n",
      "batch 22078, train_loss 39.072300,Time used 0.010002s\n",
      "batch 22079, train_loss 33.122322,Time used 0.012999s\n",
      "batch 22080, train_loss 34.154537,Time used 0.010000s\n",
      "batch 22081, train_loss 32.074532,Time used 0.009999s\n",
      "batch 22082, train_loss 33.839127,Time used 0.012000s\n",
      "batch 22083, train_loss 33.083752,Time used 0.012999s\n",
      "batch 22084, train_loss 36.054348,Time used 0.012998s\n",
      "batch 22085, train_loss 37.095131,Time used 0.010008s\n",
      "batch 22086, train_loss 34.453785,Time used 0.010999s\n",
      "batch 22087, train_loss 33.030151,Time used 0.015994s\n",
      "batch 22088, train_loss 30.696936,Time used 0.011001s\n",
      "batch 22089, train_loss 34.369415,Time used 0.011000s\n",
      "batch 22090, train_loss 33.296715,Time used 0.012997s\n",
      "batch 22091, train_loss 31.733810,Time used 0.012000s\n",
      "batch 22092, train_loss 33.856068,Time used 0.012004s\n",
      "batch 22093, train_loss 28.829800,Time used 0.014000s\n",
      "batch 22094, train_loss 36.386398,Time used 0.010998s\n",
      "batch 22095, train_loss 31.869272,Time used 0.010003s\n",
      "batch 22096, train_loss 36.728561,Time used 0.012999s\n",
      "batch 22097, train_loss 28.432100,Time used 0.011000s\n",
      "batch 22098, train_loss 37.267727,Time used 0.011001s\n",
      "batch 22099, train_loss 33.353954,Time used 0.012001s\n",
      "batch 22100, train_loss 34.333683,Time used 0.008998s\n",
      "***************************test_batch 22100, test_rmse_loss 6.841023,test_mae_loss 2.956223,test_mape_loss 50.322246,Time used 0.039000s\n",
      "batch 22101, train_loss 36.325806,Time used 0.009001s\n",
      "batch 22102, train_loss 27.612858,Time used 0.010000s\n",
      "batch 22103, train_loss 32.929714,Time used 0.012004s\n",
      "batch 22104, train_loss 36.709511,Time used 0.006998s\n",
      "batch 22105, train_loss 32.310043,Time used 0.011997s\n",
      "batch 22106, train_loss 38.447250,Time used 0.010998s\n",
      "batch 22107, train_loss 29.433809,Time used 0.012000s\n",
      "batch 22108, train_loss 30.390217,Time used 0.010999s\n",
      "batch 22109, train_loss 34.456226,Time used 0.012000s\n",
      "batch 22110, train_loss 39.380238,Time used 0.011000s\n",
      "batch 22111, train_loss 39.042397,Time used 0.011999s\n",
      "batch 22112, train_loss 27.417583,Time used 0.011002s\n",
      "batch 22113, train_loss 29.609011,Time used 0.007997s\n",
      "batch 22114, train_loss 34.440083,Time used 0.010001s\n",
      "batch 22115, train_loss 44.431210,Time used 0.018003s\n",
      "batch 22116, train_loss 39.063820,Time used 0.011997s\n",
      "batch 22117, train_loss 30.198933,Time used 0.009003s\n",
      "batch 22118, train_loss 38.265079,Time used 0.008997s\n",
      "batch 22119, train_loss 31.416388,Time used 0.011002s\n",
      "batch 22120, train_loss 33.970165,Time used 0.012006s\n",
      "batch 22121, train_loss 31.262758,Time used 0.010994s\n",
      "batch 22122, train_loss 27.737299,Time used 0.008999s\n",
      "batch 22123, train_loss 33.513729,Time used 0.010001s\n",
      "batch 22124, train_loss 28.646078,Time used 0.009999s\n",
      "batch 22125, train_loss 38.627811,Time used 0.010003s\n",
      "batch 22126, train_loss 27.221718,Time used 0.010996s\n",
      "batch 22127, train_loss 31.302792,Time used 0.010001s\n",
      "batch 22128, train_loss 32.832581,Time used 0.010002s\n",
      "batch 22129, train_loss 29.229980,Time used 0.010001s\n",
      "batch 22130, train_loss 26.865292,Time used 0.011997s\n",
      "batch 22131, train_loss 34.756802,Time used 0.010000s\n",
      "batch 22132, train_loss 30.084885,Time used 0.008000s\n",
      "batch 22133, train_loss 27.440203,Time used 0.011999s\n",
      "batch 22134, train_loss 33.083126,Time used 0.011999s\n",
      "batch 22135, train_loss 35.630989,Time used 0.011004s\n",
      "batch 22136, train_loss 31.441847,Time used 0.011998s\n",
      "batch 22137, train_loss 26.923429,Time used 0.009999s\n",
      "batch 22138, train_loss 34.363335,Time used 0.010000s\n",
      "batch 22139, train_loss 30.558460,Time used 0.012002s\n",
      "batch 22140, train_loss 36.816372,Time used 0.009999s\n",
      "batch 22141, train_loss 36.505260,Time used 0.012001s\n",
      "batch 22142, train_loss 36.770798,Time used 0.011004s\n",
      "batch 22143, train_loss 31.255955,Time used 0.010997s\n",
      "batch 22144, train_loss 33.592037,Time used 0.011999s\n",
      "batch 22145, train_loss 30.184862,Time used 0.010002s\n",
      "batch 22146, train_loss 42.857769,Time used 0.007998s\n",
      "batch 22147, train_loss 37.464424,Time used 0.011999s\n",
      "batch 22148, train_loss 36.552944,Time used 0.010000s\n",
      "batch 22149, train_loss 34.542645,Time used 0.007998s\n",
      "batch 22150, train_loss 34.237576,Time used 0.008001s\n",
      "batch 22151, train_loss 33.264091,Time used 0.010000s\n",
      "batch 22152, train_loss 38.661171,Time used 0.008004s\n",
      "batch 22153, train_loss 37.518372,Time used 0.008996s\n",
      "batch 22154, train_loss 27.378687,Time used 0.008001s\n",
      "batch 22155, train_loss 32.262993,Time used 0.008000s\n",
      "batch 22156, train_loss 35.788284,Time used 0.009999s\n",
      "batch 22157, train_loss 25.455839,Time used 0.012000s\n",
      "batch 22158, train_loss 27.421013,Time used 0.008001s\n",
      "batch 22159, train_loss 36.584053,Time used 0.010008s\n",
      "batch 22160, train_loss 39.722260,Time used 0.008992s\n",
      "batch 22161, train_loss 35.006397,Time used 0.010002s\n",
      "batch 22162, train_loss 25.472803,Time used 0.011999s\n",
      "batch 22163, train_loss 32.846615,Time used 0.009002s\n",
      "batch 22164, train_loss 41.007156,Time used 0.009995s\n",
      "batch 22165, train_loss 33.955906,Time used 0.011001s\n",
      "batch 22166, train_loss 29.533209,Time used 0.009996s\n",
      "batch 22167, train_loss 31.509008,Time used 0.008001s\n",
      "batch 22168, train_loss 36.559467,Time used 0.008000s\n",
      "batch 22169, train_loss 33.928425,Time used 0.010001s\n",
      "batch 22170, train_loss 34.204628,Time used 0.007999s\n",
      "batch 22171, train_loss 34.617714,Time used 0.008001s\n",
      "batch 22172, train_loss 34.428787,Time used 0.010002s\n",
      "batch 22173, train_loss 35.194530,Time used 0.009000s\n",
      "batch 22174, train_loss 26.781998,Time used 0.007999s\n",
      "batch 22175, train_loss 38.250793,Time used 0.008000s\n",
      "batch 22176, train_loss 36.116398,Time used 0.012002s\n",
      "batch 22177, train_loss 34.191387,Time used 0.012998s\n",
      "batch 22178, train_loss 30.540045,Time used 0.011002s\n",
      "batch 22179, train_loss 36.866219,Time used 0.012998s\n",
      "batch 22180, train_loss 33.968418,Time used 0.014002s\n",
      "batch 22181, train_loss 33.937950,Time used 0.013000s\n",
      "batch 22182, train_loss 32.844414,Time used 0.013000s\n",
      "batch 22183, train_loss 40.358688,Time used 0.014000s\n",
      "batch 22184, train_loss 27.864525,Time used 0.009998s\n",
      "batch 22185, train_loss 39.912766,Time used 0.009001s\n",
      "batch 22186, train_loss 26.160021,Time used 0.010000s\n",
      "batch 22187, train_loss 31.872759,Time used 0.012003s\n",
      "batch 22188, train_loss 31.598875,Time used 0.011994s\n",
      "batch 22189, train_loss 32.998558,Time used 0.012003s\n",
      "batch 22190, train_loss 36.422653,Time used 0.009001s\n",
      "batch 22191, train_loss 37.947346,Time used 0.007999s\n",
      "batch 22192, train_loss 30.010538,Time used 0.009003s\n",
      "batch 22193, train_loss 30.961847,Time used 0.009001s\n",
      "batch 22194, train_loss 32.267654,Time used 0.012000s\n",
      "batch 22195, train_loss 30.325397,Time used 0.010999s\n",
      "batch 22196, train_loss 37.622681,Time used 0.009999s\n",
      "batch 22197, train_loss 30.402393,Time used 0.008999s\n",
      "batch 22198, train_loss 35.628902,Time used 0.009002s\n",
      "batch 22199, train_loss 34.242985,Time used 0.012998s\n",
      "batch 22200, train_loss 31.933460,Time used 0.008999s\n",
      "***************************test_batch 22200, test_rmse_loss 6.828413,test_mae_loss 2.951339,test_mape_loss 50.285892,Time used 0.044999s\n",
      "batch 22201, train_loss 24.834969,Time used 0.013000s\n",
      "batch 22202, train_loss 36.813881,Time used 0.013001s\n",
      "batch 22203, train_loss 35.346775,Time used 0.009000s\n",
      "batch 22204, train_loss 29.419678,Time used 0.009000s\n",
      "batch 22205, train_loss 26.759602,Time used 0.012002s\n",
      "batch 22206, train_loss 25.021120,Time used 0.011001s\n",
      "batch 22207, train_loss 39.341946,Time used 0.010998s\n",
      "batch 22208, train_loss 28.902922,Time used 0.009999s\n",
      "batch 22209, train_loss 32.529106,Time used 0.009003s\n",
      "batch 22210, train_loss 33.853004,Time used 0.010006s\n",
      "batch 22211, train_loss 41.090736,Time used 0.011992s\n",
      "batch 22212, train_loss 36.005520,Time used 0.012001s\n",
      "batch 22213, train_loss 31.540243,Time used 0.011999s\n",
      "batch 22214, train_loss 40.981976,Time used 0.012001s\n",
      "batch 22215, train_loss 34.530449,Time used 0.010998s\n",
      "batch 22216, train_loss 32.418224,Time used 0.012005s\n",
      "batch 22217, train_loss 34.869064,Time used 0.010996s\n",
      "batch 22218, train_loss 35.104774,Time used 0.007998s\n",
      "batch 22219, train_loss 34.089058,Time used 0.010001s\n",
      "batch 22220, train_loss 31.915737,Time used 0.013000s\n",
      "batch 22221, train_loss 33.554863,Time used 0.016999s\n",
      "batch 22222, train_loss 33.384155,Time used 0.011999s\n",
      "batch 22223, train_loss 36.347179,Time used 0.011001s\n",
      "batch 22224, train_loss 31.257484,Time used 0.013000s\n",
      "batch 22225, train_loss 29.774704,Time used 0.013000s\n",
      "batch 22226, train_loss 39.892410,Time used 0.011999s\n",
      "batch 22227, train_loss 29.899326,Time used 0.012000s\n",
      "batch 22228, train_loss 33.518646,Time used 0.013001s\n",
      "batch 22229, train_loss 33.510216,Time used 0.012000s\n",
      "batch 22230, train_loss 33.518005,Time used 0.012001s\n",
      "batch 22231, train_loss 28.598707,Time used 0.011999s\n",
      "batch 22232, train_loss 38.997059,Time used 0.011999s\n",
      "batch 22233, train_loss 26.209558,Time used 0.012999s\n",
      "batch 22234, train_loss 32.708351,Time used 0.012002s\n",
      "batch 22235, train_loss 34.862095,Time used 0.012001s\n",
      "batch 22236, train_loss 29.055733,Time used 0.012997s\n",
      "batch 22237, train_loss 38.272057,Time used 0.013002s\n",
      "batch 22238, train_loss 32.741932,Time used 0.013002s\n",
      "batch 22239, train_loss 28.090509,Time used 0.016002s\n",
      "batch 22240, train_loss 38.387207,Time used 0.025000s\n",
      "batch 22241, train_loss 30.645273,Time used 0.012998s\n",
      "batch 22242, train_loss 36.019287,Time used 0.014000s\n",
      "batch 22243, train_loss 31.434811,Time used 0.013000s\n",
      "batch 22244, train_loss 34.043571,Time used 0.009997s\n",
      "batch 22245, train_loss 39.539494,Time used 0.012001s\n",
      "batch 22246, train_loss 34.328049,Time used 0.010000s\n",
      "batch 22247, train_loss 30.248539,Time used 0.012999s\n",
      "batch 22248, train_loss 34.867683,Time used 0.014001s\n",
      "batch 22249, train_loss 40.773056,Time used 0.012998s\n",
      "batch 22250, train_loss 33.033916,Time used 0.015000s\n",
      "batch 22251, train_loss 36.729259,Time used 0.012999s\n",
      "batch 22252, train_loss 36.304634,Time used 0.010002s\n",
      "batch 22253, train_loss 30.759886,Time used 0.011999s\n",
      "batch 22254, train_loss 32.951485,Time used 0.012998s\n",
      "batch 22255, train_loss 30.133581,Time used 0.013003s\n",
      "batch 22256, train_loss 28.992874,Time used 0.010000s\n",
      "batch 22257, train_loss 40.549896,Time used 0.012000s\n",
      "batch 22258, train_loss 29.661119,Time used 0.010002s\n",
      "batch 22259, train_loss 27.031086,Time used 0.010000s\n",
      "batch 22260, train_loss 41.174103,Time used 0.010998s\n",
      "batch 22261, train_loss 29.343868,Time used 0.011003s\n",
      "batch 22262, train_loss 27.372095,Time used 0.010000s\n",
      "batch 22263, train_loss 40.799793,Time used 0.009999s\n",
      "batch 22264, train_loss 28.680819,Time used 0.011000s\n",
      "batch 22265, train_loss 30.598555,Time used 0.009001s\n",
      "batch 22266, train_loss 37.850426,Time used 0.007999s\n",
      "batch 22267, train_loss 29.322998,Time used 0.011002s\n",
      "batch 22268, train_loss 35.397877,Time used 0.012001s\n",
      "batch 22269, train_loss 28.790293,Time used 0.009998s\n",
      "batch 22270, train_loss 26.638536,Time used 0.007998s\n",
      "batch 22271, train_loss 37.986797,Time used 0.012001s\n",
      "batch 22272, train_loss 37.878929,Time used 0.011998s\n",
      "batch 22273, train_loss 38.020287,Time used 0.009997s\n",
      "batch 22274, train_loss 32.786327,Time used 0.013000s\n",
      "batch 22275, train_loss 35.715965,Time used 0.009002s\n",
      "batch 22276, train_loss 43.490044,Time used 0.010002s\n",
      "batch 22277, train_loss 33.517956,Time used 0.011001s\n",
      "batch 22278, train_loss 30.662933,Time used 0.010999s\n",
      "batch 22279, train_loss 25.514204,Time used 0.008000s\n",
      "batch 22280, train_loss 27.990005,Time used 0.011000s\n",
      "batch 22281, train_loss 29.839792,Time used 0.007999s\n",
      "batch 22282, train_loss 38.687199,Time used 0.012001s\n",
      "batch 22283, train_loss 28.519609,Time used 0.013001s\n",
      "batch 22284, train_loss 30.299604,Time used 0.012001s\n",
      "batch 22285, train_loss 40.587803,Time used 0.008000s\n",
      "batch 22286, train_loss 33.431450,Time used 0.007996s\n",
      "batch 22287, train_loss 33.883045,Time used 0.008000s\n",
      "batch 22288, train_loss 31.090256,Time used 0.007999s\n",
      "batch 22289, train_loss 28.107615,Time used 0.010002s\n",
      "batch 22290, train_loss 29.448494,Time used 0.009003s\n",
      "batch 22291, train_loss 40.436195,Time used 0.008008s\n",
      "batch 22292, train_loss 29.647884,Time used 0.008995s\n",
      "batch 22293, train_loss 30.157530,Time used 0.009000s\n",
      "batch 22294, train_loss 33.470360,Time used 0.009001s\n",
      "batch 22295, train_loss 38.760151,Time used 0.008005s\n",
      "batch 22296, train_loss 33.262917,Time used 0.009993s\n",
      "batch 22297, train_loss 36.361622,Time used 0.009001s\n",
      "batch 22298, train_loss 23.115110,Time used 0.008000s\n",
      "batch 22299, train_loss 26.811022,Time used 0.011999s\n",
      "batch 22300, train_loss 35.309906,Time used 0.011001s\n",
      "***************************test_batch 22300, test_rmse_loss 6.806975,test_mae_loss 2.949239,test_mape_loss 50.427660,Time used 0.034000s\n",
      "batch 22301, train_loss 36.641579,Time used 0.009999s\n",
      "batch 22302, train_loss 39.286335,Time used 0.012002s\n",
      "batch 22303, train_loss 33.574978,Time used 0.009000s\n",
      "batch 22304, train_loss 34.122158,Time used 0.008002s\n",
      "batch 22305, train_loss 33.157860,Time used 0.007002s\n",
      "batch 22306, train_loss 30.037096,Time used 0.007998s\n",
      "batch 22307, train_loss 30.470823,Time used 0.009000s\n",
      "batch 22308, train_loss 33.403160,Time used 0.010003s\n",
      "batch 22309, train_loss 31.976013,Time used 0.007000s\n",
      "batch 22310, train_loss 44.244305,Time used 0.008999s\n",
      "batch 22311, train_loss 38.141895,Time used 0.012002s\n",
      "batch 22312, train_loss 27.690331,Time used 0.011999s\n",
      "batch 22313, train_loss 32.753922,Time used 0.011999s\n",
      "batch 22314, train_loss 33.985561,Time used 0.008003s\n",
      "batch 22315, train_loss 35.993671,Time used 0.007998s\n",
      "batch 22316, train_loss 26.256426,Time used 0.008002s\n",
      "batch 22317, train_loss 34.831985,Time used 0.007999s\n",
      "batch 22318, train_loss 38.859840,Time used 0.009000s\n",
      "batch 22319, train_loss 29.894365,Time used 0.008039s\n",
      "batch 22320, train_loss 29.271385,Time used 0.007961s\n",
      "batch 22321, train_loss 22.386614,Time used 0.009003s\n",
      "batch 22322, train_loss 32.969048,Time used 0.007997s\n",
      "batch 22323, train_loss 29.070099,Time used 0.010002s\n",
      "batch 22324, train_loss 35.108410,Time used 0.009998s\n",
      "batch 22325, train_loss 38.371250,Time used 0.009002s\n",
      "batch 22326, train_loss 33.226055,Time used 0.009000s\n",
      "batch 22327, train_loss 37.045330,Time used 0.010998s\n",
      "batch 22328, train_loss 34.346310,Time used 0.008999s\n",
      "batch 22329, train_loss 38.120220,Time used 0.007999s\n",
      "batch 22330, train_loss 36.770226,Time used 0.008004s\n",
      "batch 22331, train_loss 36.347996,Time used 0.008000s\n",
      "batch 22332, train_loss 28.629660,Time used 0.010995s\n",
      "batch 22333, train_loss 27.089739,Time used 0.011002s\n",
      "batch 22334, train_loss 36.589493,Time used 0.009002s\n",
      "batch 22335, train_loss 35.541733,Time used 0.011002s\n",
      "batch 22336, train_loss 31.891068,Time used 0.010997s\n",
      "batch 22337, train_loss 30.256550,Time used 0.011000s\n",
      "batch 22338, train_loss 39.388851,Time used 0.008004s\n",
      "batch 22339, train_loss 34.558865,Time used 0.008034s\n",
      "batch 22340, train_loss 34.588943,Time used 0.011966s\n",
      "batch 22341, train_loss 32.014572,Time used 0.009034s\n",
      "batch 22342, train_loss 27.503662,Time used 0.009000s\n",
      "batch 22343, train_loss 31.703167,Time used 0.008964s\n",
      "batch 22344, train_loss 32.177818,Time used 0.011999s\n",
      "batch 22345, train_loss 36.606358,Time used 0.009005s\n",
      "batch 22346, train_loss 29.387455,Time used 0.007999s\n",
      "batch 22347, train_loss 29.070620,Time used 0.010998s\n",
      "batch 22348, train_loss 29.258680,Time used 0.011002s\n",
      "batch 22349, train_loss 39.178482,Time used 0.008997s\n",
      "batch 22350, train_loss 26.982418,Time used 0.009004s\n",
      "batch 22351, train_loss 24.375322,Time used 0.008998s\n",
      "batch 22352, train_loss 30.077040,Time used 0.008000s\n",
      "batch 22353, train_loss 34.047447,Time used 0.011000s\n",
      "batch 22354, train_loss 32.609257,Time used 0.010000s\n",
      "batch 22355, train_loss 32.445671,Time used 0.010001s\n",
      "batch 22356, train_loss 39.269550,Time used 0.009000s\n",
      "batch 22357, train_loss 34.490898,Time used 0.007000s\n",
      "batch 22358, train_loss 31.587757,Time used 0.009004s\n",
      "batch 22359, train_loss 38.159817,Time used 0.008999s\n",
      "batch 22360, train_loss 35.834644,Time used 0.008000s\n",
      "batch 22361, train_loss 40.628395,Time used 0.011999s\n",
      "batch 22362, train_loss 36.674461,Time used 0.008001s\n",
      "batch 22363, train_loss 31.359198,Time used 0.011002s\n",
      "batch 22364, train_loss 28.360167,Time used 0.011001s\n",
      "batch 22365, train_loss 28.054935,Time used 0.007999s\n",
      "batch 22366, train_loss 31.251028,Time used 0.010002s\n",
      "batch 22367, train_loss 38.192135,Time used 0.010999s\n",
      "batch 22368, train_loss 36.923721,Time used 0.009000s\n",
      "batch 22369, train_loss 36.115799,Time used 0.007998s\n",
      "batch 22370, train_loss 27.114197,Time used 0.011998s\n",
      "batch 22371, train_loss 28.909399,Time used 0.008999s\n",
      "batch 22372, train_loss 30.126991,Time used 0.012000s\n",
      "batch 22373, train_loss 26.309164,Time used 0.010001s\n",
      "batch 22374, train_loss 45.770657,Time used 0.009000s\n",
      "batch 22375, train_loss 36.943398,Time used 0.011999s\n",
      "batch 22376, train_loss 38.729939,Time used 0.009000s\n",
      "batch 22377, train_loss 33.383133,Time used 0.007001s\n",
      "batch 22378, train_loss 35.276436,Time used 0.012003s\n",
      "batch 22379, train_loss 28.862638,Time used 0.012998s\n",
      "batch 22380, train_loss 26.376446,Time used 0.016003s\n",
      "batch 22381, train_loss 36.154835,Time used 0.009998s\n",
      "batch 22382, train_loss 37.202805,Time used 0.009002s\n",
      "batch 22383, train_loss 32.578560,Time used 0.011999s\n",
      "batch 22384, train_loss 33.445221,Time used 0.012000s\n",
      "batch 22385, train_loss 32.365021,Time used 0.012999s\n",
      "batch 22386, train_loss 35.772060,Time used 0.007999s\n",
      "batch 22387, train_loss 28.151743,Time used 0.010004s\n",
      "batch 22388, train_loss 25.629301,Time used 0.009999s\n",
      "batch 22389, train_loss 29.421221,Time used 0.009001s\n",
      "batch 22390, train_loss 40.125034,Time used 0.010996s\n",
      "batch 22391, train_loss 36.781063,Time used 0.010003s\n",
      "batch 22392, train_loss 31.988995,Time used 0.010996s\n",
      "batch 22393, train_loss 33.362865,Time used 0.012001s\n",
      "batch 22394, train_loss 30.002073,Time used 0.009999s\n",
      "batch 22395, train_loss 30.088444,Time used 0.011004s\n",
      "batch 22396, train_loss 28.248577,Time used 0.010998s\n",
      "batch 22397, train_loss 32.672314,Time used 0.010998s\n",
      "batch 22398, train_loss 34.116657,Time used 0.008001s\n",
      "batch 22399, train_loss 33.871330,Time used 0.011006s\n",
      "batch 22400, train_loss 26.124619,Time used 0.010995s\n",
      "***************************test_batch 22400, test_rmse_loss 6.816100,test_mae_loss 2.946832,test_mape_loss 50.061527,Time used 0.040999s\n",
      "batch 22401, train_loss 26.334019,Time used 0.011002s\n",
      "batch 22402, train_loss 41.949921,Time used 0.006999s\n",
      "batch 22403, train_loss 36.128117,Time used 0.008000s\n",
      "batch 22404, train_loss 33.796688,Time used 0.008002s\n",
      "batch 22405, train_loss 35.517632,Time used 0.009000s\n",
      "batch 22406, train_loss 36.067410,Time used 0.009999s\n",
      "batch 22407, train_loss 27.065849,Time used 0.009001s\n",
      "batch 22408, train_loss 37.977657,Time used 0.011999s\n",
      "batch 22409, train_loss 34.469460,Time used 0.010000s\n",
      "batch 22410, train_loss 29.812309,Time used 0.011000s\n",
      "batch 22411, train_loss 31.609972,Time used 0.009999s\n",
      "batch 22412, train_loss 38.866585,Time used 0.010999s\n",
      "batch 22413, train_loss 42.525887,Time used 0.012003s\n",
      "batch 22414, train_loss 33.018219,Time used 0.009998s\n",
      "batch 22415, train_loss 29.156519,Time used 0.008000s\n",
      "batch 22416, train_loss 30.156971,Time used 0.011001s\n",
      "batch 22417, train_loss 29.009140,Time used 0.011999s\n",
      "batch 22418, train_loss 30.768311,Time used 0.008000s\n",
      "batch 22419, train_loss 39.144485,Time used 0.008001s\n",
      "batch 22420, train_loss 25.351507,Time used 0.011998s\n",
      "batch 22421, train_loss 30.897268,Time used 0.008003s\n",
      "batch 22422, train_loss 33.946041,Time used 0.007999s\n",
      "batch 22423, train_loss 36.632851,Time used 0.012002s\n",
      "batch 22424, train_loss 36.077969,Time used 0.009998s\n",
      "batch 22425, train_loss 35.816483,Time used 0.008000s\n",
      "batch 22426, train_loss 29.481279,Time used 0.008002s\n",
      "batch 22427, train_loss 33.395420,Time used 0.008997s\n",
      "batch 22428, train_loss 32.943966,Time used 0.010000s\n",
      "batch 22429, train_loss 40.327286,Time used 0.008002s\n",
      "batch 22430, train_loss 36.404373,Time used 0.008001s\n",
      "batch 22431, train_loss 28.126930,Time used 0.008999s\n",
      "batch 22432, train_loss 27.406038,Time used 0.010001s\n",
      "batch 22433, train_loss 31.150784,Time used 0.010999s\n",
      "batch 22434, train_loss 28.740267,Time used 0.010998s\n",
      "batch 22435, train_loss 40.649868,Time used 0.008001s\n",
      "batch 22436, train_loss 28.781982,Time used 0.011999s\n",
      "batch 22437, train_loss 30.082752,Time used 0.009001s\n",
      "batch 22438, train_loss 33.029831,Time used 0.010999s\n",
      "batch 22439, train_loss 38.574940,Time used 0.008000s\n",
      "batch 22440, train_loss 35.302799,Time used 0.009000s\n",
      "batch 22441, train_loss 35.069672,Time used 0.012002s\n",
      "batch 22442, train_loss 33.435547,Time used 0.011999s\n",
      "batch 22443, train_loss 43.180138,Time used 0.011000s\n",
      "batch 22444, train_loss 33.486732,Time used 0.009999s\n",
      "batch 22445, train_loss 32.227936,Time used 0.008999s\n",
      "batch 22446, train_loss 38.702217,Time used 0.012000s\n",
      "batch 22447, train_loss 35.243404,Time used 0.010999s\n",
      "batch 22448, train_loss 29.102205,Time used 0.012001s\n",
      "batch 22449, train_loss 29.776810,Time used 0.010001s\n",
      "batch 22450, train_loss 42.213219,Time used 0.009998s\n",
      "batch 22451, train_loss 28.044889,Time used 0.009997s\n",
      "batch 22452, train_loss 29.192278,Time used 0.010998s\n",
      "batch 22453, train_loss 31.923954,Time used 0.011999s\n",
      "batch 22454, train_loss 32.476715,Time used 0.010002s\n",
      "batch 22455, train_loss 30.574976,Time used 0.011000s\n",
      "batch 22456, train_loss 29.049700,Time used 0.008993s\n",
      "batch 22457, train_loss 38.119354,Time used 0.010999s\n",
      "batch 22458, train_loss 30.592165,Time used 0.008999s\n",
      "batch 22459, train_loss 26.625122,Time used 0.011999s\n",
      "batch 22460, train_loss 33.980473,Time used 0.009001s\n",
      "batch 22461, train_loss 33.527725,Time used 0.011999s\n",
      "batch 22462, train_loss 38.501316,Time used 0.009001s\n",
      "batch 22463, train_loss 25.756245,Time used 0.010999s\n",
      "batch 22464, train_loss 30.048204,Time used 0.011999s\n",
      "batch 22465, train_loss 37.027912,Time used 0.010000s\n",
      "batch 22466, train_loss 31.103445,Time used 0.017001s\n",
      "batch 22467, train_loss 34.603981,Time used 0.010999s\n",
      "batch 22468, train_loss 26.085934,Time used 0.014000s\n",
      "batch 22469, train_loss 35.330231,Time used 0.011997s\n",
      "batch 22470, train_loss 41.180164,Time used 0.012003s\n",
      "batch 22471, train_loss 37.585823,Time used 0.011999s\n",
      "batch 22472, train_loss 28.327856,Time used 0.011000s\n",
      "batch 22473, train_loss 32.599121,Time used 0.008997s\n",
      "batch 22474, train_loss 28.342258,Time used 0.012001s\n",
      "batch 22475, train_loss 40.895187,Time used 0.012001s\n",
      "batch 22476, train_loss 30.735991,Time used 0.011002s\n",
      "batch 22477, train_loss 31.967344,Time used 0.013000s\n",
      "batch 22478, train_loss 29.102785,Time used 0.011999s\n",
      "batch 22479, train_loss 38.384659,Time used 0.007999s\n",
      "batch 22480, train_loss 28.715206,Time used 0.009003s\n",
      "batch 22481, train_loss 30.817299,Time used 0.011997s\n",
      "batch 22482, train_loss 31.576174,Time used 0.012003s\n",
      "batch 22483, train_loss 37.039509,Time used 0.010999s\n",
      "batch 22484, train_loss 38.331432,Time used 0.010998s\n",
      "batch 22485, train_loss 26.147547,Time used 0.011001s\n",
      "batch 22486, train_loss 37.148338,Time used 0.009003s\n",
      "batch 22487, train_loss 26.406044,Time used 0.009001s\n",
      "batch 22488, train_loss 30.541971,Time used 0.010999s\n",
      "batch 22489, train_loss 28.201990,Time used 0.010997s\n",
      "batch 22490, train_loss 24.136930,Time used 0.008000s\n",
      "batch 22491, train_loss 34.718102,Time used 0.007999s\n",
      "batch 22492, train_loss 34.128574,Time used 0.008000s\n",
      "batch 22493, train_loss 38.662418,Time used 0.008002s\n",
      "batch 22494, train_loss 41.325230,Time used 0.009000s\n",
      "batch 22495, train_loss 31.986609,Time used 0.009001s\n",
      "batch 22496, train_loss 25.957399,Time used 0.010001s\n",
      "batch 22497, train_loss 33.187531,Time used 0.011001s\n",
      "batch 22498, train_loss 30.785919,Time used 0.010000s\n",
      "batch 22499, train_loss 31.989496,Time used 0.010998s\n",
      "batch 22500, train_loss 29.637714,Time used 0.010001s\n",
      "***************************test_batch 22500, test_rmse_loss 6.789320,test_mae_loss 2.944386,test_mape_loss 50.392278,Time used 0.046000s\n",
      "batch 22501, train_loss 23.810503,Time used 0.011003s\n",
      "batch 22502, train_loss 29.755558,Time used 0.012997s\n",
      "batch 22503, train_loss 29.048498,Time used 0.010998s\n",
      "batch 22504, train_loss 38.561409,Time used 0.010010s\n",
      "batch 22505, train_loss 33.731953,Time used 0.011998s\n",
      "batch 22506, train_loss 36.130711,Time used 0.009001s\n",
      "batch 22507, train_loss 41.256378,Time used 0.009001s\n",
      "batch 22508, train_loss 38.171661,Time used 0.009999s\n",
      "batch 22509, train_loss 37.674267,Time used 0.008001s\n",
      "batch 22510, train_loss 31.106138,Time used 0.009000s\n",
      "batch 22511, train_loss 34.664986,Time used 0.009001s\n",
      "batch 22512, train_loss 30.600306,Time used 0.009998s\n",
      "batch 22513, train_loss 33.067432,Time used 0.012000s\n",
      "batch 22514, train_loss 35.534435,Time used 0.009000s\n",
      "batch 22515, train_loss 28.806128,Time used 0.012000s\n",
      "batch 22516, train_loss 39.995113,Time used 0.010001s\n",
      "batch 22517, train_loss 36.305222,Time used 0.010997s\n",
      "batch 22518, train_loss 28.953962,Time used 0.010000s\n",
      "batch 22519, train_loss 30.117887,Time used 0.010000s\n",
      "batch 22520, train_loss 36.981152,Time used 0.009003s\n",
      "batch 22521, train_loss 39.226627,Time used 0.010000s\n",
      "batch 22522, train_loss 40.401649,Time used 0.011997s\n",
      "batch 22523, train_loss 32.296154,Time used 0.010001s\n",
      "batch 22524, train_loss 31.212259,Time used 0.008001s\n",
      "batch 22525, train_loss 29.487286,Time used 0.012001s\n",
      "batch 22526, train_loss 34.696480,Time used 0.008999s\n",
      "batch 22527, train_loss 24.193117,Time used 0.011999s\n",
      "batch 22528, train_loss 30.953138,Time used 0.011002s\n",
      "batch 22529, train_loss 28.410141,Time used 0.012000s\n",
      "batch 22530, train_loss 32.262775,Time used 0.011998s\n",
      "batch 22531, train_loss 28.416775,Time used 0.008000s\n",
      "batch 22532, train_loss 40.066139,Time used 0.010001s\n",
      "batch 22533, train_loss 35.113247,Time used 0.008000s\n",
      "batch 22534, train_loss 33.449554,Time used 0.008000s\n",
      "batch 22535, train_loss 25.299894,Time used 0.011000s\n",
      "batch 22536, train_loss 33.197609,Time used 0.008998s\n",
      "batch 22537, train_loss 26.338856,Time used 0.007998s\n",
      "batch 22538, train_loss 40.899105,Time used 0.008000s\n",
      "batch 22539, train_loss 36.588108,Time used 0.009002s\n",
      "batch 22540, train_loss 28.020407,Time used 0.006999s\n",
      "batch 22541, train_loss 32.984295,Time used 0.011999s\n",
      "batch 22542, train_loss 39.151932,Time used 0.007999s\n",
      "batch 22543, train_loss 29.192865,Time used 0.008004s\n",
      "batch 22544, train_loss 27.689081,Time used 0.009997s\n",
      "batch 22545, train_loss 37.725063,Time used 0.008000s\n",
      "batch 22546, train_loss 32.510250,Time used 0.008001s\n",
      "batch 22547, train_loss 33.610661,Time used 0.011001s\n",
      "batch 22548, train_loss 36.449226,Time used 0.010999s\n",
      "batch 22549, train_loss 25.880062,Time used 0.008000s\n",
      "batch 22550, train_loss 32.262772,Time used 0.009001s\n",
      "batch 22551, train_loss 26.494026,Time used 0.006997s\n",
      "batch 22552, train_loss 30.166294,Time used 0.010001s\n",
      "batch 22553, train_loss 31.427504,Time used 0.011000s\n",
      "batch 22554, train_loss 41.873436,Time used 0.010001s\n",
      "batch 22555, train_loss 36.400974,Time used 0.012999s\n",
      "batch 22556, train_loss 44.320576,Time used 0.009000s\n",
      "batch 22557, train_loss 27.452967,Time used 0.012000s\n",
      "batch 22558, train_loss 27.982277,Time used 0.008004s\n",
      "batch 22559, train_loss 29.562237,Time used 0.011997s\n",
      "batch 22560, train_loss 32.244816,Time used 0.010987s\n",
      "batch 22561, train_loss 29.863989,Time used 0.012003s\n",
      "batch 22562, train_loss 26.769758,Time used 0.007998s\n",
      "batch 22563, train_loss 29.747784,Time used 0.012001s\n",
      "batch 22564, train_loss 27.377640,Time used 0.011999s\n",
      "batch 22565, train_loss 32.412357,Time used 0.008002s\n",
      "batch 22566, train_loss 33.341564,Time used 0.012999s\n",
      "batch 22567, train_loss 27.721029,Time used 0.011999s\n",
      "batch 22568, train_loss 39.998695,Time used 0.011001s\n",
      "batch 22569, train_loss 38.712002,Time used 0.011001s\n",
      "batch 22570, train_loss 30.668919,Time used 0.011000s\n",
      "batch 22571, train_loss 35.876114,Time used 0.008999s\n",
      "batch 22572, train_loss 33.141239,Time used 0.009999s\n",
      "batch 22573, train_loss 31.909437,Time used 0.012000s\n",
      "batch 22574, train_loss 25.286917,Time used 0.010001s\n",
      "batch 22575, train_loss 44.223396,Time used 0.008999s\n",
      "batch 22576, train_loss 33.921566,Time used 0.012002s\n",
      "batch 22577, train_loss 30.178534,Time used 0.009997s\n",
      "batch 22578, train_loss 37.375568,Time used 0.008003s\n",
      "batch 22579, train_loss 32.609776,Time used 0.012000s\n",
      "batch 22580, train_loss 35.357277,Time used 0.009000s\n",
      "batch 22581, train_loss 31.025843,Time used 0.009999s\n",
      "batch 22582, train_loss 34.830360,Time used 0.009000s\n",
      "batch 22583, train_loss 31.993885,Time used 0.007999s\n",
      "batch 22584, train_loss 32.327473,Time used 0.011002s\n",
      "batch 22585, train_loss 25.151762,Time used 0.007998s\n",
      "batch 22586, train_loss 28.495743,Time used 0.010001s\n",
      "batch 22587, train_loss 33.452049,Time used 0.009999s\n",
      "batch 22588, train_loss 28.628157,Time used 0.011998s\n",
      "batch 22589, train_loss 27.417744,Time used 0.010003s\n",
      "batch 22590, train_loss 31.323372,Time used 0.007998s\n",
      "batch 22591, train_loss 28.773851,Time used 0.010998s\n",
      "batch 22592, train_loss 33.569710,Time used 0.009000s\n",
      "batch 22593, train_loss 33.395065,Time used 0.012003s\n",
      "batch 22594, train_loss 28.983009,Time used 0.011000s\n",
      "batch 22595, train_loss 41.793621,Time used 0.012002s\n",
      "batch 22596, train_loss 33.603348,Time used 0.010999s\n",
      "batch 22597, train_loss 32.055939,Time used 0.011998s\n",
      "batch 22598, train_loss 28.385601,Time used 0.011002s\n",
      "batch 22599, train_loss 35.823338,Time used 0.010999s\n",
      "batch 22600, train_loss 28.523922,Time used 0.009001s\n",
      "***************************test_batch 22600, test_rmse_loss 6.783347,test_mae_loss 2.943497,test_mape_loss 50.547772,Time used 0.038998s\n",
      "batch 22601, train_loss 35.424435,Time used 0.008000s\n",
      "batch 22602, train_loss 33.694138,Time used 0.008999s\n",
      "batch 22603, train_loss 39.006649,Time used 0.010004s\n",
      "batch 22604, train_loss 33.560326,Time used 0.008998s\n",
      "batch 22605, train_loss 33.979889,Time used 0.009000s\n",
      "batch 22606, train_loss 38.688160,Time used 0.010999s\n",
      "batch 22607, train_loss 32.690128,Time used 0.010999s\n",
      "batch 22608, train_loss 39.774075,Time used 0.010000s\n",
      "batch 22609, train_loss 43.667507,Time used 0.011999s\n",
      "batch 22610, train_loss 30.544210,Time used 0.009001s\n",
      "batch 22611, train_loss 32.871773,Time used 0.011001s\n",
      "batch 22612, train_loss 36.068268,Time used 0.008001s\n",
      "batch 22613, train_loss 33.933907,Time used 0.007999s\n",
      "batch 22614, train_loss 35.554256,Time used 0.012002s\n",
      "batch 22615, train_loss 32.187267,Time used 0.011000s\n",
      "batch 22616, train_loss 46.052631,Time used 0.007999s\n",
      "batch 22617, train_loss 26.613245,Time used 0.008998s\n",
      "batch 22618, train_loss 37.978989,Time used 0.008002s\n",
      "batch 22619, train_loss 25.342554,Time used 0.011001s\n",
      "batch 22620, train_loss 28.753593,Time used 0.008000s\n",
      "batch 22621, train_loss 29.947594,Time used 0.008001s\n",
      "batch 22622, train_loss 26.775473,Time used 0.010998s\n",
      "batch 22623, train_loss 36.078506,Time used 0.008000s\n",
      "batch 22624, train_loss 35.444256,Time used 0.012000s\n",
      "batch 22625, train_loss 23.942381,Time used 0.009000s\n",
      "batch 22626, train_loss 31.631077,Time used 0.008000s\n",
      "batch 22627, train_loss 36.027863,Time used 0.010999s\n",
      "batch 22628, train_loss 28.764395,Time used 0.011003s\n",
      "batch 22629, train_loss 28.335810,Time used 0.010998s\n",
      "batch 22630, train_loss 36.176800,Time used 0.009000s\n",
      "batch 22631, train_loss 32.593781,Time used 0.008000s\n",
      "batch 22632, train_loss 29.442450,Time used 0.008999s\n",
      "batch 22633, train_loss 34.873005,Time used 0.010000s\n",
      "batch 22634, train_loss 30.722137,Time used 0.009001s\n",
      "batch 22635, train_loss 37.426277,Time used 0.011002s\n",
      "batch 22636, train_loss 36.678223,Time used 0.010998s\n",
      "batch 22637, train_loss 29.595263,Time used 0.009001s\n",
      "batch 22638, train_loss 29.520979,Time used 0.012998s\n",
      "batch 22639, train_loss 30.851572,Time used 0.010999s\n",
      "batch 22640, train_loss 40.463524,Time used 0.010999s\n",
      "batch 22641, train_loss 35.276634,Time used 0.011002s\n",
      "batch 22642, train_loss 22.567028,Time used 0.010998s\n",
      "batch 22643, train_loss 34.484959,Time used 0.011003s\n",
      "batch 22644, train_loss 29.932388,Time used 0.017002s\n",
      "batch 22645, train_loss 33.552994,Time used 0.011998s\n",
      "batch 22646, train_loss 32.271244,Time used 0.013000s\n",
      "batch 22647, train_loss 33.636959,Time used 0.012002s\n",
      "batch 22648, train_loss 38.065559,Time used 0.017000s\n",
      "batch 22649, train_loss 42.323082,Time used 0.011001s\n",
      "batch 22650, train_loss 36.097809,Time used 0.012002s\n",
      "batch 22651, train_loss 29.862410,Time used 0.010999s\n",
      "batch 22652, train_loss 26.662100,Time used 0.013001s\n",
      "batch 22653, train_loss 34.299198,Time used 0.012000s\n",
      "batch 22654, train_loss 26.648815,Time used 0.013000s\n",
      "batch 22655, train_loss 24.655197,Time used 0.013999s\n",
      "batch 22656, train_loss 33.658371,Time used 0.010999s\n",
      "batch 22657, train_loss 34.982552,Time used 0.012997s\n",
      "batch 22658, train_loss 34.109291,Time used 0.013001s\n",
      "batch 22659, train_loss 24.848368,Time used 0.018001s\n",
      "batch 22660, train_loss 31.276007,Time used 0.025002s\n",
      "batch 22661, train_loss 25.816540,Time used 0.014999s\n",
      "batch 22662, train_loss 30.486526,Time used 0.018999s\n",
      "batch 22663, train_loss 37.935722,Time used 0.011997s\n",
      "batch 22664, train_loss 31.302771,Time used 0.007998s\n",
      "batch 22665, train_loss 32.003265,Time used 0.009001s\n",
      "batch 22666, train_loss 34.448769,Time used 0.010000s\n",
      "batch 22667, train_loss 32.994667,Time used 0.011000s\n",
      "batch 22668, train_loss 29.744720,Time used 0.010000s\n",
      "batch 22669, train_loss 35.393314,Time used 0.012003s\n",
      "batch 22670, train_loss 40.212299,Time used 0.016000s\n",
      "batch 22671, train_loss 31.215738,Time used 0.013999s\n",
      "batch 22672, train_loss 35.519302,Time used 0.013999s\n",
      "batch 22673, train_loss 35.345139,Time used 0.012001s\n",
      "batch 22674, train_loss 31.154930,Time used 0.010998s\n",
      "batch 22675, train_loss 26.314280,Time used 0.013004s\n",
      "batch 22676, train_loss 28.708805,Time used 0.010999s\n",
      "batch 22677, train_loss 30.452621,Time used 0.008998s\n",
      "batch 22678, train_loss 43.482113,Time used 0.010000s\n",
      "batch 22679, train_loss 28.658758,Time used 0.011000s\n",
      "batch 22680, train_loss 36.931644,Time used 0.011000s\n",
      "batch 22681, train_loss 43.222664,Time used 0.008999s\n",
      "batch 22682, train_loss 31.266418,Time used 0.009001s\n",
      "batch 22683, train_loss 39.489208,Time used 0.007999s\n",
      "batch 22684, train_loss 35.446499,Time used 0.008001s\n",
      "batch 22685, train_loss 39.032364,Time used 0.012001s\n",
      "batch 22686, train_loss 26.006495,Time used 0.009999s\n",
      "batch 22687, train_loss 28.131344,Time used 0.009001s\n",
      "batch 22688, train_loss 33.954960,Time used 0.010001s\n",
      "batch 22689, train_loss 38.107250,Time used 0.006999s\n",
      "batch 22690, train_loss 31.898115,Time used 0.008000s\n",
      "batch 22691, train_loss 34.476704,Time used 0.008000s\n",
      "batch 22692, train_loss 28.995300,Time used 0.008002s\n",
      "batch 22693, train_loss 31.848398,Time used 0.011997s\n",
      "batch 22694, train_loss 31.850544,Time used 0.011000s\n",
      "batch 22695, train_loss 32.945400,Time used 0.008000s\n",
      "batch 22696, train_loss 24.979025,Time used 0.008000s\n",
      "batch 22697, train_loss 31.374674,Time used 0.008002s\n",
      "batch 22698, train_loss 35.366661,Time used 0.009002s\n",
      "batch 22699, train_loss 33.224682,Time used 0.007998s\n",
      "batch 22700, train_loss 25.691601,Time used 0.008001s\n",
      "***************************test_batch 22700, test_rmse_loss 6.763517,test_mae_loss 2.934264,test_mape_loss 50.316416,Time used 0.036999s\n",
      "batch 22701, train_loss 26.251791,Time used 0.008999s\n",
      "batch 22702, train_loss 32.626579,Time used 0.010000s\n",
      "batch 22703, train_loss 35.075073,Time used 0.010003s\n",
      "batch 22704, train_loss 31.074484,Time used 0.009032s\n",
      "batch 22705, train_loss 34.517452,Time used 0.013000s\n",
      "batch 22706, train_loss 38.426613,Time used 0.010999s\n",
      "batch 22707, train_loss 34.918457,Time used 0.011997s\n",
      "batch 22708, train_loss 35.009525,Time used 0.012000s\n",
      "batch 22709, train_loss 31.266846,Time used 0.012000s\n",
      "batch 22710, train_loss 39.294312,Time used 0.008001s\n",
      "batch 22711, train_loss 31.896141,Time used 0.010999s\n",
      "batch 22712, train_loss 33.978146,Time used 0.008001s\n",
      "batch 22713, train_loss 31.341602,Time used 0.010000s\n",
      "batch 22714, train_loss 30.236223,Time used 0.008998s\n",
      "batch 22715, train_loss 25.975201,Time used 0.009001s\n",
      "batch 22716, train_loss 31.851889,Time used 0.007999s\n",
      "batch 22717, train_loss 27.250132,Time used 0.008000s\n",
      "batch 22718, train_loss 27.052834,Time used 0.011000s\n",
      "batch 22719, train_loss 32.252632,Time used 0.008002s\n",
      "batch 22720, train_loss 35.322449,Time used 0.009001s\n",
      "batch 22721, train_loss 31.365467,Time used 0.009001s\n",
      "batch 22722, train_loss 36.316830,Time used 0.012000s\n",
      "batch 22723, train_loss 31.649500,Time used 0.010998s\n",
      "batch 22724, train_loss 29.817238,Time used 0.008000s\n",
      "batch 22725, train_loss 32.731815,Time used 0.010001s\n",
      "batch 22726, train_loss 32.204315,Time used 0.009000s\n",
      "batch 22727, train_loss 26.319359,Time used 0.007999s\n",
      "batch 22728, train_loss 40.968853,Time used 0.007999s\n",
      "batch 22729, train_loss 35.302578,Time used 0.010998s\n",
      "batch 22730, train_loss 38.090767,Time used 0.010000s\n",
      "batch 22731, train_loss 26.326557,Time used 0.011003s\n",
      "batch 22732, train_loss 38.667915,Time used 0.009999s\n",
      "batch 22733, train_loss 34.076038,Time used 0.011998s\n",
      "batch 22734, train_loss 30.214779,Time used 0.010005s\n",
      "batch 22735, train_loss 35.986130,Time used 0.008996s\n",
      "batch 22736, train_loss 28.585175,Time used 0.011001s\n",
      "batch 22737, train_loss 34.698971,Time used 0.008000s\n",
      "batch 22738, train_loss 32.582443,Time used 0.007002s\n",
      "batch 22739, train_loss 29.772837,Time used 0.006999s\n",
      "batch 22740, train_loss 35.815716,Time used 0.011000s\n",
      "batch 22741, train_loss 31.362759,Time used 0.012001s\n",
      "batch 22742, train_loss 23.189402,Time used 0.007998s\n",
      "batch 22743, train_loss 38.327377,Time used 0.012001s\n",
      "batch 22744, train_loss 29.423103,Time used 0.011999s\n",
      "batch 22745, train_loss 31.556189,Time used 0.007998s\n",
      "batch 22746, train_loss 30.453545,Time used 0.012003s\n",
      "batch 22747, train_loss 30.043404,Time used 0.010997s\n",
      "batch 22748, train_loss 29.601707,Time used 0.008000s\n",
      "batch 22749, train_loss 38.290066,Time used 0.011001s\n",
      "batch 22750, train_loss 36.946239,Time used 0.011999s\n",
      "batch 22751, train_loss 26.688793,Time used 0.012000s\n",
      "batch 22752, train_loss 35.112038,Time used 0.008001s\n",
      "batch 22753, train_loss 32.614555,Time used 0.012000s\n",
      "batch 22754, train_loss 35.547516,Time used 0.009040s\n",
      "batch 22755, train_loss 39.398277,Time used 0.007958s\n",
      "batch 22756, train_loss 32.513741,Time used 0.009001s\n",
      "batch 22757, train_loss 31.653898,Time used 0.011000s\n",
      "batch 22758, train_loss 30.400618,Time used 0.011002s\n",
      "batch 22759, train_loss 30.580978,Time used 0.011998s\n",
      "batch 22760, train_loss 27.158382,Time used 0.010001s\n",
      "batch 22761, train_loss 32.165878,Time used 0.012001s\n",
      "batch 22762, train_loss 33.789761,Time used 0.008001s\n",
      "batch 22763, train_loss 31.709238,Time used 0.012998s\n",
      "batch 22764, train_loss 27.353502,Time used 0.009001s\n",
      "batch 22765, train_loss 31.098663,Time used 0.011999s\n",
      "batch 22766, train_loss 31.265762,Time used 0.013001s\n",
      "batch 22767, train_loss 34.776001,Time used 0.010999s\n",
      "batch 22768, train_loss 30.460154,Time used 0.011000s\n",
      "batch 22769, train_loss 38.040611,Time used 0.012001s\n",
      "batch 22770, train_loss 41.699409,Time used 0.008997s\n",
      "batch 22771, train_loss 29.230900,Time used 0.010000s\n",
      "batch 22772, train_loss 25.393402,Time used 0.007001s\n",
      "batch 22773, train_loss 29.300325,Time used 0.007001s\n",
      "batch 22774, train_loss 37.486511,Time used 0.007999s\n",
      "batch 22775, train_loss 32.849995,Time used 0.011003s\n",
      "batch 22776, train_loss 33.505161,Time used 0.010998s\n",
      "batch 22777, train_loss 27.690372,Time used 0.007997s\n",
      "batch 22778, train_loss 30.428900,Time used 0.009003s\n",
      "batch 22779, train_loss 33.678024,Time used 0.008997s\n",
      "batch 22780, train_loss 36.509884,Time used 0.011998s\n",
      "batch 22781, train_loss 32.623161,Time used 0.012003s\n",
      "batch 22782, train_loss 25.758888,Time used 0.007999s\n",
      "batch 22783, train_loss 23.241121,Time used 0.007999s\n",
      "batch 22784, train_loss 31.003784,Time used 0.008001s\n",
      "batch 22785, train_loss 32.251339,Time used 0.008000s\n",
      "batch 22786, train_loss 38.349537,Time used 0.009001s\n",
      "batch 22787, train_loss 31.260017,Time used 0.010998s\n",
      "batch 22788, train_loss 31.516743,Time used 0.011001s\n",
      "batch 22789, train_loss 32.519268,Time used 0.009998s\n",
      "batch 22790, train_loss 31.746077,Time used 0.011001s\n",
      "batch 22791, train_loss 28.216944,Time used 0.011998s\n",
      "batch 22792, train_loss 32.270042,Time used 0.008002s\n",
      "batch 22793, train_loss 35.819313,Time used 0.011000s\n",
      "batch 22794, train_loss 40.665733,Time used 0.013002s\n",
      "batch 22795, train_loss 30.864372,Time used 0.011997s\n",
      "batch 22796, train_loss 28.494114,Time used 0.008001s\n",
      "batch 22797, train_loss 34.019070,Time used 0.013001s\n",
      "batch 22798, train_loss 36.692741,Time used 0.011999s\n",
      "batch 22799, train_loss 32.300854,Time used 0.007999s\n",
      "batch 22800, train_loss 41.446304,Time used 0.012000s\n",
      "***************************test_batch 22800, test_rmse_loss 6.755515,test_mae_loss 2.930137,test_mape_loss 50.202059,Time used 0.037002s\n",
      "batch 22801, train_loss 36.383556,Time used 0.013998s\n",
      "batch 22802, train_loss 35.420063,Time used 0.012999s\n",
      "batch 22803, train_loss 32.548725,Time used 0.008002s\n",
      "batch 22804, train_loss 26.955309,Time used 0.010002s\n",
      "batch 22805, train_loss 30.948172,Time used 0.011997s\n",
      "batch 22806, train_loss 32.939671,Time used 0.010999s\n",
      "batch 22807, train_loss 27.864847,Time used 0.008005s\n",
      "batch 22808, train_loss 29.415207,Time used 0.008005s\n",
      "batch 22809, train_loss 33.229622,Time used 0.008000s\n",
      "batch 22810, train_loss 34.223911,Time used 0.008999s\n",
      "batch 22811, train_loss 33.826519,Time used 0.008000s\n",
      "batch 22812, train_loss 33.691628,Time used 0.009000s\n",
      "batch 22813, train_loss 34.797409,Time used 0.009002s\n",
      "batch 22814, train_loss 31.345201,Time used 0.007998s\n",
      "batch 22815, train_loss 27.968378,Time used 0.011002s\n",
      "batch 22816, train_loss 33.200485,Time used 0.011001s\n",
      "batch 22817, train_loss 31.669830,Time used 0.010999s\n",
      "batch 22818, train_loss 28.711527,Time used 0.008000s\n",
      "batch 22819, train_loss 36.874039,Time used 0.007999s\n",
      "batch 22820, train_loss 41.192806,Time used 0.007999s\n",
      "batch 22821, train_loss 35.203049,Time used 0.013005s\n",
      "batch 22822, train_loss 30.871145,Time used 0.010002s\n",
      "batch 22823, train_loss 24.661562,Time used 0.009000s\n",
      "batch 22824, train_loss 34.117477,Time used 0.012000s\n",
      "batch 22825, train_loss 31.792734,Time used 0.012999s\n",
      "batch 22826, train_loss 31.067591,Time used 0.010000s\n",
      "batch 22827, train_loss 31.806820,Time used 0.011002s\n",
      "batch 22828, train_loss 39.915714,Time used 0.009999s\n",
      "batch 22829, train_loss 33.196957,Time used 0.009999s\n",
      "batch 22830, train_loss 27.899250,Time used 0.008001s\n",
      "batch 22831, train_loss 33.290424,Time used 0.010001s\n",
      "batch 22832, train_loss 39.176247,Time used 0.010998s\n",
      "batch 22833, train_loss 35.787548,Time used 0.010004s\n",
      "batch 22834, train_loss 29.905939,Time used 0.012001s\n",
      "batch 22835, train_loss 31.096640,Time used 0.009001s\n",
      "batch 22836, train_loss 34.142586,Time used 0.011998s\n",
      "batch 22837, train_loss 34.287994,Time used 0.008999s\n",
      "batch 22838, train_loss 26.908991,Time used 0.007000s\n",
      "batch 22839, train_loss 30.637152,Time used 0.011000s\n",
      "batch 22840, train_loss 35.345356,Time used 0.009003s\n",
      "batch 22841, train_loss 26.051676,Time used 0.007998s\n",
      "batch 22842, train_loss 38.967178,Time used 0.011999s\n",
      "batch 22843, train_loss 31.130825,Time used 0.013002s\n",
      "batch 22844, train_loss 28.978628,Time used 0.010998s\n",
      "batch 22845, train_loss 30.461744,Time used 0.008998s\n",
      "batch 22846, train_loss 28.447998,Time used 0.012002s\n",
      "batch 22847, train_loss 30.097424,Time used 0.007999s\n",
      "batch 22848, train_loss 37.093376,Time used 0.007999s\n",
      "batch 22849, train_loss 36.471264,Time used 0.009998s\n",
      "batch 22850, train_loss 26.978062,Time used 0.008000s\n",
      "batch 22851, train_loss 34.528839,Time used 0.011001s\n",
      "batch 22852, train_loss 33.517654,Time used 0.010000s\n",
      "batch 22853, train_loss 33.446938,Time used 0.011000s\n",
      "batch 22854, train_loss 33.309605,Time used 0.010002s\n",
      "batch 22855, train_loss 32.023785,Time used 0.007998s\n",
      "batch 22856, train_loss 39.270660,Time used 0.008001s\n",
      "batch 22857, train_loss 32.496922,Time used 0.009001s\n",
      "batch 22858, train_loss 25.187677,Time used 0.010000s\n",
      "batch 22859, train_loss 30.084850,Time used 0.010998s\n",
      "batch 22860, train_loss 31.742455,Time used 0.012000s\n",
      "batch 22861, train_loss 28.622044,Time used 0.008001s\n",
      "batch 22862, train_loss 41.573971,Time used 0.007998s\n",
      "batch 22863, train_loss 27.726330,Time used 0.009995s\n",
      "batch 22864, train_loss 34.421204,Time used 0.010997s\n",
      "batch 22865, train_loss 33.870846,Time used 0.008001s\n",
      "batch 22866, train_loss 35.244175,Time used 0.009999s\n",
      "batch 22867, train_loss 24.405464,Time used 0.009001s\n",
      "batch 22868, train_loss 34.525856,Time used 0.012999s\n",
      "batch 22869, train_loss 32.136078,Time used 0.010001s\n",
      "batch 22870, train_loss 33.686512,Time used 0.012000s\n",
      "batch 22871, train_loss 32.410084,Time used 0.008998s\n",
      "batch 22872, train_loss 28.378334,Time used 0.009001s\n",
      "batch 22873, train_loss 32.899834,Time used 0.011000s\n",
      "batch 22874, train_loss 33.052032,Time used 0.011000s\n",
      "batch 22875, train_loss 25.569914,Time used 0.009003s\n",
      "batch 22876, train_loss 27.838257,Time used 0.009999s\n",
      "batch 22877, train_loss 30.648369,Time used 0.012001s\n",
      "batch 22878, train_loss 35.753063,Time used 0.010002s\n",
      "batch 22879, train_loss 32.431618,Time used 0.008003s\n",
      "batch 22880, train_loss 31.199982,Time used 0.007998s\n",
      "batch 22881, train_loss 33.664665,Time used 0.012000s\n",
      "batch 22882, train_loss 30.663511,Time used 0.011000s\n",
      "batch 22883, train_loss 32.061356,Time used 0.008999s\n",
      "batch 22884, train_loss 36.578468,Time used 0.010999s\n",
      "batch 22885, train_loss 27.001476,Time used 0.010999s\n",
      "batch 22886, train_loss 32.536602,Time used 0.008001s\n",
      "batch 22887, train_loss 27.466154,Time used 0.009000s\n",
      "batch 22888, train_loss 34.582005,Time used 0.008000s\n",
      "batch 22889, train_loss 26.160431,Time used 0.010001s\n",
      "batch 22890, train_loss 47.166325,Time used 0.009001s\n",
      "batch 22891, train_loss 31.206190,Time used 0.006996s\n",
      "batch 22892, train_loss 29.529285,Time used 0.010002s\n",
      "batch 22893, train_loss 33.133533,Time used 0.011000s\n",
      "batch 22894, train_loss 37.931477,Time used 0.009000s\n",
      "batch 22895, train_loss 34.767300,Time used 0.008002s\n",
      "batch 22896, train_loss 31.683455,Time used 0.009001s\n",
      "batch 22897, train_loss 35.357449,Time used 0.008997s\n",
      "batch 22898, train_loss 33.951244,Time used 0.008002s\n",
      "batch 22899, train_loss 24.152639,Time used 0.007000s\n",
      "batch 22900, train_loss 27.466431,Time used 0.010002s\n",
      "***************************test_batch 22900, test_rmse_loss 6.740641,test_mae_loss 2.929255,test_mape_loss 50.324117,Time used 0.040002s\n",
      "batch 22901, train_loss 35.187466,Time used 0.010999s\n",
      "batch 22902, train_loss 31.586885,Time used 0.008998s\n",
      "batch 22903, train_loss 28.431011,Time used 0.007000s\n",
      "batch 22904, train_loss 38.048950,Time used 0.008000s\n",
      "batch 22905, train_loss 19.512909,Time used 0.008001s\n",
      "batch 22906, train_loss 37.264153,Time used 0.007998s\n",
      "batch 22907, train_loss 29.716806,Time used 0.011000s\n",
      "batch 22908, train_loss 29.919319,Time used 0.008001s\n",
      "batch 22909, train_loss 31.992569,Time used 0.009001s\n",
      "batch 22910, train_loss 31.189327,Time used 0.011997s\n",
      "batch 22911, train_loss 36.491253,Time used 0.011003s\n",
      "batch 22912, train_loss 36.432148,Time used 0.012002s\n",
      "batch 22913, train_loss 35.408886,Time used 0.013998s\n",
      "batch 22914, train_loss 36.933739,Time used 0.010001s\n",
      "batch 22915, train_loss 31.058907,Time used 0.011998s\n",
      "batch 22916, train_loss 35.432552,Time used 0.010001s\n",
      "batch 22917, train_loss 30.553431,Time used 0.009002s\n",
      "batch 22918, train_loss 37.403503,Time used 0.011998s\n",
      "batch 22919, train_loss 30.346352,Time used 0.012001s\n",
      "batch 22920, train_loss 30.887005,Time used 0.011001s\n",
      "batch 22921, train_loss 34.877571,Time used 0.012000s\n",
      "batch 22922, train_loss 31.873985,Time used 0.010003s\n",
      "batch 22923, train_loss 36.818146,Time used 0.010002s\n",
      "batch 22924, train_loss 33.744617,Time used 0.008998s\n",
      "batch 22925, train_loss 30.372482,Time used 0.008000s\n",
      "batch 22926, train_loss 36.862015,Time used 0.008999s\n",
      "batch 22927, train_loss 25.191288,Time used 0.007000s\n",
      "batch 22928, train_loss 27.206953,Time used 0.008002s\n",
      "batch 22929, train_loss 33.398071,Time used 0.007998s\n",
      "batch 22930, train_loss 36.744884,Time used 0.009004s\n",
      "batch 22931, train_loss 33.178230,Time used 0.010999s\n",
      "batch 22932, train_loss 30.935259,Time used 0.011999s\n",
      "batch 22933, train_loss 32.427113,Time used 0.011998s\n",
      "batch 22934, train_loss 35.434658,Time used 0.010000s\n",
      "batch 22935, train_loss 25.558708,Time used 0.007000s\n",
      "batch 22936, train_loss 33.948898,Time used 0.007002s\n",
      "batch 22937, train_loss 33.902702,Time used 0.007000s\n",
      "batch 22938, train_loss 32.251675,Time used 0.011001s\n",
      "batch 22939, train_loss 33.245819,Time used 0.010998s\n",
      "batch 22940, train_loss 24.413452,Time used 0.008001s\n",
      "batch 22941, train_loss 33.944412,Time used 0.008000s\n",
      "batch 22942, train_loss 35.088028,Time used 0.007999s\n",
      "batch 22943, train_loss 31.601816,Time used 0.010001s\n",
      "batch 22944, train_loss 30.614597,Time used 0.011997s\n",
      "batch 22945, train_loss 33.779530,Time used 0.012000s\n",
      "batch 22946, train_loss 33.618851,Time used 0.007999s\n",
      "batch 22947, train_loss 36.310585,Time used 0.011001s\n",
      "batch 22948, train_loss 29.979036,Time used 0.010000s\n",
      "batch 22949, train_loss 28.115263,Time used 0.007998s\n",
      "batch 22950, train_loss 33.112991,Time used 0.010003s\n",
      "batch 22951, train_loss 35.563267,Time used 0.008999s\n",
      "batch 22952, train_loss 25.854441,Time used 0.012000s\n",
      "batch 22953, train_loss 31.475401,Time used 0.009999s\n",
      "batch 22954, train_loss 30.237907,Time used 0.010001s\n",
      "batch 22955, train_loss 36.026752,Time used 0.007999s\n",
      "batch 22956, train_loss 34.143929,Time used 0.009998s\n",
      "batch 22957, train_loss 33.824718,Time used 0.011001s\n",
      "batch 22958, train_loss 36.961716,Time used 0.007998s\n",
      "batch 22959, train_loss 30.223557,Time used 0.008001s\n",
      "batch 22960, train_loss 34.202301,Time used 0.007998s\n",
      "batch 22961, train_loss 29.671524,Time used 0.009001s\n",
      "batch 22962, train_loss 32.075226,Time used 0.011000s\n",
      "batch 22963, train_loss 30.800146,Time used 0.010999s\n",
      "batch 22964, train_loss 28.363983,Time used 0.008000s\n",
      "batch 22965, train_loss 35.258907,Time used 0.010999s\n",
      "batch 22966, train_loss 35.224483,Time used 0.013001s\n",
      "batch 22967, train_loss 32.274101,Time used 0.012998s\n",
      "batch 22968, train_loss 25.701601,Time used 0.010001s\n",
      "batch 22969, train_loss 31.608387,Time used 0.010003s\n",
      "batch 22970, train_loss 28.417194,Time used 0.010998s\n",
      "batch 22971, train_loss 32.924946,Time used 0.013001s\n",
      "batch 22972, train_loss 26.184830,Time used 0.011000s\n",
      "batch 22973, train_loss 29.201485,Time used 0.010002s\n",
      "batch 22974, train_loss 26.674465,Time used 0.010999s\n",
      "batch 22975, train_loss 36.061806,Time used 0.012003s\n",
      "batch 22976, train_loss 29.870483,Time used 0.009995s\n",
      "batch 22977, train_loss 37.575493,Time used 0.009002s\n",
      "batch 22978, train_loss 29.378582,Time used 0.008000s\n",
      "batch 22979, train_loss 38.407188,Time used 0.007999s\n",
      "batch 22980, train_loss 43.324993,Time used 0.011999s\n",
      "batch 22981, train_loss 33.298183,Time used 0.012001s\n",
      "batch 22982, train_loss 34.352802,Time used 0.009002s\n",
      "batch 22983, train_loss 29.409395,Time used 0.006999s\n",
      "batch 22984, train_loss 28.943933,Time used 0.009999s\n",
      "batch 22985, train_loss 30.840015,Time used 0.009002s\n",
      "batch 22986, train_loss 27.071091,Time used 0.008001s\n",
      "batch 22987, train_loss 29.650356,Time used 0.008001s\n",
      "batch 22988, train_loss 32.906864,Time used 0.012001s\n",
      "batch 22989, train_loss 31.249146,Time used 0.011999s\n",
      "batch 22990, train_loss 37.631931,Time used 0.009999s\n",
      "batch 22991, train_loss 32.820221,Time used 0.012002s\n",
      "batch 22992, train_loss 34.489594,Time used 0.007999s\n",
      "batch 22993, train_loss 29.937820,Time used 0.008997s\n",
      "batch 22994, train_loss 36.100086,Time used 0.012001s\n",
      "batch 22995, train_loss 31.327942,Time used 0.009999s\n",
      "batch 22996, train_loss 26.969574,Time used 0.009000s\n",
      "batch 22997, train_loss 44.117661,Time used 0.008000s\n",
      "batch 22998, train_loss 31.144358,Time used 0.008999s\n",
      "batch 22999, train_loss 32.603577,Time used 0.011001s\n",
      "batch 23000, train_loss 33.613045,Time used 0.009000s\n",
      "***************************test_batch 23000, test_rmse_loss 6.738255,test_mae_loss 2.925616,test_mape_loss 50.232927,Time used 0.044000s\n",
      "batch 23001, train_loss 34.560055,Time used 0.012001s\n",
      "batch 23002, train_loss 26.675989,Time used 0.011002s\n",
      "batch 23003, train_loss 34.186104,Time used 0.010001s\n",
      "batch 23004, train_loss 29.539658,Time used 0.007999s\n",
      "batch 23005, train_loss 28.111572,Time used 0.012002s\n",
      "batch 23006, train_loss 31.202545,Time used 0.008001s\n",
      "batch 23007, train_loss 35.751549,Time used 0.008000s\n",
      "batch 23008, train_loss 38.576141,Time used 0.008000s\n",
      "batch 23009, train_loss 29.194715,Time used 0.008000s\n",
      "batch 23010, train_loss 31.622635,Time used 0.012000s\n",
      "batch 23011, train_loss 30.419655,Time used 0.011999s\n",
      "batch 23012, train_loss 25.451063,Time used 0.008002s\n",
      "batch 23013, train_loss 37.434399,Time used 0.007998s\n",
      "batch 23014, train_loss 33.893631,Time used 0.008001s\n",
      "batch 23015, train_loss 29.937906,Time used 0.007999s\n",
      "batch 23016, train_loss 28.632175,Time used 0.008000s\n",
      "batch 23017, train_loss 30.564833,Time used 0.008000s\n",
      "batch 23018, train_loss 30.476522,Time used 0.012012s\n",
      "batch 23019, train_loss 29.863766,Time used 0.008988s\n",
      "batch 23020, train_loss 36.147106,Time used 0.009000s\n",
      "batch 23021, train_loss 32.066761,Time used 0.011004s\n",
      "batch 23022, train_loss 31.512186,Time used 0.011998s\n",
      "batch 23023, train_loss 26.222992,Time used 0.010998s\n",
      "batch 23024, train_loss 25.151255,Time used 0.008999s\n",
      "batch 23025, train_loss 29.217457,Time used 0.009004s\n",
      "batch 23026, train_loss 34.578259,Time used 0.007997s\n",
      "batch 23027, train_loss 29.065697,Time used 0.011002s\n",
      "batch 23028, train_loss 35.274265,Time used 0.011000s\n",
      "batch 23029, train_loss 34.201458,Time used 0.008999s\n",
      "batch 23030, train_loss 40.259708,Time used 0.008001s\n",
      "batch 23031, train_loss 38.780190,Time used 0.009999s\n",
      "batch 23032, train_loss 30.323664,Time used 0.009999s\n",
      "batch 23033, train_loss 31.016527,Time used 0.010001s\n",
      "batch 23034, train_loss 31.024250,Time used 0.008999s\n",
      "batch 23035, train_loss 34.973145,Time used 0.008003s\n",
      "batch 23036, train_loss 27.716146,Time used 0.010000s\n",
      "batch 23037, train_loss 34.339283,Time used 0.007999s\n",
      "batch 23038, train_loss 34.757622,Time used 0.008001s\n",
      "batch 23039, train_loss 33.407021,Time used 0.008000s\n",
      "batch 23040, train_loss 29.140976,Time used 0.008002s\n",
      "batch 23041, train_loss 24.730141,Time used 0.007999s\n",
      "batch 23042, train_loss 28.369314,Time used 0.008002s\n",
      "batch 23043, train_loss 36.704205,Time used 0.008998s\n",
      "batch 23044, train_loss 29.125587,Time used 0.008999s\n",
      "batch 23045, train_loss 35.193653,Time used 0.012002s\n",
      "batch 23046, train_loss 32.640224,Time used 0.012000s\n",
      "batch 23047, train_loss 29.286093,Time used 0.012999s\n",
      "batch 23048, train_loss 29.289602,Time used 0.011997s\n",
      "batch 23049, train_loss 35.188915,Time used 0.012000s\n",
      "batch 23050, train_loss 31.461483,Time used 0.012003s\n",
      "batch 23051, train_loss 29.051233,Time used 0.011000s\n",
      "batch 23052, train_loss 33.362896,Time used 0.013001s\n",
      "batch 23053, train_loss 29.633345,Time used 0.011997s\n",
      "batch 23054, train_loss 29.490633,Time used 0.011000s\n",
      "batch 23055, train_loss 36.481308,Time used 0.010999s\n",
      "batch 23056, train_loss 39.943283,Time used 0.012002s\n",
      "batch 23057, train_loss 34.225613,Time used 0.010999s\n",
      "batch 23058, train_loss 26.481501,Time used 0.011999s\n",
      "batch 23059, train_loss 29.869179,Time used 0.011999s\n",
      "batch 23060, train_loss 31.577114,Time used 0.013001s\n",
      "batch 23061, train_loss 38.454731,Time used 0.011999s\n",
      "batch 23062, train_loss 30.974600,Time used 0.013002s\n",
      "batch 23063, train_loss 30.440527,Time used 0.013999s\n",
      "batch 23064, train_loss 37.814754,Time used 0.012997s\n",
      "batch 23065, train_loss 30.476706,Time used 0.016000s\n",
      "batch 23066, train_loss 32.252995,Time used 0.016999s\n",
      "batch 23067, train_loss 27.929354,Time used 0.014000s\n",
      "batch 23068, train_loss 31.110088,Time used 0.014999s\n",
      "batch 23069, train_loss 32.438805,Time used 0.012000s\n",
      "batch 23070, train_loss 28.951498,Time used 0.017000s\n",
      "batch 23071, train_loss 42.297157,Time used 0.026000s\n",
      "batch 23072, train_loss 30.516176,Time used 0.012999s\n",
      "batch 23073, train_loss 32.461571,Time used 0.011002s\n",
      "batch 23074, train_loss 28.467518,Time used 0.010998s\n",
      "batch 23075, train_loss 26.637653,Time used 0.012002s\n",
      "batch 23076, train_loss 38.894539,Time used 0.015998s\n",
      "batch 23077, train_loss 27.109568,Time used 0.012001s\n",
      "batch 23078, train_loss 32.983475,Time used 0.012000s\n",
      "batch 23079, train_loss 30.833317,Time used 0.012997s\n",
      "batch 23080, train_loss 28.453671,Time used 0.011000s\n",
      "batch 23081, train_loss 33.582676,Time used 0.011000s\n",
      "batch 23082, train_loss 32.387699,Time used 0.010998s\n",
      "batch 23083, train_loss 31.230436,Time used 0.013002s\n",
      "batch 23084, train_loss 35.323925,Time used 0.014998s\n",
      "batch 23085, train_loss 27.868303,Time used 0.014008s\n",
      "batch 23086, train_loss 33.003044,Time used 0.011994s\n",
      "batch 23087, train_loss 34.063953,Time used 0.009998s\n",
      "batch 23088, train_loss 39.758774,Time used 0.011000s\n",
      "batch 23089, train_loss 30.087877,Time used 0.012997s\n",
      "batch 23090, train_loss 36.097683,Time used 0.012000s\n",
      "batch 23091, train_loss 35.460991,Time used 0.011001s\n",
      "batch 23092, train_loss 33.893169,Time used 0.008999s\n",
      "batch 23093, train_loss 25.743105,Time used 0.008000s\n",
      "batch 23094, train_loss 26.577063,Time used 0.008000s\n",
      "batch 23095, train_loss 28.865843,Time used 0.009002s\n",
      "batch 23096, train_loss 37.475113,Time used 0.010997s\n",
      "batch 23097, train_loss 33.124649,Time used 0.011997s\n",
      "batch 23098, train_loss 33.384754,Time used 0.011002s\n",
      "batch 23099, train_loss 34.331661,Time used 0.008001s\n",
      "batch 23100, train_loss 31.216030,Time used 0.010998s\n",
      "***************************test_batch 23100, test_rmse_loss 6.715276,test_mae_loss 2.920911,test_mape_loss 50.301987,Time used 0.037001s\n",
      "batch 23101, train_loss 35.055088,Time used 0.009004s\n",
      "batch 23102, train_loss 32.455109,Time used 0.011997s\n",
      "batch 23103, train_loss 31.982262,Time used 0.011000s\n",
      "batch 23104, train_loss 33.843090,Time used 0.012000s\n",
      "batch 23105, train_loss 28.227613,Time used 0.008002s\n",
      "batch 23106, train_loss 27.254141,Time used 0.008998s\n",
      "batch 23107, train_loss 31.969345,Time used 0.008000s\n",
      "batch 23108, train_loss 32.564041,Time used 0.008000s\n",
      "batch 23109, train_loss 25.329662,Time used 0.009001s\n",
      "batch 23110, train_loss 33.151962,Time used 0.008001s\n",
      "batch 23111, train_loss 38.064480,Time used 0.011001s\n",
      "batch 23112, train_loss 31.556120,Time used 0.009000s\n",
      "batch 23113, train_loss 39.510906,Time used 0.009000s\n",
      "batch 23114, train_loss 33.317135,Time used 0.009002s\n",
      "batch 23115, train_loss 30.448490,Time used 0.011001s\n",
      "batch 23116, train_loss 30.385214,Time used 0.009998s\n",
      "batch 23117, train_loss 25.863590,Time used 0.009000s\n",
      "batch 23118, train_loss 30.120050,Time used 0.008999s\n",
      "batch 23119, train_loss 36.211842,Time used 0.010002s\n",
      "batch 23120, train_loss 34.302280,Time used 0.012001s\n",
      "batch 23121, train_loss 36.191055,Time used 0.013000s\n",
      "batch 23122, train_loss 31.640045,Time used 0.009001s\n",
      "batch 23123, train_loss 26.938694,Time used 0.009999s\n",
      "batch 23124, train_loss 31.130764,Time used 0.011999s\n",
      "batch 23125, train_loss 32.885956,Time used 0.012001s\n",
      "batch 23126, train_loss 33.035301,Time used 0.013001s\n",
      "batch 23127, train_loss 32.585037,Time used 0.010997s\n",
      "batch 23128, train_loss 30.966467,Time used 0.013002s\n",
      "batch 23129, train_loss 23.323572,Time used 0.013999s\n",
      "batch 23130, train_loss 35.095749,Time used 0.012000s\n",
      "batch 23131, train_loss 27.752251,Time used 0.012001s\n",
      "batch 23132, train_loss 33.403713,Time used 0.011999s\n",
      "batch 23133, train_loss 35.046726,Time used 0.016001s\n",
      "batch 23134, train_loss 32.127632,Time used 0.013000s\n",
      "batch 23135, train_loss 34.270363,Time used 0.011998s\n",
      "batch 23136, train_loss 30.471106,Time used 0.012003s\n",
      "batch 23137, train_loss 33.080494,Time used 0.014000s\n",
      "batch 23138, train_loss 29.737112,Time used 0.013001s\n",
      "batch 23139, train_loss 32.427681,Time used 0.015001s\n",
      "batch 23140, train_loss 32.846107,Time used 0.025000s\n",
      "batch 23141, train_loss 26.161005,Time used 0.012003s\n",
      "batch 23142, train_loss 30.978205,Time used 0.010996s\n",
      "batch 23143, train_loss 34.474674,Time used 0.012001s\n",
      "batch 23144, train_loss 39.395470,Time used 0.012001s\n",
      "batch 23145, train_loss 25.167570,Time used 0.007999s\n",
      "batch 23146, train_loss 35.657112,Time used 0.010998s\n",
      "batch 23147, train_loss 32.160023,Time used 0.013001s\n",
      "batch 23148, train_loss 34.217262,Time used 0.014000s\n",
      "batch 23149, train_loss 23.542793,Time used 0.014000s\n",
      "batch 23150, train_loss 36.210335,Time used 0.013000s\n",
      "batch 23151, train_loss 34.060459,Time used 0.025000s\n",
      "batch 23152, train_loss 34.326893,Time used 0.015001s\n",
      "batch 23153, train_loss 34.990223,Time used 0.025998s\n",
      "batch 23154, train_loss 34.576237,Time used 0.013999s\n",
      "batch 23155, train_loss 28.749237,Time used 0.011000s\n",
      "batch 23156, train_loss 24.807272,Time used 0.009999s\n",
      "batch 23157, train_loss 35.099628,Time used 0.011002s\n",
      "batch 23158, train_loss 34.938118,Time used 0.013001s\n",
      "batch 23159, train_loss 29.297794,Time used 0.007999s\n",
      "batch 23160, train_loss 29.096624,Time used 0.007999s\n",
      "batch 23161, train_loss 27.402756,Time used 0.010002s\n",
      "batch 23162, train_loss 27.747330,Time used 0.010998s\n",
      "batch 23163, train_loss 35.084953,Time used 0.012002s\n",
      "batch 23164, train_loss 32.708183,Time used 0.011997s\n",
      "batch 23165, train_loss 36.481384,Time used 0.007999s\n",
      "batch 23166, train_loss 31.380274,Time used 0.011003s\n",
      "batch 23167, train_loss 36.934723,Time used 0.012002s\n",
      "batch 23168, train_loss 35.055218,Time used 0.011995s\n",
      "batch 23169, train_loss 34.143726,Time used 0.008001s\n",
      "batch 23170, train_loss 31.329914,Time used 0.009000s\n",
      "batch 23171, train_loss 26.518162,Time used 0.007999s\n",
      "batch 23172, train_loss 33.647312,Time used 0.014001s\n",
      "batch 23173, train_loss 31.995693,Time used 0.012001s\n",
      "batch 23174, train_loss 30.084024,Time used 0.011001s\n",
      "batch 23175, train_loss 24.711653,Time used 0.012998s\n",
      "batch 23176, train_loss 34.958145,Time used 0.012001s\n",
      "batch 23177, train_loss 28.809292,Time used 0.012000s\n",
      "batch 23178, train_loss 32.180927,Time used 0.010999s\n",
      "batch 23179, train_loss 26.989008,Time used 0.012001s\n",
      "batch 23180, train_loss 36.822918,Time used 0.012001s\n",
      "batch 23181, train_loss 28.146772,Time used 0.012998s\n",
      "batch 23182, train_loss 36.121498,Time used 0.012000s\n",
      "batch 23183, train_loss 28.653856,Time used 0.012005s\n",
      "batch 23184, train_loss 37.532558,Time used 0.010998s\n",
      "batch 23185, train_loss 27.743736,Time used 0.012998s\n",
      "batch 23186, train_loss 29.737732,Time used 0.016999s\n",
      "batch 23187, train_loss 29.821629,Time used 0.017000s\n",
      "batch 23188, train_loss 30.264311,Time used 0.014002s\n",
      "batch 23189, train_loss 35.156651,Time used 0.011999s\n",
      "batch 23190, train_loss 28.619276,Time used 0.015002s\n",
      "batch 23191, train_loss 34.941036,Time used 0.012001s\n",
      "batch 23192, train_loss 32.267002,Time used 0.015005s\n",
      "batch 23193, train_loss 40.013443,Time used 0.023004s\n",
      "batch 23194, train_loss 28.050346,Time used 0.012995s\n",
      "batch 23195, train_loss 38.477867,Time used 0.011001s\n",
      "batch 23196, train_loss 34.472286,Time used 0.012001s\n",
      "batch 23197, train_loss 38.317364,Time used 0.012000s\n",
      "batch 23198, train_loss 30.490049,Time used 0.009999s\n",
      "batch 23199, train_loss 30.583595,Time used 0.012001s\n",
      "batch 23200, train_loss 32.502026,Time used 0.011998s\n",
      "***************************test_batch 23200, test_rmse_loss 6.707767,test_mae_loss 2.918551,test_mape_loss 50.359913,Time used 0.050002s\n",
      "batch 23201, train_loss 29.292292,Time used 0.013003s\n",
      "batch 23202, train_loss 29.973536,Time used 0.013999s\n",
      "batch 23203, train_loss 25.756273,Time used 0.012997s\n",
      "batch 23204, train_loss 35.328423,Time used 0.012000s\n",
      "batch 23205, train_loss 28.279308,Time used 0.009002s\n",
      "batch 23206, train_loss 29.375807,Time used 0.013999s\n",
      "batch 23207, train_loss 30.275904,Time used 0.009997s\n",
      "batch 23208, train_loss 35.046753,Time used 0.010999s\n",
      "batch 23209, train_loss 36.901760,Time used 0.010999s\n",
      "batch 23210, train_loss 31.051422,Time used 0.011001s\n",
      "batch 23211, train_loss 30.692739,Time used 0.012004s\n",
      "batch 23212, train_loss 26.003202,Time used 0.011997s\n",
      "batch 23213, train_loss 37.077507,Time used 0.011000s\n",
      "batch 23214, train_loss 25.485779,Time used 0.009000s\n",
      "batch 23215, train_loss 31.695877,Time used 0.012999s\n",
      "batch 23216, train_loss 29.901705,Time used 0.013999s\n",
      "batch 23217, train_loss 33.949368,Time used 0.013004s\n",
      "batch 23218, train_loss 35.328362,Time used 0.010000s\n",
      "batch 23219, train_loss 24.978903,Time used 0.012002s\n",
      "batch 23220, train_loss 29.043705,Time used 0.025999s\n",
      "batch 23221, train_loss 31.824156,Time used 0.017998s\n",
      "batch 23222, train_loss 38.592609,Time used 0.016003s\n",
      "batch 23223, train_loss 39.045567,Time used 0.023997s\n",
      "batch 23224, train_loss 26.482721,Time used 0.014998s\n",
      "batch 23225, train_loss 32.910934,Time used 0.017005s\n",
      "batch 23226, train_loss 38.577900,Time used 0.023997s\n",
      "batch 23227, train_loss 31.548021,Time used 0.013999s\n",
      "batch 23228, train_loss 35.346901,Time used 0.026001s\n",
      "batch 23229, train_loss 29.419722,Time used 0.012999s\n",
      "batch 23230, train_loss 26.130365,Time used 0.013000s\n",
      "batch 23231, train_loss 29.023308,Time used 0.014002s\n",
      "batch 23232, train_loss 32.656151,Time used 0.012999s\n",
      "batch 23233, train_loss 30.563690,Time used 0.012997s\n",
      "batch 23234, train_loss 28.237545,Time used 0.013000s\n",
      "batch 23235, train_loss 29.656189,Time used 0.011999s\n",
      "batch 23236, train_loss 27.234657,Time used 0.021001s\n",
      "batch 23237, train_loss 26.876478,Time used 0.014000s\n",
      "batch 23238, train_loss 31.940483,Time used 0.008998s\n",
      "batch 23239, train_loss 32.055351,Time used 0.011000s\n",
      "batch 23240, train_loss 32.751652,Time used 0.009001s\n",
      "batch 23241, train_loss 32.101196,Time used 0.013000s\n",
      "batch 23242, train_loss 29.857527,Time used 0.010000s\n",
      "batch 23243, train_loss 39.228962,Time used 0.010000s\n",
      "batch 23244, train_loss 30.014736,Time used 0.009998s\n",
      "batch 23245, train_loss 34.849651,Time used 0.012000s\n",
      "batch 23246, train_loss 30.890079,Time used 0.008002s\n",
      "batch 23247, train_loss 35.012276,Time used 0.007999s\n",
      "batch 23248, train_loss 26.875578,Time used 0.011000s\n",
      "batch 23249, train_loss 24.607216,Time used 0.009003s\n",
      "batch 23250, train_loss 34.223591,Time used 0.007997s\n",
      "batch 23251, train_loss 44.729332,Time used 0.008001s\n",
      "batch 23252, train_loss 30.345964,Time used 0.008998s\n",
      "batch 23253, train_loss 42.178879,Time used 0.010001s\n",
      "batch 23254, train_loss 34.884937,Time used 0.011001s\n",
      "batch 23255, train_loss 25.964376,Time used 0.010001s\n",
      "batch 23256, train_loss 27.550711,Time used 0.012000s\n",
      "batch 23257, train_loss 30.299709,Time used 0.011998s\n",
      "batch 23258, train_loss 28.557644,Time used 0.008003s\n",
      "batch 23259, train_loss 22.016989,Time used 0.008000s\n",
      "batch 23260, train_loss 40.433872,Time used 0.008998s\n",
      "batch 23261, train_loss 31.102383,Time used 0.010003s\n",
      "batch 23262, train_loss 28.322668,Time used 0.007999s\n",
      "batch 23263, train_loss 33.519356,Time used 0.010000s\n",
      "batch 23264, train_loss 31.736395,Time used 0.011001s\n",
      "batch 23265, train_loss 25.004448,Time used 0.010997s\n",
      "batch 23266, train_loss 37.757915,Time used 0.008000s\n",
      "batch 23267, train_loss 35.346684,Time used 0.008997s\n",
      "batch 23268, train_loss 34.364540,Time used 0.008002s\n",
      "batch 23269, train_loss 31.225719,Time used 0.006999s\n",
      "batch 23270, train_loss 31.284973,Time used 0.012002s\n",
      "batch 23271, train_loss 25.680040,Time used 0.011999s\n",
      "batch 23272, train_loss 32.852093,Time used 0.010998s\n",
      "batch 23273, train_loss 37.459454,Time used 0.008001s\n",
      "batch 23274, train_loss 35.321732,Time used 0.010000s\n",
      "batch 23275, train_loss 32.320423,Time used 0.009998s\n",
      "batch 23276, train_loss 34.842621,Time used 0.007999s\n",
      "batch 23277, train_loss 34.198574,Time used 0.008004s\n",
      "batch 23278, train_loss 26.131508,Time used 0.010995s\n",
      "batch 23279, train_loss 33.756695,Time used 0.009004s\n",
      "batch 23280, train_loss 28.516470,Time used 0.008999s\n",
      "batch 23281, train_loss 27.222378,Time used 0.009000s\n",
      "batch 23282, train_loss 26.908861,Time used 0.006998s\n",
      "batch 23283, train_loss 36.053486,Time used 0.009001s\n",
      "batch 23284, train_loss 27.202120,Time used 0.008001s\n",
      "batch 23285, train_loss 30.981709,Time used 0.012003s\n",
      "batch 23286, train_loss 32.965694,Time used 0.011001s\n",
      "batch 23287, train_loss 38.517979,Time used 0.008000s\n",
      "batch 23288, train_loss 27.077650,Time used 0.008000s\n",
      "batch 23289, train_loss 27.603603,Time used 0.008001s\n",
      "batch 23290, train_loss 35.834541,Time used 0.008002s\n",
      "batch 23291, train_loss 32.014977,Time used 0.010000s\n",
      "batch 23292, train_loss 30.922861,Time used 0.010998s\n",
      "batch 23293, train_loss 35.361675,Time used 0.011003s\n",
      "batch 23294, train_loss 28.110989,Time used 0.007998s\n",
      "batch 23295, train_loss 35.623951,Time used 0.010001s\n",
      "batch 23296, train_loss 30.769650,Time used 0.009005s\n",
      "batch 23297, train_loss 30.477289,Time used 0.011994s\n",
      "batch 23298, train_loss 27.223898,Time used 0.009000s\n",
      "batch 23299, train_loss 37.406185,Time used 0.010001s\n",
      "batch 23300, train_loss 33.949589,Time used 0.011003s\n",
      "***************************test_batch 23300, test_rmse_loss 6.702222,test_mae_loss 2.917246,test_mape_loss 50.127993,Time used 0.030999s\n",
      "batch 23301, train_loss 33.442970,Time used 0.009000s\n",
      "batch 23302, train_loss 33.047199,Time used 0.007000s\n",
      "batch 23303, train_loss 32.716347,Time used 0.010999s\n",
      "batch 23304, train_loss 29.727671,Time used 0.007999s\n",
      "batch 23305, train_loss 28.339512,Time used 0.011000s\n",
      "batch 23306, train_loss 29.592871,Time used 0.010001s\n",
      "batch 23307, train_loss 28.191957,Time used 0.009003s\n",
      "batch 23308, train_loss 35.726799,Time used 0.010996s\n",
      "batch 23309, train_loss 38.408581,Time used 0.007998s\n",
      "batch 23310, train_loss 28.328518,Time used 0.008000s\n",
      "batch 23311, train_loss 32.239296,Time used 0.012004s\n",
      "batch 23312, train_loss 35.492550,Time used 0.012999s\n",
      "batch 23313, train_loss 27.841930,Time used 0.009998s\n",
      "batch 23314, train_loss 26.907480,Time used 0.011001s\n",
      "batch 23315, train_loss 26.949677,Time used 0.012000s\n",
      "batch 23316, train_loss 29.405756,Time used 0.012000s\n",
      "batch 23317, train_loss 32.219570,Time used 0.011999s\n",
      "batch 23318, train_loss 35.243679,Time used 0.012000s\n",
      "batch 23319, train_loss 26.186327,Time used 0.007999s\n",
      "batch 23320, train_loss 29.994265,Time used 0.009000s\n",
      "batch 23321, train_loss 40.787189,Time used 0.008003s\n",
      "batch 23322, train_loss 33.165070,Time used 0.009999s\n",
      "batch 23323, train_loss 31.253138,Time used 0.007999s\n",
      "batch 23324, train_loss 31.450590,Time used 0.008003s\n",
      "batch 23325, train_loss 33.692112,Time used 0.008002s\n",
      "batch 23326, train_loss 32.045689,Time used 0.011998s\n",
      "batch 23327, train_loss 34.989979,Time used 0.012998s\n",
      "batch 23328, train_loss 31.994560,Time used 0.014000s\n",
      "batch 23329, train_loss 30.634489,Time used 0.011998s\n",
      "batch 23330, train_loss 31.719101,Time used 0.010999s\n",
      "batch 23331, train_loss 31.642231,Time used 0.011999s\n",
      "batch 23332, train_loss 37.325306,Time used 0.013000s\n",
      "batch 23333, train_loss 38.147530,Time used 0.012002s\n",
      "batch 23334, train_loss 31.976578,Time used 0.007999s\n",
      "batch 23335, train_loss 32.608517,Time used 0.009999s\n",
      "batch 23336, train_loss 29.885767,Time used 0.009000s\n",
      "batch 23337, train_loss 35.932491,Time used 0.007999s\n",
      "batch 23338, train_loss 32.400703,Time used 0.009001s\n",
      "batch 23339, train_loss 35.543110,Time used 0.009001s\n",
      "batch 23340, train_loss 27.703781,Time used 0.010999s\n",
      "batch 23341, train_loss 30.867025,Time used 0.008001s\n",
      "batch 23342, train_loss 31.154676,Time used 0.010002s\n",
      "batch 23343, train_loss 35.058823,Time used 0.012001s\n",
      "batch 23344, train_loss 28.271461,Time used 0.010999s\n",
      "batch 23345, train_loss 23.354111,Time used 0.011999s\n",
      "batch 23346, train_loss 26.177809,Time used 0.011999s\n",
      "batch 23347, train_loss 28.398777,Time used 0.008001s\n",
      "batch 23348, train_loss 28.033329,Time used 0.008000s\n",
      "batch 23349, train_loss 33.238510,Time used 0.006999s\n",
      "batch 23350, train_loss 34.112747,Time used 0.011002s\n",
      "batch 23351, train_loss 31.721270,Time used 0.008000s\n",
      "batch 23352, train_loss 33.882053,Time used 0.010000s\n",
      "batch 23353, train_loss 27.664000,Time used 0.011999s\n",
      "batch 23354, train_loss 28.348942,Time used 0.012001s\n",
      "batch 23355, train_loss 36.001816,Time used 0.009001s\n",
      "batch 23356, train_loss 29.640865,Time used 0.007999s\n",
      "batch 23357, train_loss 28.115467,Time used 0.011003s\n",
      "batch 23358, train_loss 31.301693,Time used 0.007998s\n",
      "batch 23359, train_loss 31.949736,Time used 0.011998s\n",
      "batch 23360, train_loss 31.318344,Time used 0.009002s\n",
      "batch 23361, train_loss 33.514904,Time used 0.012000s\n",
      "batch 23362, train_loss 36.180691,Time used 0.011002s\n",
      "batch 23363, train_loss 37.048195,Time used 0.008996s\n",
      "batch 23364, train_loss 35.520809,Time used 0.014002s\n",
      "batch 23365, train_loss 30.784538,Time used 0.008000s\n",
      "batch 23366, train_loss 27.370123,Time used 0.009998s\n",
      "batch 23367, train_loss 31.462215,Time used 0.011003s\n",
      "batch 23368, train_loss 33.617607,Time used 0.007998s\n",
      "batch 23369, train_loss 27.236118,Time used 0.009000s\n",
      "batch 23370, train_loss 35.675339,Time used 0.012002s\n",
      "batch 23371, train_loss 24.310753,Time used 0.010998s\n",
      "batch 23372, train_loss 36.620441,Time used 0.011000s\n",
      "batch 23373, train_loss 29.512201,Time used 0.012002s\n",
      "batch 23374, train_loss 33.865944,Time used 0.008000s\n",
      "batch 23375, train_loss 36.938213,Time used 0.008999s\n",
      "batch 23376, train_loss 24.754574,Time used 0.008000s\n",
      "batch 23377, train_loss 36.706127,Time used 0.009000s\n",
      "batch 23378, train_loss 32.834599,Time used 0.010001s\n",
      "batch 23379, train_loss 35.018124,Time used 0.012001s\n",
      "batch 23380, train_loss 32.959290,Time used 0.010997s\n",
      "batch 23381, train_loss 31.029823,Time used 0.008002s\n",
      "batch 23382, train_loss 31.403639,Time used 0.006991s\n",
      "batch 23383, train_loss 34.226147,Time used 0.012001s\n",
      "batch 23384, train_loss 26.781694,Time used 0.008000s\n",
      "batch 23385, train_loss 33.599812,Time used 0.010999s\n",
      "batch 23386, train_loss 28.878265,Time used 0.009999s\n",
      "batch 23387, train_loss 36.857422,Time used 0.008000s\n",
      "batch 23388, train_loss 30.303761,Time used 0.008000s\n",
      "batch 23389, train_loss 31.334383,Time used 0.008002s\n",
      "batch 23390, train_loss 29.497509,Time used 0.008001s\n",
      "batch 23391, train_loss 30.084328,Time used 0.011001s\n",
      "batch 23392, train_loss 35.379410,Time used 0.007999s\n",
      "batch 23393, train_loss 30.208801,Time used 0.007998s\n",
      "batch 23394, train_loss 32.169659,Time used 0.010000s\n",
      "batch 23395, train_loss 33.343697,Time used 0.008003s\n",
      "batch 23396, train_loss 27.159876,Time used 0.008000s\n",
      "batch 23397, train_loss 29.144396,Time used 0.006999s\n",
      "batch 23398, train_loss 28.324459,Time used 0.007041s\n",
      "batch 23399, train_loss 35.863972,Time used 0.009001s\n",
      "batch 23400, train_loss 24.962080,Time used 0.011965s\n",
      "***************************test_batch 23400, test_rmse_loss 6.690887,test_mae_loss 2.912291,test_mape_loss 50.069564,Time used 0.044011s\n",
      "batch 23401, train_loss 29.049250,Time used 0.011965s\n",
      "batch 23402, train_loss 29.346813,Time used 0.007001s\n",
      "batch 23403, train_loss 30.555611,Time used 0.009997s\n",
      "batch 23404, train_loss 29.527826,Time used 0.009038s\n",
      "batch 23405, train_loss 30.354605,Time used 0.008999s\n",
      "batch 23406, train_loss 32.640095,Time used 0.007965s\n",
      "batch 23407, train_loss 31.864729,Time used 0.007033s\n",
      "batch 23408, train_loss 37.973412,Time used 0.007970s\n",
      "batch 23409, train_loss 35.066303,Time used 0.010998s\n",
      "batch 23410, train_loss 30.257132,Time used 0.012000s\n",
      "batch 23411, train_loss 35.119942,Time used 0.007040s\n",
      "batch 23412, train_loss 31.658541,Time used 0.007960s\n",
      "batch 23413, train_loss 37.571457,Time used 0.009003s\n",
      "batch 23414, train_loss 35.611401,Time used 0.008000s\n",
      "batch 23415, train_loss 30.524010,Time used 0.007997s\n",
      "batch 23416, train_loss 27.273129,Time used 0.007999s\n",
      "batch 23417, train_loss 29.546179,Time used 0.009003s\n",
      "batch 23418, train_loss 35.575615,Time used 0.012036s\n",
      "batch 23419, train_loss 24.558527,Time used 0.011963s\n",
      "batch 23420, train_loss 27.182945,Time used 0.009038s\n",
      "batch 23421, train_loss 31.407454,Time used 0.007965s\n",
      "batch 23422, train_loss 29.939869,Time used 0.013000s\n",
      "batch 23423, train_loss 31.205923,Time used 0.009033s\n",
      "batch 23424, train_loss 33.305382,Time used 0.008000s\n",
      "batch 23425, train_loss 25.584183,Time used 0.008999s\n",
      "batch 23426, train_loss 32.698204,Time used 0.007999s\n",
      "batch 23427, train_loss 33.960892,Time used 0.008000s\n",
      "batch 23428, train_loss 34.152126,Time used 0.008998s\n",
      "batch 23429, train_loss 26.847466,Time used 0.009001s\n",
      "batch 23430, train_loss 36.584011,Time used 0.011001s\n",
      "batch 23431, train_loss 32.540215,Time used 0.009001s\n",
      "batch 23432, train_loss 36.394684,Time used 0.008000s\n",
      "batch 23433, train_loss 27.538645,Time used 0.010000s\n",
      "batch 23434, train_loss 30.437408,Time used 0.013001s\n",
      "batch 23435, train_loss 26.918476,Time used 0.010998s\n",
      "batch 23436, train_loss 31.017874,Time used 0.009001s\n",
      "batch 23437, train_loss 32.513901,Time used 0.009001s\n",
      "batch 23438, train_loss 30.727642,Time used 0.009003s\n",
      "batch 23439, train_loss 27.527777,Time used 0.008999s\n",
      "batch 23440, train_loss 31.416965,Time used 0.010000s\n",
      "batch 23441, train_loss 34.334976,Time used 0.011998s\n",
      "batch 23442, train_loss 29.263168,Time used 0.012000s\n",
      "batch 23443, train_loss 38.280369,Time used 0.010003s\n",
      "batch 23444, train_loss 31.436083,Time used 0.007999s\n",
      "batch 23445, train_loss 27.315447,Time used 0.008000s\n",
      "batch 23446, train_loss 33.616428,Time used 0.007999s\n",
      "batch 23447, train_loss 37.516819,Time used 0.009001s\n",
      "batch 23448, train_loss 27.512482,Time used 0.008000s\n",
      "batch 23449, train_loss 35.617966,Time used 0.008001s\n",
      "batch 23450, train_loss 25.006737,Time used 0.008009s\n",
      "batch 23451, train_loss 26.183062,Time used 0.011990s\n",
      "batch 23452, train_loss 34.003712,Time used 0.010001s\n",
      "batch 23453, train_loss 31.175684,Time used 0.007998s\n",
      "batch 23454, train_loss 32.099499,Time used 0.009002s\n",
      "batch 23455, train_loss 37.390858,Time used 0.011999s\n",
      "batch 23456, train_loss 27.545992,Time used 0.009001s\n",
      "batch 23457, train_loss 33.581497,Time used 0.010000s\n",
      "batch 23458, train_loss 30.977503,Time used 0.007997s\n",
      "batch 23459, train_loss 24.534512,Time used 0.008000s\n",
      "batch 23460, train_loss 37.436062,Time used 0.009002s\n",
      "batch 23461, train_loss 33.840656,Time used 0.007998s\n",
      "batch 23462, train_loss 33.842136,Time used 0.007998s\n",
      "batch 23463, train_loss 27.693306,Time used 0.010000s\n",
      "batch 23464, train_loss 36.209976,Time used 0.008001s\n",
      "batch 23465, train_loss 28.467623,Time used 0.007999s\n",
      "batch 23466, train_loss 30.555056,Time used 0.008996s\n",
      "batch 23467, train_loss 29.872025,Time used 0.010999s\n",
      "batch 23468, train_loss 34.580776,Time used 0.008000s\n",
      "batch 23469, train_loss 37.159653,Time used 0.012002s\n",
      "batch 23470, train_loss 30.227453,Time used 0.011997s\n",
      "batch 23471, train_loss 31.480478,Time used 0.010001s\n",
      "batch 23472, train_loss 25.895346,Time used 0.007999s\n",
      "batch 23473, train_loss 32.313274,Time used 0.011001s\n",
      "batch 23474, train_loss 30.950689,Time used 0.008999s\n",
      "batch 23475, train_loss 29.882679,Time used 0.011002s\n",
      "batch 23476, train_loss 31.532236,Time used 0.011999s\n",
      "batch 23477, train_loss 28.065325,Time used 0.007998s\n",
      "batch 23478, train_loss 28.523882,Time used 0.008004s\n",
      "batch 23479, train_loss 30.490269,Time used 0.007998s\n",
      "batch 23480, train_loss 32.739052,Time used 0.011000s\n",
      "batch 23481, train_loss 34.814926,Time used 0.010999s\n",
      "batch 23482, train_loss 26.277481,Time used 0.011001s\n",
      "batch 23483, train_loss 38.247711,Time used 0.010999s\n",
      "batch 23484, train_loss 29.242817,Time used 0.007998s\n",
      "batch 23485, train_loss 34.729710,Time used 0.011999s\n",
      "batch 23486, train_loss 29.672178,Time used 0.008003s\n",
      "batch 23487, train_loss 29.800596,Time used 0.006999s\n",
      "batch 23488, train_loss 33.560432,Time used 0.006998s\n",
      "batch 23489, train_loss 33.009281,Time used 0.008005s\n",
      "batch 23490, train_loss 29.992582,Time used 0.007995s\n",
      "batch 23491, train_loss 31.919989,Time used 0.010005s\n",
      "batch 23492, train_loss 31.601332,Time used 0.008996s\n",
      "batch 23493, train_loss 29.638620,Time used 0.010000s\n",
      "batch 23494, train_loss 34.851475,Time used 0.008004s\n",
      "batch 23495, train_loss 28.440514,Time used 0.007002s\n",
      "batch 23496, train_loss 34.231159,Time used 0.008993s\n",
      "batch 23497, train_loss 33.984631,Time used 0.008998s\n",
      "batch 23498, train_loss 34.952965,Time used 0.010005s\n",
      "batch 23499, train_loss 30.784416,Time used 0.010000s\n",
      "batch 23500, train_loss 28.871149,Time used 0.007994s\n",
      "***************************test_batch 23500, test_rmse_loss 6.677926,test_mae_loss 2.908883,test_mape_loss 50.093927,Time used 0.036997s\n",
      "batch 23501, train_loss 35.760685,Time used 0.008006s\n",
      "batch 23502, train_loss 29.068777,Time used 0.008995s\n",
      "batch 23503, train_loss 35.655247,Time used 0.008000s\n",
      "batch 23504, train_loss 33.227745,Time used 0.009999s\n",
      "batch 23505, train_loss 33.093250,Time used 0.006999s\n",
      "batch 23506, train_loss 28.542421,Time used 0.008002s\n",
      "batch 23507, train_loss 31.545853,Time used 0.012000s\n",
      "batch 23508, train_loss 29.130966,Time used 0.009002s\n",
      "batch 23509, train_loss 26.286682,Time used 0.009998s\n",
      "batch 23510, train_loss 36.049168,Time used 0.010000s\n",
      "batch 23511, train_loss 21.395039,Time used 0.008998s\n",
      "batch 23512, train_loss 34.533474,Time used 0.008000s\n",
      "batch 23513, train_loss 33.853550,Time used 0.012002s\n",
      "batch 23514, train_loss 33.187252,Time used 0.012002s\n",
      "batch 23515, train_loss 32.311440,Time used 0.010998s\n",
      "batch 23516, train_loss 31.984072,Time used 0.006999s\n",
      "batch 23517, train_loss 28.534302,Time used 0.007003s\n",
      "batch 23518, train_loss 32.559925,Time used 0.008998s\n",
      "batch 23519, train_loss 28.907862,Time used 0.010002s\n",
      "batch 23520, train_loss 29.363308,Time used 0.012999s\n",
      "batch 23521, train_loss 25.450842,Time used 0.008001s\n",
      "batch 23522, train_loss 31.015760,Time used 0.006999s\n",
      "batch 23523, train_loss 32.689182,Time used 0.012000s\n",
      "batch 23524, train_loss 29.628548,Time used 0.011999s\n",
      "batch 23525, train_loss 28.498131,Time used 0.010000s\n",
      "batch 23526, train_loss 28.923748,Time used 0.012000s\n",
      "batch 23527, train_loss 19.996817,Time used 0.010000s\n",
      "batch 23528, train_loss 30.984148,Time used 0.008002s\n",
      "batch 23529, train_loss 34.328781,Time used 0.010000s\n",
      "batch 23530, train_loss 34.151611,Time used 0.007002s\n",
      "batch 23531, train_loss 40.613880,Time used 0.009003s\n",
      "batch 23532, train_loss 29.165129,Time used 0.010996s\n",
      "batch 23533, train_loss 34.010746,Time used 0.012000s\n",
      "batch 23534, train_loss 34.357510,Time used 0.012001s\n",
      "batch 23535, train_loss 33.250088,Time used 0.012000s\n",
      "batch 23536, train_loss 29.960587,Time used 0.008002s\n",
      "batch 23537, train_loss 26.499872,Time used 0.011998s\n",
      "batch 23538, train_loss 30.967854,Time used 0.012000s\n",
      "batch 23539, train_loss 32.508671,Time used 0.011001s\n",
      "batch 23540, train_loss 32.242813,Time used 0.009999s\n",
      "batch 23541, train_loss 36.438049,Time used 0.010998s\n",
      "batch 23542, train_loss 28.268063,Time used 0.010001s\n",
      "batch 23543, train_loss 31.989239,Time used 0.009999s\n",
      "batch 23544, train_loss 37.108688,Time used 0.010001s\n",
      "batch 23545, train_loss 27.644098,Time used 0.010999s\n",
      "batch 23546, train_loss 32.962875,Time used 0.011003s\n",
      "batch 23547, train_loss 26.400585,Time used 0.010999s\n",
      "batch 23548, train_loss 33.096462,Time used 0.011002s\n",
      "batch 23549, train_loss 27.256872,Time used 0.010000s\n",
      "batch 23550, train_loss 34.132126,Time used 0.009001s\n",
      "batch 23551, train_loss 32.264069,Time used 0.008999s\n",
      "batch 23552, train_loss 36.704636,Time used 0.009001s\n",
      "batch 23553, train_loss 30.958553,Time used 0.009000s\n",
      "batch 23554, train_loss 24.523037,Time used 0.013000s\n",
      "batch 23555, train_loss 31.958136,Time used 0.010002s\n",
      "batch 23556, train_loss 32.793312,Time used 0.008997s\n",
      "batch 23557, train_loss 31.949594,Time used 0.011000s\n",
      "batch 23558, train_loss 28.774317,Time used 0.009000s\n",
      "batch 23559, train_loss 37.431824,Time used 0.008002s\n",
      "batch 23560, train_loss 34.169643,Time used 0.008999s\n",
      "batch 23561, train_loss 34.702702,Time used 0.007999s\n",
      "batch 23562, train_loss 30.231016,Time used 0.008998s\n",
      "batch 23563, train_loss 26.180090,Time used 0.008002s\n",
      "batch 23564, train_loss 25.012878,Time used 0.008000s\n",
      "batch 23565, train_loss 32.072048,Time used 0.010001s\n",
      "batch 23566, train_loss 38.834797,Time used 0.011998s\n",
      "batch 23567, train_loss 30.066256,Time used 0.009001s\n",
      "batch 23568, train_loss 32.133911,Time used 0.006999s\n",
      "batch 23569, train_loss 31.584835,Time used 0.011000s\n",
      "batch 23570, train_loss 30.404722,Time used 0.009000s\n",
      "batch 23571, train_loss 26.340279,Time used 0.008001s\n",
      "batch 23572, train_loss 27.799992,Time used 0.007999s\n",
      "batch 23573, train_loss 27.326546,Time used 0.007001s\n",
      "batch 23574, train_loss 27.391558,Time used 0.010000s\n",
      "batch 23575, train_loss 28.123995,Time used 0.011000s\n",
      "batch 23576, train_loss 28.445795,Time used 0.008000s\n",
      "batch 23577, train_loss 34.674988,Time used 0.012001s\n",
      "batch 23578, train_loss 28.935579,Time used 0.011001s\n",
      "batch 23579, train_loss 28.614767,Time used 0.011001s\n",
      "batch 23580, train_loss 31.098511,Time used 0.008000s\n",
      "batch 23581, train_loss 34.165909,Time used 0.011000s\n",
      "batch 23582, train_loss 32.530407,Time used 0.008999s\n",
      "batch 23583, train_loss 35.569260,Time used 0.012001s\n",
      "batch 23584, train_loss 28.721859,Time used 0.010000s\n",
      "batch 23585, train_loss 29.040850,Time used 0.007998s\n",
      "batch 23586, train_loss 34.846695,Time used 0.009004s\n",
      "batch 23587, train_loss 36.432171,Time used 0.008999s\n",
      "batch 23588, train_loss 30.551975,Time used 0.009999s\n",
      "batch 23589, train_loss 30.006634,Time used 0.008003s\n",
      "batch 23590, train_loss 35.101460,Time used 0.008006s\n",
      "batch 23591, train_loss 35.636253,Time used 0.008994s\n",
      "batch 23592, train_loss 38.196106,Time used 0.008000s\n",
      "batch 23593, train_loss 23.623840,Time used 0.009003s\n",
      "batch 23594, train_loss 35.503799,Time used 0.007999s\n",
      "batch 23595, train_loss 26.521959,Time used 0.008037s\n",
      "batch 23596, train_loss 32.610516,Time used 0.011963s\n",
      "batch 23597, train_loss 26.445908,Time used 0.010998s\n",
      "batch 23598, train_loss 37.526451,Time used 0.008001s\n",
      "batch 23599, train_loss 26.186806,Time used 0.008004s\n",
      "batch 23600, train_loss 28.924957,Time used 0.007001s\n",
      "***************************test_batch 23600, test_rmse_loss 6.671435,test_mae_loss 2.905174,test_mape_loss 50.019067,Time used 0.032996s\n",
      "batch 23601, train_loss 31.152069,Time used 0.008000s\n",
      "batch 23602, train_loss 37.377556,Time used 0.008999s\n",
      "batch 23603, train_loss 30.142452,Time used 0.007000s\n",
      "batch 23604, train_loss 34.325695,Time used 0.011002s\n",
      "batch 23605, train_loss 37.780369,Time used 0.008999s\n",
      "batch 23606, train_loss 27.086933,Time used 0.010998s\n",
      "batch 23607, train_loss 37.836262,Time used 0.012006s\n",
      "batch 23608, train_loss 26.270796,Time used 0.009001s\n",
      "batch 23609, train_loss 24.721888,Time used 0.011999s\n",
      "batch 23610, train_loss 29.395205,Time used 0.012001s\n",
      "batch 23611, train_loss 32.634007,Time used 0.008999s\n",
      "batch 23612, train_loss 41.946354,Time used 0.012999s\n",
      "batch 23613, train_loss 32.998280,Time used 0.017999s\n",
      "batch 23614, train_loss 19.998024,Time used 0.008998s\n",
      "batch 23615, train_loss 39.279099,Time used 0.014000s\n",
      "batch 23616, train_loss 30.540493,Time used 0.012999s\n",
      "batch 23617, train_loss 30.175922,Time used 0.012998s\n",
      "batch 23618, train_loss 34.191856,Time used 0.012999s\n",
      "batch 23619, train_loss 26.316502,Time used 0.012003s\n",
      "batch 23620, train_loss 31.790298,Time used 0.012998s\n",
      "batch 23621, train_loss 28.547617,Time used 0.013001s\n",
      "batch 23622, train_loss 26.153027,Time used 0.012000s\n",
      "batch 23623, train_loss 26.367203,Time used 0.010999s\n",
      "batch 23624, train_loss 34.517853,Time used 0.013000s\n",
      "batch 23625, train_loss 32.773933,Time used 0.012000s\n",
      "batch 23626, train_loss 33.935585,Time used 0.011000s\n",
      "batch 23627, train_loss 32.961678,Time used 0.018998s\n",
      "batch 23628, train_loss 37.952522,Time used 0.019001s\n",
      "batch 23629, train_loss 34.553940,Time used 0.012001s\n",
      "batch 23630, train_loss 31.209181,Time used 0.014999s\n",
      "batch 23631, train_loss 31.491274,Time used 0.023000s\n",
      "batch 23632, train_loss 31.039688,Time used 0.013999s\n",
      "batch 23633, train_loss 33.429947,Time used 0.016001s\n",
      "batch 23634, train_loss 26.167334,Time used 0.013000s\n",
      "batch 23635, train_loss 25.688349,Time used 0.014999s\n",
      "batch 23636, train_loss 32.591595,Time used 0.012001s\n",
      "batch 23637, train_loss 33.908718,Time used 0.011999s\n",
      "batch 23638, train_loss 36.683483,Time used 0.011002s\n",
      "batch 23639, train_loss 25.815100,Time used 0.016999s\n",
      "batch 23640, train_loss 31.639143,Time used 0.011001s\n",
      "batch 23641, train_loss 27.166380,Time used 0.013000s\n",
      "batch 23642, train_loss 29.681013,Time used 0.011999s\n",
      "batch 23643, train_loss 34.091194,Time used 0.012001s\n",
      "batch 23644, train_loss 29.462591,Time used 0.012999s\n",
      "batch 23645, train_loss 27.322477,Time used 0.012999s\n",
      "batch 23646, train_loss 34.057114,Time used 0.008999s\n",
      "batch 23647, train_loss 24.029917,Time used 0.010002s\n",
      "batch 23648, train_loss 26.364737,Time used 0.010000s\n",
      "batch 23649, train_loss 29.107859,Time used 0.010999s\n",
      "batch 23650, train_loss 30.579805,Time used 0.008998s\n",
      "batch 23651, train_loss 27.061678,Time used 0.008002s\n",
      "batch 23652, train_loss 30.763071,Time used 0.008003s\n",
      "batch 23653, train_loss 26.607281,Time used 0.009996s\n",
      "batch 23654, train_loss 35.263535,Time used 0.012000s\n",
      "batch 23655, train_loss 24.549685,Time used 0.007998s\n",
      "batch 23656, train_loss 40.853607,Time used 0.011001s\n",
      "batch 23657, train_loss 39.253620,Time used 0.009001s\n",
      "batch 23658, train_loss 39.344803,Time used 0.009001s\n",
      "batch 23659, train_loss 30.487080,Time used 0.011001s\n",
      "batch 23660, train_loss 27.587482,Time used 0.012000s\n",
      "batch 23661, train_loss 37.106270,Time used 0.011998s\n",
      "batch 23662, train_loss 36.859219,Time used 0.012006s\n",
      "batch 23663, train_loss 26.203072,Time used 0.011996s\n",
      "batch 23664, train_loss 35.190388,Time used 0.011000s\n",
      "batch 23665, train_loss 37.630642,Time used 0.009003s\n",
      "batch 23666, train_loss 27.445141,Time used 0.009998s\n",
      "batch 23667, train_loss 25.520529,Time used 0.009000s\n",
      "batch 23668, train_loss 36.113163,Time used 0.008998s\n",
      "batch 23669, train_loss 30.525795,Time used 0.010004s\n",
      "batch 23670, train_loss 36.183975,Time used 0.006997s\n",
      "batch 23671, train_loss 24.702175,Time used 0.008000s\n",
      "batch 23672, train_loss 25.183853,Time used 0.006998s\n",
      "batch 23673, train_loss 31.223032,Time used 0.008000s\n",
      "batch 23674, train_loss 27.739439,Time used 0.007000s\n",
      "batch 23675, train_loss 26.110340,Time used 0.009000s\n",
      "batch 23676, train_loss 26.410511,Time used 0.007998s\n",
      "batch 23677, train_loss 29.873804,Time used 0.010001s\n",
      "batch 23678, train_loss 28.982555,Time used 0.011002s\n",
      "batch 23679, train_loss 32.245502,Time used 0.011002s\n",
      "batch 23680, train_loss 46.277218,Time used 0.008002s\n",
      "batch 23681, train_loss 30.576908,Time used 0.008035s\n",
      "batch 23682, train_loss 33.904800,Time used 0.007959s\n",
      "batch 23683, train_loss 30.602835,Time used 0.008002s\n",
      "batch 23684, train_loss 30.423420,Time used 0.010998s\n",
      "batch 23685, train_loss 28.013500,Time used 0.008001s\n",
      "batch 23686, train_loss 35.617153,Time used 0.012001s\n",
      "batch 23687, train_loss 34.714275,Time used 0.010999s\n",
      "batch 23688, train_loss 32.109833,Time used 0.011002s\n",
      "batch 23689, train_loss 25.315285,Time used 0.009000s\n",
      "batch 23690, train_loss 30.983078,Time used 0.011000s\n",
      "batch 23691, train_loss 32.534660,Time used 0.011997s\n",
      "batch 23692, train_loss 36.011616,Time used 0.011000s\n",
      "batch 23693, train_loss 27.371223,Time used 0.008000s\n",
      "batch 23694, train_loss 32.249920,Time used 0.009001s\n",
      "batch 23695, train_loss 28.931135,Time used 0.008000s\n",
      "batch 23696, train_loss 31.977810,Time used 0.011003s\n",
      "batch 23697, train_loss 30.916552,Time used 0.011999s\n",
      "batch 23698, train_loss 28.838081,Time used 0.008001s\n",
      "batch 23699, train_loss 29.629705,Time used 0.009002s\n",
      "batch 23700, train_loss 28.974529,Time used 0.008000s\n",
      "***************************test_batch 23700, test_rmse_loss 6.661114,test_mae_loss 2.902777,test_mape_loss 50.017579,Time used 0.033998s\n",
      "batch 23701, train_loss 24.605812,Time used 0.011001s\n",
      "batch 23702, train_loss 34.654160,Time used 0.011002s\n",
      "batch 23703, train_loss 37.941124,Time used 0.011999s\n",
      "batch 23704, train_loss 27.016815,Time used 0.010001s\n",
      "batch 23705, train_loss 35.385838,Time used 0.009003s\n",
      "batch 23706, train_loss 31.044691,Time used 0.010995s\n",
      "batch 23707, train_loss 25.498369,Time used 0.008999s\n",
      "batch 23708, train_loss 34.412540,Time used 0.008001s\n",
      "batch 23709, train_loss 30.690184,Time used 0.007999s\n",
      "batch 23710, train_loss 41.373394,Time used 0.011000s\n",
      "batch 23711, train_loss 31.888142,Time used 0.008000s\n",
      "batch 23712, train_loss 28.791258,Time used 0.008002s\n",
      "batch 23713, train_loss 26.418957,Time used 0.010004s\n",
      "batch 23714, train_loss 33.290470,Time used 0.010000s\n",
      "batch 23715, train_loss 31.468878,Time used 0.011998s\n",
      "batch 23716, train_loss 29.339062,Time used 0.009000s\n",
      "batch 23717, train_loss 32.232700,Time used 0.009999s\n",
      "batch 23718, train_loss 38.603958,Time used 0.010999s\n",
      "batch 23719, train_loss 36.332386,Time used 0.011001s\n",
      "batch 23720, train_loss 30.489388,Time used 0.007999s\n",
      "batch 23721, train_loss 27.956135,Time used 0.007999s\n",
      "batch 23722, train_loss 25.265694,Time used 0.009038s\n",
      "batch 23723, train_loss 27.591772,Time used 0.010969s\n",
      "batch 23724, train_loss 30.454340,Time used 0.009001s\n",
      "batch 23725, train_loss 38.423878,Time used 0.008998s\n",
      "batch 23726, train_loss 33.296837,Time used 0.008000s\n",
      "batch 23727, train_loss 33.504669,Time used 0.009001s\n",
      "batch 23728, train_loss 31.397671,Time used 0.007999s\n",
      "batch 23729, train_loss 29.009228,Time used 0.009003s\n",
      "batch 23730, train_loss 32.336254,Time used 0.007999s\n",
      "batch 23731, train_loss 31.528437,Time used 0.010999s\n",
      "batch 23732, train_loss 32.940144,Time used 0.011999s\n",
      "batch 23733, train_loss 30.000702,Time used 0.007999s\n",
      "batch 23734, train_loss 23.564331,Time used 0.013001s\n",
      "batch 23735, train_loss 31.215599,Time used 0.011001s\n",
      "batch 23736, train_loss 29.788866,Time used 0.010998s\n",
      "batch 23737, train_loss 28.304832,Time used 0.008001s\n",
      "batch 23738, train_loss 26.371958,Time used 0.009999s\n",
      "batch 23739, train_loss 45.486626,Time used 0.012001s\n",
      "batch 23740, train_loss 31.654369,Time used 0.012002s\n",
      "batch 23741, train_loss 29.370424,Time used 0.010997s\n",
      "batch 23742, train_loss 21.990122,Time used 0.010000s\n",
      "batch 23743, train_loss 30.909800,Time used 0.009001s\n",
      "batch 23744, train_loss 26.729776,Time used 0.009000s\n",
      "batch 23745, train_loss 37.622795,Time used 0.012002s\n",
      "batch 23746, train_loss 26.200338,Time used 0.009999s\n",
      "batch 23747, train_loss 26.342075,Time used 0.008000s\n",
      "batch 23748, train_loss 31.478832,Time used 0.011000s\n",
      "batch 23749, train_loss 31.099779,Time used 0.010002s\n",
      "batch 23750, train_loss 29.406315,Time used 0.008999s\n",
      "batch 23751, train_loss 29.196070,Time used 0.007997s\n",
      "batch 23752, train_loss 33.467346,Time used 0.008003s\n",
      "batch 23753, train_loss 33.200863,Time used 0.010997s\n",
      "batch 23754, train_loss 36.031128,Time used 0.011000s\n",
      "batch 23755, train_loss 30.635921,Time used 0.010002s\n",
      "batch 23756, train_loss 23.595181,Time used 0.009998s\n",
      "batch 23757, train_loss 31.610262,Time used 0.009002s\n",
      "batch 23758, train_loss 34.955124,Time used 0.012000s\n",
      "batch 23759, train_loss 34.063385,Time used 0.009999s\n",
      "batch 23760, train_loss 36.074638,Time used 0.008999s\n",
      "batch 23761, train_loss 33.505344,Time used 0.010001s\n",
      "batch 23762, train_loss 33.744389,Time used 0.010998s\n",
      "batch 23763, train_loss 27.755407,Time used 0.008001s\n",
      "batch 23764, train_loss 32.546993,Time used 0.008003s\n",
      "batch 23765, train_loss 29.812674,Time used 0.009998s\n",
      "batch 23766, train_loss 27.619183,Time used 0.009000s\n",
      "batch 23767, train_loss 31.735674,Time used 0.008998s\n",
      "batch 23768, train_loss 35.612671,Time used 0.008000s\n",
      "batch 23769, train_loss 32.059162,Time used 0.008001s\n",
      "batch 23770, train_loss 27.978401,Time used 0.007998s\n",
      "batch 23771, train_loss 33.028404,Time used 0.009999s\n",
      "batch 23772, train_loss 31.468409,Time used 0.008001s\n",
      "batch 23773, train_loss 29.488987,Time used 0.010001s\n",
      "batch 23774, train_loss 29.344801,Time used 0.012001s\n",
      "batch 23775, train_loss 32.926380,Time used 0.008998s\n",
      "batch 23776, train_loss 36.059612,Time used 0.009002s\n",
      "batch 23777, train_loss 27.635714,Time used 0.008001s\n",
      "batch 23778, train_loss 24.544088,Time used 0.007997s\n",
      "batch 23779, train_loss 41.193501,Time used 0.007000s\n",
      "batch 23780, train_loss 30.997499,Time used 0.008002s\n",
      "batch 23781, train_loss 23.891260,Time used 0.008000s\n",
      "batch 23782, train_loss 30.815451,Time used 0.010998s\n",
      "batch 23783, train_loss 29.551283,Time used 0.012002s\n",
      "batch 23784, train_loss 31.450962,Time used 0.012001s\n",
      "batch 23785, train_loss 28.306717,Time used 0.012002s\n",
      "batch 23786, train_loss 31.387690,Time used 0.011007s\n",
      "batch 23787, train_loss 26.480280,Time used 0.010996s\n",
      "batch 23788, train_loss 32.599041,Time used 0.007995s\n",
      "batch 23789, train_loss 33.968388,Time used 0.008000s\n",
      "batch 23790, train_loss 29.054060,Time used 0.008000s\n",
      "batch 23791, train_loss 25.510683,Time used 0.009003s\n",
      "batch 23792, train_loss 33.116375,Time used 0.012999s\n",
      "batch 23793, train_loss 28.799355,Time used 0.007999s\n",
      "batch 23794, train_loss 25.166885,Time used 0.006999s\n",
      "batch 23795, train_loss 37.845024,Time used 0.010003s\n",
      "batch 23796, train_loss 24.723785,Time used 0.008006s\n",
      "batch 23797, train_loss 35.493435,Time used 0.009996s\n",
      "batch 23798, train_loss 39.491352,Time used 0.012000s\n",
      "batch 23799, train_loss 28.344761,Time used 0.010005s\n",
      "batch 23800, train_loss 35.834324,Time used 0.007996s\n",
      "***************************test_batch 23800, test_rmse_loss 6.644738,test_mae_loss 2.900554,test_mape_loss 50.079326,Time used 0.039999s\n",
      "batch 23801, train_loss 24.319078,Time used 0.011999s\n",
      "batch 23802, train_loss 35.061535,Time used 0.008000s\n",
      "batch 23803, train_loss 32.983391,Time used 0.009001s\n",
      "batch 23804, train_loss 30.755579,Time used 0.008001s\n",
      "batch 23805, train_loss 26.377905,Time used 0.010000s\n",
      "batch 23806, train_loss 32.164566,Time used 0.009999s\n",
      "batch 23807, train_loss 33.462704,Time used 0.008000s\n",
      "batch 23808, train_loss 32.877720,Time used 0.008998s\n",
      "batch 23809, train_loss 35.349277,Time used 0.008001s\n",
      "batch 23810, train_loss 39.088749,Time used 0.008002s\n",
      "batch 23811, train_loss 25.633314,Time used 0.009000s\n",
      "batch 23812, train_loss 35.766239,Time used 0.011999s\n",
      "batch 23813, train_loss 27.525831,Time used 0.009003s\n",
      "batch 23814, train_loss 29.809528,Time used 0.008998s\n",
      "batch 23815, train_loss 23.803070,Time used 0.008003s\n",
      "batch 23816, train_loss 24.259060,Time used 0.011002s\n",
      "batch 23817, train_loss 27.134346,Time used 0.010999s\n",
      "batch 23818, train_loss 34.588436,Time used 0.012001s\n",
      "batch 23819, train_loss 26.741682,Time used 0.012002s\n",
      "batch 23820, train_loss 29.976427,Time used 0.011999s\n",
      "batch 23821, train_loss 31.243645,Time used 0.012002s\n",
      "batch 23822, train_loss 25.139442,Time used 0.012000s\n",
      "batch 23823, train_loss 27.476080,Time used 0.011000s\n",
      "batch 23824, train_loss 41.208641,Time used 0.010001s\n",
      "batch 23825, train_loss 33.707497,Time used 0.011999s\n",
      "batch 23826, train_loss 29.476166,Time used 0.007002s\n",
      "batch 23827, train_loss 30.881277,Time used 0.010998s\n",
      "batch 23828, train_loss 34.946117,Time used 0.012001s\n",
      "batch 23829, train_loss 30.541407,Time used 0.008001s\n",
      "batch 23830, train_loss 33.253345,Time used 0.009000s\n",
      "batch 23831, train_loss 39.378624,Time used 0.008002s\n",
      "batch 23832, train_loss 26.196667,Time used 0.009997s\n",
      "batch 23833, train_loss 26.494238,Time used 0.010000s\n",
      "batch 23834, train_loss 28.850088,Time used 0.007999s\n",
      "batch 23835, train_loss 33.162678,Time used 0.011000s\n",
      "batch 23836, train_loss 32.172333,Time used 0.012000s\n",
      "batch 23837, train_loss 27.862364,Time used 0.009001s\n",
      "batch 23838, train_loss 35.722599,Time used 0.011998s\n",
      "batch 23839, train_loss 35.578133,Time used 0.010000s\n",
      "batch 23840, train_loss 30.831738,Time used 0.008999s\n",
      "batch 23841, train_loss 29.307800,Time used 0.008001s\n",
      "batch 23842, train_loss 27.788670,Time used 0.009002s\n",
      "batch 23843, train_loss 27.917622,Time used 0.011997s\n",
      "batch 23844, train_loss 37.358658,Time used 0.013000s\n",
      "batch 23845, train_loss 28.455084,Time used 0.012002s\n",
      "batch 23846, train_loss 34.398708,Time used 0.012000s\n",
      "batch 23847, train_loss 30.797846,Time used 0.007999s\n",
      "batch 23848, train_loss 25.008974,Time used 0.008998s\n",
      "batch 23849, train_loss 38.197681,Time used 0.011999s\n",
      "batch 23850, train_loss 31.351706,Time used 0.008002s\n",
      "batch 23851, train_loss 30.874258,Time used 0.008000s\n",
      "batch 23852, train_loss 26.165260,Time used 0.010002s\n",
      "batch 23853, train_loss 34.002457,Time used 0.007999s\n",
      "batch 23854, train_loss 30.662094,Time used 0.009000s\n",
      "batch 23855, train_loss 25.079517,Time used 0.008000s\n",
      "batch 23856, train_loss 34.349167,Time used 0.011998s\n",
      "batch 23857, train_loss 31.570375,Time used 0.011001s\n",
      "batch 23858, train_loss 33.969002,Time used 0.008000s\n",
      "batch 23859, train_loss 29.687017,Time used 0.008001s\n",
      "batch 23860, train_loss 30.276188,Time used 0.007999s\n",
      "batch 23861, train_loss 29.160236,Time used 0.009003s\n",
      "batch 23862, train_loss 31.517591,Time used 0.007000s\n",
      "batch 23863, train_loss 24.392258,Time used 0.010997s\n",
      "batch 23864, train_loss 32.244461,Time used 0.008001s\n",
      "batch 23865, train_loss 28.842846,Time used 0.009000s\n",
      "batch 23866, train_loss 27.730473,Time used 0.009999s\n",
      "batch 23867, train_loss 28.242002,Time used 0.011999s\n",
      "batch 23868, train_loss 32.328022,Time used 0.007000s\n",
      "batch 23869, train_loss 35.788342,Time used 0.006997s\n",
      "batch 23870, train_loss 28.459576,Time used 0.008000s\n",
      "batch 23871, train_loss 29.912188,Time used 0.008001s\n",
      "batch 23872, train_loss 32.354542,Time used 0.006999s\n",
      "batch 23873, train_loss 30.521225,Time used 0.006999s\n",
      "batch 23874, train_loss 38.272778,Time used 0.008000s\n",
      "batch 23875, train_loss 29.460653,Time used 0.008998s\n",
      "batch 23876, train_loss 33.659801,Time used 0.011003s\n",
      "batch 23877, train_loss 35.986969,Time used 0.010998s\n",
      "batch 23878, train_loss 34.475765,Time used 0.013002s\n",
      "batch 23879, train_loss 23.586796,Time used 0.012993s\n",
      "batch 23880, train_loss 29.024994,Time used 0.008002s\n",
      "batch 23881, train_loss 27.684034,Time used 0.012002s\n",
      "batch 23882, train_loss 32.506760,Time used 0.010999s\n",
      "batch 23883, train_loss 34.195633,Time used 0.010002s\n",
      "batch 23884, train_loss 25.319918,Time used 0.011002s\n",
      "batch 23885, train_loss 33.386177,Time used 0.013000s\n",
      "batch 23886, train_loss 30.879910,Time used 0.012000s\n",
      "batch 23887, train_loss 36.464123,Time used 0.011999s\n",
      "batch 23888, train_loss 28.720493,Time used 0.010001s\n",
      "batch 23889, train_loss 29.860823,Time used 0.007999s\n",
      "batch 23890, train_loss 28.017717,Time used 0.006999s\n",
      "batch 23891, train_loss 32.938953,Time used 0.007999s\n",
      "batch 23892, train_loss 34.554890,Time used 0.010000s\n",
      "batch 23893, train_loss 36.158482,Time used 0.007999s\n",
      "batch 23894, train_loss 30.960152,Time used 0.010002s\n",
      "batch 23895, train_loss 34.217651,Time used 0.010998s\n",
      "batch 23896, train_loss 27.414156,Time used 0.009002s\n",
      "batch 23897, train_loss 26.191732,Time used 0.011997s\n",
      "batch 23898, train_loss 26.858089,Time used 0.008001s\n",
      "batch 23899, train_loss 34.336895,Time used 0.008003s\n",
      "batch 23900, train_loss 25.511726,Time used 0.009999s\n",
      "***************************test_batch 23900, test_rmse_loss 6.640226,test_mae_loss 2.896836,test_mape_loss 49.988049,Time used 0.041999s\n",
      "batch 23901, train_loss 31.264814,Time used 0.008000s\n",
      "batch 23902, train_loss 30.711847,Time used 0.010000s\n",
      "batch 23903, train_loss 34.001682,Time used 0.011001s\n",
      "batch 23904, train_loss 28.523788,Time used 0.011002s\n",
      "batch 23905, train_loss 35.609810,Time used 0.010000s\n",
      "batch 23906, train_loss 33.141872,Time used 0.012000s\n",
      "batch 23907, train_loss 30.969196,Time used 0.011001s\n",
      "batch 23908, train_loss 33.595741,Time used 0.009000s\n",
      "batch 23909, train_loss 29.416937,Time used 0.007999s\n",
      "batch 23910, train_loss 29.707655,Time used 0.008001s\n",
      "batch 23911, train_loss 28.284565,Time used 0.012001s\n",
      "batch 23912, train_loss 31.315275,Time used 0.011988s\n",
      "batch 23913, train_loss 33.395710,Time used 0.009002s\n",
      "batch 23914, train_loss 33.637177,Time used 0.011997s\n",
      "batch 23915, train_loss 42.696449,Time used 0.008002s\n",
      "batch 23916, train_loss 30.556728,Time used 0.007003s\n",
      "batch 23917, train_loss 35.717865,Time used 0.011996s\n",
      "batch 23918, train_loss 26.037100,Time used 0.009001s\n",
      "batch 23919, train_loss 32.266804,Time used 0.011001s\n",
      "batch 23920, train_loss 27.154156,Time used 0.010999s\n",
      "batch 23921, train_loss 26.436342,Time used 0.009002s\n",
      "batch 23922, train_loss 27.083117,Time used 0.008004s\n",
      "batch 23923, train_loss 30.005886,Time used 0.009997s\n",
      "batch 23924, train_loss 24.250149,Time used 0.012001s\n",
      "batch 23925, train_loss 30.151266,Time used 0.011998s\n",
      "batch 23926, train_loss 26.699207,Time used 0.012001s\n",
      "batch 23927, train_loss 33.706264,Time used 0.012001s\n",
      "batch 23928, train_loss 27.928507,Time used 0.011998s\n",
      "batch 23929, train_loss 34.722717,Time used 0.009005s\n",
      "batch 23930, train_loss 24.939068,Time used 0.009998s\n",
      "batch 23931, train_loss 29.819622,Time used 0.011000s\n",
      "batch 23932, train_loss 29.741436,Time used 0.007001s\n",
      "batch 23933, train_loss 27.167955,Time used 0.008000s\n",
      "batch 23934, train_loss 24.902519,Time used 0.007999s\n",
      "batch 23935, train_loss 27.175863,Time used 0.007996s\n",
      "batch 23936, train_loss 29.987978,Time used 0.009001s\n",
      "batch 23937, train_loss 38.915409,Time used 0.010001s\n",
      "batch 23938, train_loss 31.657593,Time used 0.007998s\n",
      "batch 23939, train_loss 33.910069,Time used 0.011006s\n",
      "batch 23940, train_loss 32.382812,Time used 0.010994s\n",
      "batch 23941, train_loss 25.960840,Time used 0.008001s\n",
      "batch 23942, train_loss 32.338600,Time used 0.010998s\n",
      "batch 23943, train_loss 24.481699,Time used 0.010998s\n",
      "batch 23944, train_loss 30.566235,Time used 0.008998s\n",
      "batch 23945, train_loss 32.768051,Time used 0.010002s\n",
      "batch 23946, train_loss 39.548695,Time used 0.011996s\n",
      "batch 23947, train_loss 34.707115,Time used 0.008000s\n",
      "batch 23948, train_loss 26.571459,Time used 0.008001s\n",
      "batch 23949, train_loss 33.405903,Time used 0.009998s\n",
      "batch 23950, train_loss 30.475237,Time used 0.012002s\n",
      "batch 23951, train_loss 30.444805,Time used 0.008999s\n",
      "batch 23952, train_loss 32.525993,Time used 0.007998s\n",
      "batch 23953, train_loss 22.535385,Time used 0.009999s\n",
      "batch 23954, train_loss 21.790611,Time used 0.009003s\n",
      "batch 23955, train_loss 37.792809,Time used 0.007997s\n",
      "batch 23956, train_loss 28.822708,Time used 0.008001s\n",
      "batch 23957, train_loss 33.560249,Time used 0.007002s\n",
      "batch 23958, train_loss 32.013092,Time used 0.006999s\n",
      "batch 23959, train_loss 31.439146,Time used 0.008003s\n",
      "batch 23960, train_loss 28.116230,Time used 0.009998s\n",
      "batch 23961, train_loss 32.065353,Time used 0.010999s\n",
      "batch 23962, train_loss 28.340464,Time used 0.009001s\n",
      "batch 23963, train_loss 30.660568,Time used 0.010001s\n",
      "batch 23964, train_loss 37.593067,Time used 0.009997s\n",
      "batch 23965, train_loss 38.228577,Time used 0.008998s\n",
      "batch 23966, train_loss 31.848497,Time used 0.008000s\n",
      "batch 23967, train_loss 30.796192,Time used 0.008002s\n",
      "batch 23968, train_loss 28.801741,Time used 0.010999s\n",
      "batch 23969, train_loss 35.263317,Time used 0.008002s\n",
      "batch 23970, train_loss 28.016844,Time used 0.007998s\n",
      "batch 23971, train_loss 29.395109,Time used 0.010005s\n",
      "batch 23972, train_loss 22.561619,Time used 0.007998s\n",
      "batch 23973, train_loss 37.161495,Time used 0.009000s\n",
      "batch 23974, train_loss 29.661419,Time used 0.009999s\n",
      "batch 23975, train_loss 27.388590,Time used 0.009001s\n",
      "batch 23976, train_loss 34.889324,Time used 0.008000s\n",
      "batch 23977, train_loss 30.122202,Time used 0.007999s\n",
      "batch 23978, train_loss 28.611774,Time used 0.011001s\n",
      "batch 23979, train_loss 28.017553,Time used 0.012001s\n",
      "batch 23980, train_loss 30.387156,Time used 0.011000s\n",
      "batch 23981, train_loss 35.373402,Time used 0.011999s\n",
      "batch 23982, train_loss 34.717487,Time used 0.010999s\n",
      "batch 23983, train_loss 29.834402,Time used 0.010001s\n",
      "batch 23984, train_loss 27.072163,Time used 0.009001s\n",
      "batch 23985, train_loss 25.702967,Time used 0.011003s\n",
      "batch 23986, train_loss 33.872662,Time used 0.008001s\n",
      "batch 23987, train_loss 36.300632,Time used 0.008001s\n",
      "batch 23988, train_loss 29.360842,Time used 0.012000s\n",
      "batch 23989, train_loss 26.652391,Time used 0.011998s\n",
      "batch 23990, train_loss 27.750647,Time used 0.012000s\n",
      "batch 23991, train_loss 29.249262,Time used 0.009000s\n",
      "batch 23992, train_loss 23.179165,Time used 0.007999s\n",
      "batch 23993, train_loss 33.482094,Time used 0.008001s\n",
      "batch 23994, train_loss 33.174568,Time used 0.010000s\n",
      "batch 23995, train_loss 36.662575,Time used 0.008001s\n",
      "batch 23996, train_loss 30.075958,Time used 0.011000s\n",
      "batch 23997, train_loss 29.227236,Time used 0.010998s\n",
      "batch 23998, train_loss 32.090786,Time used 0.008000s\n",
      "batch 23999, train_loss 37.516186,Time used 0.007000s\n",
      "batch 24000, train_loss 29.046194,Time used 0.007000s\n",
      "***************************test_batch 24000, test_rmse_loss 6.624678,test_mae_loss 2.893595,test_mape_loss 50.077420,Time used 0.041002s\n",
      "The total time is 264.672796s\n"
     ]
    }
   ],
   "source": [
    "train_log = []\n",
    "test_log = []\n",
    "#开始时间\n",
    "timestart = time.time()\n",
    "trained_batches = 0 #记录多少个batch\n",
    "for epoch in range(500):\n",
    "\n",
    "    total_1oss = 0 #记录Loss\n",
    "    for batch in next_batch(shuffle(train_set), batch_size=128):\n",
    "        #每一个batch的开始时间\n",
    "        batchstart = time.time()\n",
    "\n",
    "        batch = torch.from_numpy(batch).float().to(device)  # (batch, seq_len)\n",
    "        # 使用短序列的前12个值作为历史，最后一个值作为预测值。\n",
    "        x, label = batch[:, :6,:], batch[:, -1,:]\n",
    "        # print(x.unsqueeze(-1).shape)\n",
    "        out, hidden = torch_lstm(x)  # out: (batch_size, seq_len, hidden_size)\n",
    "        out = output_model(out[:, -1, :])\n",
    "        prediction = out  # (batch)\n",
    "#         print(prediction.shape,label.shape)\n",
    "        loss = loss_func(prediction, label)\n",
    "#         print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #correct += (prediction == label).sum().item()\n",
    "        #累加loss\n",
    "        #total_1oss += loss.item( )\n",
    "        trained_batches += 1\n",
    "         #计算平均loss与准确率\n",
    "        #train_loss = total_1oss / train_batch_num\n",
    "        #train_log.append(train_loss)\n",
    "        train_log.append(loss.detach().cpu().numpy().tolist())\n",
    "\n",
    "        train_batch_time = (time.time() - batchstart)\n",
    "        print('batch %d, train_loss %.6f,Time used %.6fs'%(trained_batches, loss,train_batch_time))\n",
    "        print('batch %d, train_loss %.6f,Time used %.6fs'%(trained_batches, loss,train_batch_time),file=f)\n",
    "\n",
    "        # 每训练一定数量的batch，就在测试集上测试模型效果。\n",
    "        if trained_batches % 100 == 0:\n",
    "            #每一个batch的开始时间\n",
    "            batch_test_start = time.time()\n",
    "            #在每个epoch上测试\n",
    "            all_prediction = []\n",
    "            for batch in next_batch(test_set, batch_size=128):\n",
    "                batch = torch.from_numpy(batch).float().to(device)  # (batch, seq_len)\n",
    "                x, label = batch[:, :6,:], batch[:, -1,:]\n",
    "                out, hidden = torch_lstm(x)  # out: (batch_size, seq_len, hidden_size)\n",
    "                out = output_model(out[:, -1, :])\n",
    "                prediction = out  # (batch)\n",
    "                all_prediction.append(prediction.detach().cpu().numpy())\n",
    "\n",
    "            all_prediction = np.concatenate(all_prediction)\n",
    "            all_label = test_set[:, -1]\n",
    "            # 没有进行反归一化操作。\n",
    "            #all_prediction = denormalize(all_prediction)\n",
    "            #all_label = denormalize(all_label)\n",
    "            # 计算测试指标。\n",
    "            rmse_score = math.sqrt(mse(all_label, all_prediction))\n",
    "            mae_score = mae(all_label, all_prediction)\n",
    "            mape_score = mape(all_label, all_prediction)\n",
    "            test_log.append([rmse_score, mae_score, mape_score])\n",
    "            test_batch_time = (time.time() - batch_test_start)\n",
    "            print('***************************test_batch %d, test_rmse_loss %.6f,test_mae_loss %.6f,test_mape_loss %.6f,Time used %.6fs'%(trained_batches, rmse_score,mae_score,mape_score,test_batch_time))\n",
    "            print('***************************test_batch %d, test_rmse_loss %.6f,test_mae_loss %.6f,test_mape_loss %.6f,Time used %.6fs'%(trained_batches, rmse_score,mae_score,mape_score,test_batch_time),file=f)\n",
    "\n",
    "#计算总时间\n",
    "timesum = (time.time() - timestart)\n",
    "print('The total time is %fs'%(timesum))\n",
    "print('The total time is %fs'%(timesum),file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAx/ElEQVR4nO3dd3zV9fX48de5IzuEQBIIIxA2MgQMQwQFEcRRAbUqLhSVqlVb7c+qraP268Jdax1oUQSLUoqrLnAg4gACsgUJIxACIWGEJEDGvef3x72kKWXcxNzc5OY8H488cu/nfsZ55yY59z0/oqoYY4wxAI5QB2CMMab+sKRgjDGmkiUFY4wxlSwpGGOMqWRJwRhjTCVXqAMIRFJSkrZv3z7UYRhjTIOydOnSAlVNrs4xDSIptG/fnszMzFCHYYwxDYqIZFf3GGs+MsYYU8mSgjHGmEqWFIwxxlRqEH0KxpjgKi8vJycnh0OHDoU6FFMDUVFRtGnTBrfb/bPPZUnBGENOTg7x8fG0b98eEQl1OKYaVJXdu3eTk5NDenr6zz6fNR8ZYzh06BDNmze3hNAAiQjNmzevtVqeJQVjDIAlhAasNt+7sE4Kn/+Yx4vzN4Y6DGOMaTDCOinMX5/PlAWWFIwxJlBhnRRcTqHCYzcRMqa+27dvHy+88EKNjn322Wc5cOBALUdU+4YNG9YgVmYI66Tgdjoo93pDHYYx5gQaQ1JoKMJ6SKrLYTUFY6rrwQ/WsDZ3f62e86RWTXjgFz2O+frdd9/Nxo0b6dOnDyNHjiQlJYVZs2ZRWlrKuHHjePDBBykpKeGSSy4hJycHj8fDfffdR15eHrm5uQwfPpykpCS+/PLLo54/Li6Om266iY8++ojU1FQeeeQRfv/737N161aeffZZLrjgArZs2cJVV11FSUkJAM8//zyDBw9m/vz53H///cTHx5OVlcXw4cN54YUXcDgczJ07lwceeIDS0lI6duzIa6+9Rlxc3Al/HjNnzuSRRx5BVTnvvPOYPHkyHo+H6667jszMTESEiRMncvvtt/Pcc8/x0ksv4XK5OOmkk3jrrbdq9iYEKLyTgtNBhVdRVRtZYUw99thjj7F69WqWL1/O3LlzmT17NosXL0ZVueCCC1iwYAH5+fm0atWKDz/8EIDCwkISEhJ4+umn+fLLL0lKSjrm+UtKSjjzzDN54oknGDduHPfeey/z5s1j7dq1TJgwgQsuuICUlBTmzZtHVFQUGzZsYPz48ZXNPYsXL2bt2rW0a9eO0aNHM2fOHIYNG8ZDDz3EZ599RmxsLJMnT+bpp5/m/vvvP25Zc3Nzueuuu1i6dCmJiYmMGjWKd999l7Zt27J9+3ZWr14N+GpPh382mzdvJjIysnJbMIV1UnA7fImgwqu4nZYUjAnE8T7R14W5c+cyd+5c+vbtC0BxcTEbNmxg6NCh/O53v+Ouu+7i/PPPZ+jQoQGfMyIigtGjRwPQq1cvIiMjcbvd9OrViy1btgC+Wd233HILy5cvx+l08tNPP1UeP2DAADp06ADA+PHjWbhwIVFRUaxdu5bTTjsNgLKyMk499dQTxrJkyRKGDRtGcrJvResrrriCBQsWcN9997Fp0yZuvfVWzjvvPEaNGgVA7969ueKKKxg7dixjx44NuMw1FdZJweX0dZlUeBS3M8TBGGMCoqrcc889/OpXv/qf15YtW8ZHH33Evffey4gRI074qfwwt9td2VrgcDiIjIysfFxRUQHAM888Q4sWLVixYgVer5eoqKjK449saRARVJWRI0cyc+bMGpXzSImJiaxYsYJPP/2Ul156iVmzZjF16lQ+/PBDFixYwAcffMDDDz/MqlWrcLmC9687zDuafW+kdTYbU7/Fx8dTVFQEwNlnn83UqVMpLi4GYPv27ezatYvc3FxiYmK48sorufPOO1m2bNn/HPtzFBYWkpqaisPhYPr06Xg8nsrXFi9ezObNm/F6vbz99tsMGTKEQYMG8c0335CVlQX4mqiq1i6OZcCAAXz11VcUFBTg8XiYOXMmZ5xxBgUFBXi9Xi666CIeeughli1bhtfrZdu2bQwfPpzJkydTWFhY+XMJlvCuKRxuPrLOZmPqtebNm3PaaafRs2dPzjnnHC6//PLKppi4uDhmzJhBVlYWd955Jw6HA7fbzYsvvgjApEmTGD16NK1atTpmR3Mgbr75Zi666CLeeOMNRo8eTWxsbOVr/fv355ZbbqnsaB43bhwOh4PXX3+d8ePHU1paCsBDDz1Ely5djnud1NRUHnvsMYYPH17Z0TxmzBhWrFjBtddei9f/IfbRRx/F4/Fw5ZVXUlhYiKpy22230bRp0xqXMRCiWv//YWZkZGhNxvfO+D6be99dzeI/jCClSdSJDzCmkfrxxx/p3r17qMOol+bPn8+TTz7Jv//971CHclxHew9FZKmqZlTnPGHdfHS4plDurf+Jzxhj6oPwbj6q7Gi2PgVjGoOBAwdWNuUcNn36dHr16lXjcw4bNoxhw4YFvP+4cePYvHnzf22bPHkyZ599do1jqEtBTQoicjtwPaDAKuBa4CXgDKDQv9s1qro8GNev7Gi2PgVjTigc5vMsWrQo1CHwzjvv1Pk1a7MbIGjNRyLSGrgNyFDVnoATuMz/8p2q2sf/tTxYMbgcvuJ5rPnImOOKiopi9+7dtfrPxdSNwzfZqTqE9ucIdvORC4gWkXIgBsgN8vX+++KVNQVrPjLmeNq0aUNOTg75+fmhDsXUwOHbcdaGoCUFVd0uIk8CW4GDwFxVnSsilwMPi8j9wOfA3apaeuTxIjIJmASQlpZWoxgONx9VWE3BmONyu921citH0/AFs/koERgDpAOtgFgRuRK4B+gG9AeaAXcd7XhVnaKqGaqacXg6eHUdbj6yjmZjjAlMMIekngVsVtV8VS0H5gCDVXWH+pQCrwEDghWAyzqajTGmWoKZFLYCg0QkRnxDGkYAP4pIKoB/21hgdbACcB8ekmrLXBhjTECC2aewSERmA8uACuAHYArwsYgkAwIsB24MVgy2zIUxxlRPUEcfqeoDwANHbD4zmNes6nBNwUYfGWNMYMJ7mQsbfWSMMdUS3knBYTUFY4ypjrBOCpXzFKxPwRhjAhLWScFlo4+MMaZawjopHL5Hs81TMMaYwIR1UrCls40xpnrCPCnY6CNjjKmOsE4K7srRR5YUjDEmEGGdFCprCtZ8ZIwxAQnvpGD3aDbGmGoJ66QgIjgdYjUFY4wJUFgnBfDVFqyj2RhjAhP2ScHtdNgyF8YYE6CwTwoup9gyF8YYE6DwTwoOhy1zYYwxAQr7pOC2moIxxgQs7JOCy2kdzcYYE6igJgURuV1E1ojIahGZKSJRIpIuIotEJEtE3haRiGDG4HZYR7MxxgQqaElBRFoDtwEZqtoTcAKXAZOBZ1S1E7AXuC5YMYB1NBtjTHUEu/nIBUSLiAuIAXbgu0fzbP/r04CxQQ3AOpqNMSZgQUsKqrodeBLYii8ZFAJLgX2qWuHfLQdoHawYwNfRbAviGWNMYILZfJQIjAHSgVZALDC6GsdPEpFMEcnMz8+vcRwup9UUjDEmUMFsPjoL2Kyq+apaDswBTgOa+puTANoA2492sKpOUdUMVc1ITk6ucRAuh9UUjDEmUMFMCluBQSISIyICjADWAl8CF/v3mQC8F8QYcDsdtiCeMcYEKJh9CovwdSgvA1b5rzUFuAu4Q0SygObA34MVA9g8BWOMqQ7XiXepOVV9AHjgiM2bgAHBvG5VLofDmo+MMSZAYT+j2bfMhTUfGWNMIMI+KfhGH1lNwRhjAhH2ScHtEFvmwhhjAhT2ScGWuTDGmMA1gqRgk9eMMSZQ4Z8UbPKaMcYErBEkBZu8ZowxgQr7pOB2CuU2+sgYYwIS9knBZfMUjDEmYOGfFBwOvApeqy0YY8wJhX1ScDsFgHIbgWSMMScU1LWP6gOX05f3KjxK5DFKW1JawfZ9B8nZe4CkuEjW5u7nQJmHywemEeV21mG0xhgTWuGfFBy+msKRS118k1XAc59v4Mcd+9l/qOJohzJz8VZmThpEUlxk0OM0xpj6IOyTgruypvCf5qMFP+Vz9dTFtEqIYmzf1qQmRNOqaRRtEqPJLyolNSGaPQfKmPRGJo99vI4nf3lyqMI3xpg6FfZJweX875qC16tM/mQdbZtFM+/2M47bPHT90A68OH8jbqdwYb829G/frE5iNsaYUAn/jmaHr4iHF8Wbu3Yna3L3c/tZXU7YX3DrmZ0Y0imJ95bncsMbmZSUHr2ZyRhjwkXYJ4XKmoJ/qYsPVuwgJT6SMX1an/DYmAgXM64fyIzrB7LvQDn/WLQ1qLEaY0yoBS0piEhXEVle5Wu/iPxWRP4kIturbD83WDFAldFHXi8er7Iwq4AzuiTj9HdAB6JfWiKndWrOyws2sqvoULBCNcaYkAvmPZrXq2ofVe0DnAIcAN7xv/zM4ddU9aNgxQC++ykAlHuUFTn7KDxYzuldkqt9nj+c252SUg/XT8uk2JqRjDFhqq6aj0YAG1U1u46uVykhxg1AQXEpC37KRwSGdEqq9nl6tErgr+P7siZ3P2OeX8jmgpLaDtUYY0KurpLCZcDMKs9vEZGVIjJVRBKDeeGuLeIBWL+ziIUbCujdpimJsRE1OtdZJ7VgxnUD2VNSxo3Tl1Ja4anNUI0xJuSCnhREJAK4APinf9OLQEegD7ADeOoYx00SkUwRyczPz6/x9ZvHRZISH8mKnEJWbi9kQPufl4NO7dicpy/pw/q8Ip77fMPPOpcxxtQ3dVFTOAdYpqp5AKqap6oeVfUCrwADjnaQqk5R1QxVzUhOrn4fQFVdW8Yzb+1Oyiq8nNLu51dMhndL4cK+rXnl683s2m8dz8aY8FEXSWE8VZqORCS1ymvjgNXBDqB7ahMOlfvmKfRLq53Wqt+c1ZkKj5dXF26ulfMZY0x9ENSkICKxwEhgTpXNj4vIKhFZCQwHbg9mDADdWvr6FVo3jSalSVStnLNd81guOLkVM77P5tusglo5pzHGhFpQk4Kqlqhqc1UtrLLtKlXtpaq9VfUCVd0RzBgAurVsAkC/Wmg6qup3o7qSmhDFFX9fxLy1ebV6bmOMCYWwn9EM0Ckljk4pcYzu0bJWz9u2WQwf3DqEjslxPPHpOruRjzGmwWsUSSHC5eCzO87gvN6pJ965mmIiXPxmRGd+yivmzcVbLTEYYxq0RpEUgu3cXqn0bN2E+95dzQV/W8iBMpvxbIxpmCwp1AKnQ5h942AevbAXa3L38+cP1oY6JGOMqZGwv59CXYlyOxk/II1tew7wwvyNdEqJ4/qhHUIdljHGVIslhVp2+8gubC4o4aEPf6RJlJtL+rcNdUjGGBMwaz6qZW6ng+fG92Vwx+Y88P4aNuUXhzokY4wJmCWFIHA7HTx1yclEuBzcPmtF5V3fjDGmvrOkECSpCdE8PK4nK7bt469fZIU6HGOMCYglhSA6v3crLuzbmue/2MDXG2q+0qsxxtQVSwpB9n9je9I5JZ5b/vEDufsOhjocY4w5LksKQRYb6eKlq05h/6Fy3l6yLdThGGPMcVlSqAPpSbEMSm/O+ytyUbVlMIwx9ZclhToypk8rNheUsHr7/lCHYowxx2RJoY6c0zMVt1OYND2T5z7fgMcWzjPG1EM2o7mOJMS4mXJ1Bq9/s4Wn5/3Ex6t34vUqY/u25oah6biclp+NMaFn/4nq0PCuKUybOIDHLuyFqhIT6WTyJ+u4772g35HUGGMCErSkICJdRWR5la/9IvJbEWkmIvNEZIP/e+3eDq0BuGxAGp/89nTm3DSYKwel8c/MHPL2Hwp1WMYYE7ykoKrrVbWPqvYBTgEOAO8AdwOfq2pn4HP/80ZJRJg0tCMeVaZ/lx3qcIwxps6aj0YAG1U1GxgDTPNvnwaMraMY6qW05jGM7N6CKV9v4uEP11Ja4UFVbeiqMSYkAupoFpHfAK8BRcCrQF/gblWdG+B1LgNm+h+3UNUd/sc7gRaBhxueHhrXk8c+XscrX2+mwqus21FEaYWHqdf0p2lMRKjDM8Y0IoHWFCaq6n5gFJAIXAU8FsiBIhIBXAD888jX1Pdx+KgfiUVkkohkikhmfn54rxuUEh/F05f04bL+bXntmy18v3k3q7fv59KXv2dtrs1rMMbUnUCTgvi/nwtMV9U1VbadyDnAMlXN8z/PE5FUAP/3XUc7SFWnqGqGqmYkJycHeKmG7Y/ndWdo5yQeGdeLqdf0Z3dJKb94fiHz1x/1R2SMMbUu0KSwVETm4ksKn4pIPBDoTQLG85+mI4D3gQn+xxOA9wI8T9iLj3Iz/bqBjB+QxpDOSXx2xxl0TI7lnjmrKDpUHurwjDGNgATSoSkiDqAPsElV94lIM6CNqq48wXGxwFagg6oW+rc1B2YBaUA2cImq7jneeTIyMjQzMzOA4oSf5dv2ceEL3xAf5WbkSS24eVhHXv92C9eelk56UmyowzPG1GMislRVM6pzTKAzmk8FlqtqiYhcCfQD/nKig1S1BGh+xLbd+EYjmQD0aduUv1/Tnw9X7mDOshxmL80BYN+Bcp4b3zfE0Rljwk2gSeFF4GQRORn4Hb4RSG8AZwQrMPMfw7umMLxrCmP6tOKtxdvwqvLx6h1s29MVt9NBy4SoUIdojAkTgSaFClVVERkDPK+qfxeR64IZmPlfQzsnM7RzMhvzi/l49U6GPTkfj1cZkN6MW4Z3YmjnJEQC7f83xpj/FWhHc5GI3INvKOqH/j4Gd/DCMsfTMTmOKwelMaJbCneM7ML2vQe5eupiJr6+hNx9B1FVNuUX2wQ4Y0y1BdrR3BK4HFiiql+LSBowTFXfCHaA0Lg7mgNRWuFh+nfZPDX3JyJcDgZ3bM7Hq3fy+MW9uSSjbajDM8aESE06mgOqKajqTuBNIEFEzgcO1VVCMCcW6XJy/dAOfPyboaQmRPHx6p0kRLuZsmATizfv4a3FWymrCHQEsTGmMQu0pnAJ8AQwH9+ktaHAnao6O6jR+VlNIXCHyj1k7z7AmtxC7pi1AhFQhbRmMVw3JJ1L+7fFIcKBsgpbQsOYMFeTmkKgSWEFMFJVd/mfJwOfqerJNYq0miwpVF9ZhZdRz3xFy4Qorhncnhe/2sSKbfto3zyGCq9SXFrBV3cO5/VvtjCsazInt20a6pCNMbUsmElhlar2qvLcAayoui2YLCnUTFmFF7dTKkckLdxQwJ//vQaAn/KKGdShGd9v2kPrptG8f8tpHCz30CYxJpQhG2NqUTCTwhNAb/6zXMWlwEpVvavaUdaAJYXad9mU7/h+0x5aJUSxY/8hnCIoMOtXg0iJjyIxNoK4SLtbqzENWdBmNKvqnSJyEXCaf9MUVX2nugGa+uOmYZ1YtHkxj17Um/U797M2dz+Z2Xu5blom+w+Wc2a3Fjx6YS/eW76dq05tR6TLGeqQjTF1IKCaQqhZTSE49paUkRj7n87mZVv3MmHqYtKaxbAmdz9dW8SzPq+ICae248ExPUMYqTGmJmp9SKqIFPnvrXzkV5GI2EL/DVzVhADQLy2RlQ+M4q1Jg2ga42Z9XhG9Wicw7btsPl61o3K/woO2Yqsx4eq4SUFV41W1yVG+4lW1SV0FaeqOiBAf5eaRcb24aVhH/nXTYE5u25Tf/2sl2btLePmrjfT981y+27g71KEaY4LAmo/MCW3bc4Dznvuag+Ueyj2+35fRPVry0lWnhDgyY8zxBHPpbNOItW0Ww5ybBzMrM4eDZR5cTuGN77LZtucAMxZlM39dPtMmDrDVWo0JA1ZTMNW2paCEYU/Or3zucggDOzRj+sSBOBy2Sqsx9YXVFEydaJ8UywtX9GPjrmJ6tG7Crv2l3D1nFXfPWckj43rhcga6+K4xpr6xpGBq5NxeqZWPVZXcwkM89/kGDpV7+ctlfThY7iEmwn69jGlogvpXKyJN8d2lrSegwETgbOAGIN+/2x9U9aNgxmGCS0S4Y2QXIl0Onvh0PSty9pG77yAzbxhERvtmoQ7PGFMNwa7n/wX4RFW7AScDP/q3P6OqffxflhDCxM3DOnLFwDQcIjSPjeSOWSvYf8jmNBjTkAStpiAiCcDpwDUAqloGlNntIsOXiPDwON8aiYs27eayV77n1Ec+57oh6fzmrC44rRPamHovmDWFdHxNRK+JyA8i8qqIxPpfu0VEVorIVBFJPNrBIjJJRDJFJDM/P/9ou5h6bGCH5rxz82kM65bCc19kcdOMpXZ7UGMagGAmBRfQD3hRVfsCJcDdwItAR6APsAN46mgHq+oUVc1Q1Yzk5OQghmmCpU/bpvzt8n78fnRX5q7NY97avFCHZIw5gWAmhRwgR1UX+Z/PBvqpap6qelTVC7wCDAhiDKYemDS0A+lJsTz+6XrumbOKzC17Qh2SMeYYgpYU/Pd13iYiXf2bRgBrRSS1ym7jgNXBisHUDy6ng9+e1ZmsXcXMXLyVe99djddrTUnG1EfBHkh+K/CmiEQAm4BrgedEpA++IapbgF8FOQZTD1xwcis6pcSxKqeQu+es4rVvt9CtZTyDOzbHBh8YU3/YMhemTlV4vAx/aj7b9hwEfAvrPXXJycTaXd6MqXW2zIWp91xOB69e3Z+f8orI2XuQJz5dx0Mfunn0wt6hDs0YgyUFEwJdW8bTtWU8APsOlvHyV5sY0a0FZ53UIsSRGWMsKZiQuv2sLny1Pp9J0zMZ2jkZj1f52xX9SIh2hzo0YxolW87ShFSU28nsmwZzaf+2bNldwsKsAj5dszPUYRnTaFlSMCEXF+ni0Qt7M///DaN102g+XW1JwZhQsaRg6g0RYVSPFnydVcAX6/JYt3N/qEMyptGxpGDqldE9WlJW4WXi65lc/OJ3rN5eGOqQjGlULCmYeiWjfTNuGJrOn35xEgnRbq55bTE7Cg+GOixjGg2bvGbqrQ15RYz92zd0SI5jSOckxvVtTZcW8aEOy5gGoyaT16ymYOqtzi3iefKXJ7M+r4gX52/k8U/WhzokY8KeJQVTr53TK5WVD4zihqHpzF+/iz0lZaEOyZiwZknB1HtRbicX9mtDhVf5cGUue0vKmJW5jY9W7WDr7gOhDs+YsGIzmk2D0D21Cd1axvPA+2t48IO1VFRZevus7im8OqF/CKMzJnxYUjANxlOXnMynq3dS7lXO6+W7Lcebi7KZuXgbmwtKSE+KPcEZjDEnYknBNBg9WiXQo1XCf2379fBOzFy8jc/W5nHD6R1CFJkx4cP6FEyD1iYxhu6pTXjnh+3c/vZyFm3a/V+ve+wOb8ZUiyUF0+CNPKkFa3fs550ftnPjjKVs2+PrfC6t8DDiqfnc+c8VNIT5OMbUB0FNCiLSVERmi8g6EflRRE4VkWYiMk9ENvi/JwYzBhP+rhiYxuUD03j92v5UeJWrpy5mS0EJX67LZ8vuA/xzaQ7PfrYh1GEa0yAEdUaziEwDvlbVV/33aY4B/gDsUdXHRORuIFFV7zreeWxGswlU5pY9XP9GJk4R2ifFkr37AP3bJ7Lgp3yW3jeSKLcz1CEaU2fq1YxmEUkATgf+DqCqZaq6DxgDTPPvNg0YG6wYTOOT0b4Zs28cjFeVpdl7GdOnFVcOakdJmYcv1+0KdXjG1HvBbD5KB/KB10TkBxF5VURigRaqusO/z07gqPdgFJFJIpIpIpn5+flBDNOEm04pcfz9mv5ktEvkykHtGJjejKS4CP690vdrp6rWx2DMMQQzKbiAfsCLqtoXKAHurrqD+v4yj/rXqapTVDVDVTOSk5ODGKYJR/3SEpl902DSk2JxOR2c0zOVz9fl8faSrYx46it+P3slqsquokOhDtWYeiWY8xRygBxVXeR/PhtfUsgTkVRV3SEiqYDV6U3Q3TC0AwuzCrjrX6uIcjvYtLSEH3fuZ03ufl69OoMR3Y9aYTWm0QlaTUFVdwLbRKSrf9MIYC3wPjDBv20C8F6wYjDmsLTmMXx021AmX9SLBXcOZ0B6M9bvLKJlkyjumbOK3H12zwZjIPijj/oArwIRwCbgWnyJaBaQBmQDl6jqnuOdx0Yfmdp2sMzD3gNl7CkpY+zfvqHCq5zXO5VnLulDhMum75jwUJPRR0Fd5kJVlwNHC2hEMK9rzIlERziJjoimVdNoPvnt6cxemsNLX22kwuPlhStOwemQUIdoTEjYRyLT6HVKiePuc7px//kn8emaPJ74dL0tj2EaLVsQzxi/iUPSycov5qWvNvLSVxuJjXAyonsLnr20Dw6rOZhGwpKCMVX86Rc96NU6gZ2Fh8jeXcK7y3M5pV0iEwa3r5zbIGIJwoQvSwrGVBHhcjB+QBrgm+S250A5j378IwfKPPwzcxt7DpRxVvcWPDKuF3n7D9GqabT1P5iwYn0KxhyDiPDUL0+mZ6sEJn+yjtIKL2d2TWH20hwueH4hQx//knvmrAx1mMbUKqspGHMcyfGRvDVpEPPW5jG4YxIJMW46psTxxKfr6dU6gVmZOZzZLYXRPVNDHaoxtSKo8xRqi81TMPVN4cFyot1OLnrxW9bvLOKxi3pxYb82ABSXVlBW4aVZbESIozSNXb1aJdWYcJYQ7SbC5WD6dQPom9aUO2at4Nf/WEZxaQUTX1/imxDn8VLu8YY6VGOqxZqPjPkZmsZEMOP6gbz81Uae+WwD63cWkbWrGIDJn6zjzUVb+UXvVjw4pofdy8E0CJYUjPmZ3E4Ht5zZmdhIFw9+sJbOKXF4vMorX28mIdrN25nb2HewjJevqlYt3piQsKRgTC25ZnB7YiKc9E1LZG3ufu57dzXTJg7g240FPP7JemYu3kqE00HbZjFktEu0CXGmXrKOZmOCpNzjxe10UFbh5Zy/LGBjfknlaxNObcd955/E3gPlJMdHhjBKE87q3YJ4xjRmbqdvHEeEy8GLV57Cdxt3MyC9GdO/z2bad9l8u3E3mwpKuOmMjtw+sotNgjP1go0+MqYOdGkRz4TB7eme2oT7zjuJDsmx5BeXMqJbCs9/mcWbi7IB2FF4kFmZ22xBPhMyVlMwpo5FRzh599enoQpNolxc/NJ3vDR/IynxUfzhnVXsKSkjZ88B7hjV9cQnM6aWWU3BmBBoEuUmIdqNiHDrmZ3ILTzEjTOWkhwXyTk9W/LcF1ncMWs5X67fxeaCEr5Yl4fXag+mDlhNwZgQO6NLMtcMbk9yfCTXD01HFRJj1/LBilzmLNteud+tZ3bid1Z7MEEW7NtxbgGKAA9QoaoZIvIn4AYg37/bH1T1o+Odx0YfmcaotMLDwg0F7Cg8xLLsvcz5YTsvXNGPlPhIPliRy2/P6kKiLaVhjqO+jj4arqoFR2x7RlWfrINrG9NgRbp8N/kB+GVGG7bsLuF3s1bgcgpFhyqYtzaPVyf056RWTUIcqQkn1qdgTAMQ6XLy0pWn0CTaRZTbyZSrTkGBS6d8xz8WbWVPSVmoQzRhItjNR5uBvYACL6vqFH/z0TXAfiAT+J2q7j3KsZOASQBpaWmnZGdnBy1OYxqKguJSVH1Lem/fd5DrXl/Cup1FNI+N4O1fDaJTSnyoQzT1SE2aj4KdFFqr6nYRSQHmAbcC64ECfIni/4BUVZ14vPNYn4IxR6eqLN+2j0nTl1JSWkHzuAjSk+K4YWg6Qzsnhzo8E2L1bulsVd3u/74LeAcYoKp5qupRVS/wCjAgmDEYE85EhL5picy8YRBj+rSiX1oiG/KKuG3mDxQeKCdrVxGb8otRVcoqvGwpKDnxSU2jFrSOZhGJBRyqWuR/PAr4s4ikquoO/27jgNXBisGYxqJTShyPXtgbgDW5hZz/14Wc/ewCdu4/BMBZ3VM4VO5lYVYBo3u05M9je5ASHxXKkE09FczRRy2Ad0Tk8HX+oaqfiMh0EemDr/loC/CrIMZgTKPTo1UC4wekMWdZDr8f3ZXyCuXZz38C4KJ+bfhwVS4XvlDIGxMH0CE5LsTRmvrGVkk1Jgx5vMrBcg9xkb7PffPX70IVhndLYWXOPiZMXUynlDhm/epU/B/cTBiqr/MUjDF1zOmQyoQAMKxrSuXj3m2acsfILtz33hoWZhXQrlks4174huT4SAZ3TOLcXi3JaN8sFGGbesBqCsY0QqUVHs588isi3Q6axUSwbmcRfdo2ZfGWPVR4vDx+8cmszNnH2L6tKavw8vaSbTx6YS+7pWgDYzUFY0xAIl1Onri4N7fM/IFN+SU8PK4nVwxsR9Ghci59+Xv+3z9XALDgp3wUyN59gM4t4rh5WKfQBm6CzmoKxjRi+UWlLNq8m3N7plbeHnRn4SFe/XoT7ZJiue9d3+DADkmx7Coq5cJ+rTm7R0v2HijjhS838rcr+pGeFBvKIpjjqHeT12qLJQVjQuMP76yitNzLr4d35LIp31NcWsGhcg9Oh1DuUbq2iKdlQhTdU5tw1+iu1mldz1hSMMYEVUlpBb//10py9x3kmsHt+c1by4mNcFJS5uGP53bn+qHplhjqEetTMMYEVWyki79d3q/yea/WCaQmRPPbt3/g4Y9+5LMf8+ie2oTM7D20iI/ivvNPYuaSraQ1i+GCk1sRH+UOYfQmEFZTMMb8bOUeLzO+z+a1b7aQX1RKp5Q41uQWcvi/iyoM65rM69faqjZ1yWoKxpiQcDsdXHtaOteell657d8rc5m9NId7z+vO3LV5PP7Jer7NKmBwpyRKSiu4btoSWjeN4clf9rYmp3rEkoIxJijO792K83u3AqBNYgwzvsvm9lnLObdXKiu27WPZ1n3AHtKTYkiKiyTK7eTsHi2JjrC5EKFkScEYE3RRbifPje/LU3N/4s1FW4mLdPH4xb2ZnZnDk3N/qtzvFye34q/j+1Y+LyguJS7SVTlpbvu+g6Q2iaocPmtqnyUFY0ydyGjfjJmTBv3XtpHdW7AiZx8dk+N4/dstTP1mMynxkSzN3suvh3fijlnLSWsWw8xJg5i7Jo87Z6/gxjM6ctfobse8TlmFlwiX3VSypqyj2RhTL+wtKWPo419SXFqByyFUeJXEGDdFhyqIjnBSXFpBtNtJhUe5fWQXvt+0m4PlHkad1IIVOYW4HEKPVk14/NP1PHtpH87tlRrqIoWczVMwxjRon6zewc7CQwzpnMQjH63j1jM7UXiwnI9W7aBlQjTj+rbm3L98zcFyD51S4nA5hHU7i4iLdFHu8VJa4cXpENKaxTDv9tNxOY9dYzhY5iHS5cCrSn5xKakJ0XVY0rphScEYE/a+ySrgULmHM7v5Vn7dsKuYFvFR5BeX8t3GAprHRXLzm8s4p2dL2iRG4xChoLiMs3u0YHNBCcu37eOmYR25eupiUuIjcYiwPq+IP57bnYtPaUNCtDtsRkNZUjDGNHqqyq0zf2BhVgGl5V48qkS7nRQeLAfg8P/7ptFumsVGUO5R2jWP4esNBQCM7tGSv17eF7e/llFSWoHTIQ1yhVibp2CMafREhOerzLoG3+S6t5Zso0mUi2i3kz//ey2TL+rNaZ2SAN9NiT5ZvZMftu7l1YWbueUfy7i0f1umfZvNN1kF9GidwKxfDWL73oOkNYv5n2apQ+UeXA7B5XSQtauY5z7fwLh+rRle5T4WDUVQawoisgUoAjxAhapmiEgz4G2gPb7bcV6iqnuPdx6rKRhj6srLX23kybnrKfcoSXGRnNElmX8ty6F102i27ztIcnwkkS4HEU4HQzon0STKzbTvtnBqh+ZcMagdN0zLpMzjxeUQ7v/FSfRLS2Tump30a5fIoXIP327czb4D5fzxvO60aBLc+2TXu+Yjf1LIUNWCKtseB/ao6mMicjeQqKp3He88lhSMMXVpR+FBlmzZy5ndUoiLdHH/e6v5Z2YON5zegY27inE6hP2Hylm8eQ8Hynyd3lm7iol0OUhPiuWlK0/hj++u4pus3f9z7pgIJ15VWjSJ4pbhnYiLdOF2Oji1Y3MiXQ7W5O4nNtJJm8QY5q3N46zuLWo8oa+hJIX1wDBV3SEiqcB8Ve16vPNYUjDGhJKqUlrh/Z9+BVVl/8EK4qJcXDblO1Zv388Htw6hU0ocqsqCDQVs3FXM+b1TWbW9kIRoN73bNGVNbiE3zlhK3v7SY14z0uWgtMLL3y7vx3m9aza8tj4mhc3AXkCBl1V1iojsU9Wm/tcF2Hv4+RHHTgImAaSlpZ2SnZ0dtDiNMebnOlBWwd4D5bRuGtjQVq9X2ZhfTLlH2XewjMwte6nwKp1T4sgvKmXL7hJG92jJwA7NcdZwBnd9TAqtVXW7iKQA84BbgferJgER2auqicc7j9UUjDGm+mqSFII6F1xVt/u/7wLeAQYAef5mI/zfdwUzBmOMMYELWlIQkVgRiT/8GBgFrAbeByb4d5sAvBesGIwxxlRPMOcptADe8c8MdAH/UNVPRGQJMEtErgOygUuCGIMxxphqCFpSUNVNwMlH2b4bGBGs6xpjjKk5W1/WGGNMJUsKxhhjKllSMMYYU8mSgjHGmEoNYulsEcnHN1KpJpKAghPuFb4ac/mt7I1XYy5/1bK3U9Xk6hzcIJLCzyEimdWd0RdOGnP5reyNs+zQuMv/c8tuzUfGGGMqWVIwxhhTqTEkhSmhDiDEGnP5reyNV2Mu/88qe9j3KRhjjAlcY6gpGGOMCZAlBWOMMZXCOimIyGgRWS8iWf77QYc1EdkiIqtEZLmIZPq3NROReSKywf/9uDc0akhEZKqI7BKR1VW2HbW84vOc/3dhpYj0C13kP98xyv4nEdnuf/+Xi8i5VV67x1/29SJydmiirh0i0lZEvhSRtSKyRkR+498e9u/9ccpee++9qoblF+AENgIdgAhgBXBSqOMKcpm3AElHbHscuNv/+G5gcqjjrMXyng70A1afqLzAucDHgACDgEWhjj8IZf8T8P+Osu9J/t//SCDd/3fhDHUZfkbZU4F+/sfxwE/+Mob9e3+cstfaex/ONYUBQJaqblLVMuAtYEyIYwqFMcA0/+NpwNjQhVK7VHUBsOeIzccq7xjgDfX5Hmh6+A6ADdExyn4sY4C3VLVUVTcDWfj+PhokVd2hqsv8j4uAH4HWNIL3/jhlP5Zqv/fhnBRaA9uqPM/h+D+8cKDAXBFZKiKT/NtaqOoO/+Od+G5+FM6OVd7G8vtwi7+JZGqVpsKwLbuItAf6AotoZO/9EWWHWnrvwzkpNEZDVLUfcA7waxE5veqL6qtPNpoxyI2tvMCLQEegD7ADeCqk0QSZiMQB/wJ+q6r7q74W7u/9Ucpea+99OCeF7UDbKs/b+LeFLVXd7v++C3gHXzUx73BV2f99V+girBPHKm/Y/z6oap6qelTVC7zCf5oJwq7sIuLG90/xTVWd49/cKN77o5W9Nt/7cE4KS4DOIpIuIhHAZcD7IY4paEQkVkTiDz8GRgGr8ZV5gn+3CcB7oYmwzhyrvO8DV/tHogwCCqs0NYSFI9rJx+F7/8FX9stEJFJE0oHOwOK6jq+2iO/G738HflTVp6u8FPbv/bHKXqvvfah704PcU38uvt75jcAfQx1PkMvaAd8ogxXAmsPlBZoDnwMbgM+AZqGOtRbLPBNfVbkcX1vpdccqL76RJ3/z/y6sAjJCHX8Qyj7dX7aV/n8GqVX2/6O/7OuBc0Id/88s+xB8TUMrgeX+r3Mbw3t/nLLX2ntvy1wYY4ypFM7NR8YYY6rJkoIxxphKlhSMMcZUsqRgjDGmkiUFY4wxlSwpmAZFROaLSNBvyC4it4nIjyLy5hHbrxGR56t5rj8EsM/rInJxdeM84hzi//6nI57f4l8lU0Ukqer+x1o9VEQm+Fcb3SAiEzCNhiUF02iIiKsau98MjFTVK2rh0idMCrWkj4g8BzQTkbHAw/7t3wBnAdlH7H8OvslMnYFJ+JZKQESaAQ8AA/HNjH1AwmjJdXN8lhRMrROR9v5P2a/413yfKyLR/tcqP+mLSJKIbPE/vkZE3vWvg7/F/+n2DhH5QUS+9/+jOuwq/5rxq0VkgP/4WP9CYIv9x4ypct73ReQLfBObjoz1Dv95VovIb/3bXsI3GfBjEbn9KEVs6y/HBhF5oMq53vUvRrjm8IKEIvIYEO2P903/tqv9n8xXiMj0Kuc9XUS+FZFNVWsNInKniCzxH/NglfJ+6D/HahG5VFV/AF4ArgLOVtU/AKjqD6q65SjlONbqoWcD81R1j6ruBeYBo49yvAlD1fnkZEx1dAbGq+oNIjILuAiYcYJjeuJb9TEK3xK/d6lqXxF5BrgaeNa/X4yq9hHfgn9T/cf9EfhCVSeKSFNgsYh85t+/H9BbVf9rqWkROQW4Ft8nYgEWichXqnqjiIwGhqtqwVHiHOC/5gFgiYh8qKqZwERV3eNPgEtE5F+qereI3KKqffzX7AHcCwxW1YIjkl0qvhmr3fDNSp0tIqP8P8sB/hjf95c7GchV1fP8500QkT7+8kwHvhCRh1T13uP8vI+1gmZYripqAmM1BRMsm1V1uf/xUqB9AMd8qapFqpoPFAIf+LevOuL4mVB5T4Em/iQwCrhbRJYD8/ElljT//vOOTAh+Q4B3VLVEVYuBOcDQAOKcp6q7VfWg/5gh/u23icgK4Ht8i5B1PsqxZwL/PJxsjojrXVX1qupa/rPs8yj/1w/AMnwJozO+n8lIEZksIkNVtRBYoaq/Afao6rvAfQGUxZj/YjUFEyylVR57gGj/4wr+82Ek6jjHeKs89/Lfv6tHrs2i+D5FX6Sq66u+ICIDgZJqRX5i/3N9ERmGr93+VFU9ICLz+d/ynUjV8kuV74+q6stH7uzvGD4XeEhEPlfVPwOo6p/830+0hs2xVtDcDgw7Yvv8QAthGjarKZi6tgU4xf+4pqNtLgUQkSH4VrwsBD4Fbq0y4qZvAOf5GhgrIjHiW1l2nH/biYwU3/2Ao/Hd3esbIAHY608I3fDd9vGwcvEtdwzwBfBLEWnuj7Nq89HRfApMFN/6+YhIaxFJEZFWwAFVnQE8ga+JrLqOtXrop8AoEUn0dzCP8m8zjYDVFExdexKY5e+I/bCG5zgkIj8AbmCif9v/4etzWCkiDmAzcP7xTqKqy0Tkdf6zlPCr/s7aE1mMbz37NsAMVc0UkVXAjSLyI77VKL+vsv8Uf1zLVPUKEXkY+EpEPPiaha45ToxzRaQ78J0/3xUDVwKdgCdExItvpdSbjnUOEbkN+D3Q0h/HR6p6PfARvppGFr7+kWv919wjIv+Hb/l5gD8fo/nNhCFbJdUYY0wlaz4yxhhTyZKCMcaYSpYUjDHGVLKkYIwxppIlBWOMMZUsKRhjjKlkScEYY0yl/w+loYRqpjEq1gAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_loss曲线\n",
    "x = np.linspace(0,len(train_log),len(train_log))\n",
    "plt.plot(x,train_log,label=\"train_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('1.4torchLSTMtrainloss.jpg')\n",
    "plt.show()\n",
    "#plt.clf()\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,0],label=\"test_rmse_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('1.4torchLSTMtestrmseloss.jpg')\n",
    "plt.show()\n",
    "#plt.clf()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,1],label=\"test_mae_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('1.4torchLSTMtestrmaeloss.jpg')\n",
    "plt.show()\n",
    "#plt.clf()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,2],label=\"test_mape_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('1.4torchLSTMtestrmapeloss.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_loss曲线\n",
    "x = np.linspace(0,len(train_log),len(train_log))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x,train_log,label=\"train_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(x_test,test_log[:,0],label=\"test_rmse_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(x_test,test_log[:,1],label=\"test_mae_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(x_test,test_log[:,2],label=\"test_mape_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('LSTM-4-photo.jpg')\n",
    "plt.show()\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(Pytorch_RL)",
   "language": "python",
   "name": "pytorch_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}