{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae\n",
    "#plt.switch_backend('agg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: \n",
      "b'2014040101'\n",
      " shape:(4392,) \n",
      " in_flow:\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 4. 1. 1. 0. 0.]\n",
      " [0. 0. 2. 5. 0. 2. 2. 0.]\n",
      " [0. 0. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 3. 1. 4. 2. 0. 0.]\n",
      " [0. 3. 3. 6. 3. 0. 0. 0.]\n",
      " [0. 2. 6. 5. 5. 0. 0. 0.]\n",
      " [0. 6. 3. 8. 1. 0. 0. 0.]\n",
      " [0. 2. 0. 2. 0. 0. 0. 0.]\n",
      " [3. 4. 5. 0. 1. 0. 1. 0.]\n",
      " [0. 2. 2. 1. 0. 0. 2. 1.]\n",
      " [1. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 3. 1. 0.]\n",
      " [0. 0. 0. 1. 2. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1.]] \n",
      " out_flow: \n",
      "[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 3. 2. 1. 0. 0.]\n",
      " [0. 0. 0. 3. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 2. 1. 0. 0. 0.]\n",
      " [0. 4. 2. 1. 2. 0. 0. 0.]\n",
      " [0. 1. 5. 5. 3. 0. 0. 0.]\n",
      " [0. 2. 5. 3. 4. 0. 0. 0.]\n",
      " [0. 2. 4. 7. 0. 0. 0. 0.]\n",
      " [1. 1. 2. 9. 1. 0. 0. 0.]\n",
      " [1. 1. 2. 2. 1. 0. 2. 0.]\n",
      " [1. 2. 2. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 2. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 2. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "(4392, 2, 16, 8)\n"
     ]
    }
   ],
   "source": [
    "f_data = h5py.File(\"./BikeNYC/NYC14_M16x8_T60_NewEnd.h5\")\n",
    "BikeNYC_date = f_data['date']\n",
    "BikeNYC_data = f_data['data']\n",
    "print(f'date: \\n{BikeNYC_date[0]}\\n shape:{BikeNYC_date.shape} \\n in_flow:\\n{BikeNYC_data[0][0]} \\n out_flow: \\n{BikeNYC_data[0][1]}')\n",
    "print(BikeNYC_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3074, 16, 8) (439, 16, 8) (879, 16, 8)\n",
      "(3067, 7, 16, 8)\n",
      "(432, 7, 16, 8)\n",
      "(872, 7, 16, 8)\n",
      "(3067, 7, 128)\n",
      "(432, 7, 128)\n",
      "(872, 7, 128)\n"
     ]
    }
   ],
   "source": [
    "#读取数据集，进行划分\n",
    "def sliding_window(seq,window_size):\n",
    "    result = []\n",
    "    for i in range(seq.shape[0]- window_size):\n",
    "        result.append(seq[i: i+window_size])\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "\n",
    "def MLPreshape(set):\n",
    "    set = set.reshape((set.shape[0],set.shape[1],-1))\n",
    "    return set\n",
    "\n",
    "def MLPreshape_inverse(set):\n",
    "    set = set.reshape((set.shape[0],set.shape[1],16,8))\n",
    "    return set\n",
    "\n",
    "data_num = BikeNYC_date.shape[0]\n",
    "flow_in_num = 0\n",
    "train_seq = BikeNYC_data[:int(data_num*0.7),flow_in_num,:,:]\n",
    "validation_seq = BikeNYC_data[int(data_num*0.7):int(data_num*0.8),flow_in_num,:,:]\n",
    "test_seq = BikeNYC_data[int(data_num*0.8):,flow_in_num,:,:]\n",
    "print(train_seq.shape,validation_seq.shape,test_seq.shape)\n",
    "\n",
    "window_size = 7\n",
    "train_set = sliding_window(train_seq, window_size)\n",
    "validation_set = sliding_window(validation_seq, window_size)\n",
    "test_set = sliding_window(test_seq, window_size)\n",
    "print(train_set.shape)\n",
    "print(validation_set.shape)\n",
    "print(test_set.shape)\n",
    "\n",
    "train_set = MLPreshape(train_set)\n",
    "validation_set = MLPreshape(validation_set)\n",
    "test_set = MLPreshape(test_set)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(validation_set.shape)\n",
    "print(test_set.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class OutputNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(OutputNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.relu(self.fc2(x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "torch_lstm = nn.LSTM(input_size=16*8, hidden_size=32, num_layers=1, batch_first=True)\n",
    "output_model = OutputNet(state_dim=32, hidden_dim=64, action_dim=16*8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(list(torch_lstm.parameters()) + list(output_model.parameters()), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "#保存打印文件\n",
    "f = open(\"./date/1.4torchLSTM.txt\", 'a+')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# 这两句只在第二次运行这个框架时运行，是为了重载文件流防止内存溢出。\n",
    "f.close()\n",
    "os.remove(\"./date/1.4torchLSTM.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_index = (y_true > 0)\n",
    "    y_true = y_true[non_zero_index]\n",
    "    y_pred = y_pred[non_zero_index]\n",
    "\n",
    "    mape = np.abs((y_true - y_pred) / y_true)\n",
    "    mape[np.isinf(mape)] = 0\n",
    "    return np.mean(mape) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def next_batch(data, batch_size):\n",
    "    data_length = data.shape[0]\n",
    "    num_batches = math.ceil(data_length / batch_size)\n",
    "    for batch_index in range(num_batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = min((batch_index + 1) * batch_size, data_length)\n",
    "        yield data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1, train_loss 361.269226,Time used 0.009998s\n",
      "batch 2, train_loss 365.146179,Time used 0.016001s\n",
      "batch 3, train_loss 429.444946,Time used 0.008999s\n",
      "batch 4, train_loss 402.518219,Time used 0.007999s\n",
      "batch 5, train_loss 377.766113,Time used 0.009000s\n",
      "batch 6, train_loss 397.482452,Time used 0.010001s\n",
      "batch 7, train_loss 371.128326,Time used 0.031998s\n",
      "batch 8, train_loss 417.392426,Time used 0.008002s\n",
      "batch 9, train_loss 388.844055,Time used 0.007999s\n",
      "batch 10, train_loss 450.744293,Time used 0.008001s\n",
      "batch 11, train_loss 474.601013,Time used 0.010002s\n",
      "batch 12, train_loss 457.248138,Time used 0.008999s\n",
      "batch 13, train_loss 425.259979,Time used 0.007998s\n",
      "batch 14, train_loss 383.982635,Time used 0.008001s\n",
      "batch 15, train_loss 419.344727,Time used 0.021000s\n",
      "batch 16, train_loss 470.692474,Time used 0.008999s\n",
      "batch 17, train_loss 420.883698,Time used 0.007997s\n",
      "batch 18, train_loss 357.058868,Time used 0.009001s\n",
      "batch 19, train_loss 433.963013,Time used 0.006000s\n",
      "batch 20, train_loss 397.047668,Time used 0.009001s\n",
      "batch 21, train_loss 356.982788,Time used 0.009000s\n",
      "batch 22, train_loss 438.402313,Time used 0.011003s\n",
      "batch 23, train_loss 470.998657,Time used 0.008999s\n",
      "batch 24, train_loss 375.468628,Time used 0.009001s\n",
      "batch 25, train_loss 428.885559,Time used 0.010998s\n",
      "batch 26, train_loss 399.304596,Time used 0.019001s\n",
      "batch 27, train_loss 454.947540,Time used 0.012001s\n",
      "batch 28, train_loss 392.618134,Time used 0.007999s\n",
      "batch 29, train_loss 356.872284,Time used 0.008000s\n",
      "batch 30, train_loss 444.283508,Time used 0.009001s\n",
      "batch 31, train_loss 423.480133,Time used 0.007000s\n",
      "batch 32, train_loss 350.955902,Time used 0.005999s\n",
      "batch 33, train_loss 373.229401,Time used 0.007000s\n",
      "batch 34, train_loss 355.851532,Time used 0.007999s\n",
      "batch 35, train_loss 472.176422,Time used 0.007001s\n",
      "batch 36, train_loss 389.691742,Time used 0.010001s\n",
      "batch 37, train_loss 413.688110,Time used 0.008999s\n",
      "batch 38, train_loss 458.118042,Time used 0.008001s\n",
      "batch 39, train_loss 519.638245,Time used 0.009000s\n",
      "batch 40, train_loss 446.342316,Time used 0.009001s\n",
      "batch 41, train_loss 417.099884,Time used 0.008996s\n",
      "batch 42, train_loss 456.645508,Time used 0.008002s\n",
      "batch 43, train_loss 333.579773,Time used 0.006999s\n",
      "batch 44, train_loss 411.894745,Time used 0.006000s\n",
      "batch 45, train_loss 429.096039,Time used 0.007999s\n",
      "batch 46, train_loss 332.712677,Time used 0.008000s\n",
      "batch 47, train_loss 353.728790,Time used 0.006999s\n",
      "batch 48, train_loss 414.393799,Time used 0.008003s\n",
      "batch 49, train_loss 329.641357,Time used 0.005000s\n",
      "batch 50, train_loss 443.297028,Time used 0.007999s\n",
      "batch 51, train_loss 368.234497,Time used 0.006003s\n",
      "batch 52, train_loss 441.876953,Time used 0.006997s\n",
      "batch 53, train_loss 375.321411,Time used 0.005020s\n",
      "batch 54, train_loss 290.184998,Time used 0.004983s\n",
      "batch 55, train_loss 354.148224,Time used 0.007998s\n",
      "batch 56, train_loss 460.385834,Time used 0.005002s\n",
      "batch 57, train_loss 461.010315,Time used 0.006000s\n",
      "batch 58, train_loss 377.161682,Time used 0.008000s\n",
      "batch 59, train_loss 389.966583,Time used 0.006000s\n",
      "batch 60, train_loss 404.476715,Time used 0.006000s\n",
      "batch 61, train_loss 497.619446,Time used 0.004999s\n",
      "batch 62, train_loss 394.174347,Time used 0.006033s\n",
      "batch 63, train_loss 426.387817,Time used 0.006968s\n",
      "batch 64, train_loss 447.130371,Time used 0.005000s\n",
      "batch 65, train_loss 421.947021,Time used 0.006006s\n",
      "batch 66, train_loss 366.505219,Time used 0.005995s\n",
      "batch 67, train_loss 437.421082,Time used 0.005000s\n",
      "batch 68, train_loss 381.246948,Time used 0.004999s\n",
      "batch 69, train_loss 480.443451,Time used 0.004997s\n",
      "batch 70, train_loss 478.897430,Time used 0.005000s\n",
      "batch 71, train_loss 446.818695,Time used 0.004000s\n",
      "batch 72, train_loss 329.895599,Time used 0.004999s\n",
      "batch 73, train_loss 427.869781,Time used 0.005996s\n",
      "batch 74, train_loss 342.898834,Time used 0.007033s\n",
      "batch 75, train_loss 502.722321,Time used 0.007998s\n",
      "batch 76, train_loss 343.232941,Time used 0.005000s\n",
      "batch 77, train_loss 455.916168,Time used 0.006000s\n",
      "batch 78, train_loss 422.581512,Time used 0.004984s\n",
      "batch 79, train_loss 427.683472,Time used 0.005983s\n",
      "batch 80, train_loss 287.252289,Time used 0.005000s\n",
      "batch 81, train_loss 438.650665,Time used 0.005000s\n",
      "batch 82, train_loss 490.935699,Time used 0.005000s\n",
      "batch 83, train_loss 489.448761,Time used 0.005001s\n",
      "batch 84, train_loss 390.971741,Time used 0.004999s\n",
      "batch 85, train_loss 366.089600,Time used 0.005001s\n",
      "batch 86, train_loss 381.957977,Time used 0.005034s\n",
      "batch 87, train_loss 352.426788,Time used 0.004999s\n",
      "batch 88, train_loss 383.564575,Time used 0.007004s\n",
      "batch 89, train_loss 383.863617,Time used 0.006962s\n",
      "batch 90, train_loss 399.900726,Time used 0.006002s\n",
      "batch 91, train_loss 412.588287,Time used 0.006004s\n",
      "batch 92, train_loss 431.417908,Time used 0.004995s\n",
      "batch 93, train_loss 364.934326,Time used 0.008003s\n",
      "batch 94, train_loss 444.324219,Time used 0.007996s\n",
      "batch 95, train_loss 371.696167,Time used 0.006999s\n",
      "batch 96, train_loss 460.308746,Time used 0.008001s\n",
      "batch 97, train_loss 374.824493,Time used 0.007999s\n",
      "batch 98, train_loss 368.309692,Time used 0.005002s\n",
      "batch 99, train_loss 420.494568,Time used 0.006002s\n",
      "batch 100, train_loss 377.176117,Time used 0.006998s\n",
      "***************************test_batch 100, test_rmse_loss 22.202196,test_mae_loss 10.149411,test_mape_loss 93.891230,Time used 0.018004s\n",
      "batch 101, train_loss 397.816956,Time used 0.004999s\n",
      "batch 102, train_loss 362.398315,Time used 0.005000s\n",
      "batch 103, train_loss 382.881989,Time used 0.007035s\n",
      "batch 104, train_loss 379.352570,Time used 0.005964s\n",
      "batch 105, train_loss 414.851959,Time used 0.004000s\n",
      "batch 106, train_loss 434.437805,Time used 0.005000s\n",
      "batch 107, train_loss 441.987000,Time used 0.005001s\n",
      "batch 108, train_loss 422.063354,Time used 0.005038s\n",
      "batch 109, train_loss 403.075714,Time used 0.003963s\n",
      "batch 110, train_loss 390.034576,Time used 0.006037s\n",
      "batch 111, train_loss 434.013397,Time used 0.004964s\n",
      "batch 112, train_loss 434.381653,Time used 0.004999s\n",
      "batch 113, train_loss 434.382294,Time used 0.006032s\n",
      "batch 114, train_loss 396.726746,Time used 0.005001s\n",
      "batch 115, train_loss 438.902130,Time used 0.005002s\n",
      "batch 116, train_loss 422.547821,Time used 0.004967s\n",
      "batch 117, train_loss 306.032928,Time used 0.004999s\n",
      "batch 118, train_loss 401.639496,Time used 0.007032s\n",
      "batch 119, train_loss 430.177887,Time used 0.004963s\n",
      "batch 120, train_loss 443.493805,Time used 0.006004s\n",
      "batch 121, train_loss 456.868134,Time used 0.008998s\n",
      "batch 122, train_loss 370.597992,Time used 0.008030s\n",
      "batch 123, train_loss 327.797333,Time used 0.004972s\n",
      "batch 124, train_loss 377.575043,Time used 0.007000s\n",
      "batch 125, train_loss 370.510071,Time used 0.008001s\n",
      "batch 126, train_loss 433.650787,Time used 0.006000s\n",
      "batch 127, train_loss 396.580505,Time used 0.004997s\n",
      "batch 128, train_loss 352.810516,Time used 0.009003s\n",
      "batch 129, train_loss 442.940735,Time used 0.007001s\n",
      "batch 130, train_loss 492.980896,Time used 0.005028s\n",
      "batch 131, train_loss 338.846558,Time used 0.005001s\n",
      "batch 132, train_loss 411.920990,Time used 0.003999s\n",
      "batch 133, train_loss 454.613373,Time used 0.003999s\n",
      "batch 134, train_loss 391.908539,Time used 0.005000s\n",
      "batch 135, train_loss 501.586243,Time used 0.005006s\n",
      "batch 136, train_loss 403.192108,Time used 0.005961s\n",
      "batch 137, train_loss 361.375610,Time used 0.007000s\n",
      "batch 138, train_loss 434.141449,Time used 0.005999s\n",
      "batch 139, train_loss 330.315155,Time used 0.004000s\n",
      "batch 140, train_loss 487.958435,Time used 0.005000s\n",
      "batch 141, train_loss 314.543854,Time used 0.006004s\n",
      "batch 142, train_loss 343.800934,Time used 0.005001s\n",
      "batch 143, train_loss 445.842438,Time used 0.004999s\n",
      "batch 144, train_loss 379.346771,Time used 0.005000s\n",
      "batch 145, train_loss 456.880249,Time used 0.007999s\n",
      "batch 146, train_loss 388.985046,Time used 0.006001s\n",
      "batch 147, train_loss 407.517029,Time used 0.005000s\n",
      "batch 148, train_loss 346.358826,Time used 0.005001s\n",
      "batch 149, train_loss 397.383484,Time used 0.004999s\n",
      "batch 150, train_loss 414.302063,Time used 0.005000s\n",
      "batch 151, train_loss 490.859924,Time used 0.005000s\n",
      "batch 152, train_loss 350.978882,Time used 0.006001s\n",
      "batch 153, train_loss 429.028320,Time used 0.004999s\n",
      "batch 154, train_loss 376.657013,Time used 0.005001s\n",
      "batch 155, train_loss 391.509644,Time used 0.004999s\n",
      "batch 156, train_loss 412.050293,Time used 0.003999s\n",
      "batch 157, train_loss 306.872620,Time used 0.005000s\n",
      "batch 158, train_loss 327.920135,Time used 0.006001s\n",
      "batch 159, train_loss 367.525604,Time used 0.004999s\n",
      "batch 160, train_loss 369.617645,Time used 0.004000s\n",
      "batch 161, train_loss 401.577942,Time used 0.005039s\n",
      "batch 162, train_loss 410.162689,Time used 0.003996s\n",
      "batch 163, train_loss 426.842926,Time used 0.005002s\n",
      "batch 164, train_loss 469.618164,Time used 0.004964s\n",
      "batch 165, train_loss 350.801636,Time used 0.005034s\n",
      "batch 166, train_loss 442.763062,Time used 0.004966s\n",
      "batch 167, train_loss 396.216614,Time used 0.006003s\n",
      "batch 168, train_loss 366.811646,Time used 0.005029s\n",
      "batch 169, train_loss 430.308807,Time used 0.005002s\n",
      "batch 170, train_loss 405.893555,Time used 0.005031s\n",
      "batch 171, train_loss 379.073883,Time used 0.005002s\n",
      "batch 172, train_loss 370.867035,Time used 0.004964s\n",
      "batch 173, train_loss 399.441803,Time used 0.005001s\n",
      "batch 174, train_loss 401.034760,Time used 0.005001s\n",
      "batch 175, train_loss 359.737366,Time used 0.005030s\n",
      "batch 176, train_loss 302.373932,Time used 0.005004s\n",
      "batch 177, train_loss 445.421295,Time used 0.005968s\n",
      "batch 178, train_loss 350.680176,Time used 0.009995s\n",
      "batch 179, train_loss 391.233826,Time used 0.007004s\n",
      "batch 180, train_loss 431.777496,Time used 0.005001s\n",
      "batch 181, train_loss 443.020325,Time used 0.005996s\n",
      "batch 182, train_loss 375.594971,Time used 0.007001s\n",
      "batch 183, train_loss 415.722809,Time used 0.008003s\n",
      "batch 184, train_loss 436.463135,Time used 0.007999s\n",
      "batch 185, train_loss 343.624664,Time used 0.005002s\n",
      "batch 186, train_loss 389.921417,Time used 0.004999s\n",
      "batch 187, train_loss 347.835815,Time used 0.004996s\n",
      "batch 188, train_loss 434.799530,Time used 0.005000s\n",
      "batch 189, train_loss 331.749176,Time used 0.006001s\n",
      "batch 190, train_loss 343.934418,Time used 0.006999s\n",
      "batch 191, train_loss 335.169952,Time used 0.008005s\n",
      "batch 192, train_loss 486.171387,Time used 0.004000s\n",
      "batch 193, train_loss 497.611816,Time used 0.005000s\n",
      "batch 194, train_loss 352.080841,Time used 0.004999s\n",
      "batch 195, train_loss 330.994934,Time used 0.005000s\n",
      "batch 196, train_loss 449.016266,Time used 0.005036s\n",
      "batch 197, train_loss 327.073059,Time used 0.005962s\n",
      "batch 198, train_loss 383.560242,Time used 0.005000s\n",
      "batch 199, train_loss 381.176422,Time used 0.005002s\n",
      "batch 200, train_loss 324.779053,Time used 0.004999s\n",
      "***************************test_batch 200, test_rmse_loss 21.627635,test_mae_loss 9.655161,test_mape_loss 78.122465,Time used 0.021036s\n",
      "batch 201, train_loss 357.728607,Time used 0.004962s\n",
      "batch 202, train_loss 309.827942,Time used 0.007000s\n",
      "batch 203, train_loss 399.606873,Time used 0.006001s\n",
      "batch 204, train_loss 338.301300,Time used 0.005035s\n",
      "batch 205, train_loss 431.325226,Time used 0.004981s\n",
      "batch 206, train_loss 355.728210,Time used 0.004028s\n",
      "batch 207, train_loss 422.635223,Time used 0.005961s\n",
      "batch 208, train_loss 294.508881,Time used 0.006000s\n",
      "batch 209, train_loss 418.455566,Time used 0.004000s\n",
      "batch 210, train_loss 365.203369,Time used 0.007019s\n",
      "batch 211, train_loss 444.961273,Time used 0.007981s\n",
      "batch 212, train_loss 424.923401,Time used 0.004996s\n",
      "batch 213, train_loss 389.496674,Time used 0.005001s\n",
      "batch 214, train_loss 350.775726,Time used 0.006000s\n",
      "batch 215, train_loss 372.171387,Time used 0.004999s\n",
      "batch 216, train_loss 441.940399,Time used 0.006038s\n",
      "batch 217, train_loss 334.176453,Time used 0.004993s\n",
      "batch 218, train_loss 379.596069,Time used 0.004002s\n",
      "batch 219, train_loss 372.551025,Time used 0.003999s\n",
      "batch 220, train_loss 359.671692,Time used 0.006034s\n",
      "batch 221, train_loss 443.454010,Time used 0.004000s\n",
      "batch 222, train_loss 382.227295,Time used 0.006006s\n",
      "batch 223, train_loss 323.362274,Time used 0.004995s\n",
      "batch 224, train_loss 393.354797,Time used 0.004999s\n",
      "batch 225, train_loss 432.319031,Time used 0.005001s\n",
      "batch 226, train_loss 303.067749,Time used 0.004966s\n",
      "batch 227, train_loss 323.313812,Time used 0.005000s\n",
      "batch 228, train_loss 382.713837,Time used 0.006000s\n",
      "batch 229, train_loss 416.861969,Time used 0.004034s\n",
      "batch 230, train_loss 394.531525,Time used 0.005001s\n",
      "batch 231, train_loss 341.134583,Time used 0.004971s\n",
      "batch 232, train_loss 371.600372,Time used 0.004998s\n",
      "batch 233, train_loss 302.024139,Time used 0.005001s\n",
      "batch 234, train_loss 353.658539,Time used 0.005000s\n",
      "batch 235, train_loss 357.974731,Time used 0.004996s\n",
      "batch 236, train_loss 337.382263,Time used 0.005002s\n",
      "batch 237, train_loss 446.022949,Time used 0.004032s\n",
      "batch 238, train_loss 418.738983,Time used 0.004970s\n",
      "batch 239, train_loss 362.178192,Time used 0.004997s\n",
      "batch 240, train_loss 415.540802,Time used 0.005000s\n",
      "batch 241, train_loss 375.467865,Time used 0.003998s\n",
      "batch 242, train_loss 358.152527,Time used 0.005001s\n",
      "batch 243, train_loss 330.379272,Time used 0.003999s\n",
      "batch 244, train_loss 330.040283,Time used 0.006003s\n",
      "batch 245, train_loss 398.648743,Time used 0.004000s\n",
      "batch 246, train_loss 332.596832,Time used 0.004000s\n",
      "batch 247, train_loss 317.427155,Time used 0.005999s\n",
      "batch 248, train_loss 391.245758,Time used 0.008001s\n",
      "batch 249, train_loss 394.054962,Time used 0.008001s\n",
      "batch 250, train_loss 378.643188,Time used 0.006999s\n",
      "batch 251, train_loss 279.805939,Time used 0.007002s\n",
      "batch 252, train_loss 394.210480,Time used 0.006000s\n",
      "batch 253, train_loss 366.577454,Time used 0.007000s\n",
      "batch 254, train_loss 403.289429,Time used 0.005998s\n",
      "batch 255, train_loss 349.494751,Time used 0.004998s\n",
      "batch 256, train_loss 431.019623,Time used 0.004000s\n",
      "batch 257, train_loss 425.023102,Time used 0.005005s\n",
      "batch 258, train_loss 373.540314,Time used 0.004999s\n",
      "batch 259, train_loss 359.802338,Time used 0.004000s\n",
      "batch 260, train_loss 326.019043,Time used 0.005999s\n",
      "batch 261, train_loss 380.406647,Time used 0.005002s\n",
      "batch 262, train_loss 353.342377,Time used 0.005000s\n",
      "batch 263, train_loss 344.954193,Time used 0.005001s\n",
      "batch 264, train_loss 338.153351,Time used 0.004000s\n",
      "batch 265, train_loss 362.160034,Time used 0.004999s\n",
      "batch 266, train_loss 381.920227,Time used 0.008004s\n",
      "batch 267, train_loss 403.426941,Time used 0.004995s\n",
      "batch 268, train_loss 311.663544,Time used 0.006000s\n",
      "batch 269, train_loss 368.043396,Time used 0.005000s\n",
      "batch 270, train_loss 368.835602,Time used 0.005001s\n",
      "batch 271, train_loss 298.268738,Time used 0.005002s\n",
      "batch 272, train_loss 321.769073,Time used 0.006000s\n",
      "batch 273, train_loss 350.573181,Time used 0.006001s\n",
      "batch 274, train_loss 303.203522,Time used 0.004998s\n",
      "batch 275, train_loss 351.339203,Time used 0.005001s\n",
      "batch 276, train_loss 387.910431,Time used 0.005000s\n",
      "batch 277, train_loss 275.482880,Time used 0.004996s\n",
      "batch 278, train_loss 432.469513,Time used 0.004000s\n",
      "batch 279, train_loss 364.948273,Time used 0.003999s\n",
      "batch 280, train_loss 333.954315,Time used 0.007000s\n",
      "batch 281, train_loss 381.914612,Time used 0.008001s\n",
      "batch 282, train_loss 342.567505,Time used 0.007000s\n",
      "batch 283, train_loss 379.323792,Time used 0.004000s\n",
      "batch 284, train_loss 357.565613,Time used 0.005001s\n",
      "batch 285, train_loss 373.950958,Time used 0.004999s\n",
      "batch 286, train_loss 372.996185,Time used 0.004999s\n",
      "batch 287, train_loss 305.779724,Time used 0.003999s\n",
      "batch 288, train_loss 396.156555,Time used 0.004999s\n",
      "batch 289, train_loss 425.172729,Time used 0.005006s\n",
      "batch 290, train_loss 324.996918,Time used 0.007996s\n",
      "batch 291, train_loss 309.573700,Time used 0.007963s\n",
      "batch 292, train_loss 391.780975,Time used 0.004997s\n",
      "batch 293, train_loss 329.317078,Time used 0.005000s\n",
      "batch 294, train_loss 317.545685,Time used 0.005000s\n",
      "batch 295, train_loss 305.611908,Time used 0.005000s\n",
      "batch 296, train_loss 399.192352,Time used 0.005002s\n",
      "batch 297, train_loss 335.876343,Time used 0.005000s\n",
      "batch 298, train_loss 325.492340,Time used 0.008000s\n",
      "batch 299, train_loss 336.496429,Time used 0.007999s\n",
      "batch 300, train_loss 330.794586,Time used 0.005999s\n",
      "***************************test_batch 300, test_rmse_loss 20.654993,test_mae_loss 9.013905,test_mape_loss 83.447116,Time used 0.021000s\n",
      "batch 301, train_loss 314.808258,Time used 0.006001s\n",
      "batch 302, train_loss 318.947510,Time used 0.006000s\n",
      "batch 303, train_loss 368.038452,Time used 0.004998s\n",
      "batch 304, train_loss 398.054199,Time used 0.005000s\n",
      "batch 305, train_loss 336.420074,Time used 0.008003s\n",
      "batch 306, train_loss 286.508484,Time used 0.006000s\n",
      "batch 307, train_loss 381.408813,Time used 0.005999s\n",
      "batch 308, train_loss 442.902832,Time used 0.005002s\n",
      "batch 309, train_loss 299.191101,Time used 0.005000s\n",
      "batch 310, train_loss 314.696472,Time used 0.007000s\n",
      "batch 311, train_loss 364.348236,Time used 0.006999s\n",
      "batch 312, train_loss 361.289520,Time used 0.005999s\n",
      "batch 313, train_loss 260.322998,Time used 0.007000s\n",
      "batch 314, train_loss 356.524200,Time used 0.005998s\n",
      "batch 315, train_loss 304.114136,Time used 0.005001s\n",
      "batch 316, train_loss 420.448547,Time used 0.006032s\n",
      "batch 317, train_loss 330.039337,Time used 0.005971s\n",
      "batch 318, train_loss 288.904938,Time used 0.005002s\n",
      "batch 319, train_loss 365.133850,Time used 0.005993s\n",
      "batch 320, train_loss 373.790588,Time used 0.006001s\n",
      "batch 321, train_loss 472.154510,Time used 0.005003s\n",
      "batch 322, train_loss 294.947266,Time used 0.004997s\n",
      "batch 323, train_loss 322.112366,Time used 0.005999s\n",
      "batch 324, train_loss 304.807007,Time used 0.006001s\n",
      "batch 325, train_loss 406.672760,Time used 0.003999s\n",
      "batch 326, train_loss 273.055420,Time used 0.004000s\n",
      "batch 327, train_loss 345.797150,Time used 0.006001s\n",
      "batch 328, train_loss 389.293610,Time used 0.004001s\n",
      "batch 329, train_loss 307.023132,Time used 0.004999s\n",
      "batch 330, train_loss 348.144714,Time used 0.006999s\n",
      "batch 331, train_loss 350.970093,Time used 0.005002s\n",
      "batch 332, train_loss 243.115738,Time used 0.005998s\n",
      "batch 333, train_loss 345.505432,Time used 0.006003s\n",
      "batch 334, train_loss 359.867920,Time used 0.004997s\n",
      "batch 335, train_loss 290.234772,Time used 0.004999s\n",
      "batch 336, train_loss 358.805054,Time used 0.008000s\n",
      "batch 337, train_loss 361.457672,Time used 0.004998s\n",
      "batch 338, train_loss 385.700378,Time used 0.004999s\n",
      "batch 339, train_loss 318.567139,Time used 0.007004s\n",
      "batch 340, train_loss 346.397675,Time used 0.009998s\n",
      "batch 341, train_loss 279.590393,Time used 0.007000s\n",
      "batch 342, train_loss 403.414581,Time used 0.005000s\n",
      "batch 343, train_loss 331.279480,Time used 0.008021s\n",
      "batch 344, train_loss 357.362549,Time used 0.006981s\n",
      "batch 345, train_loss 371.781433,Time used 0.006998s\n",
      "batch 346, train_loss 298.769501,Time used 0.008000s\n",
      "batch 347, train_loss 405.679108,Time used 0.007000s\n",
      "batch 348, train_loss 336.003876,Time used 0.006999s\n",
      "batch 349, train_loss 316.438721,Time used 0.005003s\n",
      "batch 350, train_loss 286.663666,Time used 0.005999s\n",
      "batch 351, train_loss 337.745667,Time used 0.007001s\n",
      "batch 352, train_loss 237.476013,Time used 0.007999s\n",
      "batch 353, train_loss 330.412201,Time used 0.007999s\n",
      "batch 354, train_loss 289.696716,Time used 0.006000s\n",
      "batch 355, train_loss 394.866425,Time used 0.007003s\n",
      "batch 356, train_loss 241.207596,Time used 0.007998s\n",
      "batch 357, train_loss 320.743652,Time used 0.007004s\n",
      "batch 358, train_loss 295.648438,Time used 0.008996s\n",
      "batch 359, train_loss 409.739868,Time used 0.008003s\n",
      "batch 360, train_loss 248.211792,Time used 0.006998s\n",
      "batch 361, train_loss 316.380646,Time used 0.004999s\n",
      "batch 362, train_loss 320.086731,Time used 0.004999s\n",
      "batch 363, train_loss 302.109436,Time used 0.006999s\n",
      "batch 364, train_loss 309.122406,Time used 0.007001s\n",
      "batch 365, train_loss 380.683502,Time used 0.005002s\n",
      "batch 366, train_loss 367.470917,Time used 0.005002s\n",
      "batch 367, train_loss 301.811493,Time used 0.005996s\n",
      "batch 368, train_loss 330.475372,Time used 0.006000s\n",
      "batch 369, train_loss 304.285309,Time used 0.005003s\n",
      "batch 370, train_loss 352.163513,Time used 0.005995s\n",
      "batch 371, train_loss 304.531952,Time used 0.006999s\n",
      "batch 372, train_loss 289.498260,Time used 0.007000s\n",
      "batch 373, train_loss 312.465485,Time used 0.005004s\n",
      "batch 374, train_loss 296.513092,Time used 0.005000s\n",
      "batch 375, train_loss 305.614716,Time used 0.004996s\n",
      "batch 376, train_loss 225.447052,Time used 0.006001s\n",
      "batch 377, train_loss 332.494659,Time used 0.005004s\n",
      "batch 378, train_loss 307.732758,Time used 0.004995s\n",
      "batch 379, train_loss 344.421539,Time used 0.006999s\n",
      "batch 380, train_loss 391.576477,Time used 0.005001s\n",
      "batch 381, train_loss 333.442474,Time used 0.008034s\n",
      "batch 382, train_loss 303.062439,Time used 0.006964s\n",
      "batch 383, train_loss 330.129547,Time used 0.005996s\n",
      "batch 384, train_loss 344.707855,Time used 0.003998s\n",
      "batch 385, train_loss 306.120728,Time used 0.004999s\n",
      "batch 386, train_loss 324.576508,Time used 0.004999s\n",
      "batch 387, train_loss 318.488007,Time used 0.005000s\n",
      "batch 388, train_loss 356.031799,Time used 0.005030s\n",
      "batch 389, train_loss 286.820435,Time used 0.005000s\n",
      "batch 390, train_loss 315.556274,Time used 0.005000s\n",
      "batch 391, train_loss 251.137497,Time used 0.005971s\n",
      "batch 392, train_loss 304.470367,Time used 0.005000s\n",
      "batch 393, train_loss 286.694916,Time used 0.007999s\n",
      "batch 394, train_loss 297.842255,Time used 0.005001s\n",
      "batch 395, train_loss 358.528931,Time used 0.005000s\n",
      "batch 396, train_loss 317.915253,Time used 0.005030s\n",
      "batch 397, train_loss 371.303558,Time used 0.005001s\n",
      "batch 398, train_loss 355.634094,Time used 0.005000s\n",
      "batch 399, train_loss 289.940979,Time used 0.006970s\n",
      "batch 400, train_loss 330.150360,Time used 0.007999s\n",
      "***************************test_batch 400, test_rmse_loss 19.659603,test_mae_loss 8.458082,test_mape_loss 94.938066,Time used 0.024036s\n",
      "batch 401, train_loss 247.018250,Time used 0.005004s\n",
      "batch 402, train_loss 258.819580,Time used 0.004002s\n",
      "batch 403, train_loss 372.341705,Time used 0.005035s\n",
      "batch 404, train_loss 297.270630,Time used 0.005001s\n",
      "batch 405, train_loss 301.835632,Time used 0.003995s\n",
      "batch 406, train_loss 299.943176,Time used 0.005968s\n",
      "batch 407, train_loss 364.129761,Time used 0.005001s\n",
      "batch 408, train_loss 293.889099,Time used 0.004999s\n",
      "batch 409, train_loss 316.163696,Time used 0.007001s\n",
      "batch 410, train_loss 338.656891,Time used 0.007963s\n",
      "batch 411, train_loss 288.420685,Time used 0.006001s\n",
      "batch 412, train_loss 276.475464,Time used 0.005998s\n",
      "batch 413, train_loss 302.107544,Time used 0.006998s\n",
      "batch 414, train_loss 305.431946,Time used 0.008001s\n",
      "batch 415, train_loss 295.852539,Time used 0.008036s\n",
      "batch 416, train_loss 293.302917,Time used 0.005967s\n",
      "batch 417, train_loss 383.983246,Time used 0.006998s\n",
      "batch 418, train_loss 302.513824,Time used 0.008002s\n",
      "batch 419, train_loss 308.304565,Time used 0.005002s\n",
      "batch 420, train_loss 294.612488,Time used 0.005997s\n",
      "batch 421, train_loss 296.237122,Time used 0.006003s\n",
      "batch 422, train_loss 271.102142,Time used 0.005000s\n",
      "batch 423, train_loss 263.458893,Time used 0.004997s\n",
      "batch 424, train_loss 336.109772,Time used 0.005004s\n",
      "batch 425, train_loss 273.412567,Time used 0.008001s\n",
      "batch 426, train_loss 288.238251,Time used 0.006997s\n",
      "batch 427, train_loss 332.808807,Time used 0.005999s\n",
      "batch 428, train_loss 274.623474,Time used 0.003999s\n",
      "batch 429, train_loss 331.294464,Time used 0.005001s\n",
      "batch 430, train_loss 339.234894,Time used 0.005005s\n",
      "batch 431, train_loss 324.535187,Time used 0.006999s\n",
      "batch 432, train_loss 271.462921,Time used 0.006998s\n",
      "batch 433, train_loss 304.467651,Time used 0.005031s\n",
      "batch 434, train_loss 331.183075,Time used 0.006003s\n",
      "batch 435, train_loss 366.219147,Time used 0.007000s\n",
      "batch 436, train_loss 274.165344,Time used 0.006966s\n",
      "batch 437, train_loss 262.592133,Time used 0.004999s\n",
      "batch 438, train_loss 326.263031,Time used 0.004999s\n",
      "batch 439, train_loss 329.577545,Time used 0.006002s\n",
      "batch 440, train_loss 309.567902,Time used 0.005000s\n",
      "batch 441, train_loss 263.432617,Time used 0.004997s\n",
      "batch 442, train_loss 340.136780,Time used 0.007038s\n",
      "batch 443, train_loss 249.528763,Time used 0.004995s\n",
      "batch 444, train_loss 303.014252,Time used 0.006972s\n",
      "batch 445, train_loss 224.481949,Time used 0.007994s\n",
      "batch 446, train_loss 278.527344,Time used 0.007000s\n",
      "batch 447, train_loss 301.983887,Time used 0.006004s\n",
      "batch 448, train_loss 319.472656,Time used 0.006999s\n",
      "batch 449, train_loss 309.681000,Time used 0.007004s\n",
      "batch 450, train_loss 303.112366,Time used 0.005997s\n",
      "batch 451, train_loss 247.579422,Time used 0.007001s\n",
      "batch 452, train_loss 348.123840,Time used 0.007000s\n",
      "batch 453, train_loss 263.540680,Time used 0.006999s\n",
      "batch 454, train_loss 322.996521,Time used 0.005998s\n",
      "batch 455, train_loss 265.676056,Time used 0.005000s\n",
      "batch 456, train_loss 269.304352,Time used 0.005001s\n",
      "batch 457, train_loss 239.282364,Time used 0.005002s\n",
      "batch 458, train_loss 285.572754,Time used 0.006002s\n",
      "batch 459, train_loss 300.350006,Time used 0.005029s\n",
      "batch 460, train_loss 287.865387,Time used 0.005000s\n",
      "batch 461, train_loss 316.403442,Time used 0.005001s\n",
      "batch 462, train_loss 339.145203,Time used 0.004998s\n",
      "batch 463, train_loss 302.958679,Time used 0.005003s\n",
      "batch 464, train_loss 259.243500,Time used 0.005966s\n",
      "batch 465, train_loss 282.277893,Time used 0.006997s\n",
      "batch 466, train_loss 332.189514,Time used 0.008001s\n",
      "batch 467, train_loss 330.686951,Time used 0.003999s\n",
      "batch 468, train_loss 288.578583,Time used 0.005000s\n",
      "batch 469, train_loss 269.554321,Time used 0.005001s\n",
      "batch 470, train_loss 235.072327,Time used 0.004001s\n",
      "batch 471, train_loss 295.990021,Time used 0.004001s\n",
      "batch 472, train_loss 264.645599,Time used 0.006000s\n",
      "batch 473, train_loss 275.676880,Time used 0.006000s\n",
      "batch 474, train_loss 277.236176,Time used 0.005001s\n",
      "batch 475, train_loss 306.166290,Time used 0.004999s\n",
      "batch 476, train_loss 272.167999,Time used 0.005003s\n",
      "batch 477, train_loss 309.620331,Time used 0.005001s\n",
      "batch 478, train_loss 310.038513,Time used 0.008000s\n",
      "batch 479, train_loss 236.550797,Time used 0.008003s\n",
      "batch 480, train_loss 306.627472,Time used 0.006998s\n",
      "batch 481, train_loss 223.372620,Time used 0.004999s\n",
      "batch 482, train_loss 224.025848,Time used 0.004999s\n",
      "batch 483, train_loss 224.997238,Time used 0.004999s\n",
      "batch 484, train_loss 270.637787,Time used 0.005000s\n",
      "batch 485, train_loss 237.270050,Time used 0.007004s\n",
      "batch 486, train_loss 351.862152,Time used 0.005999s\n",
      "batch 487, train_loss 275.609436,Time used 0.004000s\n",
      "batch 488, train_loss 222.197067,Time used 0.006002s\n",
      "batch 489, train_loss 324.178528,Time used 0.003999s\n",
      "batch 490, train_loss 267.299194,Time used 0.004031s\n",
      "batch 491, train_loss 266.665680,Time used 0.009969s\n",
      "batch 492, train_loss 244.439529,Time used 0.004999s\n",
      "batch 493, train_loss 317.099304,Time used 0.005005s\n",
      "batch 494, train_loss 302.943298,Time used 0.004996s\n",
      "batch 495, train_loss 253.610931,Time used 0.004001s\n",
      "batch 496, train_loss 325.999084,Time used 0.005000s\n",
      "batch 497, train_loss 308.509552,Time used 0.005000s\n",
      "batch 498, train_loss 398.960327,Time used 0.005000s\n",
      "batch 499, train_loss 316.158051,Time used 0.005001s\n",
      "batch 500, train_loss 283.775787,Time used 0.007999s\n",
      "***************************test_batch 500, test_rmse_loss 18.659143,test_mae_loss 7.913237,test_mape_loss 101.554282,Time used 0.021003s\n",
      "batch 501, train_loss 265.978180,Time used 0.006029s\n",
      "batch 502, train_loss 282.835602,Time used 0.005000s\n",
      "batch 503, train_loss 263.053284,Time used 0.004971s\n",
      "batch 504, train_loss 281.471191,Time used 0.005028s\n",
      "batch 505, train_loss 277.987762,Time used 0.005986s\n",
      "batch 506, train_loss 333.279236,Time used 0.004993s\n",
      "batch 507, train_loss 261.627777,Time used 0.005000s\n",
      "batch 508, train_loss 245.508667,Time used 0.006001s\n",
      "batch 509, train_loss 259.475159,Time used 0.005002s\n",
      "batch 510, train_loss 268.550629,Time used 0.004992s\n",
      "batch 511, train_loss 230.030548,Time used 0.006003s\n",
      "batch 512, train_loss 288.296631,Time used 0.005001s\n",
      "batch 513, train_loss 258.130859,Time used 0.004974s\n",
      "batch 514, train_loss 272.174622,Time used 0.005997s\n",
      "batch 515, train_loss 243.767807,Time used 0.005001s\n",
      "batch 516, train_loss 276.208679,Time used 0.005001s\n",
      "batch 517, train_loss 327.781158,Time used 0.005996s\n",
      "batch 518, train_loss 274.647247,Time used 0.006000s\n",
      "batch 519, train_loss 295.328522,Time used 0.005001s\n",
      "batch 520, train_loss 283.778320,Time used 0.005000s\n",
      "batch 521, train_loss 236.825958,Time used 0.005998s\n",
      "batch 522, train_loss 212.090546,Time used 0.006039s\n",
      "batch 523, train_loss 299.591064,Time used 0.003996s\n",
      "batch 524, train_loss 278.656982,Time used 0.003996s\n",
      "batch 525, train_loss 280.104675,Time used 0.005968s\n",
      "batch 526, train_loss 242.912231,Time used 0.005030s\n",
      "batch 527, train_loss 308.249390,Time used 0.004999s\n",
      "batch 528, train_loss 293.832397,Time used 0.003966s\n",
      "batch 529, train_loss 254.219421,Time used 0.004999s\n",
      "batch 530, train_loss 231.432938,Time used 0.005010s\n",
      "batch 531, train_loss 290.465485,Time used 0.004000s\n",
      "batch 532, train_loss 251.025223,Time used 0.008001s\n",
      "batch 533, train_loss 242.566223,Time used 0.005998s\n",
      "batch 534, train_loss 219.160736,Time used 0.005000s\n",
      "batch 535, train_loss 228.621506,Time used 0.004000s\n",
      "batch 536, train_loss 234.955795,Time used 0.005019s\n",
      "batch 537, train_loss 238.235413,Time used 0.006022s\n",
      "batch 538, train_loss 273.086426,Time used 0.007962s\n",
      "batch 539, train_loss 260.670441,Time used 0.004998s\n",
      "batch 540, train_loss 327.175018,Time used 0.005000s\n",
      "batch 541, train_loss 278.497650,Time used 0.005000s\n",
      "batch 542, train_loss 281.927765,Time used 0.007035s\n",
      "batch 543, train_loss 251.451202,Time used 0.004000s\n",
      "batch 544, train_loss 355.218842,Time used 0.004968s\n",
      "batch 545, train_loss 292.890259,Time used 0.004000s\n",
      "batch 546, train_loss 295.425018,Time used 0.004998s\n",
      "batch 547, train_loss 263.384735,Time used 0.004004s\n",
      "batch 548, train_loss 258.391663,Time used 0.003999s\n",
      "batch 549, train_loss 274.015472,Time used 0.004969s\n",
      "batch 550, train_loss 255.225494,Time used 0.004999s\n",
      "batch 551, train_loss 262.583008,Time used 0.007002s\n",
      "batch 552, train_loss 242.834061,Time used 0.004033s\n",
      "batch 553, train_loss 252.723343,Time used 0.005002s\n",
      "batch 554, train_loss 194.934753,Time used 0.004996s\n",
      "batch 555, train_loss 301.088196,Time used 0.004999s\n",
      "batch 556, train_loss 237.384979,Time used 0.004999s\n",
      "batch 557, train_loss 266.369781,Time used 0.006009s\n",
      "batch 558, train_loss 248.005585,Time used 0.005992s\n",
      "batch 559, train_loss 217.197266,Time used 0.006999s\n",
      "batch 560, train_loss 288.724609,Time used 0.007001s\n",
      "batch 561, train_loss 257.569763,Time used 0.004999s\n",
      "batch 562, train_loss 178.208969,Time used 0.004000s\n",
      "batch 563, train_loss 275.866455,Time used 0.003998s\n",
      "batch 564, train_loss 201.638855,Time used 0.007004s\n",
      "batch 565, train_loss 286.969238,Time used 0.005001s\n",
      "batch 566, train_loss 248.271881,Time used 0.004998s\n",
      "batch 567, train_loss 302.296814,Time used 0.004997s\n",
      "batch 568, train_loss 187.606964,Time used 0.004000s\n",
      "batch 569, train_loss 225.416412,Time used 0.007002s\n",
      "batch 570, train_loss 371.005188,Time used 0.007001s\n",
      "batch 571, train_loss 269.932495,Time used 0.006001s\n",
      "batch 572, train_loss 323.879852,Time used 0.005999s\n",
      "batch 573, train_loss 243.013367,Time used 0.006000s\n",
      "batch 574, train_loss 274.927551,Time used 0.007999s\n",
      "batch 575, train_loss 278.069580,Time used 0.005033s\n",
      "batch 576, train_loss 247.130356,Time used 0.005965s\n",
      "batch 577, train_loss 278.724060,Time used 0.005000s\n",
      "batch 578, train_loss 236.864014,Time used 0.007001s\n",
      "batch 579, train_loss 279.571381,Time used 0.006000s\n",
      "batch 580, train_loss 248.439255,Time used 0.007004s\n",
      "batch 581, train_loss 269.454895,Time used 0.005999s\n",
      "batch 582, train_loss 239.024780,Time used 0.005001s\n",
      "batch 583, train_loss 238.353348,Time used 0.006002s\n",
      "batch 584, train_loss 290.176483,Time used 0.008000s\n",
      "batch 585, train_loss 254.416260,Time used 0.006997s\n",
      "batch 586, train_loss 219.325180,Time used 0.006004s\n",
      "batch 587, train_loss 257.303040,Time used 0.005998s\n",
      "batch 588, train_loss 246.222168,Time used 0.006003s\n",
      "batch 589, train_loss 245.301071,Time used 0.007998s\n",
      "batch 590, train_loss 258.707306,Time used 0.007000s\n",
      "batch 591, train_loss 234.874695,Time used 0.005000s\n",
      "batch 592, train_loss 245.009567,Time used 0.005001s\n",
      "batch 593, train_loss 292.187958,Time used 0.004001s\n",
      "batch 594, train_loss 243.438492,Time used 0.006000s\n",
      "batch 595, train_loss 269.176727,Time used 0.004998s\n",
      "batch 596, train_loss 220.520859,Time used 0.004000s\n",
      "batch 597, train_loss 278.458160,Time used 0.006001s\n",
      "batch 598, train_loss 264.531830,Time used 0.005004s\n",
      "batch 599, train_loss 196.252609,Time used 0.005005s\n",
      "batch 600, train_loss 187.788300,Time used 0.006996s\n",
      "***************************test_batch 600, test_rmse_loss 17.639521,test_mae_loss 7.314432,test_mape_loss 98.771811,Time used 0.026999s\n",
      "batch 601, train_loss 267.118286,Time used 0.008001s\n",
      "batch 602, train_loss 222.874664,Time used 0.008000s\n",
      "batch 603, train_loss 275.763977,Time used 0.004998s\n",
      "batch 604, train_loss 221.651779,Time used 0.005002s\n",
      "batch 605, train_loss 240.701523,Time used 0.004999s\n",
      "batch 606, train_loss 281.375946,Time used 0.005001s\n",
      "batch 607, train_loss 280.776764,Time used 0.005000s\n",
      "batch 608, train_loss 291.914490,Time used 0.005004s\n",
      "batch 609, train_loss 223.785736,Time used 0.006996s\n",
      "batch 610, train_loss 302.359558,Time used 0.006002s\n",
      "batch 611, train_loss 247.093170,Time used 0.004998s\n",
      "batch 612, train_loss 226.742386,Time used 0.005002s\n",
      "batch 613, train_loss 176.096634,Time used 0.005999s\n",
      "batch 614, train_loss 197.064865,Time used 0.006000s\n",
      "batch 615, train_loss 241.859787,Time used 0.005997s\n",
      "batch 616, train_loss 233.508087,Time used 0.008003s\n",
      "batch 617, train_loss 227.229004,Time used 0.007998s\n",
      "batch 618, train_loss 285.570923,Time used 0.007998s\n",
      "batch 619, train_loss 288.620728,Time used 0.008001s\n",
      "batch 620, train_loss 210.793213,Time used 0.006999s\n",
      "batch 621, train_loss 211.467957,Time used 0.006000s\n",
      "batch 622, train_loss 245.307877,Time used 0.007004s\n",
      "batch 623, train_loss 241.182434,Time used 0.004000s\n",
      "batch 624, train_loss 176.579376,Time used 0.005000s\n",
      "batch 625, train_loss 217.030594,Time used 0.005000s\n",
      "batch 626, train_loss 278.229645,Time used 0.004999s\n",
      "batch 627, train_loss 266.285187,Time used 0.005000s\n",
      "batch 628, train_loss 242.354675,Time used 0.004999s\n",
      "batch 629, train_loss 233.556854,Time used 0.004999s\n",
      "batch 630, train_loss 245.578430,Time used 0.005002s\n",
      "batch 631, train_loss 202.846405,Time used 0.004999s\n",
      "batch 632, train_loss 222.760498,Time used 0.006001s\n",
      "batch 633, train_loss 294.876862,Time used 0.007999s\n",
      "batch 634, train_loss 208.311569,Time used 0.007000s\n",
      "batch 635, train_loss 272.094513,Time used 0.008001s\n",
      "batch 636, train_loss 205.932861,Time used 0.005003s\n",
      "batch 637, train_loss 205.622162,Time used 0.005000s\n",
      "batch 638, train_loss 257.437531,Time used 0.005016s\n",
      "batch 639, train_loss 230.533463,Time used 0.004984s\n",
      "batch 640, train_loss 237.794815,Time used 0.006997s\n",
      "batch 641, train_loss 266.049103,Time used 0.005001s\n",
      "batch 642, train_loss 235.173981,Time used 0.005033s\n",
      "batch 643, train_loss 213.989563,Time used 0.006003s\n",
      "batch 644, train_loss 260.619385,Time used 0.004966s\n",
      "batch 645, train_loss 187.792618,Time used 0.006995s\n",
      "batch 646, train_loss 196.952164,Time used 0.004999s\n",
      "batch 647, train_loss 221.103134,Time used 0.005001s\n",
      "batch 648, train_loss 247.180145,Time used 0.007004s\n",
      "batch 649, train_loss 196.373611,Time used 0.005999s\n",
      "batch 650, train_loss 246.586990,Time used 0.004999s\n",
      "batch 651, train_loss 279.527161,Time used 0.005002s\n",
      "batch 652, train_loss 264.969116,Time used 0.004998s\n",
      "batch 653, train_loss 168.140488,Time used 0.006004s\n",
      "batch 654, train_loss 211.942902,Time used 0.007997s\n",
      "batch 655, train_loss 310.856415,Time used 0.006003s\n",
      "batch 656, train_loss 296.887573,Time used 0.006001s\n",
      "batch 657, train_loss 158.694641,Time used 0.005996s\n",
      "batch 658, train_loss 235.350525,Time used 0.005001s\n",
      "batch 659, train_loss 215.186646,Time used 0.005003s\n",
      "batch 660, train_loss 245.630341,Time used 0.005997s\n",
      "batch 661, train_loss 226.386993,Time used 0.004996s\n",
      "batch 662, train_loss 191.021057,Time used 0.006002s\n",
      "batch 663, train_loss 193.465424,Time used 0.005001s\n",
      "batch 664, train_loss 218.175354,Time used 0.004997s\n",
      "batch 665, train_loss 287.303009,Time used 0.005003s\n",
      "batch 666, train_loss 233.421112,Time used 0.004995s\n",
      "batch 667, train_loss 219.356735,Time used 0.004030s\n",
      "batch 668, train_loss 203.046707,Time used 0.005004s\n",
      "batch 669, train_loss 251.179779,Time used 0.005966s\n",
      "batch 670, train_loss 214.283722,Time used 0.004997s\n",
      "batch 671, train_loss 214.427109,Time used 0.006006s\n",
      "batch 672, train_loss 201.440323,Time used 0.007000s\n",
      "batch 673, train_loss 161.073273,Time used 0.005994s\n",
      "batch 674, train_loss 199.690948,Time used 0.005001s\n",
      "batch 675, train_loss 294.677887,Time used 0.006002s\n",
      "batch 676, train_loss 185.678009,Time used 0.007996s\n",
      "batch 677, train_loss 236.715027,Time used 0.005005s\n",
      "batch 678, train_loss 202.792526,Time used 0.005997s\n",
      "batch 679, train_loss 187.028839,Time used 0.004998s\n",
      "batch 680, train_loss 202.142807,Time used 0.005001s\n",
      "batch 681, train_loss 238.674652,Time used 0.006000s\n",
      "batch 682, train_loss 272.299255,Time used 0.004999s\n",
      "batch 683, train_loss 195.256180,Time used 0.005004s\n",
      "batch 684, train_loss 229.430710,Time used 0.007001s\n",
      "batch 685, train_loss 229.901489,Time used 0.005997s\n",
      "batch 686, train_loss 166.641479,Time used 0.004997s\n",
      "batch 687, train_loss 224.508865,Time used 0.006001s\n",
      "batch 688, train_loss 239.406158,Time used 0.006001s\n",
      "batch 689, train_loss 242.312500,Time used 0.004998s\n",
      "batch 690, train_loss 179.300354,Time used 0.007000s\n",
      "batch 691, train_loss 196.607056,Time used 0.005002s\n",
      "batch 692, train_loss 229.716736,Time used 0.005000s\n",
      "batch 693, train_loss 270.378082,Time used 0.004999s\n",
      "batch 694, train_loss 276.738037,Time used 0.004998s\n",
      "batch 695, train_loss 233.983368,Time used 0.005001s\n",
      "batch 696, train_loss 227.867599,Time used 0.006001s\n",
      "batch 697, train_loss 261.762177,Time used 0.005002s\n",
      "batch 698, train_loss 245.430695,Time used 0.007999s\n",
      "batch 699, train_loss 215.670563,Time used 0.005000s\n",
      "batch 700, train_loss 181.537537,Time used 0.006001s\n",
      "***************************test_batch 700, test_rmse_loss 16.654963,test_mae_loss 6.707880,test_mape_loss 90.265369,Time used 0.023003s\n",
      "batch 701, train_loss 200.320312,Time used 0.006996s\n",
      "batch 702, train_loss 193.437210,Time used 0.007972s\n",
      "batch 703, train_loss 245.197449,Time used 0.008004s\n",
      "batch 704, train_loss 188.074219,Time used 0.007996s\n",
      "batch 705, train_loss 264.473999,Time used 0.008001s\n",
      "batch 706, train_loss 205.943787,Time used 0.006001s\n",
      "batch 707, train_loss 235.507431,Time used 0.004999s\n",
      "batch 708, train_loss 230.313843,Time used 0.007003s\n",
      "batch 709, train_loss 233.529419,Time used 0.004005s\n",
      "batch 710, train_loss 232.569489,Time used 0.005999s\n",
      "batch 711, train_loss 200.167725,Time used 0.004999s\n",
      "batch 712, train_loss 222.881943,Time used 0.006000s\n",
      "batch 713, train_loss 225.925537,Time used 0.005997s\n",
      "batch 714, train_loss 200.217575,Time used 0.006001s\n",
      "batch 715, train_loss 166.282928,Time used 0.004998s\n",
      "batch 716, train_loss 199.087051,Time used 0.005003s\n",
      "batch 717, train_loss 176.009537,Time used 0.005000s\n",
      "batch 718, train_loss 230.626312,Time used 0.004001s\n",
      "batch 719, train_loss 206.784439,Time used 0.008034s\n",
      "batch 720, train_loss 207.311935,Time used 0.004964s\n",
      "batch 721, train_loss 202.069977,Time used 0.003999s\n",
      "batch 722, train_loss 199.737106,Time used 0.003999s\n",
      "batch 723, train_loss 205.589600,Time used 0.005000s\n",
      "batch 724, train_loss 209.934601,Time used 0.007000s\n",
      "batch 725, train_loss 211.989090,Time used 0.007999s\n",
      "batch 726, train_loss 236.726334,Time used 0.006000s\n",
      "batch 727, train_loss 249.719406,Time used 0.007003s\n",
      "batch 728, train_loss 226.659195,Time used 0.006003s\n",
      "batch 729, train_loss 198.517563,Time used 0.006001s\n",
      "batch 730, train_loss 192.432968,Time used 0.006031s\n",
      "batch 731, train_loss 207.765106,Time used 0.005000s\n",
      "batch 732, train_loss 223.273514,Time used 0.004966s\n",
      "batch 733, train_loss 178.850708,Time used 0.006004s\n",
      "batch 734, train_loss 190.090118,Time used 0.006994s\n",
      "batch 735, train_loss 233.059280,Time used 0.008999s\n",
      "batch 736, train_loss 259.869598,Time used 0.006001s\n",
      "batch 737, train_loss 208.728516,Time used 0.004998s\n",
      "batch 738, train_loss 219.487137,Time used 0.006008s\n",
      "batch 739, train_loss 198.842941,Time used 0.005028s\n",
      "batch 740, train_loss 241.955246,Time used 0.004996s\n",
      "batch 741, train_loss 174.862686,Time used 0.008004s\n",
      "batch 742, train_loss 176.973282,Time used 0.004968s\n",
      "batch 743, train_loss 154.255310,Time used 0.005998s\n",
      "batch 744, train_loss 220.267548,Time used 0.009034s\n",
      "batch 745, train_loss 240.295334,Time used 0.005998s\n",
      "batch 746, train_loss 176.438141,Time used 0.004999s\n",
      "batch 747, train_loss 242.765701,Time used 0.008004s\n",
      "batch 748, train_loss 252.847580,Time used 0.007000s\n",
      "batch 749, train_loss 201.317444,Time used 0.004998s\n",
      "batch 750, train_loss 192.040543,Time used 0.005003s\n",
      "batch 751, train_loss 189.998871,Time used 0.008032s\n",
      "batch 752, train_loss 207.278595,Time used 0.005001s\n",
      "batch 753, train_loss 258.486328,Time used 0.003999s\n",
      "batch 754, train_loss 194.327972,Time used 0.005002s\n",
      "batch 755, train_loss 183.132309,Time used 0.007967s\n",
      "batch 756, train_loss 199.332428,Time used 0.008029s\n",
      "batch 757, train_loss 231.645721,Time used 0.004963s\n",
      "batch 758, train_loss 241.109818,Time used 0.004000s\n",
      "batch 759, train_loss 215.699677,Time used 0.006000s\n",
      "batch 760, train_loss 174.927017,Time used 0.005006s\n",
      "batch 761, train_loss 196.042847,Time used 0.007998s\n",
      "batch 762, train_loss 165.437744,Time used 0.005997s\n",
      "batch 763, train_loss 220.400360,Time used 0.007000s\n",
      "batch 764, train_loss 197.907303,Time used 0.006002s\n",
      "batch 765, train_loss 170.308792,Time used 0.005000s\n",
      "batch 766, train_loss 218.376846,Time used 0.006003s\n",
      "batch 767, train_loss 142.147614,Time used 0.005034s\n",
      "batch 768, train_loss 166.702255,Time used 0.005965s\n",
      "batch 769, train_loss 195.879227,Time used 0.004994s\n",
      "batch 770, train_loss 222.053619,Time used 0.005031s\n",
      "batch 771, train_loss 182.752014,Time used 0.006003s\n",
      "batch 772, train_loss 196.610641,Time used 0.005965s\n",
      "batch 773, train_loss 188.434219,Time used 0.005000s\n",
      "batch 774, train_loss 176.982544,Time used 0.004999s\n",
      "batch 775, train_loss 164.128906,Time used 0.007034s\n",
      "batch 776, train_loss 189.173355,Time used 0.004989s\n",
      "batch 777, train_loss 164.075150,Time used 0.005998s\n",
      "batch 778, train_loss 185.428543,Time used 0.005004s\n",
      "batch 779, train_loss 192.958160,Time used 0.005997s\n",
      "batch 780, train_loss 201.369980,Time used 0.005999s\n",
      "batch 781, train_loss 192.606277,Time used 0.005000s\n",
      "batch 782, train_loss 192.662399,Time used 0.005999s\n",
      "batch 783, train_loss 177.645569,Time used 0.007997s\n",
      "batch 784, train_loss 254.035141,Time used 0.004001s\n",
      "batch 785, train_loss 212.010574,Time used 0.006007s\n",
      "batch 786, train_loss 229.178986,Time used 0.005001s\n",
      "batch 787, train_loss 203.979645,Time used 0.004997s\n",
      "batch 788, train_loss 254.238052,Time used 0.005001s\n",
      "batch 789, train_loss 185.763672,Time used 0.005000s\n",
      "batch 790, train_loss 214.105316,Time used 0.004999s\n",
      "batch 791, train_loss 161.732208,Time used 0.005000s\n",
      "batch 792, train_loss 206.590408,Time used 0.005001s\n",
      "batch 793, train_loss 171.326248,Time used 0.005003s\n",
      "batch 794, train_loss 171.543625,Time used 0.004995s\n",
      "batch 795, train_loss 190.715027,Time used 0.004999s\n",
      "batch 796, train_loss 223.373978,Time used 0.006021s\n",
      "batch 797, train_loss 176.686127,Time used 0.004998s\n",
      "batch 798, train_loss 218.852005,Time used 0.005000s\n",
      "batch 799, train_loss 178.252121,Time used 0.008003s\n",
      "batch 800, train_loss 197.356323,Time used 0.006995s\n",
      "***************************test_batch 800, test_rmse_loss 15.753135,test_mae_loss 6.186613,test_mape_loss 81.607210,Time used 0.029001s\n",
      "batch 801, train_loss 170.850388,Time used 0.005000s\n",
      "batch 802, train_loss 196.858582,Time used 0.004999s\n",
      "batch 803, train_loss 200.113068,Time used 0.005002s\n",
      "batch 804, train_loss 173.544052,Time used 0.005000s\n",
      "batch 805, train_loss 230.563538,Time used 0.005998s\n",
      "batch 806, train_loss 192.637924,Time used 0.003999s\n",
      "batch 807, train_loss 206.054520,Time used 0.004033s\n",
      "batch 808, train_loss 195.501831,Time used 0.005000s\n",
      "batch 809, train_loss 217.330139,Time used 0.004968s\n",
      "batch 810, train_loss 173.766205,Time used 0.005030s\n",
      "batch 811, train_loss 208.709946,Time used 0.006967s\n",
      "batch 812, train_loss 176.002838,Time used 0.006001s\n",
      "batch 813, train_loss 199.537552,Time used 0.007001s\n",
      "batch 814, train_loss 176.215958,Time used 0.005001s\n",
      "batch 815, train_loss 208.362671,Time used 0.006000s\n",
      "batch 816, train_loss 161.821777,Time used 0.003997s\n",
      "batch 817, train_loss 240.800217,Time used 0.004997s\n",
      "batch 818, train_loss 186.849777,Time used 0.005001s\n",
      "batch 819, train_loss 123.653137,Time used 0.004000s\n",
      "batch 820, train_loss 163.830200,Time used 0.004001s\n",
      "batch 821, train_loss 179.714325,Time used 0.006999s\n",
      "batch 822, train_loss 156.215683,Time used 0.004005s\n",
      "batch 823, train_loss 180.782700,Time used 0.008996s\n",
      "batch 824, train_loss 190.746307,Time used 0.005000s\n",
      "batch 825, train_loss 194.063019,Time used 0.005003s\n",
      "batch 826, train_loss 186.760635,Time used 0.005029s\n",
      "batch 827, train_loss 174.059952,Time used 0.005001s\n",
      "batch 828, train_loss 168.999176,Time used 0.004033s\n",
      "batch 829, train_loss 191.606598,Time used 0.006963s\n",
      "batch 830, train_loss 183.886810,Time used 0.006001s\n",
      "batch 831, train_loss 152.407944,Time used 0.005005s\n",
      "batch 832, train_loss 218.336380,Time used 0.006994s\n",
      "batch 833, train_loss 197.228775,Time used 0.004000s\n",
      "batch 834, train_loss 196.953323,Time used 0.004000s\n",
      "batch 835, train_loss 175.181625,Time used 0.006999s\n",
      "batch 836, train_loss 167.908005,Time used 0.005003s\n",
      "batch 837, train_loss 296.834930,Time used 0.004998s\n",
      "batch 838, train_loss 193.186951,Time used 0.007998s\n",
      "batch 839, train_loss 229.503540,Time used 0.006999s\n",
      "batch 840, train_loss 144.317810,Time used 0.005001s\n",
      "batch 841, train_loss 218.405502,Time used 0.005000s\n",
      "batch 842, train_loss 208.825958,Time used 0.005003s\n",
      "batch 843, train_loss 210.433014,Time used 0.005033s\n",
      "batch 844, train_loss 169.876419,Time used 0.004968s\n",
      "batch 845, train_loss 192.282288,Time used 0.006033s\n",
      "batch 846, train_loss 155.988892,Time used 0.004964s\n",
      "batch 847, train_loss 184.283737,Time used 0.005032s\n",
      "batch 848, train_loss 207.690109,Time used 0.004969s\n",
      "batch 849, train_loss 199.854904,Time used 0.005036s\n",
      "batch 850, train_loss 168.093491,Time used 0.004969s\n",
      "batch 851, train_loss 204.861160,Time used 0.004997s\n",
      "batch 852, train_loss 192.551743,Time used 0.004000s\n",
      "batch 853, train_loss 174.047897,Time used 0.004000s\n",
      "batch 854, train_loss 180.957565,Time used 0.004996s\n",
      "batch 855, train_loss 177.901627,Time used 0.005000s\n",
      "batch 856, train_loss 158.565460,Time used 0.005000s\n",
      "batch 857, train_loss 168.470703,Time used 0.007001s\n",
      "batch 858, train_loss 141.343765,Time used 0.004001s\n",
      "batch 859, train_loss 163.792892,Time used 0.006033s\n",
      "batch 860, train_loss 178.894485,Time used 0.005000s\n",
      "batch 861, train_loss 181.228104,Time used 0.004972s\n",
      "batch 862, train_loss 181.004135,Time used 0.005996s\n",
      "batch 863, train_loss 156.021072,Time used 0.004999s\n",
      "batch 864, train_loss 207.909058,Time used 0.005003s\n",
      "batch 865, train_loss 168.152023,Time used 0.007999s\n",
      "batch 866, train_loss 156.616272,Time used 0.007034s\n",
      "batch 867, train_loss 219.947510,Time used 0.004968s\n",
      "batch 868, train_loss 147.241211,Time used 0.006998s\n",
      "batch 869, train_loss 194.678314,Time used 0.003999s\n",
      "batch 870, train_loss 176.841980,Time used 0.004000s\n",
      "batch 871, train_loss 168.786896,Time used 0.007002s\n",
      "batch 872, train_loss 188.545242,Time used 0.004999s\n",
      "batch 873, train_loss 162.989090,Time used 0.005003s\n",
      "batch 874, train_loss 180.684021,Time used 0.004999s\n",
      "batch 875, train_loss 167.481491,Time used 0.006998s\n",
      "batch 876, train_loss 181.154694,Time used 0.007001s\n",
      "batch 877, train_loss 207.893219,Time used 0.003999s\n",
      "batch 878, train_loss 192.187302,Time used 0.005001s\n",
      "batch 879, train_loss 199.918350,Time used 0.004999s\n",
      "batch 880, train_loss 185.075729,Time used 0.010001s\n",
      "batch 881, train_loss 147.615982,Time used 0.009001s\n",
      "batch 882, train_loss 127.690147,Time used 0.006000s\n",
      "batch 883, train_loss 191.250137,Time used 0.005000s\n",
      "batch 884, train_loss 164.938324,Time used 0.006000s\n",
      "batch 885, train_loss 189.886703,Time used 0.004999s\n",
      "batch 886, train_loss 230.121017,Time used 0.005000s\n",
      "batch 887, train_loss 174.798172,Time used 0.004997s\n",
      "batch 888, train_loss 147.079941,Time used 0.004999s\n",
      "batch 889, train_loss 157.654114,Time used 0.005965s\n",
      "batch 890, train_loss 146.649704,Time used 0.004998s\n",
      "batch 891, train_loss 184.613052,Time used 0.006003s\n",
      "batch 892, train_loss 145.988907,Time used 0.006055s\n",
      "batch 893, train_loss 184.298874,Time used 0.004978s\n",
      "batch 894, train_loss 193.229935,Time used 0.004001s\n",
      "batch 895, train_loss 128.113831,Time used 0.006999s\n",
      "batch 896, train_loss 190.377563,Time used 0.006996s\n",
      "batch 897, train_loss 160.556107,Time used 0.006002s\n",
      "batch 898, train_loss 179.676865,Time used 0.004998s\n",
      "batch 899, train_loss 135.503494,Time used 0.005000s\n",
      "batch 900, train_loss 160.582657,Time used 0.005002s\n",
      "***************************test_batch 900, test_rmse_loss 14.973205,test_mae_loss 5.807915,test_mape_loss 77.588647,Time used 0.016000s\n",
      "batch 901, train_loss 164.295105,Time used 0.005997s\n",
      "batch 902, train_loss 252.610138,Time used 0.005002s\n",
      "batch 903, train_loss 153.432266,Time used 0.004997s\n",
      "batch 904, train_loss 222.493698,Time used 0.003979s\n",
      "batch 905, train_loss 167.238541,Time used 0.004999s\n",
      "batch 906, train_loss 155.975342,Time used 0.004001s\n",
      "batch 907, train_loss 144.341370,Time used 0.005000s\n",
      "batch 908, train_loss 211.419342,Time used 0.004999s\n",
      "batch 909, train_loss 177.881134,Time used 0.003999s\n",
      "batch 910, train_loss 157.736206,Time used 0.005002s\n",
      "batch 911, train_loss 195.408936,Time used 0.003999s\n",
      "batch 912, train_loss 200.977081,Time used 0.006001s\n",
      "batch 913, train_loss 193.948776,Time used 0.004967s\n",
      "batch 914, train_loss 161.330185,Time used 0.005997s\n",
      "batch 915, train_loss 171.749054,Time used 0.004999s\n",
      "batch 916, train_loss 119.828087,Time used 0.008003s\n",
      "batch 917, train_loss 156.784256,Time used 0.004998s\n",
      "batch 918, train_loss 158.913757,Time used 0.004001s\n",
      "batch 919, train_loss 184.625702,Time used 0.004998s\n",
      "batch 920, train_loss 160.678070,Time used 0.007999s\n",
      "batch 921, train_loss 164.203110,Time used 0.005003s\n",
      "batch 922, train_loss 188.530991,Time used 0.005993s\n",
      "batch 923, train_loss 153.096039,Time used 0.005000s\n",
      "batch 924, train_loss 179.316101,Time used 0.004000s\n",
      "batch 925, train_loss 210.823853,Time used 0.006000s\n",
      "batch 926, train_loss 191.343277,Time used 0.005000s\n",
      "batch 927, train_loss 202.055283,Time used 0.004000s\n",
      "batch 928, train_loss 162.629913,Time used 0.004000s\n",
      "batch 929, train_loss 193.555618,Time used 0.007039s\n",
      "batch 930, train_loss 169.442078,Time used 0.003993s\n",
      "batch 931, train_loss 174.064545,Time used 0.004988s\n",
      "batch 932, train_loss 153.730637,Time used 0.007972s\n",
      "batch 933, train_loss 184.044006,Time used 0.004000s\n",
      "batch 934, train_loss 146.113297,Time used 0.006000s\n",
      "batch 935, train_loss 116.553040,Time used 0.006000s\n",
      "batch 936, train_loss 176.372391,Time used 0.004000s\n",
      "batch 937, train_loss 152.160156,Time used 0.003999s\n",
      "batch 938, train_loss 162.086975,Time used 0.004000s\n",
      "batch 939, train_loss 186.679489,Time used 0.005002s\n",
      "batch 940, train_loss 195.154694,Time used 0.005001s\n",
      "batch 941, train_loss 142.079590,Time used 0.003999s\n",
      "batch 942, train_loss 212.555862,Time used 0.006004s\n",
      "batch 943, train_loss 148.384064,Time used 0.003994s\n",
      "batch 944, train_loss 195.975174,Time used 0.003999s\n",
      "batch 945, train_loss 155.814545,Time used 0.005001s\n",
      "batch 946, train_loss 176.229385,Time used 0.006999s\n",
      "batch 947, train_loss 143.738052,Time used 0.006999s\n",
      "batch 948, train_loss 171.134903,Time used 0.007000s\n",
      "batch 949, train_loss 195.546234,Time used 0.007000s\n",
      "batch 950, train_loss 129.931702,Time used 0.005005s\n",
      "batch 951, train_loss 147.743271,Time used 0.004999s\n",
      "batch 952, train_loss 209.326492,Time used 0.005001s\n",
      "batch 953, train_loss 175.800339,Time used 0.005995s\n",
      "batch 954, train_loss 171.874741,Time used 0.005001s\n",
      "batch 955, train_loss 160.550247,Time used 0.005001s\n",
      "batch 956, train_loss 163.015503,Time used 0.005998s\n",
      "batch 957, train_loss 114.668861,Time used 0.005001s\n",
      "batch 958, train_loss 164.348251,Time used 0.004999s\n",
      "batch 959, train_loss 153.614075,Time used 0.006001s\n",
      "batch 960, train_loss 152.446808,Time used 0.004000s\n",
      "batch 961, train_loss 141.664185,Time used 0.004998s\n",
      "batch 962, train_loss 208.442062,Time used 0.005004s\n",
      "batch 963, train_loss 141.332428,Time used 0.004996s\n",
      "batch 964, train_loss 178.485855,Time used 0.011013s\n",
      "batch 965, train_loss 131.810623,Time used 0.006988s\n",
      "batch 966, train_loss 213.425949,Time used 0.005000s\n",
      "batch 967, train_loss 136.984863,Time used 0.005000s\n",
      "batch 968, train_loss 120.771378,Time used 0.003999s\n",
      "batch 969, train_loss 148.156235,Time used 0.003999s\n",
      "batch 970, train_loss 169.466324,Time used 0.004000s\n",
      "batch 971, train_loss 152.792923,Time used 0.006000s\n",
      "batch 972, train_loss 175.487762,Time used 0.004998s\n",
      "batch 973, train_loss 125.147484,Time used 0.004000s\n",
      "batch 974, train_loss 145.570190,Time used 0.005000s\n",
      "batch 975, train_loss 171.721039,Time used 0.005000s\n",
      "batch 976, train_loss 127.234375,Time used 0.004000s\n",
      "batch 977, train_loss 193.806381,Time used 0.005000s\n",
      "batch 978, train_loss 158.345596,Time used 0.004008s\n",
      "batch 979, train_loss 214.362183,Time used 0.003999s\n",
      "batch 980, train_loss 173.537170,Time used 0.004000s\n",
      "batch 981, train_loss 144.423065,Time used 0.005002s\n",
      "batch 982, train_loss 161.664261,Time used 0.007999s\n",
      "batch 983, train_loss 202.952759,Time used 0.005000s\n",
      "batch 984, train_loss 155.840546,Time used 0.004999s\n",
      "batch 985, train_loss 142.257492,Time used 0.006000s\n",
      "batch 986, train_loss 165.620255,Time used 0.004000s\n",
      "batch 987, train_loss 157.497192,Time used 0.005000s\n",
      "batch 988, train_loss 180.029160,Time used 0.005002s\n",
      "batch 989, train_loss 191.215866,Time used 0.006999s\n",
      "batch 990, train_loss 149.975052,Time used 0.007004s\n",
      "batch 991, train_loss 146.307587,Time used 0.005998s\n",
      "batch 992, train_loss 161.726364,Time used 0.004996s\n",
      "batch 993, train_loss 168.313736,Time used 0.004000s\n",
      "batch 994, train_loss 120.695839,Time used 0.007002s\n",
      "batch 995, train_loss 131.327148,Time used 0.004001s\n",
      "batch 996, train_loss 153.677582,Time used 0.005000s\n",
      "batch 997, train_loss 162.099228,Time used 0.004998s\n",
      "batch 998, train_loss 153.104874,Time used 0.003997s\n",
      "batch 999, train_loss 191.351883,Time used 0.006999s\n",
      "batch 1000, train_loss 165.717773,Time used 0.005001s\n",
      "***************************test_batch 1000, test_rmse_loss 14.296778,test_mae_loss 5.514957,test_mape_loss 75.159235,Time used 0.022007s\n",
      "batch 1001, train_loss 153.359756,Time used 0.006994s\n",
      "batch 1002, train_loss 195.531876,Time used 0.004027s\n",
      "batch 1003, train_loss 172.399506,Time used 0.006001s\n",
      "batch 1004, train_loss 119.336220,Time used 0.006006s\n",
      "batch 1005, train_loss 176.478394,Time used 0.005969s\n",
      "batch 1006, train_loss 133.541626,Time used 0.005998s\n",
      "batch 1007, train_loss 149.851990,Time used 0.005001s\n",
      "batch 1008, train_loss 170.706726,Time used 0.004999s\n",
      "batch 1009, train_loss 155.791351,Time used 0.005996s\n",
      "batch 1010, train_loss 142.665512,Time used 0.005002s\n",
      "batch 1011, train_loss 123.839043,Time used 0.007998s\n",
      "batch 1012, train_loss 161.143600,Time used 0.006001s\n",
      "batch 1013, train_loss 142.820953,Time used 0.006001s\n",
      "batch 1014, train_loss 166.751007,Time used 0.005000s\n",
      "batch 1015, train_loss 173.565094,Time used 0.006008s\n",
      "batch 1016, train_loss 149.057373,Time used 0.007988s\n",
      "batch 1017, train_loss 204.090942,Time used 0.007021s\n",
      "batch 1018, train_loss 156.815628,Time used 0.004977s\n",
      "batch 1019, train_loss 158.869232,Time used 0.005001s\n",
      "batch 1020, train_loss 150.684448,Time used 0.004998s\n",
      "batch 1021, train_loss 169.052399,Time used 0.007997s\n",
      "batch 1022, train_loss 137.764786,Time used 0.005010s\n",
      "batch 1023, train_loss 152.221664,Time used 0.005022s\n",
      "batch 1024, train_loss 153.304520,Time used 0.004971s\n",
      "batch 1025, train_loss 154.223801,Time used 0.004998s\n",
      "batch 1026, train_loss 176.327591,Time used 0.005999s\n",
      "batch 1027, train_loss 125.468895,Time used 0.005002s\n",
      "batch 1028, train_loss 111.961273,Time used 0.004037s\n",
      "batch 1029, train_loss 155.169510,Time used 0.006999s\n",
      "batch 1030, train_loss 188.615829,Time used 0.005001s\n",
      "batch 1031, train_loss 191.491852,Time used 0.004969s\n",
      "batch 1032, train_loss 128.991577,Time used 0.006029s\n",
      "batch 1033, train_loss 166.025131,Time used 0.004996s\n",
      "batch 1034, train_loss 151.491562,Time used 0.007002s\n",
      "batch 1035, train_loss 140.015732,Time used 0.004034s\n",
      "batch 1036, train_loss 149.577118,Time used 0.005967s\n",
      "batch 1037, train_loss 161.626907,Time used 0.005003s\n",
      "batch 1038, train_loss 155.611801,Time used 0.005000s\n",
      "batch 1039, train_loss 160.619537,Time used 0.014997s\n",
      "batch 1040, train_loss 130.635986,Time used 0.008043s\n",
      "batch 1041, train_loss 173.550064,Time used 0.004960s\n",
      "batch 1042, train_loss 135.399994,Time used 0.005030s\n",
      "batch 1043, train_loss 165.410141,Time used 0.004967s\n",
      "batch 1044, train_loss 179.858246,Time used 0.005003s\n",
      "batch 1045, train_loss 140.774216,Time used 0.005999s\n",
      "batch 1046, train_loss 165.369354,Time used 0.007046s\n",
      "batch 1047, train_loss 116.490585,Time used 0.004953s\n",
      "batch 1048, train_loss 142.769104,Time used 0.005031s\n",
      "batch 1049, train_loss 160.915741,Time used 0.004966s\n",
      "batch 1050, train_loss 145.649826,Time used 0.005036s\n",
      "batch 1051, train_loss 143.149582,Time used 0.005002s\n",
      "batch 1052, train_loss 122.345856,Time used 0.005964s\n",
      "batch 1053, train_loss 151.547699,Time used 0.006003s\n",
      "batch 1054, train_loss 152.368256,Time used 0.004999s\n",
      "batch 1055, train_loss 156.771896,Time used 0.006999s\n",
      "batch 1056, train_loss 181.419525,Time used 0.007001s\n",
      "batch 1057, train_loss 140.715988,Time used 0.004997s\n",
      "batch 1058, train_loss 164.469650,Time used 0.005000s\n",
      "batch 1059, train_loss 163.519913,Time used 0.007000s\n",
      "batch 1060, train_loss 123.350067,Time used 0.008024s\n",
      "batch 1061, train_loss 152.510010,Time used 0.006974s\n",
      "batch 1062, train_loss 129.683395,Time used 0.007001s\n",
      "batch 1063, train_loss 143.663864,Time used 0.005004s\n",
      "batch 1064, train_loss 148.598480,Time used 0.004999s\n",
      "batch 1065, train_loss 152.718323,Time used 0.005000s\n",
      "batch 1066, train_loss 114.026405,Time used 0.005000s\n",
      "batch 1067, train_loss 136.143097,Time used 0.005000s\n",
      "batch 1068, train_loss 131.214539,Time used 0.004000s\n",
      "batch 1069, train_loss 216.172867,Time used 0.004999s\n",
      "batch 1070, train_loss 128.588257,Time used 0.007032s\n",
      "batch 1071, train_loss 147.701172,Time used 0.006966s\n",
      "batch 1072, train_loss 158.039551,Time used 0.007034s\n",
      "batch 1073, train_loss 156.358841,Time used 0.006994s\n",
      "batch 1074, train_loss 132.464752,Time used 0.006000s\n",
      "batch 1075, train_loss 139.239014,Time used 0.006972s\n",
      "batch 1076, train_loss 130.831360,Time used 0.008037s\n",
      "batch 1077, train_loss 152.822357,Time used 0.004991s\n",
      "batch 1078, train_loss 146.089966,Time used 0.004971s\n",
      "batch 1079, train_loss 143.302551,Time used 0.005034s\n",
      "batch 1080, train_loss 195.528259,Time used 0.004967s\n",
      "batch 1081, train_loss 133.681152,Time used 0.005002s\n",
      "batch 1082, train_loss 128.469696,Time used 0.005033s\n",
      "batch 1083, train_loss 106.946030,Time used 0.003996s\n",
      "batch 1084, train_loss 138.100906,Time used 0.005967s\n",
      "batch 1085, train_loss 150.639374,Time used 0.004003s\n",
      "batch 1086, train_loss 118.955681,Time used 0.005000s\n",
      "batch 1087, train_loss 141.072250,Time used 0.006036s\n",
      "batch 1088, train_loss 166.603607,Time used 0.007965s\n",
      "batch 1089, train_loss 131.969269,Time used 0.003999s\n",
      "batch 1090, train_loss 127.172050,Time used 0.005997s\n",
      "batch 1091, train_loss 151.649231,Time used 0.008035s\n",
      "batch 1092, train_loss 130.701645,Time used 0.004966s\n",
      "batch 1093, train_loss 185.974487,Time used 0.005000s\n",
      "batch 1094, train_loss 118.297867,Time used 0.004999s\n",
      "batch 1095, train_loss 170.857697,Time used 0.004999s\n",
      "batch 1096, train_loss 120.722496,Time used 0.004999s\n",
      "batch 1097, train_loss 153.142258,Time used 0.004000s\n",
      "batch 1098, train_loss 164.958710,Time used 0.005001s\n",
      "batch 1099, train_loss 149.389099,Time used 0.007041s\n",
      "batch 1100, train_loss 140.885361,Time used 0.004992s\n",
      "***************************test_batch 1100, test_rmse_loss 13.572480,test_mae_loss 5.253052,test_mape_loss 73.456692,Time used 0.021970s\n",
      "batch 1101, train_loss 126.096825,Time used 0.005999s\n",
      "batch 1102, train_loss 132.344162,Time used 0.005000s\n",
      "batch 1103, train_loss 151.613693,Time used 0.005029s\n",
      "batch 1104, train_loss 215.064682,Time used 0.004969s\n",
      "batch 1105, train_loss 107.501556,Time used 0.005963s\n",
      "batch 1106, train_loss 200.594666,Time used 0.005001s\n",
      "batch 1107, train_loss 136.984650,Time used 0.005003s\n",
      "batch 1108, train_loss 118.963005,Time used 0.007995s\n",
      "batch 1109, train_loss 122.460663,Time used 0.005001s\n",
      "batch 1110, train_loss 150.844864,Time used 0.006000s\n",
      "batch 1111, train_loss 174.828629,Time used 0.004999s\n",
      "batch 1112, train_loss 161.824966,Time used 0.005001s\n",
      "batch 1113, train_loss 132.838455,Time used 0.006008s\n",
      "batch 1114, train_loss 136.036804,Time used 0.007031s\n",
      "batch 1115, train_loss 127.573318,Time used 0.003996s\n",
      "batch 1116, train_loss 149.277771,Time used 0.005967s\n",
      "batch 1117, train_loss 137.932724,Time used 0.003998s\n",
      "batch 1118, train_loss 161.959335,Time used 0.004999s\n",
      "batch 1119, train_loss 144.957581,Time used 0.005002s\n",
      "batch 1120, train_loss 133.390335,Time used 0.004000s\n",
      "batch 1121, train_loss 133.078110,Time used 0.006000s\n",
      "batch 1122, train_loss 157.953644,Time used 0.004999s\n",
      "batch 1123, train_loss 138.416412,Time used 0.005000s\n",
      "batch 1124, train_loss 131.525894,Time used 0.005000s\n",
      "batch 1125, train_loss 127.484688,Time used 0.006003s\n",
      "batch 1126, train_loss 152.171906,Time used 0.009000s\n",
      "batch 1127, train_loss 108.284348,Time used 0.007040s\n",
      "batch 1128, train_loss 120.187698,Time used 0.004993s\n",
      "batch 1129, train_loss 136.103943,Time used 0.004956s\n",
      "batch 1130, train_loss 177.211090,Time used 0.005001s\n",
      "batch 1131, train_loss 157.172775,Time used 0.005000s\n",
      "batch 1132, train_loss 115.753578,Time used 0.007000s\n",
      "batch 1133, train_loss 127.825211,Time used 0.008000s\n",
      "batch 1134, train_loss 127.059433,Time used 0.006000s\n",
      "batch 1135, train_loss 111.626053,Time used 0.005000s\n",
      "batch 1136, train_loss 152.179703,Time used 0.004999s\n",
      "batch 1137, train_loss 108.137192,Time used 0.006001s\n",
      "batch 1138, train_loss 133.925568,Time used 0.006001s\n",
      "batch 1139, train_loss 130.608582,Time used 0.007002s\n",
      "batch 1140, train_loss 112.750496,Time used 0.007998s\n",
      "batch 1141, train_loss 143.427567,Time used 0.008001s\n",
      "batch 1142, train_loss 124.499306,Time used 0.004999s\n",
      "batch 1143, train_loss 137.586014,Time used 0.005004s\n",
      "batch 1144, train_loss 109.373367,Time used 0.005995s\n",
      "batch 1145, train_loss 165.578110,Time used 0.005000s\n",
      "batch 1146, train_loss 143.321686,Time used 0.005002s\n",
      "batch 1147, train_loss 114.967056,Time used 0.005000s\n",
      "batch 1148, train_loss 128.721848,Time used 0.004998s\n",
      "batch 1149, train_loss 153.164337,Time used 0.004001s\n",
      "batch 1150, train_loss 170.785080,Time used 0.005004s\n",
      "batch 1151, train_loss 163.807953,Time used 0.005033s\n",
      "batch 1152, train_loss 141.721222,Time used 0.003997s\n",
      "batch 1153, train_loss 120.569534,Time used 0.006983s\n",
      "batch 1154, train_loss 151.209671,Time used 0.003999s\n",
      "batch 1155, train_loss 132.357727,Time used 0.004962s\n",
      "batch 1156, train_loss 152.428101,Time used 0.005002s\n",
      "batch 1157, train_loss 116.679779,Time used 0.004000s\n",
      "batch 1158, train_loss 123.835701,Time used 0.004000s\n",
      "batch 1159, train_loss 164.710876,Time used 0.005001s\n",
      "batch 1160, train_loss 132.490616,Time used 0.005999s\n",
      "batch 1161, train_loss 142.312057,Time used 0.004000s\n",
      "batch 1162, train_loss 137.191772,Time used 0.004998s\n",
      "batch 1163, train_loss 141.483795,Time used 0.005003s\n",
      "batch 1164, train_loss 118.898758,Time used 0.004001s\n",
      "batch 1165, train_loss 131.582962,Time used 0.004998s\n",
      "batch 1166, train_loss 107.392693,Time used 0.007028s\n",
      "batch 1167, train_loss 104.704361,Time used 0.005002s\n",
      "batch 1168, train_loss 124.920700,Time used 0.004966s\n",
      "batch 1169, train_loss 149.930923,Time used 0.007999s\n",
      "batch 1170, train_loss 163.430023,Time used 0.005000s\n",
      "batch 1171, train_loss 136.398727,Time used 0.005004s\n",
      "batch 1172, train_loss 149.606598,Time used 0.004000s\n",
      "batch 1173, train_loss 143.578384,Time used 0.005001s\n",
      "batch 1174, train_loss 124.303795,Time used 0.004996s\n",
      "batch 1175, train_loss 129.148697,Time used 0.006002s\n",
      "batch 1176, train_loss 112.752022,Time used 0.003997s\n",
      "batch 1177, train_loss 132.489304,Time used 0.007012s\n",
      "batch 1178, train_loss 119.389412,Time used 0.005980s\n",
      "batch 1179, train_loss 137.870209,Time used 0.005001s\n",
      "batch 1180, train_loss 141.962967,Time used 0.004998s\n",
      "batch 1181, train_loss 115.808121,Time used 0.005004s\n",
      "batch 1182, train_loss 118.977982,Time used 0.005030s\n",
      "batch 1183, train_loss 140.927933,Time used 0.005000s\n",
      "batch 1184, train_loss 136.514114,Time used 0.004966s\n",
      "batch 1185, train_loss 133.412094,Time used 0.004999s\n",
      "batch 1186, train_loss 107.071205,Time used 0.005001s\n",
      "batch 1187, train_loss 130.527664,Time used 0.004999s\n",
      "batch 1188, train_loss 124.515038,Time used 0.005999s\n",
      "batch 1189, train_loss 124.086761,Time used 0.006000s\n",
      "batch 1190, train_loss 130.168869,Time used 0.003997s\n",
      "batch 1191, train_loss 157.745911,Time used 0.005000s\n",
      "batch 1192, train_loss 154.644623,Time used 0.004000s\n",
      "batch 1193, train_loss 137.614990,Time used 0.004034s\n",
      "batch 1194, train_loss 129.882935,Time used 0.004999s\n",
      "batch 1195, train_loss 104.222069,Time used 0.004002s\n",
      "batch 1196, train_loss 133.341568,Time used 0.004966s\n",
      "batch 1197, train_loss 152.565598,Time used 0.004999s\n",
      "batch 1198, train_loss 106.469353,Time used 0.005001s\n",
      "batch 1199, train_loss 127.749146,Time used 0.007001s\n",
      "batch 1200, train_loss 131.436478,Time used 0.005030s\n",
      "***************************test_batch 1200, test_rmse_loss 12.868201,test_mae_loss 5.004556,test_mape_loss 71.760232,Time used 0.015971s\n",
      "batch 1201, train_loss 135.293243,Time used 0.007996s\n",
      "batch 1202, train_loss 137.235809,Time used 0.007999s\n",
      "batch 1203, train_loss 152.880249,Time used 0.006999s\n",
      "batch 1204, train_loss 133.345062,Time used 0.005000s\n",
      "batch 1205, train_loss 129.702820,Time used 0.006001s\n",
      "batch 1206, train_loss 103.979446,Time used 0.005001s\n",
      "batch 1207, train_loss 107.376747,Time used 0.004999s\n",
      "batch 1208, train_loss 123.459595,Time used 0.005002s\n",
      "batch 1209, train_loss 136.099304,Time used 0.005999s\n",
      "batch 1210, train_loss 139.560944,Time used 0.005000s\n",
      "batch 1211, train_loss 126.082672,Time used 0.005999s\n",
      "batch 1212, train_loss 128.939972,Time used 0.005002s\n",
      "batch 1213, train_loss 117.786568,Time used 0.004998s\n",
      "batch 1214, train_loss 123.045250,Time used 0.004999s\n",
      "batch 1215, train_loss 112.205399,Time used 0.006001s\n",
      "batch 1216, train_loss 156.400711,Time used 0.007001s\n",
      "batch 1217, train_loss 150.014297,Time used 0.004999s\n",
      "batch 1218, train_loss 110.990227,Time used 0.006001s\n",
      "batch 1219, train_loss 115.239594,Time used 0.007001s\n",
      "batch 1220, train_loss 126.123093,Time used 0.006999s\n",
      "batch 1221, train_loss 132.964188,Time used 0.005000s\n",
      "batch 1222, train_loss 130.258118,Time used 0.005001s\n",
      "batch 1223, train_loss 118.498833,Time used 0.004000s\n",
      "batch 1224, train_loss 83.735008,Time used 0.005995s\n",
      "batch 1225, train_loss 141.990570,Time used 0.005030s\n",
      "batch 1226, train_loss 116.680840,Time used 0.007967s\n",
      "batch 1227, train_loss 110.368530,Time used 0.006029s\n",
      "batch 1228, train_loss 153.165848,Time used 0.006964s\n",
      "batch 1229, train_loss 147.307983,Time used 0.008000s\n",
      "batch 1230, train_loss 126.136902,Time used 0.007003s\n",
      "batch 1231, train_loss 100.257729,Time used 0.006998s\n",
      "batch 1232, train_loss 127.819771,Time used 0.006999s\n",
      "batch 1233, train_loss 150.071716,Time used 0.007998s\n",
      "batch 1234, train_loss 166.404541,Time used 0.008000s\n",
      "batch 1235, train_loss 99.368553,Time used 0.008000s\n",
      "batch 1236, train_loss 110.883026,Time used 0.007998s\n",
      "batch 1237, train_loss 126.192696,Time used 0.007001s\n",
      "batch 1238, train_loss 102.396973,Time used 0.008000s\n",
      "batch 1239, train_loss 113.119057,Time used 0.008001s\n",
      "batch 1240, train_loss 108.851791,Time used 0.007999s\n",
      "batch 1241, train_loss 162.445312,Time used 0.007999s\n",
      "batch 1242, train_loss 100.325943,Time used 0.006018s\n",
      "batch 1243, train_loss 111.223923,Time used 0.004000s\n",
      "batch 1244, train_loss 122.863144,Time used 0.004000s\n",
      "batch 1245, train_loss 113.608826,Time used 0.005004s\n",
      "batch 1246, train_loss 103.823204,Time used 0.005032s\n",
      "batch 1247, train_loss 112.227791,Time used 0.003999s\n",
      "batch 1248, train_loss 118.603401,Time used 0.005966s\n",
      "batch 1249, train_loss 117.490273,Time used 0.007001s\n",
      "batch 1250, train_loss 115.208046,Time used 0.006002s\n",
      "batch 1251, train_loss 122.555458,Time used 0.008033s\n",
      "batch 1252, train_loss 104.416145,Time used 0.007966s\n",
      "batch 1253, train_loss 146.291672,Time used 0.005000s\n",
      "batch 1254, train_loss 121.145493,Time used 0.003999s\n",
      "batch 1255, train_loss 105.558739,Time used 0.004000s\n",
      "batch 1256, train_loss 112.214226,Time used 0.005998s\n",
      "batch 1257, train_loss 97.913460,Time used 0.006009s\n",
      "batch 1258, train_loss 126.366768,Time used 0.004999s\n",
      "batch 1259, train_loss 124.449295,Time used 0.004994s\n",
      "batch 1260, train_loss 97.616615,Time used 0.006002s\n",
      "batch 1261, train_loss 132.641830,Time used 0.004998s\n",
      "batch 1262, train_loss 165.509613,Time used 0.003997s\n",
      "batch 1263, train_loss 130.333710,Time used 0.006002s\n",
      "batch 1264, train_loss 120.531044,Time used 0.007000s\n",
      "batch 1265, train_loss 98.320023,Time used 0.004000s\n",
      "batch 1266, train_loss 105.521469,Time used 0.005000s\n",
      "batch 1267, train_loss 111.494171,Time used 0.006001s\n",
      "batch 1268, train_loss 124.373993,Time used 0.006998s\n",
      "batch 1269, train_loss 124.720306,Time used 0.008003s\n",
      "batch 1270, train_loss 113.760811,Time used 0.005000s\n",
      "batch 1271, train_loss 109.745537,Time used 0.006000s\n",
      "batch 1272, train_loss 140.710510,Time used 0.004000s\n",
      "batch 1273, train_loss 145.585709,Time used 0.008996s\n",
      "batch 1274, train_loss 92.358627,Time used 0.005002s\n",
      "batch 1275, train_loss 123.599518,Time used 0.004998s\n",
      "batch 1276, train_loss 117.385986,Time used 0.004999s\n",
      "batch 1277, train_loss 104.544266,Time used 0.005001s\n",
      "batch 1278, train_loss 128.454056,Time used 0.006000s\n",
      "batch 1279, train_loss 82.240410,Time used 0.006999s\n",
      "batch 1280, train_loss 98.949394,Time used 0.007005s\n",
      "batch 1281, train_loss 107.464546,Time used 0.007027s\n",
      "batch 1282, train_loss 116.049889,Time used 0.007967s\n",
      "batch 1283, train_loss 95.707184,Time used 0.009998s\n",
      "batch 1284, train_loss 131.940582,Time used 0.007000s\n",
      "batch 1285, train_loss 126.832756,Time used 0.006000s\n",
      "batch 1286, train_loss 146.543564,Time used 0.004998s\n",
      "batch 1287, train_loss 150.592606,Time used 0.006002s\n",
      "batch 1288, train_loss 140.805862,Time used 0.005013s\n",
      "batch 1289, train_loss 125.203896,Time used 0.005990s\n",
      "batch 1290, train_loss 86.225601,Time used 0.004997s\n",
      "batch 1291, train_loss 130.948547,Time used 0.004999s\n",
      "batch 1292, train_loss 102.148849,Time used 0.008008s\n",
      "batch 1293, train_loss 98.144791,Time used 0.007028s\n",
      "batch 1294, train_loss 133.590942,Time used 0.004969s\n",
      "batch 1295, train_loss 95.599007,Time used 0.006033s\n",
      "batch 1296, train_loss 115.079552,Time used 0.004000s\n",
      "batch 1297, train_loss 94.561768,Time used 0.004993s\n",
      "batch 1298, train_loss 110.391754,Time used 0.004961s\n",
      "batch 1299, train_loss 133.082993,Time used 0.006003s\n",
      "batch 1300, train_loss 120.010612,Time used 0.005999s\n",
      "***************************test_batch 1300, test_rmse_loss 12.180151,test_mae_loss 4.767051,test_mape_loss 69.408656,Time used 0.018999s\n",
      "batch 1301, train_loss 124.440201,Time used 0.006998s\n",
      "batch 1302, train_loss 109.815887,Time used 0.005036s\n",
      "batch 1303, train_loss 146.198349,Time used 0.004998s\n",
      "batch 1304, train_loss 100.070641,Time used 0.006963s\n",
      "batch 1305, train_loss 99.122787,Time used 0.004000s\n",
      "batch 1306, train_loss 126.155266,Time used 0.005000s\n",
      "batch 1307, train_loss 98.627495,Time used 0.005001s\n",
      "batch 1308, train_loss 104.624100,Time used 0.008000s\n",
      "batch 1309, train_loss 126.463905,Time used 0.006036s\n",
      "batch 1310, train_loss 107.556145,Time used 0.004996s\n",
      "batch 1311, train_loss 119.405525,Time used 0.007002s\n",
      "batch 1312, train_loss 107.249496,Time used 0.004966s\n",
      "batch 1313, train_loss 111.896881,Time used 0.004003s\n",
      "batch 1314, train_loss 119.209480,Time used 0.005002s\n",
      "batch 1315, train_loss 88.573730,Time used 0.006999s\n",
      "batch 1316, train_loss 108.627472,Time used 0.006004s\n",
      "batch 1317, train_loss 93.441025,Time used 0.005994s\n",
      "batch 1318, train_loss 141.538986,Time used 0.003999s\n",
      "batch 1319, train_loss 111.335693,Time used 0.004000s\n",
      "batch 1320, train_loss 124.616989,Time used 0.005000s\n",
      "batch 1321, train_loss 156.042023,Time used 0.004997s\n",
      "batch 1322, train_loss 137.529129,Time used 0.005970s\n",
      "batch 1323, train_loss 137.320694,Time used 0.005000s\n",
      "batch 1324, train_loss 101.744179,Time used 0.004000s\n",
      "batch 1325, train_loss 93.799675,Time used 0.006036s\n",
      "batch 1326, train_loss 115.448112,Time used 0.003993s\n",
      "batch 1327, train_loss 130.604721,Time used 0.005000s\n",
      "batch 1328, train_loss 97.120056,Time used 0.005001s\n",
      "batch 1329, train_loss 93.153564,Time used 0.005002s\n",
      "batch 1330, train_loss 91.516693,Time used 0.004001s\n",
      "batch 1331, train_loss 89.672600,Time used 0.004987s\n",
      "batch 1332, train_loss 127.072464,Time used 0.004982s\n",
      "batch 1333, train_loss 76.332634,Time used 0.005030s\n",
      "batch 1334, train_loss 99.818504,Time used 0.004968s\n",
      "batch 1335, train_loss 120.443726,Time used 0.007004s\n",
      "batch 1336, train_loss 126.787460,Time used 0.007032s\n",
      "batch 1337, train_loss 119.448441,Time used 0.004966s\n",
      "batch 1338, train_loss 104.030716,Time used 0.005028s\n",
      "batch 1339, train_loss 79.362892,Time used 0.004974s\n",
      "batch 1340, train_loss 109.037712,Time used 0.004025s\n",
      "batch 1341, train_loss 104.197945,Time used 0.004973s\n",
      "batch 1342, train_loss 107.478699,Time used 0.006000s\n",
      "batch 1343, train_loss 142.964249,Time used 0.005001s\n",
      "batch 1344, train_loss 99.076553,Time used 0.004994s\n",
      "batch 1345, train_loss 102.177727,Time used 0.005002s\n",
      "batch 1346, train_loss 125.664230,Time used 0.007000s\n",
      "batch 1347, train_loss 87.735847,Time used 0.012001s\n",
      "batch 1348, train_loss 99.885475,Time used 0.005003s\n",
      "batch 1349, train_loss 139.086884,Time used 0.004997s\n",
      "batch 1350, train_loss 98.192192,Time used 0.005000s\n",
      "batch 1351, train_loss 131.182953,Time used 0.005000s\n",
      "batch 1352, train_loss 81.750961,Time used 0.004999s\n",
      "batch 1353, train_loss 100.050537,Time used 0.003999s\n",
      "batch 1354, train_loss 121.719559,Time used 0.004002s\n",
      "batch 1355, train_loss 112.745880,Time used 0.005032s\n",
      "batch 1356, train_loss 99.942413,Time used 0.004968s\n",
      "batch 1357, train_loss 105.647995,Time used 0.005018s\n",
      "batch 1358, train_loss 91.597992,Time used 0.005014s\n",
      "batch 1359, train_loss 128.281158,Time used 0.006968s\n",
      "batch 1360, train_loss 98.523865,Time used 0.005001s\n",
      "batch 1361, train_loss 95.713882,Time used 0.006000s\n",
      "batch 1362, train_loss 111.439491,Time used 0.003999s\n",
      "batch 1363, train_loss 132.028015,Time used 0.005001s\n",
      "batch 1364, train_loss 95.728989,Time used 0.003999s\n",
      "batch 1365, train_loss 95.120758,Time used 0.003999s\n",
      "batch 1366, train_loss 99.081940,Time used 0.005001s\n",
      "batch 1367, train_loss 95.641579,Time used 0.003999s\n",
      "batch 1368, train_loss 150.906021,Time used 0.005002s\n",
      "batch 1369, train_loss 83.473511,Time used 0.004999s\n",
      "batch 1370, train_loss 124.050621,Time used 0.006001s\n",
      "batch 1371, train_loss 90.293922,Time used 0.006001s\n",
      "batch 1372, train_loss 112.082657,Time used 0.004999s\n",
      "batch 1373, train_loss 136.512711,Time used 0.005999s\n",
      "batch 1374, train_loss 69.837234,Time used 0.005000s\n",
      "batch 1375, train_loss 93.779373,Time used 0.005002s\n",
      "batch 1376, train_loss 88.008492,Time used 0.006999s\n",
      "batch 1377, train_loss 119.333420,Time used 0.003999s\n",
      "batch 1378, train_loss 129.304474,Time used 0.005001s\n",
      "batch 1379, train_loss 86.773521,Time used 0.003998s\n",
      "batch 1380, train_loss 130.720566,Time used 0.005002s\n",
      "batch 1381, train_loss 93.626945,Time used 0.006000s\n",
      "batch 1382, train_loss 113.039993,Time used 0.006997s\n",
      "batch 1383, train_loss 107.639244,Time used 0.004000s\n",
      "batch 1384, train_loss 92.578163,Time used 0.007001s\n",
      "batch 1385, train_loss 106.891739,Time used 0.006000s\n",
      "batch 1386, train_loss 100.714195,Time used 0.004002s\n",
      "batch 1387, train_loss 104.308701,Time used 0.006034s\n",
      "batch 1388, train_loss 97.209923,Time used 0.004000s\n",
      "batch 1389, train_loss 126.865074,Time used 0.003969s\n",
      "batch 1390, train_loss 120.460938,Time used 0.005000s\n",
      "batch 1391, train_loss 115.268227,Time used 0.003965s\n",
      "batch 1392, train_loss 96.335091,Time used 0.005036s\n",
      "batch 1393, train_loss 82.123062,Time used 0.005000s\n",
      "batch 1394, train_loss 98.345268,Time used 0.007004s\n",
      "batch 1395, train_loss 116.906654,Time used 0.004999s\n",
      "batch 1396, train_loss 101.777588,Time used 0.005000s\n",
      "batch 1397, train_loss 82.525070,Time used 0.005029s\n",
      "batch 1398, train_loss 85.861534,Time used 0.005003s\n",
      "batch 1399, train_loss 119.747124,Time used 0.004966s\n",
      "batch 1400, train_loss 92.640045,Time used 0.005036s\n",
      "***************************test_batch 1400, test_rmse_loss 11.599982,test_mae_loss 4.590736,test_mape_loss 69.394371,Time used 0.016000s\n",
      "batch 1401, train_loss 103.227829,Time used 0.004966s\n",
      "batch 1402, train_loss 112.546822,Time used 0.004030s\n",
      "batch 1403, train_loss 89.329666,Time used 0.004999s\n",
      "batch 1404, train_loss 104.173149,Time used 0.004966s\n",
      "batch 1405, train_loss 102.057121,Time used 0.003999s\n",
      "batch 1406, train_loss 97.592720,Time used 0.004001s\n",
      "batch 1407, train_loss 125.942650,Time used 0.005000s\n",
      "batch 1408, train_loss 92.272247,Time used 0.004999s\n",
      "batch 1409, train_loss 100.186768,Time used 0.005001s\n",
      "batch 1410, train_loss 108.964050,Time used 0.005001s\n",
      "batch 1411, train_loss 119.994087,Time used 0.007004s\n",
      "batch 1412, train_loss 125.055588,Time used 0.006998s\n",
      "batch 1413, train_loss 119.010315,Time used 0.005001s\n",
      "batch 1414, train_loss 109.451881,Time used 0.005999s\n",
      "batch 1415, train_loss 103.203682,Time used 0.008032s\n",
      "batch 1416, train_loss 90.593407,Time used 0.007001s\n",
      "batch 1417, train_loss 87.479393,Time used 0.004999s\n",
      "batch 1418, train_loss 93.844322,Time used 0.005000s\n",
      "batch 1419, train_loss 89.647057,Time used 0.006001s\n",
      "batch 1420, train_loss 125.578957,Time used 0.005001s\n",
      "batch 1421, train_loss 94.133156,Time used 0.004998s\n",
      "batch 1422, train_loss 99.575394,Time used 0.006998s\n",
      "batch 1423, train_loss 98.774361,Time used 0.005002s\n",
      "batch 1424, train_loss 96.649361,Time used 0.004999s\n",
      "batch 1425, train_loss 121.495621,Time used 0.007001s\n",
      "batch 1426, train_loss 98.808006,Time used 0.005000s\n",
      "batch 1427, train_loss 102.634979,Time used 0.005001s\n",
      "batch 1428, train_loss 98.852768,Time used 0.005001s\n",
      "batch 1429, train_loss 115.023895,Time used 0.005000s\n",
      "batch 1430, train_loss 120.900345,Time used 0.005000s\n",
      "batch 1431, train_loss 112.534782,Time used 0.005002s\n",
      "batch 1432, train_loss 101.581970,Time used 0.005000s\n",
      "batch 1433, train_loss 84.042900,Time used 0.005031s\n",
      "batch 1434, train_loss 71.360588,Time used 0.005965s\n",
      "batch 1435, train_loss 106.270378,Time used 0.005003s\n",
      "batch 1436, train_loss 81.446388,Time used 0.005008s\n",
      "batch 1437, train_loss 113.325890,Time used 0.007989s\n",
      "batch 1438, train_loss 95.858566,Time used 0.005000s\n",
      "batch 1439, train_loss 87.698997,Time used 0.004999s\n",
      "batch 1440, train_loss 135.570312,Time used 0.006999s\n",
      "batch 1441, train_loss 114.215240,Time used 0.004994s\n",
      "batch 1442, train_loss 96.215706,Time used 0.005000s\n",
      "batch 1443, train_loss 100.706848,Time used 0.005000s\n",
      "batch 1444, train_loss 125.935486,Time used 0.007000s\n",
      "batch 1445, train_loss 99.154930,Time used 0.005000s\n",
      "batch 1446, train_loss 94.481247,Time used 0.007002s\n",
      "batch 1447, train_loss 89.221687,Time used 0.008000s\n",
      "batch 1448, train_loss 122.572006,Time used 0.005999s\n",
      "batch 1449, train_loss 104.116592,Time used 0.003999s\n",
      "batch 1450, train_loss 97.445724,Time used 0.004003s\n",
      "batch 1451, train_loss 98.660202,Time used 0.006000s\n",
      "batch 1452, train_loss 93.538307,Time used 0.005996s\n",
      "batch 1453, train_loss 100.447624,Time used 0.005002s\n",
      "batch 1454, train_loss 98.579666,Time used 0.005005s\n",
      "batch 1455, train_loss 105.026581,Time used 0.004998s\n",
      "batch 1456, train_loss 107.269119,Time used 0.005028s\n",
      "batch 1457, train_loss 84.382927,Time used 0.004969s\n",
      "batch 1458, train_loss 105.523033,Time used 0.006009s\n",
      "batch 1459, train_loss 76.592628,Time used 0.004992s\n",
      "batch 1460, train_loss 91.338707,Time used 0.004998s\n",
      "batch 1461, train_loss 110.002182,Time used 0.005034s\n",
      "batch 1462, train_loss 90.411392,Time used 0.004001s\n",
      "batch 1463, train_loss 94.613342,Time used 0.004968s\n",
      "batch 1464, train_loss 80.499207,Time used 0.008016s\n",
      "batch 1465, train_loss 123.237961,Time used 0.006965s\n",
      "batch 1466, train_loss 91.168343,Time used 0.005004s\n",
      "batch 1467, train_loss 103.276688,Time used 0.005002s\n",
      "batch 1468, train_loss 110.163292,Time used 0.006994s\n",
      "batch 1469, train_loss 82.336128,Time used 0.007003s\n",
      "batch 1470, train_loss 81.720795,Time used 0.005996s\n",
      "batch 1471, train_loss 97.883522,Time used 0.004999s\n",
      "batch 1472, train_loss 99.581764,Time used 0.005002s\n",
      "batch 1473, train_loss 88.714020,Time used 0.004000s\n",
      "batch 1474, train_loss 91.699707,Time used 0.005006s\n",
      "batch 1475, train_loss 128.034134,Time used 0.007001s\n",
      "batch 1476, train_loss 76.319656,Time used 0.005998s\n",
      "batch 1477, train_loss 96.791222,Time used 0.008030s\n",
      "batch 1478, train_loss 100.316620,Time used 0.004963s\n",
      "batch 1479, train_loss 106.034378,Time used 0.005001s\n",
      "batch 1480, train_loss 86.868324,Time used 0.005000s\n",
      "batch 1481, train_loss 106.804596,Time used 0.007039s\n",
      "batch 1482, train_loss 92.791122,Time used 0.003966s\n",
      "batch 1483, train_loss 119.332573,Time used 0.006005s\n",
      "batch 1484, train_loss 86.266205,Time used 0.006997s\n",
      "batch 1485, train_loss 99.089088,Time used 0.005000s\n",
      "batch 1486, train_loss 94.180481,Time used 0.007033s\n",
      "batch 1487, train_loss 86.702324,Time used 0.003999s\n",
      "batch 1488, train_loss 83.930443,Time used 0.005000s\n",
      "batch 1489, train_loss 76.905479,Time used 0.005030s\n",
      "batch 1490, train_loss 86.053902,Time used 0.004972s\n",
      "batch 1491, train_loss 128.609619,Time used 0.007030s\n",
      "batch 1492, train_loss 100.687668,Time used 0.004026s\n",
      "batch 1493, train_loss 100.002495,Time used 0.005963s\n",
      "batch 1494, train_loss 96.997887,Time used 0.004000s\n",
      "batch 1495, train_loss 101.893387,Time used 0.004999s\n",
      "batch 1496, train_loss 105.667419,Time used 0.005002s\n",
      "batch 1497, train_loss 107.434364,Time used 0.005000s\n",
      "batch 1498, train_loss 93.447952,Time used 0.005000s\n",
      "batch 1499, train_loss 99.589241,Time used 0.006004s\n",
      "batch 1500, train_loss 71.488686,Time used 0.005036s\n",
      "***************************test_batch 1500, test_rmse_loss 11.114527,test_mae_loss 4.437587,test_mape_loss 68.104623,Time used 0.017018s\n",
      "batch 1501, train_loss 114.539238,Time used 0.004980s\n",
      "batch 1502, train_loss 101.269806,Time used 0.007967s\n",
      "batch 1503, train_loss 82.662003,Time used 0.007033s\n",
      "batch 1504, train_loss 88.574532,Time used 0.006967s\n",
      "batch 1505, train_loss 95.275490,Time used 0.005000s\n",
      "batch 1506, train_loss 67.224579,Time used 0.005000s\n",
      "batch 1507, train_loss 93.382439,Time used 0.004996s\n",
      "batch 1508, train_loss 90.508087,Time used 0.005000s\n",
      "batch 1509, train_loss 86.242371,Time used 0.004000s\n",
      "batch 1510, train_loss 98.218941,Time used 0.006001s\n",
      "batch 1511, train_loss 108.809250,Time used 0.005004s\n",
      "batch 1512, train_loss 92.009819,Time used 0.005032s\n",
      "batch 1513, train_loss 91.330719,Time used 0.007998s\n",
      "batch 1514, train_loss 80.956871,Time used 0.008002s\n",
      "batch 1515, train_loss 92.720886,Time used 0.005002s\n",
      "batch 1516, train_loss 85.292923,Time used 0.006960s\n",
      "batch 1517, train_loss 100.659958,Time used 0.004999s\n",
      "batch 1518, train_loss 103.375679,Time used 0.004999s\n",
      "batch 1519, train_loss 87.633232,Time used 0.005002s\n",
      "batch 1520, train_loss 123.506836,Time used 0.004998s\n",
      "batch 1521, train_loss 99.590370,Time used 0.004000s\n",
      "batch 1522, train_loss 73.235603,Time used 0.006002s\n",
      "batch 1523, train_loss 104.031349,Time used 0.004030s\n",
      "batch 1524, train_loss 94.004745,Time used 0.005000s\n",
      "batch 1525, train_loss 85.463989,Time used 0.005003s\n",
      "batch 1526, train_loss 68.918312,Time used 0.003999s\n",
      "batch 1527, train_loss 94.515007,Time used 0.005002s\n",
      "batch 1528, train_loss 99.608582,Time used 0.004996s\n",
      "batch 1529, train_loss 111.587326,Time used 0.007005s\n",
      "batch 1530, train_loss 88.129112,Time used 0.004964s\n",
      "batch 1531, train_loss 91.023170,Time used 0.006030s\n",
      "batch 1532, train_loss 93.864388,Time used 0.004969s\n",
      "batch 1533, train_loss 80.633919,Time used 0.005000s\n",
      "batch 1534, train_loss 76.500214,Time used 0.014002s\n",
      "batch 1535, train_loss 113.726410,Time used 0.004999s\n",
      "batch 1536, train_loss 104.177505,Time used 0.008001s\n",
      "batch 1537, train_loss 82.851540,Time used 0.006943s\n",
      "batch 1538, train_loss 94.161880,Time used 0.004001s\n",
      "batch 1539, train_loss 87.742462,Time used 0.004999s\n",
      "batch 1540, train_loss 91.452827,Time used 0.004035s\n",
      "batch 1541, train_loss 87.657524,Time used 0.005002s\n",
      "batch 1542, train_loss 79.795486,Time used 0.003998s\n",
      "batch 1543, train_loss 74.497147,Time used 0.004974s\n",
      "batch 1544, train_loss 68.279228,Time used 0.005025s\n",
      "batch 1545, train_loss 92.863144,Time used 0.005001s\n",
      "batch 1546, train_loss 102.860825,Time used 0.004968s\n",
      "batch 1547, train_loss 82.736427,Time used 0.005033s\n",
      "batch 1548, train_loss 96.108780,Time used 0.004999s\n",
      "batch 1549, train_loss 105.951126,Time used 0.006968s\n",
      "batch 1550, train_loss 88.563171,Time used 0.007023s\n",
      "batch 1551, train_loss 90.830437,Time used 0.004998s\n",
      "batch 1552, train_loss 82.504608,Time used 0.004975s\n",
      "batch 1553, train_loss 113.503479,Time used 0.005000s\n",
      "batch 1554, train_loss 96.768082,Time used 0.005000s\n",
      "batch 1555, train_loss 96.990616,Time used 0.005038s\n",
      "batch 1556, train_loss 104.822449,Time used 0.003998s\n",
      "batch 1557, train_loss 92.876556,Time used 0.005014s\n",
      "batch 1558, train_loss 92.704010,Time used 0.006953s\n",
      "batch 1559, train_loss 102.753021,Time used 0.006000s\n",
      "batch 1560, train_loss 94.345520,Time used 0.005000s\n",
      "batch 1561, train_loss 75.149574,Time used 0.007030s\n",
      "batch 1562, train_loss 80.136452,Time used 0.007970s\n",
      "batch 1563, train_loss 99.081451,Time used 0.006999s\n",
      "batch 1564, train_loss 101.778381,Time used 0.004033s\n",
      "batch 1565, train_loss 87.420372,Time used 0.006002s\n",
      "batch 1566, train_loss 89.660652,Time used 0.004962s\n",
      "batch 1567, train_loss 78.338120,Time used 0.004001s\n",
      "batch 1568, train_loss 78.293419,Time used 0.004999s\n",
      "batch 1569, train_loss 95.341415,Time used 0.005006s\n",
      "batch 1570, train_loss 99.297554,Time used 0.004001s\n",
      "batch 1571, train_loss 90.484444,Time used 0.008000s\n",
      "batch 1572, train_loss 113.855362,Time used 0.004998s\n",
      "batch 1573, train_loss 104.141502,Time used 0.006001s\n",
      "batch 1574, train_loss 98.072792,Time used 0.004001s\n",
      "batch 1575, train_loss 88.810944,Time used 0.006002s\n",
      "batch 1576, train_loss 90.052208,Time used 0.004999s\n",
      "batch 1577, train_loss 95.009476,Time used 0.004001s\n",
      "batch 1578, train_loss 78.003136,Time used 0.005998s\n",
      "batch 1579, train_loss 86.114098,Time used 0.003999s\n",
      "batch 1580, train_loss 80.705643,Time used 0.005002s\n",
      "batch 1581, train_loss 73.106758,Time used 0.004998s\n",
      "batch 1582, train_loss 95.015602,Time used 0.003999s\n",
      "batch 1583, train_loss 112.670311,Time used 0.004001s\n",
      "batch 1584, train_loss 74.149803,Time used 0.005999s\n",
      "batch 1585, train_loss 107.289276,Time used 0.005000s\n",
      "batch 1586, train_loss 94.485275,Time used 0.004998s\n",
      "batch 1587, train_loss 86.473335,Time used 0.004999s\n",
      "batch 1588, train_loss 84.968575,Time used 0.004002s\n",
      "batch 1589, train_loss 86.998192,Time used 0.005999s\n",
      "batch 1590, train_loss 69.268005,Time used 0.007999s\n",
      "batch 1591, train_loss 89.867653,Time used 0.007002s\n",
      "batch 1592, train_loss 99.822861,Time used 0.005000s\n",
      "batch 1593, train_loss 114.034111,Time used 0.004998s\n",
      "batch 1594, train_loss 97.994232,Time used 0.008025s\n",
      "batch 1595, train_loss 64.663979,Time used 0.006978s\n",
      "batch 1596, train_loss 97.440506,Time used 0.007000s\n",
      "batch 1597, train_loss 85.034195,Time used 0.005999s\n",
      "batch 1598, train_loss 74.140083,Time used 0.005000s\n",
      "batch 1599, train_loss 118.145477,Time used 0.005001s\n",
      "batch 1600, train_loss 87.538239,Time used 0.004999s\n",
      "***************************test_batch 1600, test_rmse_loss 10.703608,test_mae_loss 4.311391,test_mape_loss 67.013112,Time used 0.023003s\n",
      "batch 1601, train_loss 80.503967,Time used 0.005004s\n",
      "batch 1602, train_loss 91.325226,Time used 0.004998s\n",
      "batch 1603, train_loss 91.738045,Time used 0.005001s\n",
      "batch 1604, train_loss 69.401344,Time used 0.007997s\n",
      "batch 1605, train_loss 71.288162,Time used 0.005000s\n",
      "batch 1606, train_loss 84.495712,Time used 0.009004s\n",
      "batch 1607, train_loss 83.392921,Time used 0.006998s\n",
      "batch 1608, train_loss 97.701347,Time used 0.005001s\n",
      "batch 1609, train_loss 92.895233,Time used 0.004997s\n",
      "batch 1610, train_loss 88.746826,Time used 0.004998s\n",
      "batch 1611, train_loss 106.132835,Time used 0.005001s\n",
      "batch 1612, train_loss 119.261047,Time used 0.007003s\n",
      "batch 1613, train_loss 70.520851,Time used 0.004997s\n",
      "batch 1614, train_loss 79.001701,Time used 0.006002s\n",
      "batch 1615, train_loss 78.283508,Time used 0.007000s\n",
      "batch 1616, train_loss 81.260361,Time used 0.004999s\n",
      "batch 1617, train_loss 87.882584,Time used 0.004001s\n",
      "batch 1618, train_loss 56.674500,Time used 0.005000s\n",
      "batch 1619, train_loss 74.352196,Time used 0.005000s\n",
      "batch 1620, train_loss 97.246956,Time used 0.004002s\n",
      "batch 1621, train_loss 92.748672,Time used 0.004998s\n",
      "batch 1622, train_loss 77.109055,Time used 0.004998s\n",
      "batch 1623, train_loss 117.615578,Time used 0.006003s\n",
      "batch 1624, train_loss 81.499870,Time used 0.006997s\n",
      "batch 1625, train_loss 78.626289,Time used 0.005000s\n",
      "batch 1626, train_loss 84.658699,Time used 0.004000s\n",
      "batch 1627, train_loss 85.229996,Time used 0.004001s\n",
      "batch 1628, train_loss 85.523521,Time used 0.003999s\n",
      "batch 1629, train_loss 97.808990,Time used 0.005001s\n",
      "batch 1630, train_loss 87.630447,Time used 0.006001s\n",
      "batch 1631, train_loss 89.120277,Time used 0.008009s\n",
      "batch 1632, train_loss 83.066154,Time used 0.006021s\n",
      "batch 1633, train_loss 68.780792,Time used 0.005032s\n",
      "batch 1634, train_loss 88.418427,Time used 0.005004s\n",
      "batch 1635, train_loss 90.963852,Time used 0.004002s\n",
      "batch 1636, train_loss 108.195099,Time used 0.004964s\n",
      "batch 1637, train_loss 79.383224,Time used 0.005003s\n",
      "batch 1638, train_loss 79.931458,Time used 0.004030s\n",
      "batch 1639, train_loss 92.366859,Time used 0.005001s\n",
      "batch 1640, train_loss 88.955276,Time used 0.005969s\n",
      "batch 1641, train_loss 95.509926,Time used 0.005000s\n",
      "batch 1642, train_loss 83.234062,Time used 0.004000s\n",
      "batch 1643, train_loss 96.427658,Time used 0.004998s\n",
      "batch 1644, train_loss 90.668167,Time used 0.006001s\n",
      "batch 1645, train_loss 81.345139,Time used 0.004999s\n",
      "batch 1646, train_loss 88.836449,Time used 0.005000s\n",
      "batch 1647, train_loss 76.056236,Time used 0.005042s\n",
      "batch 1648, train_loss 82.415359,Time used 0.003992s\n",
      "batch 1649, train_loss 71.637321,Time used 0.006998s\n",
      "batch 1650, train_loss 82.001595,Time used 0.006967s\n",
      "batch 1651, train_loss 80.868759,Time used 0.004001s\n",
      "batch 1652, train_loss 81.743027,Time used 0.004999s\n",
      "batch 1653, train_loss 83.374924,Time used 0.006012s\n",
      "batch 1654, train_loss 98.673416,Time used 0.004984s\n",
      "batch 1655, train_loss 80.465469,Time used 0.005004s\n",
      "batch 1656, train_loss 90.394669,Time used 0.005033s\n",
      "batch 1657, train_loss 80.636307,Time used 0.005000s\n",
      "batch 1658, train_loss 86.454750,Time used 0.004996s\n",
      "batch 1659, train_loss 67.055191,Time used 0.004002s\n",
      "batch 1660, train_loss 83.148323,Time used 0.004997s\n",
      "batch 1661, train_loss 85.477737,Time used 0.005000s\n",
      "batch 1662, train_loss 89.003700,Time used 0.005000s\n",
      "batch 1663, train_loss 73.084755,Time used 0.004999s\n",
      "batch 1664, train_loss 92.169434,Time used 0.005005s\n",
      "batch 1665, train_loss 101.842903,Time used 0.006998s\n",
      "batch 1666, train_loss 76.343735,Time used 0.005005s\n",
      "batch 1667, train_loss 74.611671,Time used 0.004996s\n",
      "batch 1668, train_loss 67.211937,Time used 0.006997s\n",
      "batch 1669, train_loss 85.079933,Time used 0.008036s\n",
      "batch 1670, train_loss 77.364845,Time used 0.007000s\n",
      "batch 1671, train_loss 79.739815,Time used 0.004963s\n",
      "batch 1672, train_loss 88.922050,Time used 0.004000s\n",
      "batch 1673, train_loss 97.982147,Time used 0.005000s\n",
      "batch 1674, train_loss 68.278625,Time used 0.006007s\n",
      "batch 1675, train_loss 84.629311,Time used 0.004995s\n",
      "batch 1676, train_loss 71.739914,Time used 0.005002s\n",
      "batch 1677, train_loss 111.451889,Time used 0.006039s\n",
      "batch 1678, train_loss 95.868797,Time used 0.004961s\n",
      "batch 1679, train_loss 101.331177,Time used 0.005035s\n",
      "batch 1680, train_loss 89.562668,Time used 0.005968s\n",
      "batch 1681, train_loss 84.686241,Time used 0.004998s\n",
      "batch 1682, train_loss 90.700096,Time used 0.006031s\n",
      "batch 1683, train_loss 95.917915,Time used 0.005001s\n",
      "batch 1684, train_loss 89.537987,Time used 0.005970s\n",
      "batch 1685, train_loss 79.465218,Time used 0.004998s\n",
      "batch 1686, train_loss 88.958641,Time used 0.005000s\n",
      "batch 1687, train_loss 84.717934,Time used 0.005000s\n",
      "batch 1688, train_loss 81.293839,Time used 0.004997s\n",
      "batch 1689, train_loss 73.262177,Time used 0.005000s\n",
      "batch 1690, train_loss 84.355087,Time used 0.005001s\n",
      "batch 1691, train_loss 71.054916,Time used 0.005006s\n",
      "batch 1692, train_loss 71.908455,Time used 0.004999s\n",
      "batch 1693, train_loss 67.780968,Time used 0.004997s\n",
      "batch 1694, train_loss 71.953033,Time used 0.005001s\n",
      "batch 1695, train_loss 90.485764,Time used 0.003999s\n",
      "batch 1696, train_loss 72.522354,Time used 0.003999s\n",
      "batch 1697, train_loss 108.502441,Time used 0.006004s\n",
      "batch 1698, train_loss 70.264740,Time used 0.004997s\n",
      "batch 1699, train_loss 66.475159,Time used 0.005001s\n",
      "batch 1700, train_loss 103.940155,Time used 0.004997s\n",
      "***************************test_batch 1700, test_rmse_loss 10.379334,test_mae_loss 4.218171,test_mape_loss 65.973847,Time used 0.020038s\n",
      "batch 1701, train_loss 60.568916,Time used 0.006963s\n",
      "batch 1702, train_loss 100.486115,Time used 0.006038s\n",
      "batch 1703, train_loss 103.246910,Time used 0.004999s\n",
      "batch 1704, train_loss 88.668144,Time used 0.005965s\n",
      "batch 1705, train_loss 93.565887,Time used 0.007999s\n",
      "batch 1706, train_loss 96.527885,Time used 0.004998s\n",
      "batch 1707, train_loss 72.496811,Time used 0.005000s\n",
      "batch 1708, train_loss 81.352776,Time used 0.008004s\n",
      "batch 1709, train_loss 73.545280,Time used 0.007034s\n",
      "batch 1710, train_loss 99.985321,Time used 0.004961s\n",
      "batch 1711, train_loss 107.015862,Time used 0.004998s\n",
      "batch 1712, train_loss 113.305748,Time used 0.006001s\n",
      "batch 1713, train_loss 91.793739,Time used 0.008000s\n",
      "batch 1714, train_loss 65.511322,Time used 0.007000s\n",
      "batch 1715, train_loss 67.526169,Time used 0.006999s\n",
      "batch 1716, train_loss 73.018669,Time used 0.007005s\n",
      "batch 1717, train_loss 76.478416,Time used 0.007001s\n",
      "batch 1718, train_loss 107.857086,Time used 0.005001s\n",
      "batch 1719, train_loss 76.135681,Time used 0.007030s\n",
      "batch 1720, train_loss 68.653885,Time used 0.004001s\n",
      "batch 1721, train_loss 70.123581,Time used 0.004997s\n",
      "batch 1722, train_loss 78.257561,Time used 0.004999s\n",
      "batch 1723, train_loss 70.445808,Time used 0.005964s\n",
      "batch 1724, train_loss 58.857738,Time used 0.004000s\n",
      "batch 1725, train_loss 78.486740,Time used 0.005004s\n",
      "batch 1726, train_loss 80.919701,Time used 0.005996s\n",
      "batch 1727, train_loss 85.726189,Time used 0.005000s\n",
      "batch 1728, train_loss 85.725807,Time used 0.004000s\n",
      "batch 1729, train_loss 82.220657,Time used 0.004996s\n",
      "batch 1730, train_loss 88.514389,Time used 0.005000s\n",
      "batch 1731, train_loss 91.556366,Time used 0.005002s\n",
      "batch 1732, train_loss 67.216919,Time used 0.004999s\n",
      "batch 1733, train_loss 71.736961,Time used 0.005001s\n",
      "batch 1734, train_loss 74.461792,Time used 0.006003s\n",
      "batch 1735, train_loss 83.994896,Time used 0.004995s\n",
      "batch 1736, train_loss 89.799522,Time used 0.004986s\n",
      "batch 1737, train_loss 104.472282,Time used 0.004962s\n",
      "batch 1738, train_loss 63.503033,Time used 0.005000s\n",
      "batch 1739, train_loss 73.729179,Time used 0.005000s\n",
      "batch 1740, train_loss 61.453068,Time used 0.006003s\n",
      "batch 1741, train_loss 86.413643,Time used 0.006001s\n",
      "batch 1742, train_loss 73.271004,Time used 0.005001s\n",
      "batch 1743, train_loss 75.468018,Time used 0.004998s\n",
      "batch 1744, train_loss 74.955338,Time used 0.005000s\n",
      "batch 1745, train_loss 89.925514,Time used 0.005001s\n",
      "batch 1746, train_loss 72.435623,Time used 0.005996s\n",
      "batch 1747, train_loss 90.253723,Time used 0.005039s\n",
      "batch 1748, train_loss 72.499741,Time used 0.004994s\n",
      "batch 1749, train_loss 87.455345,Time used 0.006968s\n",
      "batch 1750, train_loss 81.887016,Time used 0.004998s\n",
      "batch 1751, train_loss 91.404839,Time used 0.004001s\n",
      "batch 1752, train_loss 99.382805,Time used 0.006003s\n",
      "batch 1753, train_loss 79.590088,Time used 0.004999s\n",
      "batch 1754, train_loss 71.085510,Time used 0.006002s\n",
      "batch 1755, train_loss 68.268692,Time used 0.007998s\n",
      "batch 1756, train_loss 100.541061,Time used 0.005004s\n",
      "batch 1757, train_loss 67.599068,Time used 0.006000s\n",
      "batch 1758, train_loss 67.532692,Time used 0.004999s\n",
      "batch 1759, train_loss 80.494827,Time used 0.005036s\n",
      "batch 1760, train_loss 68.301689,Time used 0.004999s\n",
      "batch 1761, train_loss 98.341354,Time used 0.005004s\n",
      "batch 1762, train_loss 83.967148,Time used 0.003959s\n",
      "batch 1763, train_loss 91.386833,Time used 0.005019s\n",
      "batch 1764, train_loss 83.091568,Time used 0.004981s\n",
      "batch 1765, train_loss 91.064690,Time used 0.004999s\n",
      "batch 1766, train_loss 59.971661,Time used 0.006004s\n",
      "batch 1767, train_loss 76.405495,Time used 0.004999s\n",
      "batch 1768, train_loss 91.875893,Time used 0.005034s\n",
      "batch 1769, train_loss 84.580635,Time used 0.004003s\n",
      "batch 1770, train_loss 74.515335,Time used 0.004998s\n",
      "batch 1771, train_loss 80.564041,Time used 0.004998s\n",
      "batch 1772, train_loss 61.201183,Time used 0.005965s\n",
      "batch 1773, train_loss 90.919250,Time used 0.006000s\n",
      "batch 1774, train_loss 83.203247,Time used 0.005999s\n",
      "batch 1775, train_loss 83.993721,Time used 0.007001s\n",
      "batch 1776, train_loss 84.639481,Time used 0.008003s\n",
      "batch 1777, train_loss 98.628769,Time used 0.006000s\n",
      "batch 1778, train_loss 103.373497,Time used 0.007035s\n",
      "batch 1779, train_loss 58.804962,Time used 0.006992s\n",
      "batch 1780, train_loss 76.764381,Time used 0.007002s\n",
      "batch 1781, train_loss 74.286964,Time used 0.009000s\n",
      "batch 1782, train_loss 77.775223,Time used 0.006001s\n",
      "batch 1783, train_loss 66.276482,Time used 0.005001s\n",
      "batch 1784, train_loss 100.378578,Time used 0.004998s\n",
      "batch 1785, train_loss 80.201721,Time used 0.005000s\n",
      "batch 1786, train_loss 86.333710,Time used 0.005000s\n",
      "batch 1787, train_loss 77.118835,Time used 0.007000s\n",
      "batch 1788, train_loss 93.249550,Time used 0.004000s\n",
      "batch 1789, train_loss 76.486420,Time used 0.005001s\n",
      "batch 1790, train_loss 71.171150,Time used 0.004999s\n",
      "batch 1791, train_loss 88.447968,Time used 0.005002s\n",
      "batch 1792, train_loss 77.859993,Time used 0.005004s\n",
      "batch 1793, train_loss 98.952202,Time used 0.006030s\n",
      "batch 1794, train_loss 76.251549,Time used 0.006997s\n",
      "batch 1795, train_loss 78.760689,Time used 0.006964s\n",
      "batch 1796, train_loss 65.297287,Time used 0.005002s\n",
      "batch 1797, train_loss 45.382526,Time used 0.005000s\n",
      "batch 1798, train_loss 78.474335,Time used 0.006011s\n",
      "batch 1799, train_loss 65.826363,Time used 0.007990s\n",
      "batch 1800, train_loss 84.585213,Time used 0.007001s\n",
      "***************************test_batch 1800, test_rmse_loss 10.111739,test_mae_loss 4.144661,test_mape_loss 65.351220,Time used 0.017994s\n",
      "batch 1801, train_loss 74.867340,Time used 0.007998s\n",
      "batch 1802, train_loss 92.593040,Time used 0.005005s\n",
      "batch 1803, train_loss 69.441322,Time used 0.004997s\n",
      "batch 1804, train_loss 83.943405,Time used 0.005998s\n",
      "batch 1805, train_loss 70.035912,Time used 0.005000s\n",
      "batch 1806, train_loss 91.534180,Time used 0.005001s\n",
      "batch 1807, train_loss 77.440269,Time used 0.005001s\n",
      "batch 1808, train_loss 78.792992,Time used 0.004999s\n",
      "batch 1809, train_loss 80.770363,Time used 0.007004s\n",
      "batch 1810, train_loss 80.035248,Time used 0.006034s\n",
      "batch 1811, train_loss 82.895721,Time used 0.004964s\n",
      "batch 1812, train_loss 78.538712,Time used 0.008022s\n",
      "batch 1813, train_loss 79.152412,Time used 0.005977s\n",
      "batch 1814, train_loss 66.609100,Time used 0.005035s\n",
      "batch 1815, train_loss 85.470001,Time used 0.003995s\n",
      "batch 1816, train_loss 75.298439,Time used 0.005966s\n",
      "batch 1817, train_loss 80.015984,Time used 0.006034s\n",
      "batch 1818, train_loss 94.345245,Time used 0.004001s\n",
      "batch 1819, train_loss 81.959625,Time used 0.005000s\n",
      "batch 1820, train_loss 66.492500,Time used 0.004968s\n",
      "batch 1821, train_loss 73.817902,Time used 0.004999s\n",
      "batch 1822, train_loss 91.138069,Time used 0.005000s\n",
      "batch 1823, train_loss 47.751297,Time used 0.005000s\n",
      "batch 1824, train_loss 75.367493,Time used 0.005000s\n",
      "batch 1825, train_loss 77.772408,Time used 0.006997s\n",
      "batch 1826, train_loss 62.872959,Time used 0.004002s\n",
      "batch 1827, train_loss 75.413734,Time used 0.005001s\n",
      "batch 1828, train_loss 87.340218,Time used 0.006037s\n",
      "batch 1829, train_loss 80.905289,Time used 0.004992s\n",
      "batch 1830, train_loss 76.176819,Time used 0.004001s\n",
      "batch 1831, train_loss 75.539970,Time used 0.004996s\n",
      "batch 1832, train_loss 61.139645,Time used 0.007004s\n",
      "batch 1833, train_loss 80.855774,Time used 0.004001s\n",
      "batch 1834, train_loss 87.297142,Time used 0.006999s\n",
      "batch 1835, train_loss 71.578880,Time used 0.005000s\n",
      "batch 1836, train_loss 85.519524,Time used 0.005000s\n",
      "batch 1837, train_loss 77.087250,Time used 0.004999s\n",
      "batch 1838, train_loss 60.175552,Time used 0.005000s\n",
      "batch 1839, train_loss 81.907639,Time used 0.004000s\n",
      "batch 1840, train_loss 93.054283,Time used 0.006003s\n",
      "batch 1841, train_loss 84.901466,Time used 0.004000s\n",
      "batch 1842, train_loss 82.176994,Time used 0.004001s\n",
      "batch 1843, train_loss 69.531921,Time used 0.005000s\n",
      "batch 1844, train_loss 73.134186,Time used 0.004998s\n",
      "batch 1845, train_loss 79.207535,Time used 0.004999s\n",
      "batch 1846, train_loss 70.642319,Time used 0.006004s\n",
      "batch 1847, train_loss 89.118614,Time used 0.006998s\n",
      "batch 1848, train_loss 72.496498,Time used 0.004999s\n",
      "batch 1849, train_loss 83.650200,Time used 0.004997s\n",
      "batch 1850, train_loss 81.159241,Time used 0.005000s\n",
      "batch 1851, train_loss 77.169067,Time used 0.007039s\n",
      "batch 1852, train_loss 79.426567,Time used 0.004966s\n",
      "batch 1853, train_loss 80.051651,Time used 0.004964s\n",
      "batch 1854, train_loss 91.000191,Time used 0.003999s\n",
      "batch 1855, train_loss 68.372307,Time used 0.004000s\n",
      "batch 1856, train_loss 60.160103,Time used 0.005001s\n",
      "batch 1857, train_loss 77.883934,Time used 0.004040s\n",
      "batch 1858, train_loss 60.178905,Time used 0.004994s\n",
      "batch 1859, train_loss 65.782494,Time used 0.004971s\n",
      "batch 1860, train_loss 66.408478,Time used 0.005009s\n",
      "batch 1861, train_loss 88.259331,Time used 0.004987s\n",
      "batch 1862, train_loss 77.315590,Time used 0.005033s\n",
      "batch 1863, train_loss 80.229797,Time used 0.004998s\n",
      "batch 1864, train_loss 81.299561,Time used 0.005009s\n",
      "batch 1865, train_loss 82.467903,Time used 0.004998s\n",
      "batch 1866, train_loss 75.496323,Time used 0.004969s\n",
      "batch 1867, train_loss 71.129097,Time used 0.007993s\n",
      "batch 1868, train_loss 83.858559,Time used 0.007001s\n",
      "batch 1869, train_loss 73.994484,Time used 0.005004s\n",
      "batch 1870, train_loss 79.237511,Time used 0.006032s\n",
      "batch 1871, train_loss 72.883995,Time used 0.007966s\n",
      "batch 1872, train_loss 78.675102,Time used 0.006002s\n",
      "batch 1873, train_loss 70.000816,Time used 0.004999s\n",
      "batch 1874, train_loss 70.581573,Time used 0.004999s\n",
      "batch 1875, train_loss 76.433136,Time used 0.006001s\n",
      "batch 1876, train_loss 91.449333,Time used 0.004002s\n",
      "batch 1877, train_loss 63.713028,Time used 0.004997s\n",
      "batch 1878, train_loss 80.346008,Time used 0.006000s\n",
      "batch 1879, train_loss 96.395813,Time used 0.005000s\n",
      "batch 1880, train_loss 84.656540,Time used 0.006001s\n",
      "batch 1881, train_loss 82.073792,Time used 0.006003s\n",
      "batch 1882, train_loss 80.093185,Time used 0.006001s\n",
      "batch 1883, train_loss 80.995941,Time used 0.006998s\n",
      "batch 1884, train_loss 97.208664,Time used 0.005000s\n",
      "batch 1885, train_loss 70.525421,Time used 0.007002s\n",
      "batch 1886, train_loss 63.037224,Time used 0.005033s\n",
      "batch 1887, train_loss 84.411171,Time used 0.004967s\n",
      "batch 1888, train_loss 64.740356,Time used 0.006032s\n",
      "batch 1889, train_loss 92.117592,Time used 0.004997s\n",
      "batch 1890, train_loss 55.187775,Time used 0.005002s\n",
      "batch 1891, train_loss 57.878075,Time used 0.005964s\n",
      "batch 1892, train_loss 68.900742,Time used 0.007034s\n",
      "batch 1893, train_loss 84.101692,Time used 0.005000s\n",
      "batch 1894, train_loss 68.664467,Time used 0.004997s\n",
      "batch 1895, train_loss 64.816231,Time used 0.005034s\n",
      "batch 1896, train_loss 67.798203,Time used 0.004003s\n",
      "batch 1897, train_loss 76.491089,Time used 0.004966s\n",
      "batch 1898, train_loss 69.080505,Time used 0.004032s\n",
      "batch 1899, train_loss 79.742470,Time used 0.004963s\n",
      "batch 1900, train_loss 61.643246,Time used 0.004998s\n",
      "***************************test_batch 1900, test_rmse_loss 9.865351,test_mae_loss 4.077129,test_mape_loss 64.974676,Time used 0.019000s\n",
      "batch 1901, train_loss 83.254578,Time used 0.007006s\n",
      "batch 1902, train_loss 64.822754,Time used 0.003963s\n",
      "batch 1903, train_loss 72.696106,Time used 0.003966s\n",
      "batch 1904, train_loss 76.371674,Time used 0.004964s\n",
      "batch 1905, train_loss 79.989601,Time used 0.006003s\n",
      "batch 1906, train_loss 90.647202,Time used 0.004998s\n",
      "batch 1907, train_loss 72.069824,Time used 0.006000s\n",
      "batch 1908, train_loss 80.563011,Time used 0.005000s\n",
      "batch 1909, train_loss 81.735283,Time used 0.006035s\n",
      "batch 1910, train_loss 72.742317,Time used 0.005965s\n",
      "batch 1911, train_loss 71.777237,Time used 0.005002s\n",
      "batch 1912, train_loss 78.307610,Time used 0.005998s\n",
      "batch 1913, train_loss 66.324074,Time used 0.006002s\n",
      "batch 1914, train_loss 86.710892,Time used 0.005002s\n",
      "batch 1915, train_loss 58.396877,Time used 0.006025s\n",
      "batch 1916, train_loss 68.033714,Time used 0.007996s\n",
      "batch 1917, train_loss 81.874634,Time used 0.005999s\n",
      "batch 1918, train_loss 67.874939,Time used 0.004001s\n",
      "batch 1919, train_loss 68.522934,Time used 0.005001s\n",
      "batch 1920, train_loss 88.957825,Time used 0.006999s\n",
      "batch 1921, train_loss 78.909279,Time used 0.005001s\n",
      "batch 1922, train_loss 73.333473,Time used 0.005001s\n",
      "batch 1923, train_loss 66.174622,Time used 0.004999s\n",
      "batch 1924, train_loss 66.822182,Time used 0.007998s\n",
      "batch 1925, train_loss 73.380180,Time used 0.008000s\n",
      "batch 1926, train_loss 78.716095,Time used 0.008002s\n",
      "batch 1927, train_loss 76.391167,Time used 0.007998s\n",
      "batch 1928, train_loss 78.819466,Time used 0.006001s\n",
      "batch 1929, train_loss 76.725479,Time used 0.005999s\n",
      "batch 1930, train_loss 73.421074,Time used 0.007013s\n",
      "batch 1931, train_loss 81.607574,Time used 0.007999s\n",
      "batch 1932, train_loss 62.970699,Time used 0.007001s\n",
      "batch 1933, train_loss 66.061081,Time used 0.005000s\n",
      "batch 1934, train_loss 77.116959,Time used 0.004999s\n",
      "batch 1935, train_loss 82.000793,Time used 0.005003s\n",
      "batch 1936, train_loss 87.324821,Time used 0.007998s\n",
      "batch 1937, train_loss 45.964638,Time used 0.007002s\n",
      "batch 1938, train_loss 75.292450,Time used 0.004997s\n",
      "batch 1939, train_loss 72.182770,Time used 0.004000s\n",
      "batch 1940, train_loss 79.537926,Time used 0.005000s\n",
      "batch 1941, train_loss 75.995453,Time used 0.004999s\n",
      "batch 1942, train_loss 74.530640,Time used 0.005002s\n",
      "batch 1943, train_loss 66.393311,Time used 0.006002s\n",
      "batch 1944, train_loss 92.138809,Time used 0.007996s\n",
      "batch 1945, train_loss 72.317101,Time used 0.005001s\n",
      "batch 1946, train_loss 60.560017,Time used 0.006001s\n",
      "batch 1947, train_loss 77.735214,Time used 0.007000s\n",
      "batch 1948, train_loss 90.915787,Time used 0.005000s\n",
      "batch 1949, train_loss 86.482872,Time used 0.005996s\n",
      "batch 1950, train_loss 79.916595,Time used 0.005041s\n",
      "batch 1951, train_loss 75.507019,Time used 0.004995s\n",
      "batch 1952, train_loss 63.987495,Time used 0.006002s\n",
      "batch 1953, train_loss 72.700066,Time used 0.006967s\n",
      "batch 1954, train_loss 84.232475,Time used 0.007035s\n",
      "batch 1955, train_loss 71.270599,Time used 0.005962s\n",
      "batch 1956, train_loss 104.638092,Time used 0.005003s\n",
      "batch 1957, train_loss 67.585030,Time used 0.004001s\n",
      "batch 1958, train_loss 71.064171,Time used 0.007999s\n",
      "batch 1959, train_loss 64.495041,Time used 0.006998s\n",
      "batch 1960, train_loss 70.133125,Time used 0.006004s\n",
      "batch 1961, train_loss 71.856293,Time used 0.006001s\n",
      "batch 1962, train_loss 59.801792,Time used 0.004999s\n",
      "batch 1963, train_loss 81.494888,Time used 0.004999s\n",
      "batch 1964, train_loss 59.807217,Time used 0.005002s\n",
      "batch 1965, train_loss 76.394745,Time used 0.005996s\n",
      "batch 1966, train_loss 71.112312,Time used 0.007999s\n",
      "batch 1967, train_loss 76.593796,Time used 0.008001s\n",
      "batch 1968, train_loss 53.540062,Time used 0.006001s\n",
      "batch 1969, train_loss 76.185822,Time used 0.005000s\n",
      "batch 1970, train_loss 70.034676,Time used 0.005020s\n",
      "batch 1971, train_loss 72.049065,Time used 0.005978s\n",
      "batch 1972, train_loss 78.863121,Time used 0.006001s\n",
      "batch 1973, train_loss 79.991486,Time used 0.006020s\n",
      "batch 1974, train_loss 81.348091,Time used 0.006999s\n",
      "batch 1975, train_loss 77.692291,Time used 0.005000s\n",
      "batch 1976, train_loss 60.095100,Time used 0.005998s\n",
      "batch 1977, train_loss 85.630081,Time used 0.005003s\n",
      "batch 1978, train_loss 48.368141,Time used 0.004999s\n",
      "batch 1979, train_loss 79.782295,Time used 0.005001s\n",
      "batch 1980, train_loss 77.051109,Time used 0.005998s\n",
      "batch 1981, train_loss 69.201889,Time used 0.005003s\n",
      "batch 1982, train_loss 61.224449,Time used 0.003998s\n",
      "batch 1983, train_loss 78.570374,Time used 0.005002s\n",
      "batch 1984, train_loss 65.402832,Time used 0.004998s\n",
      "batch 1985, train_loss 76.724365,Time used 0.005000s\n",
      "batch 1986, train_loss 83.263641,Time used 0.005996s\n",
      "batch 1987, train_loss 84.947121,Time used 0.005000s\n",
      "batch 1988, train_loss 72.012657,Time used 0.005000s\n",
      "batch 1989, train_loss 64.266876,Time used 0.005000s\n",
      "batch 1990, train_loss 71.375259,Time used 0.005002s\n",
      "batch 1991, train_loss 59.752968,Time used 0.005998s\n",
      "batch 1992, train_loss 74.239082,Time used 0.005005s\n",
      "batch 1993, train_loss 63.620247,Time used 0.007000s\n",
      "batch 1994, train_loss 71.987892,Time used 0.008002s\n",
      "batch 1995, train_loss 75.364265,Time used 0.007001s\n",
      "batch 1996, train_loss 64.688187,Time used 0.003994s\n",
      "batch 1997, train_loss 61.580914,Time used 0.004001s\n",
      "batch 1998, train_loss 68.296432,Time used 0.005003s\n",
      "batch 1999, train_loss 69.702797,Time used 0.005000s\n",
      "batch 2000, train_loss 80.293175,Time used 0.005000s\n",
      "***************************test_batch 2000, test_rmse_loss 9.709427,test_mae_loss 4.030285,test_mape_loss 63.920896,Time used 0.017998s\n",
      "batch 2001, train_loss 94.360901,Time used 0.005002s\n",
      "batch 2002, train_loss 67.872078,Time used 0.007000s\n",
      "batch 2003, train_loss 55.424969,Time used 0.004999s\n",
      "batch 2004, train_loss 79.047142,Time used 0.006997s\n",
      "batch 2005, train_loss 73.143158,Time used 0.007003s\n",
      "batch 2006, train_loss 63.229568,Time used 0.005003s\n",
      "batch 2007, train_loss 88.172546,Time used 0.005003s\n",
      "batch 2008, train_loss 73.363518,Time used 0.004999s\n",
      "batch 2009, train_loss 72.308861,Time used 0.005014s\n",
      "batch 2010, train_loss 73.515511,Time used 0.003988s\n",
      "batch 2011, train_loss 72.050056,Time used 0.004999s\n",
      "batch 2012, train_loss 72.147392,Time used 0.004998s\n",
      "batch 2013, train_loss 70.054482,Time used 0.004999s\n",
      "batch 2014, train_loss 73.559181,Time used 0.005000s\n",
      "batch 2015, train_loss 69.429832,Time used 0.005003s\n",
      "batch 2016, train_loss 81.267403,Time used 0.007001s\n",
      "batch 2017, train_loss 62.675343,Time used 0.007003s\n",
      "batch 2018, train_loss 64.728119,Time used 0.005996s\n",
      "batch 2019, train_loss 75.558357,Time used 0.008004s\n",
      "batch 2020, train_loss 71.079201,Time used 0.005028s\n",
      "batch 2021, train_loss 76.810417,Time used 0.005001s\n",
      "batch 2022, train_loss 66.662773,Time used 0.004970s\n",
      "batch 2023, train_loss 77.112854,Time used 0.005028s\n",
      "batch 2024, train_loss 55.842213,Time used 0.005969s\n",
      "batch 2025, train_loss 64.139977,Time used 0.004998s\n",
      "batch 2026, train_loss 82.864746,Time used 0.005000s\n",
      "batch 2027, train_loss 79.875488,Time used 0.005001s\n",
      "batch 2028, train_loss 65.895645,Time used 0.005003s\n",
      "batch 2029, train_loss 74.000671,Time used 0.005002s\n",
      "batch 2030, train_loss 74.861771,Time used 0.004962s\n",
      "batch 2031, train_loss 71.433632,Time used 0.004998s\n",
      "batch 2032, train_loss 78.840530,Time used 0.005001s\n",
      "batch 2033, train_loss 61.159950,Time used 0.006004s\n",
      "batch 2034, train_loss 69.871284,Time used 0.004998s\n",
      "batch 2035, train_loss 69.539024,Time used 0.005000s\n",
      "batch 2036, train_loss 79.858330,Time used 0.007038s\n",
      "batch 2037, train_loss 67.299423,Time used 0.004995s\n",
      "batch 2038, train_loss 91.962990,Time used 0.005000s\n",
      "batch 2039, train_loss 53.861259,Time used 0.005967s\n",
      "batch 2040, train_loss 83.653198,Time used 0.007996s\n",
      "batch 2041, train_loss 63.081459,Time used 0.005001s\n",
      "batch 2042, train_loss 64.324966,Time used 0.004000s\n",
      "batch 2043, train_loss 69.967590,Time used 0.007032s\n",
      "batch 2044, train_loss 67.555298,Time used 0.006999s\n",
      "batch 2045, train_loss 74.158813,Time used 0.005001s\n",
      "batch 2046, train_loss 69.606834,Time used 0.005001s\n",
      "batch 2047, train_loss 71.800446,Time used 0.004002s\n",
      "batch 2048, train_loss 64.806587,Time used 0.004997s\n",
      "batch 2049, train_loss 81.101227,Time used 0.004969s\n",
      "batch 2050, train_loss 54.436504,Time used 0.004996s\n",
      "batch 2051, train_loss 63.309841,Time used 0.004000s\n",
      "batch 2052, train_loss 100.754219,Time used 0.008036s\n",
      "batch 2053, train_loss 79.225761,Time used 0.005005s\n",
      "batch 2054, train_loss 65.026634,Time used 0.004997s\n",
      "batch 2055, train_loss 72.181862,Time used 0.004998s\n",
      "batch 2056, train_loss 58.443176,Time used 0.003967s\n",
      "batch 2057, train_loss 76.342064,Time used 0.005996s\n",
      "batch 2058, train_loss 73.812714,Time used 0.007001s\n",
      "batch 2059, train_loss 64.864334,Time used 0.004001s\n",
      "batch 2060, train_loss 68.482742,Time used 0.007000s\n",
      "batch 2061, train_loss 73.360176,Time used 0.005001s\n",
      "batch 2062, train_loss 92.922203,Time used 0.005031s\n",
      "batch 2063, train_loss 76.945374,Time used 0.004998s\n",
      "batch 2064, train_loss 57.930286,Time used 0.005002s\n",
      "batch 2065, train_loss 80.141937,Time used 0.004000s\n",
      "batch 2066, train_loss 91.014877,Time used 0.003999s\n",
      "batch 2067, train_loss 66.897804,Time used 0.005002s\n",
      "batch 2068, train_loss 65.505112,Time used 0.007999s\n",
      "batch 2069, train_loss 62.727291,Time used 0.009001s\n",
      "batch 2070, train_loss 63.044952,Time used 0.005003s\n",
      "batch 2071, train_loss 72.514381,Time used 0.007996s\n",
      "batch 2072, train_loss 81.881752,Time used 0.006000s\n",
      "batch 2073, train_loss 55.884308,Time used 0.005001s\n",
      "batch 2074, train_loss 82.281990,Time used 0.006004s\n",
      "batch 2075, train_loss 53.677334,Time used 0.004995s\n",
      "batch 2076, train_loss 70.007004,Time used 0.005003s\n",
      "batch 2077, train_loss 74.081505,Time used 0.005999s\n",
      "batch 2078, train_loss 69.839935,Time used 0.005033s\n",
      "batch 2079, train_loss 64.058289,Time used 0.004000s\n",
      "batch 2080, train_loss 77.409294,Time used 0.003990s\n",
      "batch 2081, train_loss 68.798882,Time used 0.007001s\n",
      "batch 2082, train_loss 55.984905,Time used 0.005002s\n",
      "batch 2083, train_loss 78.201912,Time used 0.006996s\n",
      "batch 2084, train_loss 69.645126,Time used 0.005014s\n",
      "batch 2085, train_loss 64.051926,Time used 0.004987s\n",
      "batch 2086, train_loss 77.437935,Time used 0.005999s\n",
      "batch 2087, train_loss 75.369545,Time used 0.008036s\n",
      "batch 2088, train_loss 72.147354,Time used 0.004966s\n",
      "batch 2089, train_loss 71.736229,Time used 0.005000s\n",
      "batch 2090, train_loss 67.734238,Time used 0.006000s\n",
      "batch 2091, train_loss 49.937897,Time used 0.006002s\n",
      "batch 2092, train_loss 67.455078,Time used 0.004998s\n",
      "batch 2093, train_loss 62.288696,Time used 0.007999s\n",
      "batch 2094, train_loss 57.246696,Time used 0.005001s\n",
      "batch 2095, train_loss 73.528534,Time used 0.005004s\n",
      "batch 2096, train_loss 67.366302,Time used 0.006998s\n",
      "batch 2097, train_loss 80.474068,Time used 0.005000s\n",
      "batch 2098, train_loss 83.006447,Time used 0.007031s\n",
      "batch 2099, train_loss 67.897957,Time used 0.005032s\n",
      "batch 2100, train_loss 66.855629,Time used 0.004968s\n",
      "***************************test_batch 2100, test_rmse_loss 9.511828,test_mae_loss 3.980262,test_mape_loss 64.155622,Time used 0.017000s\n",
      "batch 2101, train_loss 74.610825,Time used 0.005003s\n",
      "batch 2102, train_loss 71.060951,Time used 0.004998s\n",
      "batch 2103, train_loss 86.507431,Time used 0.004999s\n",
      "batch 2104, train_loss 70.225525,Time used 0.003998s\n",
      "batch 2105, train_loss 78.699303,Time used 0.007000s\n",
      "batch 2106, train_loss 76.159584,Time used 0.005004s\n",
      "batch 2107, train_loss 63.307812,Time used 0.005999s\n",
      "batch 2108, train_loss 73.092575,Time used 0.005001s\n",
      "batch 2109, train_loss 53.261478,Time used 0.004996s\n",
      "batch 2110, train_loss 73.517372,Time used 0.003998s\n",
      "batch 2111, train_loss 64.212364,Time used 0.006000s\n",
      "batch 2112, train_loss 80.692154,Time used 0.006000s\n",
      "batch 2113, train_loss 73.977768,Time used 0.006004s\n",
      "batch 2114, train_loss 70.357887,Time used 0.005033s\n",
      "batch 2115, train_loss 57.126141,Time used 0.005001s\n",
      "batch 2116, train_loss 73.544083,Time used 0.003963s\n",
      "batch 2117, train_loss 67.359879,Time used 0.005002s\n",
      "batch 2118, train_loss 63.521767,Time used 0.005001s\n",
      "batch 2119, train_loss 70.093575,Time used 0.005002s\n",
      "batch 2120, train_loss 47.800621,Time used 0.004996s\n",
      "batch 2121, train_loss 71.781815,Time used 0.004001s\n",
      "batch 2122, train_loss 54.482815,Time used 0.005998s\n",
      "batch 2123, train_loss 71.869690,Time used 0.004998s\n",
      "batch 2124, train_loss 81.476959,Time used 0.005002s\n",
      "batch 2125, train_loss 74.728973,Time used 0.006007s\n",
      "batch 2126, train_loss 63.690811,Time used 0.005030s\n",
      "batch 2127, train_loss 79.115585,Time used 0.005000s\n",
      "batch 2128, train_loss 63.357143,Time used 0.005965s\n",
      "batch 2129, train_loss 76.257652,Time used 0.004998s\n",
      "batch 2130, train_loss 75.853348,Time used 0.005000s\n",
      "batch 2131, train_loss 75.571381,Time used 0.006040s\n",
      "batch 2132, train_loss 54.341175,Time used 0.006964s\n",
      "batch 2133, train_loss 81.792938,Time used 0.008004s\n",
      "batch 2134, train_loss 66.488197,Time used 0.007026s\n",
      "batch 2135, train_loss 84.329231,Time used 0.006968s\n",
      "batch 2136, train_loss 67.756798,Time used 0.005999s\n",
      "batch 2137, train_loss 79.364471,Time used 0.005997s\n",
      "batch 2138, train_loss 73.449326,Time used 0.005000s\n",
      "batch 2139, train_loss 73.165474,Time used 0.005000s\n",
      "batch 2140, train_loss 67.665672,Time used 0.005033s\n",
      "batch 2141, train_loss 83.499794,Time used 0.004967s\n",
      "batch 2142, train_loss 70.012184,Time used 0.006001s\n",
      "batch 2143, train_loss 63.743469,Time used 0.008000s\n",
      "batch 2144, train_loss 70.432526,Time used 0.006003s\n",
      "batch 2145, train_loss 72.475876,Time used 0.004998s\n",
      "batch 2146, train_loss 75.828354,Time used 0.004999s\n",
      "batch 2147, train_loss 67.344124,Time used 0.005001s\n",
      "batch 2148, train_loss 51.329796,Time used 0.005998s\n",
      "batch 2149, train_loss 58.837715,Time used 0.006001s\n",
      "batch 2150, train_loss 81.526543,Time used 0.006001s\n",
      "batch 2151, train_loss 69.143646,Time used 0.005002s\n",
      "batch 2152, train_loss 64.112633,Time used 0.006997s\n",
      "batch 2153, train_loss 78.084694,Time used 0.005002s\n",
      "batch 2154, train_loss 71.064041,Time used 0.004998s\n",
      "batch 2155, train_loss 74.902130,Time used 0.006015s\n",
      "batch 2156, train_loss 59.739594,Time used 0.004987s\n",
      "batch 2157, train_loss 62.192257,Time used 0.004998s\n",
      "batch 2158, train_loss 54.652843,Time used 0.005000s\n",
      "batch 2159, train_loss 78.354118,Time used 0.006001s\n",
      "batch 2160, train_loss 54.624741,Time used 0.005002s\n",
      "batch 2161, train_loss 60.882107,Time used 0.004999s\n",
      "batch 2162, train_loss 82.904144,Time used 0.003999s\n",
      "batch 2163, train_loss 63.906208,Time used 0.006999s\n",
      "batch 2164, train_loss 90.789581,Time used 0.007999s\n",
      "batch 2165, train_loss 71.322792,Time used 0.007001s\n",
      "batch 2166, train_loss 73.936829,Time used 0.005999s\n",
      "batch 2167, train_loss 66.155891,Time used 0.005003s\n",
      "batch 2168, train_loss 52.152096,Time used 0.006998s\n",
      "batch 2169, train_loss 62.511490,Time used 0.004999s\n",
      "batch 2170, train_loss 46.614738,Time used 0.004002s\n",
      "batch 2171, train_loss 74.224869,Time used 0.005000s\n",
      "batch 2172, train_loss 63.139553,Time used 0.004997s\n",
      "batch 2173, train_loss 83.953400,Time used 0.008004s\n",
      "batch 2174, train_loss 76.628372,Time used 0.004997s\n",
      "batch 2175, train_loss 63.742146,Time used 0.005000s\n",
      "batch 2176, train_loss 72.308052,Time used 0.006001s\n",
      "batch 2177, train_loss 61.794979,Time used 0.006999s\n",
      "batch 2178, train_loss 69.063599,Time used 0.004004s\n",
      "batch 2179, train_loss 69.049919,Time used 0.005007s\n",
      "batch 2180, train_loss 74.500320,Time used 0.006029s\n",
      "batch 2181, train_loss 62.746620,Time used 0.004967s\n",
      "batch 2182, train_loss 63.761749,Time used 0.004999s\n",
      "batch 2183, train_loss 66.796791,Time used 0.004999s\n",
      "batch 2184, train_loss 71.319679,Time used 0.004000s\n",
      "batch 2185, train_loss 63.839443,Time used 0.007000s\n",
      "batch 2186, train_loss 77.820587,Time used 0.004997s\n",
      "batch 2187, train_loss 66.766891,Time used 0.005002s\n",
      "batch 2188, train_loss 76.864243,Time used 0.004999s\n",
      "batch 2189, train_loss 83.932060,Time used 0.005999s\n",
      "batch 2190, train_loss 74.701981,Time used 0.005002s\n",
      "batch 2191, train_loss 73.103554,Time used 0.004999s\n",
      "batch 2192, train_loss 62.592800,Time used 0.004999s\n",
      "batch 2193, train_loss 61.408821,Time used 0.005004s\n",
      "batch 2194, train_loss 69.246834,Time used 0.004000s\n",
      "batch 2195, train_loss 74.701042,Time used 0.004999s\n",
      "batch 2196, train_loss 60.457989,Time used 0.005000s\n",
      "batch 2197, train_loss 63.265068,Time used 0.004999s\n",
      "batch 2198, train_loss 58.267773,Time used 0.006002s\n",
      "batch 2199, train_loss 55.905910,Time used 0.005001s\n",
      "batch 2200, train_loss 71.419846,Time used 0.007000s\n",
      "***************************test_batch 2200, test_rmse_loss 9.392377,test_mae_loss 3.947300,test_mape_loss 63.524685,Time used 0.016998s\n",
      "batch 2201, train_loss 65.589066,Time used 0.008001s\n",
      "batch 2202, train_loss 67.810997,Time used 0.005999s\n",
      "batch 2203, train_loss 77.477776,Time used 0.004998s\n",
      "batch 2204, train_loss 68.958061,Time used 0.005001s\n",
      "batch 2205, train_loss 60.773750,Time used 0.005000s\n",
      "batch 2206, train_loss 57.861645,Time used 0.006002s\n",
      "batch 2207, train_loss 74.801018,Time used 0.005000s\n",
      "batch 2208, train_loss 64.693115,Time used 0.006002s\n",
      "batch 2209, train_loss 78.498230,Time used 0.004999s\n",
      "batch 2210, train_loss 61.381081,Time used 0.005998s\n",
      "batch 2211, train_loss 65.357384,Time used 0.004999s\n",
      "batch 2212, train_loss 70.980042,Time used 0.003999s\n",
      "batch 2213, train_loss 54.157875,Time used 0.005002s\n",
      "batch 2214, train_loss 88.765282,Time used 0.006000s\n",
      "batch 2215, train_loss 60.143574,Time used 0.005001s\n",
      "batch 2216, train_loss 70.841385,Time used 0.006999s\n",
      "batch 2217, train_loss 63.591331,Time used 0.005001s\n",
      "batch 2218, train_loss 69.686295,Time used 0.007001s\n",
      "batch 2219, train_loss 84.502846,Time used 0.003999s\n",
      "batch 2220, train_loss 72.927971,Time used 0.005002s\n",
      "batch 2221, train_loss 55.113056,Time used 0.005000s\n",
      "batch 2222, train_loss 60.113869,Time used 0.005000s\n",
      "batch 2223, train_loss 63.600563,Time used 0.004996s\n",
      "batch 2224, train_loss 62.152161,Time used 0.005002s\n",
      "batch 2225, train_loss 63.723206,Time used 0.005000s\n",
      "batch 2226, train_loss 77.443787,Time used 0.005001s\n",
      "batch 2227, train_loss 61.999016,Time used 0.004999s\n",
      "batch 2228, train_loss 71.975967,Time used 0.008000s\n",
      "batch 2229, train_loss 67.597992,Time used 0.005999s\n",
      "batch 2230, train_loss 71.093231,Time used 0.006001s\n",
      "batch 2231, train_loss 64.198013,Time used 0.005998s\n",
      "batch 2232, train_loss 62.467648,Time used 0.005002s\n",
      "batch 2233, train_loss 64.163567,Time used 0.006996s\n",
      "batch 2234, train_loss 70.540100,Time used 0.005998s\n",
      "batch 2235, train_loss 71.988289,Time used 0.005000s\n",
      "batch 2236, train_loss 50.285378,Time used 0.004001s\n",
      "batch 2237, train_loss 63.251560,Time used 0.005002s\n",
      "batch 2238, train_loss 62.708954,Time used 0.004999s\n",
      "batch 2239, train_loss 77.983170,Time used 0.005001s\n",
      "batch 2240, train_loss 77.599403,Time used 0.006001s\n",
      "batch 2241, train_loss 83.373856,Time used 0.005000s\n",
      "batch 2242, train_loss 63.966270,Time used 0.004999s\n",
      "batch 2243, train_loss 64.361427,Time used 0.008000s\n",
      "batch 2244, train_loss 64.226013,Time used 0.006959s\n",
      "batch 2245, train_loss 66.417770,Time used 0.005997s\n",
      "batch 2246, train_loss 69.005386,Time used 0.006999s\n",
      "batch 2247, train_loss 73.516808,Time used 0.005006s\n",
      "batch 2248, train_loss 89.387650,Time used 0.004033s\n",
      "batch 2249, train_loss 77.016251,Time used 0.005000s\n",
      "batch 2250, train_loss 60.956894,Time used 0.004964s\n",
      "batch 2251, train_loss 59.011566,Time used 0.004000s\n",
      "batch 2252, train_loss 56.202320,Time used 0.005000s\n",
      "batch 2253, train_loss 60.533283,Time used 0.006005s\n",
      "batch 2254, train_loss 74.144188,Time used 0.008000s\n",
      "batch 2255, train_loss 60.897030,Time used 0.007998s\n",
      "batch 2256, train_loss 50.763161,Time used 0.009000s\n",
      "batch 2257, train_loss 63.931236,Time used 0.006997s\n",
      "batch 2258, train_loss 64.041466,Time used 0.004988s\n",
      "batch 2259, train_loss 77.654846,Time used 0.006001s\n",
      "batch 2260, train_loss 56.189384,Time used 0.006000s\n",
      "batch 2261, train_loss 68.755150,Time used 0.006000s\n",
      "batch 2262, train_loss 69.335648,Time used 0.004999s\n",
      "batch 2263, train_loss 68.856369,Time used 0.005000s\n",
      "batch 2264, train_loss 65.255310,Time used 0.008037s\n",
      "batch 2265, train_loss 67.972282,Time used 0.005996s\n",
      "batch 2266, train_loss 72.578697,Time used 0.005966s\n",
      "batch 2267, train_loss 70.104416,Time used 0.004998s\n",
      "batch 2268, train_loss 70.003067,Time used 0.006999s\n",
      "batch 2269, train_loss 69.472404,Time used 0.004997s\n",
      "batch 2270, train_loss 63.521469,Time used 0.005002s\n",
      "batch 2271, train_loss 63.144936,Time used 0.007000s\n",
      "batch 2272, train_loss 68.118988,Time used 0.005994s\n",
      "batch 2273, train_loss 71.005371,Time used 0.004000s\n",
      "batch 2274, train_loss 50.770077,Time used 0.007004s\n",
      "batch 2275, train_loss 73.219322,Time used 0.005001s\n",
      "batch 2276, train_loss 67.483360,Time used 0.004998s\n",
      "batch 2277, train_loss 62.986866,Time used 0.006004s\n",
      "batch 2278, train_loss 57.103344,Time used 0.004996s\n",
      "batch 2279, train_loss 72.907608,Time used 0.005009s\n",
      "batch 2280, train_loss 68.174576,Time used 0.004991s\n",
      "batch 2281, train_loss 62.933926,Time used 0.004998s\n",
      "batch 2282, train_loss 50.496811,Time used 0.008002s\n",
      "batch 2283, train_loss 60.194077,Time used 0.008023s\n",
      "batch 2284, train_loss 67.544365,Time used 0.007034s\n",
      "batch 2285, train_loss 53.002304,Time used 0.004965s\n",
      "batch 2286, train_loss 84.946518,Time used 0.004965s\n",
      "batch 2287, train_loss 72.089722,Time used 0.003998s\n",
      "batch 2288, train_loss 55.794907,Time used 0.006001s\n",
      "batch 2289, train_loss 64.643623,Time used 0.008039s\n",
      "batch 2290, train_loss 65.716568,Time used 0.004994s\n",
      "batch 2291, train_loss 81.135155,Time used 0.004970s\n",
      "batch 2292, train_loss 71.351028,Time used 0.007000s\n",
      "batch 2293, train_loss 62.559402,Time used 0.005001s\n",
      "batch 2294, train_loss 70.386894,Time used 0.007032s\n",
      "batch 2295, train_loss 61.194611,Time used 0.006001s\n",
      "batch 2296, train_loss 73.274551,Time used 0.005000s\n",
      "batch 2297, train_loss 63.550201,Time used 0.004969s\n",
      "batch 2298, train_loss 56.983917,Time used 0.005036s\n",
      "batch 2299, train_loss 79.040802,Time used 0.003999s\n",
      "batch 2300, train_loss 61.364777,Time used 0.006963s\n",
      "***************************test_batch 2300, test_rmse_loss 9.264419,test_mae_loss 3.916685,test_mape_loss 63.241786,Time used 0.027006s\n",
      "batch 2301, train_loss 64.094376,Time used 0.006995s\n",
      "batch 2302, train_loss 64.542908,Time used 0.005000s\n",
      "batch 2303, train_loss 73.540504,Time used 0.005000s\n",
      "batch 2304, train_loss 72.898933,Time used 0.004999s\n",
      "batch 2305, train_loss 71.145569,Time used 0.006000s\n",
      "batch 2306, train_loss 75.215828,Time used 0.006000s\n",
      "batch 2307, train_loss 65.767242,Time used 0.004963s\n",
      "batch 2308, train_loss 80.326668,Time used 0.005996s\n",
      "batch 2309, train_loss 70.391098,Time used 0.006002s\n",
      "batch 2310, train_loss 65.905556,Time used 0.006000s\n",
      "batch 2311, train_loss 55.302059,Time used 0.006001s\n",
      "batch 2312, train_loss 86.103004,Time used 0.005000s\n",
      "batch 2313, train_loss 62.803890,Time used 0.005034s\n",
      "batch 2314, train_loss 74.023460,Time used 0.005007s\n",
      "batch 2315, train_loss 57.290699,Time used 0.003996s\n",
      "batch 2316, train_loss 59.245323,Time used 0.005962s\n",
      "batch 2317, train_loss 58.322433,Time used 0.005000s\n",
      "batch 2318, train_loss 46.673367,Time used 0.004000s\n",
      "batch 2319, train_loss 58.181564,Time used 0.006998s\n",
      "batch 2320, train_loss 56.183262,Time used 0.006999s\n",
      "batch 2321, train_loss 69.394440,Time used 0.006005s\n",
      "batch 2322, train_loss 54.580322,Time used 0.005000s\n",
      "batch 2323, train_loss 60.463108,Time used 0.005000s\n",
      "batch 2324, train_loss 65.522003,Time used 0.005001s\n",
      "batch 2325, train_loss 78.847191,Time used 0.005035s\n",
      "batch 2326, train_loss 70.879669,Time used 0.004999s\n",
      "batch 2327, train_loss 77.895111,Time used 0.004965s\n",
      "batch 2328, train_loss 63.136303,Time used 0.004997s\n",
      "batch 2329, train_loss 65.059494,Time used 0.006001s\n",
      "batch 2330, train_loss 67.114510,Time used 0.005999s\n",
      "batch 2331, train_loss 64.008293,Time used 0.006998s\n",
      "batch 2332, train_loss 64.712845,Time used 0.006035s\n",
      "batch 2333, train_loss 61.617592,Time used 0.007967s\n",
      "batch 2334, train_loss 73.042206,Time used 0.006036s\n",
      "batch 2335, train_loss 50.048950,Time used 0.004966s\n",
      "batch 2336, train_loss 70.624687,Time used 0.005028s\n",
      "batch 2337, train_loss 65.730133,Time used 0.005972s\n",
      "batch 2338, train_loss 56.689594,Time used 0.005998s\n",
      "batch 2339, train_loss 70.589172,Time used 0.005003s\n",
      "batch 2340, train_loss 59.213799,Time used 0.005027s\n",
      "batch 2341, train_loss 72.270264,Time used 0.004972s\n",
      "batch 2342, train_loss 61.059063,Time used 0.005033s\n",
      "batch 2343, train_loss 65.680763,Time used 0.004966s\n",
      "batch 2344, train_loss 69.365112,Time used 0.005033s\n",
      "batch 2345, train_loss 59.115532,Time used 0.004965s\n",
      "batch 2346, train_loss 79.912994,Time used 0.005033s\n",
      "batch 2347, train_loss 71.705208,Time used 0.005000s\n",
      "batch 2348, train_loss 62.543591,Time used 0.004964s\n",
      "batch 2349, train_loss 59.277721,Time used 0.005000s\n",
      "batch 2350, train_loss 72.360542,Time used 0.005043s\n",
      "batch 2351, train_loss 68.486603,Time used 0.004994s\n",
      "batch 2352, train_loss 64.796043,Time used 0.004963s\n",
      "batch 2353, train_loss 62.347515,Time used 0.005011s\n",
      "batch 2354, train_loss 63.152248,Time used 0.004992s\n",
      "batch 2355, train_loss 87.754715,Time used 0.005000s\n",
      "batch 2356, train_loss 72.180435,Time used 0.005002s\n",
      "batch 2357, train_loss 62.577213,Time used 0.005029s\n",
      "batch 2358, train_loss 66.740311,Time used 0.004968s\n",
      "batch 2359, train_loss 70.092415,Time used 0.004978s\n",
      "batch 2360, train_loss 73.775444,Time used 0.006036s\n",
      "batch 2361, train_loss 67.909302,Time used 0.004972s\n",
      "batch 2362, train_loss 60.520134,Time used 0.005990s\n",
      "batch 2363, train_loss 53.445515,Time used 0.006998s\n",
      "batch 2364, train_loss 66.025703,Time used 0.005999s\n",
      "batch 2365, train_loss 66.013519,Time used 0.005038s\n",
      "batch 2366, train_loss 64.293198,Time used 0.004002s\n",
      "batch 2367, train_loss 62.658501,Time used 0.004995s\n",
      "batch 2368, train_loss 65.448006,Time used 0.006970s\n",
      "batch 2369, train_loss 64.657845,Time used 0.004998s\n",
      "batch 2370, train_loss 62.342766,Time used 0.005002s\n",
      "batch 2371, train_loss 59.044193,Time used 0.007002s\n",
      "batch 2372, train_loss 71.401146,Time used 0.008026s\n",
      "batch 2373, train_loss 66.195778,Time used 0.008003s\n",
      "batch 2374, train_loss 54.174694,Time used 0.005001s\n",
      "batch 2375, train_loss 63.384781,Time used 0.003968s\n",
      "batch 2376, train_loss 60.511017,Time used 0.006033s\n",
      "batch 2377, train_loss 56.241734,Time used 0.003947s\n",
      "batch 2378, train_loss 57.836678,Time used 0.005001s\n",
      "batch 2379, train_loss 68.252090,Time used 0.005000s\n",
      "batch 2380, train_loss 68.588074,Time used 0.004000s\n",
      "batch 2381, train_loss 67.426414,Time used 0.006000s\n",
      "batch 2382, train_loss 63.036308,Time used 0.007002s\n",
      "batch 2383, train_loss 79.029953,Time used 0.006032s\n",
      "batch 2384, train_loss 74.014175,Time used 0.004971s\n",
      "batch 2385, train_loss 65.988670,Time used 0.005026s\n",
      "batch 2386, train_loss 72.899391,Time used 0.005969s\n",
      "batch 2387, train_loss 63.725212,Time used 0.005001s\n",
      "batch 2388, train_loss 67.757652,Time used 0.004035s\n",
      "batch 2389, train_loss 54.495892,Time used 0.006000s\n",
      "batch 2390, train_loss 59.637539,Time used 0.005001s\n",
      "batch 2391, train_loss 78.974266,Time used 0.004994s\n",
      "batch 2392, train_loss 59.754475,Time used 0.004972s\n",
      "batch 2393, train_loss 67.278595,Time used 0.006001s\n",
      "batch 2394, train_loss 68.745605,Time used 0.007019s\n",
      "batch 2395, train_loss 62.380390,Time used 0.005978s\n",
      "batch 2396, train_loss 50.493660,Time used 0.004000s\n",
      "batch 2397, train_loss 67.849991,Time used 0.005000s\n",
      "batch 2398, train_loss 54.868732,Time used 0.005039s\n",
      "batch 2399, train_loss 55.266731,Time used 0.004998s\n",
      "batch 2400, train_loss 75.901299,Time used 0.005002s\n",
      "***************************test_batch 2400, test_rmse_loss 9.169792,test_mae_loss 3.892653,test_mape_loss 63.087688,Time used 0.022962s\n",
      "batch 2401, train_loss 72.815727,Time used 0.005000s\n",
      "batch 2402, train_loss 62.946548,Time used 0.005002s\n",
      "batch 2403, train_loss 62.904709,Time used 0.006999s\n",
      "batch 2404, train_loss 84.426506,Time used 0.007000s\n",
      "batch 2405, train_loss 59.836250,Time used 0.004999s\n",
      "batch 2406, train_loss 73.776176,Time used 0.004999s\n",
      "batch 2407, train_loss 69.339050,Time used 0.005040s\n",
      "batch 2408, train_loss 58.987873,Time used 0.003997s\n",
      "batch 2409, train_loss 51.752510,Time used 0.004964s\n",
      "batch 2410, train_loss 66.588814,Time used 0.005037s\n",
      "batch 2411, train_loss 58.144409,Time used 0.005002s\n",
      "batch 2412, train_loss 59.656059,Time used 0.004996s\n",
      "batch 2413, train_loss 59.192394,Time used 0.005966s\n",
      "batch 2414, train_loss 46.428581,Time used 0.009002s\n",
      "batch 2415, train_loss 77.704018,Time used 0.006996s\n",
      "batch 2416, train_loss 52.226532,Time used 0.005000s\n",
      "batch 2417, train_loss 80.195358,Time used 0.004000s\n",
      "batch 2418, train_loss 58.202881,Time used 0.005029s\n",
      "batch 2419, train_loss 63.868484,Time used 0.006009s\n",
      "batch 2420, train_loss 72.492104,Time used 0.004962s\n",
      "batch 2421, train_loss 72.142738,Time used 0.007002s\n",
      "batch 2422, train_loss 65.210762,Time used 0.007001s\n",
      "batch 2423, train_loss 57.256458,Time used 0.005998s\n",
      "batch 2424, train_loss 67.347290,Time used 0.003999s\n",
      "batch 2425, train_loss 56.166752,Time used 0.005999s\n",
      "batch 2426, train_loss 59.924526,Time used 0.007035s\n",
      "batch 2427, train_loss 62.513103,Time used 0.003997s\n",
      "batch 2428, train_loss 66.974129,Time used 0.005968s\n",
      "batch 2429, train_loss 63.703159,Time used 0.006999s\n",
      "batch 2430, train_loss 52.998436,Time used 0.004998s\n",
      "batch 2431, train_loss 58.565895,Time used 0.004998s\n",
      "batch 2432, train_loss 65.514671,Time used 0.005000s\n",
      "batch 2433, train_loss 83.827454,Time used 0.005000s\n",
      "batch 2434, train_loss 70.732704,Time used 0.006005s\n",
      "batch 2435, train_loss 54.000618,Time used 0.005000s\n",
      "batch 2436, train_loss 78.861526,Time used 0.005001s\n",
      "batch 2437, train_loss 52.793587,Time used 0.006000s\n",
      "batch 2438, train_loss 52.548298,Time used 0.008034s\n",
      "batch 2439, train_loss 68.640869,Time used 0.007961s\n",
      "batch 2440, train_loss 50.540764,Time used 0.007001s\n",
      "batch 2441, train_loss 67.298958,Time used 0.006043s\n",
      "batch 2442, train_loss 72.232521,Time used 0.004989s\n",
      "batch 2443, train_loss 66.680763,Time used 0.005000s\n",
      "batch 2444, train_loss 74.557571,Time used 0.004961s\n",
      "batch 2445, train_loss 58.043919,Time used 0.006001s\n",
      "batch 2446, train_loss 72.871407,Time used 0.004999s\n",
      "batch 2447, train_loss 70.075142,Time used 0.007002s\n",
      "batch 2448, train_loss 64.349747,Time used 0.005001s\n",
      "batch 2449, train_loss 51.445942,Time used 0.004998s\n",
      "batch 2450, train_loss 62.859032,Time used 0.006000s\n",
      "batch 2451, train_loss 55.448051,Time used 0.006002s\n",
      "batch 2452, train_loss 78.796013,Time used 0.006000s\n",
      "batch 2453, train_loss 53.291306,Time used 0.008000s\n",
      "batch 2454, train_loss 86.623466,Time used 0.005004s\n",
      "batch 2455, train_loss 67.085220,Time used 0.005000s\n",
      "batch 2456, train_loss 86.842201,Time used 0.006037s\n",
      "batch 2457, train_loss 51.653561,Time used 0.005001s\n",
      "batch 2458, train_loss 58.366806,Time used 0.004958s\n",
      "batch 2459, train_loss 60.480289,Time used 0.007005s\n",
      "batch 2460, train_loss 46.504978,Time used 0.005999s\n",
      "batch 2461, train_loss 70.560768,Time used 0.005998s\n",
      "batch 2462, train_loss 69.755882,Time used 0.007000s\n",
      "batch 2463, train_loss 64.521736,Time used 0.008008s\n",
      "batch 2464, train_loss 75.434341,Time used 0.004996s\n",
      "batch 2465, train_loss 48.584240,Time used 0.007998s\n",
      "batch 2466, train_loss 50.706612,Time used 0.006000s\n",
      "batch 2467, train_loss 57.148632,Time used 0.004995s\n",
      "batch 2468, train_loss 62.779987,Time used 0.006969s\n",
      "batch 2469, train_loss 61.686161,Time used 0.006005s\n",
      "batch 2470, train_loss 81.973358,Time used 0.007999s\n",
      "batch 2471, train_loss 65.490005,Time used 0.006000s\n",
      "batch 2472, train_loss 68.812706,Time used 0.004999s\n",
      "batch 2473, train_loss 62.431423,Time used 0.004997s\n",
      "batch 2474, train_loss 64.921059,Time used 0.006997s\n",
      "batch 2475, train_loss 66.612015,Time used 0.008001s\n",
      "batch 2476, train_loss 54.365135,Time used 0.005039s\n",
      "batch 2477, train_loss 56.743427,Time used 0.005967s\n",
      "batch 2478, train_loss 74.583160,Time used 0.004994s\n",
      "batch 2479, train_loss 63.419613,Time used 0.006002s\n",
      "batch 2480, train_loss 59.120430,Time used 0.005997s\n",
      "batch 2481, train_loss 71.125389,Time used 0.008001s\n",
      "batch 2482, train_loss 62.082310,Time used 0.007999s\n",
      "batch 2483, train_loss 70.605453,Time used 0.004999s\n",
      "batch 2484, train_loss 90.582565,Time used 0.008043s\n",
      "batch 2485, train_loss 50.616570,Time used 0.007963s\n",
      "batch 2486, train_loss 64.926956,Time used 0.007998s\n",
      "batch 2487, train_loss 68.597809,Time used 0.007999s\n",
      "batch 2488, train_loss 67.906235,Time used 0.007007s\n",
      "batch 2489, train_loss 59.252289,Time used 0.007996s\n",
      "batch 2490, train_loss 58.404083,Time used 0.004997s\n",
      "batch 2491, train_loss 55.923313,Time used 0.004992s\n",
      "batch 2492, train_loss 66.406242,Time used 0.006999s\n",
      "batch 2493, train_loss 59.271404,Time used 0.005005s\n",
      "batch 2494, train_loss 49.729465,Time used 0.005027s\n",
      "batch 2495, train_loss 69.619431,Time used 0.005999s\n",
      "batch 2496, train_loss 62.833328,Time used 0.006001s\n",
      "batch 2497, train_loss 56.423771,Time used 0.006997s\n",
      "batch 2498, train_loss 57.210106,Time used 0.006001s\n",
      "batch 2499, train_loss 60.060764,Time used 0.004999s\n",
      "batch 2500, train_loss 54.048012,Time used 0.006003s\n",
      "***************************test_batch 2500, test_rmse_loss 9.126427,test_mae_loss 3.879272,test_mape_loss 61.965347,Time used 0.029000s\n",
      "batch 2501, train_loss 59.500835,Time used 0.007000s\n",
      "batch 2502, train_loss 63.985760,Time used 0.005997s\n",
      "batch 2503, train_loss 60.750492,Time used 0.005000s\n",
      "batch 2504, train_loss 65.755585,Time used 0.005004s\n",
      "batch 2505, train_loss 74.518112,Time used 0.006000s\n",
      "batch 2506, train_loss 75.204308,Time used 0.004996s\n",
      "batch 2507, train_loss 55.597012,Time used 0.005999s\n",
      "batch 2508, train_loss 80.171471,Time used 0.007003s\n",
      "batch 2509, train_loss 77.252693,Time used 0.005002s\n",
      "batch 2510, train_loss 51.318455,Time used 0.005998s\n",
      "batch 2511, train_loss 60.141739,Time used 0.004999s\n",
      "batch 2512, train_loss 54.986607,Time used 0.007036s\n",
      "batch 2513, train_loss 67.548447,Time used 0.005001s\n",
      "batch 2514, train_loss 65.287987,Time used 0.005005s\n",
      "batch 2515, train_loss 54.896778,Time used 0.005993s\n",
      "batch 2516, train_loss 65.024864,Time used 0.008003s\n",
      "batch 2517, train_loss 63.122986,Time used 0.007019s\n",
      "batch 2518, train_loss 64.702545,Time used 0.005979s\n",
      "batch 2519, train_loss 67.309319,Time used 0.006000s\n",
      "batch 2520, train_loss 69.939400,Time used 0.005002s\n",
      "batch 2521, train_loss 58.813240,Time used 0.004995s\n",
      "batch 2522, train_loss 74.133141,Time used 0.006002s\n",
      "batch 2523, train_loss 64.968178,Time used 0.004998s\n",
      "batch 2524, train_loss 64.511208,Time used 0.005000s\n",
      "batch 2525, train_loss 67.237015,Time used 0.003999s\n",
      "batch 2526, train_loss 65.722023,Time used 0.007000s\n",
      "batch 2527, train_loss 59.347813,Time used 0.004004s\n",
      "batch 2528, train_loss 57.413609,Time used 0.005002s\n",
      "batch 2529, train_loss 54.635349,Time used 0.005033s\n",
      "batch 2530, train_loss 63.237621,Time used 0.004965s\n",
      "batch 2531, train_loss 59.657921,Time used 0.005036s\n",
      "batch 2532, train_loss 66.657700,Time used 0.005964s\n",
      "batch 2533, train_loss 63.024254,Time used 0.007003s\n",
      "batch 2534, train_loss 65.584404,Time used 0.005996s\n",
      "batch 2535, train_loss 57.301399,Time used 0.006003s\n",
      "batch 2536, train_loss 86.103745,Time used 0.005000s\n",
      "batch 2537, train_loss 53.924534,Time used 0.004997s\n",
      "batch 2538, train_loss 63.381756,Time used 0.004999s\n",
      "batch 2539, train_loss 64.783249,Time used 0.005002s\n",
      "batch 2540, train_loss 53.541782,Time used 0.010006s\n",
      "batch 2541, train_loss 71.490730,Time used 0.005002s\n",
      "batch 2542, train_loss 58.941341,Time used 0.006994s\n",
      "batch 2543, train_loss 64.808144,Time used 0.005001s\n",
      "batch 2544, train_loss 57.815048,Time used 0.005026s\n",
      "batch 2545, train_loss 75.695114,Time used 0.004996s\n",
      "batch 2546, train_loss 65.521004,Time used 0.006035s\n",
      "batch 2547, train_loss 68.514343,Time used 0.004969s\n",
      "batch 2548, train_loss 61.651218,Time used 0.004997s\n",
      "batch 2549, train_loss 59.167385,Time used 0.004999s\n",
      "batch 2550, train_loss 55.723328,Time used 0.004999s\n",
      "batch 2551, train_loss 73.591057,Time used 0.005000s\n",
      "batch 2552, train_loss 70.830704,Time used 0.006007s\n",
      "batch 2553, train_loss 61.465401,Time used 0.004997s\n",
      "batch 2554, train_loss 67.008659,Time used 0.005000s\n",
      "batch 2555, train_loss 59.373138,Time used 0.004999s\n",
      "batch 2556, train_loss 57.678734,Time used 0.005001s\n",
      "batch 2557, train_loss 67.583702,Time used 0.005000s\n",
      "batch 2558, train_loss 58.088627,Time used 0.005000s\n",
      "batch 2559, train_loss 53.327156,Time used 0.005995s\n",
      "batch 2560, train_loss 64.349510,Time used 0.004000s\n",
      "batch 2561, train_loss 66.152916,Time used 0.005000s\n",
      "batch 2562, train_loss 50.662193,Time used 0.005004s\n",
      "batch 2563, train_loss 52.011574,Time used 0.004000s\n",
      "batch 2564, train_loss 70.211281,Time used 0.005000s\n",
      "batch 2565, train_loss 66.760635,Time used 0.005000s\n",
      "batch 2566, train_loss 61.540314,Time used 0.006029s\n",
      "batch 2567, train_loss 65.565735,Time used 0.004973s\n",
      "batch 2568, train_loss 58.537964,Time used 0.006996s\n",
      "batch 2569, train_loss 69.847160,Time used 0.008964s\n",
      "batch 2570, train_loss 63.731411,Time used 0.007032s\n",
      "batch 2571, train_loss 61.547699,Time used 0.006967s\n",
      "batch 2572, train_loss 53.572048,Time used 0.007048s\n",
      "batch 2573, train_loss 76.884010,Time used 0.006951s\n",
      "batch 2574, train_loss 63.221718,Time used 0.005036s\n",
      "batch 2575, train_loss 57.095989,Time used 0.004000s\n",
      "batch 2576, train_loss 68.950554,Time used 0.006001s\n",
      "batch 2577, train_loss 64.934616,Time used 0.003996s\n",
      "batch 2578, train_loss 71.589272,Time used 0.005001s\n",
      "batch 2579, train_loss 51.547039,Time used 0.004970s\n",
      "batch 2580, train_loss 64.294495,Time used 0.005000s\n",
      "batch 2581, train_loss 50.307278,Time used 0.005000s\n",
      "batch 2582, train_loss 53.487659,Time used 0.005030s\n",
      "batch 2583, train_loss 62.708210,Time used 0.004971s\n",
      "batch 2584, train_loss 61.161900,Time used 0.005028s\n",
      "batch 2585, train_loss 53.281208,Time used 0.005971s\n",
      "batch 2586, train_loss 56.081669,Time used 0.007000s\n",
      "batch 2587, train_loss 63.047165,Time used 0.007000s\n",
      "batch 2588, train_loss 63.558270,Time used 0.005037s\n",
      "batch 2589, train_loss 68.778259,Time used 0.003997s\n",
      "batch 2590, train_loss 74.914291,Time used 0.005000s\n",
      "batch 2591, train_loss 71.696198,Time used 0.004970s\n",
      "batch 2592, train_loss 57.928497,Time used 0.005030s\n",
      "batch 2593, train_loss 60.482044,Time used 0.005000s\n",
      "batch 2594, train_loss 60.243664,Time used 0.005000s\n",
      "batch 2595, train_loss 74.126541,Time used 0.005000s\n",
      "batch 2596, train_loss 49.316345,Time used 0.005001s\n",
      "batch 2597, train_loss 53.581268,Time used 0.004999s\n",
      "batch 2598, train_loss 68.383545,Time used 0.005000s\n",
      "batch 2599, train_loss 60.585304,Time used 0.004002s\n",
      "batch 2600, train_loss 66.732002,Time used 0.005999s\n",
      "***************************test_batch 2600, test_rmse_loss 9.050093,test_mae_loss 3.862151,test_mape_loss 61.851539,Time used 0.019037s\n",
      "batch 2601, train_loss 64.235161,Time used 0.005999s\n",
      "batch 2602, train_loss 84.172600,Time used 0.005964s\n",
      "batch 2603, train_loss 52.950405,Time used 0.006004s\n",
      "batch 2604, train_loss 67.256783,Time used 0.005000s\n",
      "batch 2605, train_loss 72.776947,Time used 0.006998s\n",
      "batch 2606, train_loss 56.344139,Time used 0.007998s\n",
      "batch 2607, train_loss 65.598732,Time used 0.008000s\n",
      "batch 2608, train_loss 46.486286,Time used 0.005036s\n",
      "batch 2609, train_loss 72.301033,Time used 0.005000s\n",
      "batch 2610, train_loss 59.103004,Time used 0.005002s\n",
      "batch 2611, train_loss 65.565109,Time used 0.005001s\n",
      "batch 2612, train_loss 57.751522,Time used 0.004999s\n",
      "batch 2613, train_loss 62.089851,Time used 0.004969s\n",
      "batch 2614, train_loss 75.902206,Time used 0.004998s\n",
      "batch 2615, train_loss 43.365696,Time used 0.005000s\n",
      "batch 2616, train_loss 57.658394,Time used 0.004000s\n",
      "batch 2617, train_loss 77.378868,Time used 0.005003s\n",
      "batch 2618, train_loss 54.860008,Time used 0.003991s\n",
      "batch 2619, train_loss 57.692322,Time used 0.006967s\n",
      "batch 2620, train_loss 50.733067,Time used 0.004998s\n",
      "batch 2621, train_loss 61.062557,Time used 0.005001s\n",
      "batch 2622, train_loss 45.039268,Time used 0.005037s\n",
      "batch 2623, train_loss 55.895523,Time used 0.004002s\n",
      "batch 2624, train_loss 64.106354,Time used 0.004000s\n",
      "batch 2625, train_loss 65.115982,Time used 0.006007s\n",
      "batch 2626, train_loss 64.032043,Time used 0.007035s\n",
      "batch 2627, train_loss 70.749512,Time used 0.004996s\n",
      "batch 2628, train_loss 68.315308,Time used 0.005005s\n",
      "batch 2629, train_loss 58.464996,Time used 0.005032s\n",
      "batch 2630, train_loss 56.785332,Time used 0.005000s\n",
      "batch 2631, train_loss 78.937454,Time used 0.005004s\n",
      "batch 2632, train_loss 56.282890,Time used 0.006000s\n",
      "batch 2633, train_loss 62.949795,Time used 0.004998s\n",
      "batch 2634, train_loss 60.273476,Time used 0.006998s\n",
      "batch 2635, train_loss 68.628395,Time used 0.004000s\n",
      "batch 2636, train_loss 61.523178,Time used 0.005004s\n",
      "batch 2637, train_loss 63.224674,Time used 0.005000s\n",
      "batch 2638, train_loss 67.012932,Time used 0.005000s\n",
      "batch 2639, train_loss 51.492325,Time used 0.005001s\n",
      "batch 2640, train_loss 71.764145,Time used 0.004001s\n",
      "batch 2641, train_loss 59.152790,Time used 0.005999s\n",
      "batch 2642, train_loss 71.189629,Time used 0.006998s\n",
      "batch 2643, train_loss 58.931717,Time used 0.005002s\n",
      "batch 2644, train_loss 58.166615,Time used 0.005000s\n",
      "batch 2645, train_loss 62.574123,Time used 0.005000s\n",
      "batch 2646, train_loss 59.075729,Time used 0.005000s\n",
      "batch 2647, train_loss 66.401642,Time used 0.004996s\n",
      "batch 2648, train_loss 66.018822,Time used 0.004999s\n",
      "batch 2649, train_loss 66.242043,Time used 0.005000s\n",
      "batch 2650, train_loss 58.501068,Time used 0.007003s\n",
      "batch 2651, train_loss 69.050812,Time used 0.005001s\n",
      "batch 2652, train_loss 62.178074,Time used 0.005000s\n",
      "batch 2653, train_loss 61.263443,Time used 0.004999s\n",
      "batch 2654, train_loss 65.499229,Time used 0.005000s\n",
      "batch 2655, train_loss 58.964466,Time used 0.005003s\n",
      "batch 2656, train_loss 56.311127,Time used 0.005034s\n",
      "batch 2657, train_loss 71.473839,Time used 0.004998s\n",
      "batch 2658, train_loss 59.034100,Time used 0.005000s\n",
      "batch 2659, train_loss 55.924881,Time used 0.006963s\n",
      "batch 2660, train_loss 77.337631,Time used 0.005003s\n",
      "batch 2661, train_loss 59.100506,Time used 0.006038s\n",
      "batch 2662, train_loss 51.764248,Time used 0.007960s\n",
      "batch 2663, train_loss 59.194603,Time used 0.006015s\n",
      "batch 2664, train_loss 52.994377,Time used 0.007986s\n",
      "batch 2665, train_loss 65.867882,Time used 0.006001s\n",
      "batch 2666, train_loss 74.354988,Time used 0.008001s\n",
      "batch 2667, train_loss 60.570869,Time used 0.007997s\n",
      "batch 2668, train_loss 46.529770,Time used 0.005000s\n",
      "batch 2669, train_loss 58.988163,Time used 0.005000s\n",
      "batch 2670, train_loss 59.137619,Time used 0.007003s\n",
      "batch 2671, train_loss 59.999969,Time used 0.008000s\n",
      "batch 2672, train_loss 82.776443,Time used 0.008035s\n",
      "batch 2673, train_loss 57.046936,Time used 0.004994s\n",
      "batch 2674, train_loss 51.018822,Time used 0.006970s\n",
      "batch 2675, train_loss 76.016846,Time used 0.005001s\n",
      "batch 2676, train_loss 54.706787,Time used 0.005001s\n",
      "batch 2677, train_loss 52.928638,Time used 0.006999s\n",
      "batch 2678, train_loss 58.709393,Time used 0.007999s\n",
      "batch 2679, train_loss 67.194084,Time used 0.007000s\n",
      "batch 2680, train_loss 69.371735,Time used 0.004999s\n",
      "batch 2681, train_loss 53.354465,Time used 0.005001s\n",
      "batch 2682, train_loss 64.488083,Time used 0.008001s\n",
      "batch 2683, train_loss 54.953972,Time used 0.006999s\n",
      "batch 2684, train_loss 62.453045,Time used 0.008000s\n",
      "batch 2685, train_loss 57.291370,Time used 0.004998s\n",
      "batch 2686, train_loss 55.793400,Time used 0.008000s\n",
      "batch 2687, train_loss 71.257576,Time used 0.008000s\n",
      "batch 2688, train_loss 66.160080,Time used 0.004002s\n",
      "batch 2689, train_loss 70.398186,Time used 0.007000s\n",
      "batch 2690, train_loss 62.445000,Time used 0.007008s\n",
      "batch 2691, train_loss 59.573086,Time used 0.007000s\n",
      "batch 2692, train_loss 62.158855,Time used 0.004999s\n",
      "batch 2693, train_loss 55.499859,Time used 0.004999s\n",
      "batch 2694, train_loss 55.878139,Time used 0.007001s\n",
      "batch 2695, train_loss 61.298332,Time used 0.005002s\n",
      "batch 2696, train_loss 57.481396,Time used 0.004998s\n",
      "batch 2697, train_loss 70.186485,Time used 0.004999s\n",
      "batch 2698, train_loss 55.404964,Time used 0.004999s\n",
      "batch 2699, train_loss 57.775391,Time used 0.003999s\n",
      "batch 2700, train_loss 59.723743,Time used 0.005998s\n",
      "***************************test_batch 2700, test_rmse_loss 8.962846,test_mae_loss 3.837847,test_mape_loss 61.941663,Time used 0.016003s\n",
      "batch 2701, train_loss 63.584480,Time used 0.004999s\n",
      "batch 2702, train_loss 52.445450,Time used 0.005002s\n",
      "batch 2703, train_loss 68.985603,Time used 0.005003s\n",
      "batch 2704, train_loss 68.605209,Time used 0.004998s\n",
      "batch 2705, train_loss 56.829464,Time used 0.005000s\n",
      "batch 2706, train_loss 57.475574,Time used 0.005000s\n",
      "batch 2707, train_loss 64.353554,Time used 0.005999s\n",
      "batch 2708, train_loss 64.125870,Time used 0.003997s\n",
      "batch 2709, train_loss 58.374485,Time used 0.003996s\n",
      "batch 2710, train_loss 75.960556,Time used 0.005001s\n",
      "batch 2711, train_loss 64.011497,Time used 0.005000s\n",
      "batch 2712, train_loss 52.225079,Time used 0.005002s\n",
      "batch 2713, train_loss 49.650955,Time used 0.004998s\n",
      "batch 2714, train_loss 62.392212,Time used 0.005001s\n",
      "batch 2715, train_loss 64.861420,Time used 0.004997s\n",
      "batch 2716, train_loss 67.382523,Time used 0.006001s\n",
      "batch 2717, train_loss 69.281425,Time used 0.004000s\n",
      "batch 2718, train_loss 55.438755,Time used 0.005999s\n",
      "batch 2719, train_loss 53.133595,Time used 0.004999s\n",
      "batch 2720, train_loss 55.496563,Time used 0.004001s\n",
      "batch 2721, train_loss 54.968861,Time used 0.006002s\n",
      "batch 2722, train_loss 61.167774,Time used 0.007002s\n",
      "batch 2723, train_loss 58.204090,Time used 0.006000s\n",
      "batch 2724, train_loss 69.206581,Time used 0.004000s\n",
      "batch 2725, train_loss 57.656456,Time used 0.003998s\n",
      "batch 2726, train_loss 63.453655,Time used 0.006004s\n",
      "batch 2727, train_loss 69.033028,Time used 0.007035s\n",
      "batch 2728, train_loss 54.204399,Time used 0.004996s\n",
      "batch 2729, train_loss 67.624016,Time used 0.008968s\n",
      "batch 2730, train_loss 58.126076,Time used 0.006031s\n",
      "batch 2731, train_loss 66.293007,Time used 0.005966s\n",
      "batch 2732, train_loss 79.655029,Time used 0.004000s\n",
      "batch 2733, train_loss 58.036274,Time used 0.005001s\n",
      "batch 2734, train_loss 69.728287,Time used 0.006038s\n",
      "batch 2735, train_loss 50.259235,Time used 0.004963s\n",
      "batch 2736, train_loss 55.361584,Time used 0.005004s\n",
      "batch 2737, train_loss 66.437080,Time used 0.004996s\n",
      "batch 2738, train_loss 62.229847,Time used 0.007037s\n",
      "batch 2739, train_loss 56.477779,Time used 0.005040s\n",
      "batch 2740, train_loss 49.332001,Time used 0.004959s\n",
      "batch 2741, train_loss 61.648010,Time used 0.005038s\n",
      "batch 2742, train_loss 61.278118,Time used 0.005965s\n",
      "batch 2743, train_loss 53.687737,Time used 0.005042s\n",
      "batch 2744, train_loss 66.197357,Time used 0.004992s\n",
      "batch 2745, train_loss 75.154648,Time used 0.006997s\n",
      "batch 2746, train_loss 62.280533,Time used 0.009002s\n",
      "batch 2747, train_loss 60.191460,Time used 0.007998s\n",
      "batch 2748, train_loss 77.861404,Time used 0.008002s\n",
      "batch 2749, train_loss 65.160667,Time used 0.004965s\n",
      "batch 2750, train_loss 62.254288,Time used 0.005000s\n",
      "batch 2751, train_loss 61.738487,Time used 0.005000s\n",
      "batch 2752, train_loss 59.084660,Time used 0.005035s\n",
      "batch 2753, train_loss 69.263596,Time used 0.007001s\n",
      "batch 2754, train_loss 57.522934,Time used 0.004999s\n",
      "batch 2755, train_loss 46.920311,Time used 0.005961s\n",
      "batch 2756, train_loss 52.273197,Time used 0.006001s\n",
      "batch 2757, train_loss 53.250317,Time used 0.006004s\n",
      "batch 2758, train_loss 59.046684,Time used 0.007997s\n",
      "batch 2759, train_loss 68.433601,Time used 0.007051s\n",
      "batch 2760, train_loss 57.528374,Time used 0.006963s\n",
      "batch 2761, train_loss 70.563980,Time used 0.005997s\n",
      "batch 2762, train_loss 60.455971,Time used 0.006001s\n",
      "batch 2763, train_loss 64.569618,Time used 0.005002s\n",
      "batch 2764, train_loss 42.588951,Time used 0.005036s\n",
      "batch 2765, train_loss 58.480465,Time used 0.005000s\n",
      "batch 2766, train_loss 46.166424,Time used 0.007966s\n",
      "batch 2767, train_loss 61.202000,Time used 0.007006s\n",
      "batch 2768, train_loss 69.304832,Time used 0.004962s\n",
      "batch 2769, train_loss 61.569767,Time used 0.004999s\n",
      "batch 2770, train_loss 54.608162,Time used 0.005000s\n",
      "batch 2771, train_loss 56.927189,Time used 0.005003s\n",
      "batch 2772, train_loss 81.141739,Time used 0.005000s\n",
      "batch 2773, train_loss 48.970058,Time used 0.005000s\n",
      "batch 2774, train_loss 71.162056,Time used 0.005037s\n",
      "batch 2775, train_loss 68.537437,Time used 0.005997s\n",
      "batch 2776, train_loss 65.882431,Time used 0.004977s\n",
      "batch 2777, train_loss 55.121014,Time used 0.007028s\n",
      "batch 2778, train_loss 59.721294,Time used 0.005995s\n",
      "batch 2779, train_loss 50.448505,Time used 0.004968s\n",
      "batch 2780, train_loss 47.573387,Time used 0.006033s\n",
      "batch 2781, train_loss 58.935966,Time used 0.005005s\n",
      "batch 2782, train_loss 65.127060,Time used 0.004965s\n",
      "batch 2783, train_loss 65.955788,Time used 0.008033s\n",
      "batch 2784, train_loss 76.730652,Time used 0.004997s\n",
      "batch 2785, train_loss 67.854095,Time used 0.004997s\n",
      "batch 2786, train_loss 59.387085,Time used 0.005000s\n",
      "batch 2787, train_loss 69.003204,Time used 0.006995s\n",
      "batch 2788, train_loss 72.291374,Time used 0.005000s\n",
      "batch 2789, train_loss 73.129608,Time used 0.005036s\n",
      "batch 2790, train_loss 54.308308,Time used 0.008002s\n",
      "batch 2791, train_loss 51.699566,Time used 0.007965s\n",
      "batch 2792, train_loss 67.470978,Time used 0.005001s\n",
      "batch 2793, train_loss 70.773422,Time used 0.003999s\n",
      "batch 2794, train_loss 66.883339,Time used 0.006034s\n",
      "batch 2795, train_loss 65.550415,Time used 0.004995s\n",
      "batch 2796, train_loss 52.086163,Time used 0.004999s\n",
      "batch 2797, train_loss 56.860970,Time used 0.005038s\n",
      "batch 2798, train_loss 58.945911,Time used 0.003968s\n",
      "batch 2799, train_loss 64.574196,Time used 0.005028s\n",
      "batch 2800, train_loss 57.192581,Time used 0.005006s\n",
      "***************************test_batch 2800, test_rmse_loss 8.910543,test_mae_loss 3.822950,test_mape_loss 61.759438,Time used 0.017964s\n",
      "batch 2801, train_loss 56.346909,Time used 0.005001s\n",
      "batch 2802, train_loss 53.725521,Time used 0.005000s\n",
      "batch 2803, train_loss 52.033016,Time used 0.005000s\n",
      "batch 2804, train_loss 55.096569,Time used 0.006000s\n",
      "batch 2805, train_loss 69.472099,Time used 0.006999s\n",
      "batch 2806, train_loss 51.093697,Time used 0.004997s\n",
      "batch 2807, train_loss 59.810181,Time used 0.005000s\n",
      "batch 2808, train_loss 50.764423,Time used 0.003999s\n",
      "batch 2809, train_loss 64.401917,Time used 0.006999s\n",
      "batch 2810, train_loss 67.250992,Time used 0.006999s\n",
      "batch 2811, train_loss 53.224804,Time used 0.006001s\n",
      "batch 2812, train_loss 66.848289,Time used 0.007003s\n",
      "batch 2813, train_loss 62.440960,Time used 0.004999s\n",
      "batch 2814, train_loss 53.967300,Time used 0.005000s\n",
      "batch 2815, train_loss 78.714020,Time used 0.006002s\n",
      "batch 2816, train_loss 64.277626,Time used 0.007000s\n",
      "batch 2817, train_loss 47.687355,Time used 0.007031s\n",
      "batch 2818, train_loss 62.434444,Time used 0.004970s\n",
      "batch 2819, train_loss 55.465153,Time used 0.005000s\n",
      "batch 2820, train_loss 60.358463,Time used 0.006996s\n",
      "batch 2821, train_loss 64.105377,Time used 0.005000s\n",
      "batch 2822, train_loss 67.822472,Time used 0.004001s\n",
      "batch 2823, train_loss 73.941040,Time used 0.006005s\n",
      "batch 2824, train_loss 53.833370,Time used 0.006995s\n",
      "batch 2825, train_loss 50.588734,Time used 0.005000s\n",
      "batch 2826, train_loss 59.841671,Time used 0.007004s\n",
      "batch 2827, train_loss 58.507919,Time used 0.005001s\n",
      "batch 2828, train_loss 58.031666,Time used 0.005997s\n",
      "batch 2829, train_loss 45.894768,Time used 0.006036s\n",
      "batch 2830, train_loss 55.799164,Time used 0.004964s\n",
      "batch 2831, train_loss 66.934753,Time used 0.006001s\n",
      "batch 2832, train_loss 58.883377,Time used 0.007034s\n",
      "batch 2833, train_loss 59.032879,Time used 0.007999s\n",
      "batch 2834, train_loss 58.790646,Time used 0.006998s\n",
      "batch 2835, train_loss 65.505264,Time used 0.008036s\n",
      "batch 2836, train_loss 51.847469,Time used 0.005005s\n",
      "batch 2837, train_loss 59.259300,Time used 0.007993s\n",
      "batch 2838, train_loss 72.379776,Time used 0.008967s\n",
      "batch 2839, train_loss 72.606209,Time used 0.007998s\n",
      "batch 2840, train_loss 52.329079,Time used 0.004999s\n",
      "batch 2841, train_loss 54.091629,Time used 0.005003s\n",
      "batch 2842, train_loss 61.537933,Time used 0.005997s\n",
      "batch 2843, train_loss 59.094597,Time used 0.006005s\n",
      "batch 2844, train_loss 66.497093,Time used 0.005998s\n",
      "batch 2845, train_loss 63.028687,Time used 0.008000s\n",
      "batch 2846, train_loss 72.818520,Time used 0.005996s\n",
      "batch 2847, train_loss 61.453064,Time used 0.004000s\n",
      "batch 2848, train_loss 55.875965,Time used 0.004999s\n",
      "batch 2849, train_loss 51.418865,Time used 0.005038s\n",
      "batch 2850, train_loss 70.667610,Time used 0.004966s\n",
      "batch 2851, train_loss 68.678726,Time used 0.005036s\n",
      "batch 2852, train_loss 56.316116,Time used 0.005965s\n",
      "batch 2853, train_loss 50.931976,Time used 0.005029s\n",
      "batch 2854, train_loss 58.793663,Time used 0.005006s\n",
      "batch 2855, train_loss 46.092503,Time used 0.004965s\n",
      "batch 2856, train_loss 57.241470,Time used 0.003998s\n",
      "batch 2857, train_loss 64.141129,Time used 0.006999s\n",
      "batch 2858, train_loss 64.405128,Time used 0.005000s\n",
      "batch 2859, train_loss 60.283337,Time used 0.005001s\n",
      "batch 2860, train_loss 63.875340,Time used 0.008031s\n",
      "batch 2861, train_loss 56.146400,Time used 0.005003s\n",
      "batch 2862, train_loss 59.189137,Time used 0.005966s\n",
      "batch 2863, train_loss 61.149975,Time used 0.007002s\n",
      "batch 2864, train_loss 55.672207,Time used 0.006996s\n",
      "batch 2865, train_loss 72.384529,Time used 0.004999s\n",
      "batch 2866, train_loss 60.538269,Time used 0.004000s\n",
      "batch 2867, train_loss 56.236496,Time used 0.006007s\n",
      "batch 2868, train_loss 53.055958,Time used 0.004998s\n",
      "batch 2869, train_loss 65.583015,Time used 0.007999s\n",
      "batch 2870, train_loss 69.183456,Time used 0.006996s\n",
      "batch 2871, train_loss 60.492519,Time used 0.004999s\n",
      "batch 2872, train_loss 53.999012,Time used 0.005001s\n",
      "batch 2873, train_loss 70.686455,Time used 0.005046s\n",
      "batch 2874, train_loss 50.555912,Time used 0.007005s\n",
      "batch 2875, train_loss 55.709202,Time used 0.007993s\n",
      "batch 2876, train_loss 64.639969,Time used 0.005034s\n",
      "batch 2877, train_loss 47.918892,Time used 0.006003s\n",
      "batch 2878, train_loss 53.055298,Time used 0.005968s\n",
      "batch 2879, train_loss 59.226780,Time used 0.005001s\n",
      "batch 2880, train_loss 64.098679,Time used 0.005000s\n",
      "batch 2881, train_loss 68.537193,Time used 0.006000s\n",
      "batch 2882, train_loss 67.219421,Time used 0.006033s\n",
      "batch 2883, train_loss 60.782417,Time used 0.005007s\n",
      "batch 2884, train_loss 55.212135,Time used 0.004965s\n",
      "batch 2885, train_loss 55.415382,Time used 0.008999s\n",
      "batch 2886, train_loss 58.465046,Time used 0.005999s\n",
      "batch 2887, train_loss 59.317657,Time used 0.007035s\n",
      "batch 2888, train_loss 65.770950,Time used 0.004999s\n",
      "batch 2889, train_loss 64.509926,Time used 0.005000s\n",
      "batch 2890, train_loss 47.634598,Time used 0.005968s\n",
      "batch 2891, train_loss 59.932945,Time used 0.003999s\n",
      "batch 2892, train_loss 59.526398,Time used 0.005000s\n",
      "batch 2893, train_loss 59.952908,Time used 0.008000s\n",
      "batch 2894, train_loss 63.933281,Time used 0.006000s\n",
      "batch 2895, train_loss 57.778999,Time used 0.006000s\n",
      "batch 2896, train_loss 63.176430,Time used 0.005000s\n",
      "batch 2897, train_loss 62.981316,Time used 0.003999s\n",
      "batch 2898, train_loss 56.941601,Time used 0.004999s\n",
      "batch 2899, train_loss 68.532104,Time used 0.003999s\n",
      "batch 2900, train_loss 53.677101,Time used 0.003997s\n",
      "***************************test_batch 2900, test_rmse_loss 8.807024,test_mae_loss 3.788329,test_mape_loss 61.663356,Time used 0.024004s\n",
      "batch 2901, train_loss 50.763302,Time used 0.005030s\n",
      "batch 2902, train_loss 59.210781,Time used 0.005966s\n",
      "batch 2903, train_loss 56.005756,Time used 0.004999s\n",
      "batch 2904, train_loss 62.763218,Time used 0.005003s\n",
      "batch 2905, train_loss 65.996986,Time used 0.005000s\n",
      "batch 2906, train_loss 56.142250,Time used 0.004998s\n",
      "batch 2907, train_loss 64.188690,Time used 0.006036s\n",
      "batch 2908, train_loss 57.397541,Time used 0.004965s\n",
      "batch 2909, train_loss 62.734516,Time used 0.005031s\n",
      "batch 2910, train_loss 48.021687,Time used 0.005997s\n",
      "batch 2911, train_loss 65.137085,Time used 0.003998s\n",
      "batch 2912, train_loss 65.568863,Time used 0.005002s\n",
      "batch 2913, train_loss 65.969193,Time used 0.005968s\n",
      "batch 2914, train_loss 54.746941,Time used 0.005000s\n",
      "batch 2915, train_loss 56.172955,Time used 0.005999s\n",
      "batch 2916, train_loss 51.603004,Time used 0.005000s\n",
      "batch 2917, train_loss 64.430588,Time used 0.004001s\n",
      "batch 2918, train_loss 65.031265,Time used 0.004032s\n",
      "batch 2919, train_loss 58.197506,Time used 0.007966s\n",
      "batch 2920, train_loss 62.463219,Time used 0.006003s\n",
      "batch 2921, train_loss 62.103573,Time used 0.005036s\n",
      "batch 2922, train_loss 60.214195,Time used 0.004997s\n",
      "batch 2923, train_loss 61.818623,Time used 0.007968s\n",
      "batch 2924, train_loss 53.772861,Time used 0.004996s\n",
      "batch 2925, train_loss 55.001415,Time used 0.004998s\n",
      "batch 2926, train_loss 60.782776,Time used 0.004000s\n",
      "batch 2927, train_loss 52.620613,Time used 0.007999s\n",
      "batch 2928, train_loss 58.901413,Time used 0.007001s\n",
      "batch 2929, train_loss 59.905811,Time used 0.005031s\n",
      "batch 2930, train_loss 64.655754,Time used 0.004969s\n",
      "batch 2931, train_loss 61.200531,Time used 0.008034s\n",
      "batch 2932, train_loss 67.080589,Time used 0.005002s\n",
      "batch 2933, train_loss 71.259094,Time used 0.005961s\n",
      "batch 2934, train_loss 60.120510,Time used 0.004999s\n",
      "batch 2935, train_loss 56.561729,Time used 0.006004s\n",
      "batch 2936, train_loss 45.160671,Time used 0.006998s\n",
      "batch 2937, train_loss 69.198036,Time used 0.004033s\n",
      "batch 2938, train_loss 58.116314,Time used 0.005002s\n",
      "batch 2939, train_loss 60.656361,Time used 0.006967s\n",
      "batch 2940, train_loss 46.921772,Time used 0.007002s\n",
      "batch 2941, train_loss 48.675308,Time used 0.006000s\n",
      "batch 2942, train_loss 43.031914,Time used 0.005003s\n",
      "batch 2943, train_loss 71.500305,Time used 0.003997s\n",
      "batch 2944, train_loss 59.062092,Time used 0.008004s\n",
      "batch 2945, train_loss 58.035500,Time used 0.004997s\n",
      "batch 2946, train_loss 78.926300,Time used 0.005000s\n",
      "batch 2947, train_loss 51.047005,Time used 0.006004s\n",
      "batch 2948, train_loss 55.956959,Time used 0.005027s\n",
      "batch 2949, train_loss 70.144684,Time used 0.005969s\n",
      "batch 2950, train_loss 52.542740,Time used 0.005998s\n",
      "batch 2951, train_loss 49.984756,Time used 0.005000s\n",
      "batch 2952, train_loss 63.243156,Time used 0.007999s\n",
      "batch 2953, train_loss 57.677544,Time used 0.008030s\n",
      "batch 2954, train_loss 57.940880,Time used 0.004999s\n",
      "batch 2955, train_loss 59.349068,Time used 0.007001s\n",
      "batch 2956, train_loss 56.120300,Time used 0.006997s\n",
      "batch 2957, train_loss 57.051067,Time used 0.007004s\n",
      "batch 2958, train_loss 59.171982,Time used 0.005998s\n",
      "batch 2959, train_loss 60.197041,Time used 0.007001s\n",
      "batch 2960, train_loss 56.415329,Time used 0.005002s\n",
      "batch 2961, train_loss 68.725365,Time used 0.004002s\n",
      "batch 2962, train_loss 53.651611,Time used 0.004963s\n",
      "batch 2963, train_loss 59.903069,Time used 0.004999s\n",
      "batch 2964, train_loss 65.420807,Time used 0.005000s\n",
      "batch 2965, train_loss 51.605183,Time used 0.005000s\n",
      "batch 2966, train_loss 60.039669,Time used 0.005001s\n",
      "batch 2967, train_loss 50.794712,Time used 0.004023s\n",
      "batch 2968, train_loss 62.233612,Time used 0.004992s\n",
      "batch 2969, train_loss 73.763382,Time used 0.005973s\n",
      "batch 2970, train_loss 59.592430,Time used 0.004998s\n",
      "batch 2971, train_loss 59.760445,Time used 0.005001s\n",
      "batch 2972, train_loss 65.676460,Time used 0.005036s\n",
      "batch 2973, train_loss 50.772865,Time used 0.004000s\n",
      "batch 2974, train_loss 47.430614,Time used 0.005002s\n",
      "batch 2975, train_loss 74.078751,Time used 0.005000s\n",
      "batch 2976, train_loss 49.544392,Time used 0.005028s\n",
      "batch 2977, train_loss 58.377831,Time used 0.005028s\n",
      "batch 2978, train_loss 69.531151,Time used 0.004966s\n",
      "batch 2979, train_loss 54.328304,Time used 0.005006s\n",
      "batch 2980, train_loss 62.660709,Time used 0.003998s\n",
      "batch 2981, train_loss 57.871826,Time used 0.004000s\n",
      "batch 2982, train_loss 60.063641,Time used 0.004999s\n",
      "batch 2983, train_loss 53.536053,Time used 0.006001s\n",
      "batch 2984, train_loss 55.725414,Time used 0.005000s\n",
      "batch 2985, train_loss 49.056046,Time used 0.004997s\n",
      "batch 2986, train_loss 52.284267,Time used 0.005998s\n",
      "batch 2987, train_loss 54.191967,Time used 0.004001s\n",
      "batch 2988, train_loss 65.523277,Time used 0.003999s\n",
      "batch 2989, train_loss 60.169418,Time used 0.005038s\n",
      "batch 2990, train_loss 52.917801,Time used 0.004999s\n",
      "batch 2991, train_loss 60.552761,Time used 0.005000s\n",
      "batch 2992, train_loss 56.602013,Time used 0.007963s\n",
      "batch 2993, train_loss 67.960327,Time used 0.006999s\n",
      "batch 2994, train_loss 61.409454,Time used 0.006001s\n",
      "batch 2995, train_loss 59.848694,Time used 0.006000s\n",
      "batch 2996, train_loss 42.449959,Time used 0.005038s\n",
      "batch 2997, train_loss 71.406654,Time used 0.004965s\n",
      "batch 2998, train_loss 74.456352,Time used 0.005035s\n",
      "batch 2999, train_loss 61.205917,Time used 0.005005s\n",
      "batch 3000, train_loss 50.857578,Time used 0.004993s\n",
      "***************************test_batch 3000, test_rmse_loss 8.758368,test_mae_loss 3.761336,test_mape_loss 61.132878,Time used 0.020965s\n",
      "batch 3001, train_loss 53.545246,Time used 0.008000s\n",
      "batch 3002, train_loss 61.034344,Time used 0.007036s\n",
      "batch 3003, train_loss 67.178108,Time used 0.003999s\n",
      "batch 3004, train_loss 47.054966,Time used 0.005013s\n",
      "batch 3005, train_loss 60.893177,Time used 0.005955s\n",
      "batch 3006, train_loss 60.492012,Time used 0.004999s\n",
      "batch 3007, train_loss 56.707634,Time used 0.005000s\n",
      "batch 3008, train_loss 73.038918,Time used 0.007002s\n",
      "batch 3009, train_loss 62.737858,Time used 0.007998s\n",
      "batch 3010, train_loss 44.391014,Time used 0.007001s\n",
      "batch 3011, train_loss 43.114086,Time used 0.005000s\n",
      "batch 3012, train_loss 72.609322,Time used 0.005001s\n",
      "batch 3013, train_loss 58.514191,Time used 0.007032s\n",
      "batch 3014, train_loss 63.280750,Time used 0.005968s\n",
      "batch 3015, train_loss 70.011688,Time used 0.006000s\n",
      "batch 3016, train_loss 55.209049,Time used 0.006999s\n",
      "batch 3017, train_loss 61.118809,Time used 0.003999s\n",
      "batch 3018, train_loss 53.363346,Time used 0.004000s\n",
      "batch 3019, train_loss 59.545391,Time used 0.005997s\n",
      "batch 3020, train_loss 59.530216,Time used 0.005033s\n",
      "batch 3021, train_loss 51.874340,Time used 0.005006s\n",
      "batch 3022, train_loss 63.238628,Time used 0.008000s\n",
      "batch 3023, train_loss 54.195469,Time used 0.004968s\n",
      "batch 3024, train_loss 55.529034,Time used 0.008000s\n",
      "batch 3025, train_loss 58.964653,Time used 0.004971s\n",
      "batch 3026, train_loss 64.238037,Time used 0.004997s\n",
      "batch 3027, train_loss 57.797607,Time used 0.005000s\n",
      "batch 3028, train_loss 71.166573,Time used 0.006007s\n",
      "batch 3029, train_loss 63.903404,Time used 0.004993s\n",
      "batch 3030, train_loss 54.415665,Time used 0.005033s\n",
      "batch 3031, train_loss 75.395592,Time used 0.005969s\n",
      "batch 3032, train_loss 54.288773,Time used 0.005031s\n",
      "batch 3033, train_loss 52.345230,Time used 0.005004s\n",
      "batch 3034, train_loss 45.684319,Time used 0.005962s\n",
      "batch 3035, train_loss 54.516319,Time used 0.008034s\n",
      "batch 3036, train_loss 69.673744,Time used 0.005003s\n",
      "batch 3037, train_loss 52.655293,Time used 0.004959s\n",
      "batch 3038, train_loss 56.445347,Time used 0.004999s\n",
      "batch 3039, train_loss 64.300179,Time used 0.005967s\n",
      "batch 3040, train_loss 52.645191,Time used 0.005002s\n",
      "batch 3041, train_loss 56.294163,Time used 0.005031s\n",
      "batch 3042, train_loss 53.326218,Time used 0.005973s\n",
      "batch 3043, train_loss 59.633762,Time used 0.007001s\n",
      "batch 3044, train_loss 50.133274,Time used 0.005005s\n",
      "batch 3045, train_loss 67.495972,Time used 0.005033s\n",
      "batch 3046, train_loss 58.169952,Time used 0.003996s\n",
      "batch 3047, train_loss 57.467354,Time used 0.006972s\n",
      "batch 3048, train_loss 53.154297,Time used 0.007997s\n",
      "batch 3049, train_loss 64.656761,Time used 0.005002s\n",
      "batch 3050, train_loss 59.782173,Time used 0.004996s\n",
      "batch 3051, train_loss 61.127090,Time used 0.007038s\n",
      "batch 3052, train_loss 61.728443,Time used 0.007001s\n",
      "batch 3053, train_loss 57.302498,Time used 0.007034s\n",
      "batch 3054, train_loss 44.085293,Time used 0.004967s\n",
      "batch 3055, train_loss 71.624207,Time used 0.005999s\n",
      "batch 3056, train_loss 52.743969,Time used 0.007035s\n",
      "batch 3057, train_loss 58.221123,Time used 0.004967s\n",
      "batch 3058, train_loss 54.436935,Time used 0.007000s\n",
      "batch 3059, train_loss 55.724831,Time used 0.007028s\n",
      "batch 3060, train_loss 62.583954,Time used 0.007967s\n",
      "batch 3061, train_loss 68.027176,Time used 0.005000s\n",
      "batch 3062, train_loss 65.739868,Time used 0.005002s\n",
      "batch 3063, train_loss 54.083447,Time used 0.007998s\n",
      "batch 3064, train_loss 46.655605,Time used 0.005014s\n",
      "batch 3065, train_loss 54.574722,Time used 0.006992s\n",
      "batch 3066, train_loss 48.003532,Time used 0.005028s\n",
      "batch 3067, train_loss 58.523609,Time used 0.004968s\n",
      "batch 3068, train_loss 57.761265,Time used 0.008036s\n",
      "batch 3069, train_loss 58.610462,Time used 0.005002s\n",
      "batch 3070, train_loss 65.562248,Time used 0.003993s\n",
      "batch 3071, train_loss 58.670238,Time used 0.006971s\n",
      "batch 3072, train_loss 59.478260,Time used 0.005000s\n",
      "batch 3073, train_loss 53.815567,Time used 0.005998s\n",
      "batch 3074, train_loss 55.158432,Time used 0.005001s\n",
      "batch 3075, train_loss 63.840462,Time used 0.006032s\n",
      "batch 3076, train_loss 53.106705,Time used 0.005000s\n",
      "batch 3077, train_loss 67.845139,Time used 0.006971s\n",
      "batch 3078, train_loss 58.805721,Time used 0.004997s\n",
      "batch 3079, train_loss 60.254993,Time used 0.005000s\n",
      "batch 3080, train_loss 56.676819,Time used 0.004000s\n",
      "batch 3081, train_loss 56.212307,Time used 0.008001s\n",
      "batch 3082, train_loss 52.296532,Time used 0.007000s\n",
      "batch 3083, train_loss 47.572975,Time used 0.005997s\n",
      "batch 3084, train_loss 51.012135,Time used 0.005000s\n",
      "batch 3085, train_loss 53.534470,Time used 0.005000s\n",
      "batch 3086, train_loss 52.976944,Time used 0.006000s\n",
      "batch 3087, train_loss 60.423271,Time used 0.005999s\n",
      "batch 3088, train_loss 63.733238,Time used 0.006000s\n",
      "batch 3089, train_loss 65.911240,Time used 0.004997s\n",
      "batch 3090, train_loss 54.487549,Time used 0.005000s\n",
      "batch 3091, train_loss 58.604652,Time used 0.005003s\n",
      "batch 3092, train_loss 70.914177,Time used 0.007000s\n",
      "batch 3093, train_loss 57.568283,Time used 0.004996s\n",
      "batch 3094, train_loss 59.911148,Time used 0.006001s\n",
      "batch 3095, train_loss 63.374878,Time used 0.003996s\n",
      "batch 3096, train_loss 57.755142,Time used 0.004999s\n",
      "batch 3097, train_loss 70.589149,Time used 0.003997s\n",
      "batch 3098, train_loss 63.527134,Time used 0.006001s\n",
      "batch 3099, train_loss 58.407505,Time used 0.008000s\n",
      "batch 3100, train_loss 52.893143,Time used 0.008000s\n",
      "***************************test_batch 3100, test_rmse_loss 8.691437,test_mae_loss 3.741402,test_mape_loss 61.213197,Time used 0.018000s\n",
      "batch 3101, train_loss 55.738533,Time used 0.005999s\n",
      "batch 3102, train_loss 63.818321,Time used 0.005001s\n",
      "batch 3103, train_loss 65.634804,Time used 0.004999s\n",
      "batch 3104, train_loss 56.008701,Time used 0.005002s\n",
      "batch 3105, train_loss 66.735619,Time used 0.005001s\n",
      "batch 3106, train_loss 53.508896,Time used 0.003998s\n",
      "batch 3107, train_loss 53.287483,Time used 0.004000s\n",
      "batch 3108, train_loss 70.462822,Time used 0.004998s\n",
      "batch 3109, train_loss 58.321472,Time used 0.005000s\n",
      "batch 3110, train_loss 63.325504,Time used 0.005000s\n",
      "batch 3111, train_loss 67.753342,Time used 0.006001s\n",
      "batch 3112, train_loss 52.673492,Time used 0.004996s\n",
      "batch 3113, train_loss 53.925415,Time used 0.005002s\n",
      "batch 3114, train_loss 63.228054,Time used 0.004999s\n",
      "batch 3115, train_loss 57.544392,Time used 0.004997s\n",
      "batch 3116, train_loss 57.877499,Time used 0.005002s\n",
      "batch 3117, train_loss 46.973083,Time used 0.005004s\n",
      "batch 3118, train_loss 38.800961,Time used 0.004997s\n",
      "batch 3119, train_loss 50.227486,Time used 0.004999s\n",
      "batch 3120, train_loss 50.759186,Time used 0.006001s\n",
      "batch 3121, train_loss 54.586334,Time used 0.004997s\n",
      "batch 3122, train_loss 58.261276,Time used 0.006001s\n",
      "batch 3123, train_loss 47.812531,Time used 0.005032s\n",
      "batch 3124, train_loss 61.469212,Time used 0.005004s\n",
      "batch 3125, train_loss 57.244865,Time used 0.004965s\n",
      "batch 3126, train_loss 51.545204,Time used 0.005031s\n",
      "batch 3127, train_loss 67.559959,Time used 0.005000s\n",
      "batch 3128, train_loss 49.764633,Time used 0.005963s\n",
      "batch 3129, train_loss 65.644920,Time used 0.005001s\n",
      "batch 3130, train_loss 56.645897,Time used 0.004000s\n",
      "batch 3131, train_loss 54.504627,Time used 0.005033s\n",
      "batch 3132, train_loss 67.056801,Time used 0.004001s\n",
      "batch 3133, train_loss 66.084496,Time used 0.004968s\n",
      "batch 3134, train_loss 56.408321,Time used 0.006039s\n",
      "batch 3135, train_loss 54.027634,Time used 0.005961s\n",
      "batch 3136, train_loss 64.182007,Time used 0.005032s\n",
      "batch 3137, train_loss 53.971474,Time used 0.005967s\n",
      "batch 3138, train_loss 58.102478,Time used 0.003999s\n",
      "batch 3139, train_loss 54.307835,Time used 0.005000s\n",
      "batch 3140, train_loss 67.417831,Time used 0.007000s\n",
      "batch 3141, train_loss 56.506344,Time used 0.008001s\n",
      "batch 3142, train_loss 56.934498,Time used 0.007002s\n",
      "batch 3143, train_loss 55.912415,Time used 0.007984s\n",
      "batch 3144, train_loss 52.306362,Time used 0.004999s\n",
      "batch 3145, train_loss 59.254650,Time used 0.004000s\n",
      "batch 3146, train_loss 62.057629,Time used 0.005001s\n",
      "batch 3147, train_loss 79.566971,Time used 0.005034s\n",
      "batch 3148, train_loss 46.697552,Time used 0.004998s\n",
      "batch 3149, train_loss 57.814529,Time used 0.006000s\n",
      "batch 3150, train_loss 64.014404,Time used 0.006001s\n",
      "batch 3151, train_loss 52.446976,Time used 0.006997s\n",
      "batch 3152, train_loss 57.456104,Time used 0.008004s\n",
      "batch 3153, train_loss 54.707584,Time used 0.006996s\n",
      "batch 3154, train_loss 61.042500,Time used 0.004970s\n",
      "batch 3155, train_loss 52.968922,Time used 0.004000s\n",
      "batch 3156, train_loss 69.880722,Time used 0.004000s\n",
      "batch 3157, train_loss 54.184677,Time used 0.005999s\n",
      "batch 3158, train_loss 55.034626,Time used 0.008034s\n",
      "batch 3159, train_loss 66.842293,Time used 0.008003s\n",
      "batch 3160, train_loss 50.628975,Time used 0.006962s\n",
      "batch 3161, train_loss 53.947441,Time used 0.006030s\n",
      "batch 3162, train_loss 48.307758,Time used 0.005008s\n",
      "batch 3163, train_loss 63.788578,Time used 0.003999s\n",
      "batch 3164, train_loss 57.724205,Time used 0.006002s\n",
      "batch 3165, train_loss 52.369980,Time used 0.005998s\n",
      "batch 3166, train_loss 57.600468,Time used 0.005004s\n",
      "batch 3167, train_loss 54.279888,Time used 0.005968s\n",
      "batch 3168, train_loss 50.307739,Time used 0.005028s\n",
      "batch 3169, train_loss 59.802776,Time used 0.006997s\n",
      "batch 3170, train_loss 51.994888,Time used 0.006012s\n",
      "batch 3171, train_loss 59.037071,Time used 0.006990s\n",
      "batch 3172, train_loss 52.898506,Time used 0.006001s\n",
      "batch 3173, train_loss 52.792824,Time used 0.005999s\n",
      "batch 3174, train_loss 70.011841,Time used 0.005999s\n",
      "batch 3175, train_loss 63.603107,Time used 0.005032s\n",
      "batch 3176, train_loss 50.410889,Time used 0.008967s\n",
      "batch 3177, train_loss 52.407265,Time used 0.006001s\n",
      "batch 3178, train_loss 57.810863,Time used 0.007001s\n",
      "batch 3179, train_loss 60.403088,Time used 0.005999s\n",
      "batch 3180, train_loss 59.274067,Time used 0.005000s\n",
      "batch 3181, train_loss 64.539314,Time used 0.007001s\n",
      "batch 3182, train_loss 56.421124,Time used 0.006031s\n",
      "batch 3183, train_loss 48.869225,Time used 0.007969s\n",
      "batch 3184, train_loss 54.756638,Time used 0.006993s\n",
      "batch 3185, train_loss 58.630379,Time used 0.007004s\n",
      "batch 3186, train_loss 63.145809,Time used 0.007998s\n",
      "batch 3187, train_loss 56.360260,Time used 0.006004s\n",
      "batch 3188, train_loss 64.858650,Time used 0.004000s\n",
      "batch 3189, train_loss 53.040550,Time used 0.003999s\n",
      "batch 3190, train_loss 53.013844,Time used 0.007002s\n",
      "batch 3191, train_loss 58.236164,Time used 0.004999s\n",
      "batch 3192, train_loss 55.529633,Time used 0.005000s\n",
      "batch 3193, train_loss 56.907951,Time used 0.007002s\n",
      "batch 3194, train_loss 55.256294,Time used 0.005002s\n",
      "batch 3195, train_loss 60.084938,Time used 0.005000s\n",
      "batch 3196, train_loss 44.602608,Time used 0.006000s\n",
      "batch 3197, train_loss 56.829784,Time used 0.009001s\n",
      "batch 3198, train_loss 64.820572,Time used 0.007999s\n",
      "batch 3199, train_loss 61.225338,Time used 0.005003s\n",
      "batch 3200, train_loss 65.305801,Time used 0.005001s\n",
      "***************************test_batch 3200, test_rmse_loss 8.671205,test_mae_loss 3.732520,test_mape_loss 60.612759,Time used 0.016999s\n",
      "batch 3201, train_loss 56.364586,Time used 0.004999s\n",
      "batch 3202, train_loss 51.248035,Time used 0.004035s\n",
      "batch 3203, train_loss 46.393700,Time used 0.004967s\n",
      "batch 3204, train_loss 55.840065,Time used 0.003999s\n",
      "batch 3205, train_loss 55.343548,Time used 0.004998s\n",
      "batch 3206, train_loss 60.184708,Time used 0.005000s\n",
      "batch 3207, train_loss 60.119682,Time used 0.007035s\n",
      "batch 3208, train_loss 64.218529,Time used 0.004034s\n",
      "batch 3209, train_loss 63.297989,Time used 0.005001s\n",
      "batch 3210, train_loss 48.082397,Time used 0.004969s\n",
      "batch 3211, train_loss 71.032387,Time used 0.005000s\n",
      "batch 3212, train_loss 45.839958,Time used 0.005000s\n",
      "batch 3213, train_loss 52.202526,Time used 0.006997s\n",
      "batch 3214, train_loss 58.820629,Time used 0.005001s\n",
      "batch 3215, train_loss 55.897781,Time used 0.006000s\n",
      "batch 3216, train_loss 64.814087,Time used 0.004998s\n",
      "batch 3217, train_loss 57.013664,Time used 0.006000s\n",
      "batch 3218, train_loss 54.963078,Time used 0.004000s\n",
      "batch 3219, train_loss 54.518436,Time used 0.005000s\n",
      "batch 3220, train_loss 65.401428,Time used 0.005005s\n",
      "batch 3221, train_loss 56.969685,Time used 0.007993s\n",
      "batch 3222, train_loss 46.512867,Time used 0.007000s\n",
      "batch 3223, train_loss 48.430222,Time used 0.006002s\n",
      "batch 3224, train_loss 58.487606,Time used 0.005998s\n",
      "batch 3225, train_loss 65.567726,Time used 0.004001s\n",
      "batch 3226, train_loss 61.522881,Time used 0.007999s\n",
      "batch 3227, train_loss 71.513824,Time used 0.005000s\n",
      "batch 3228, train_loss 69.175285,Time used 0.005002s\n",
      "batch 3229, train_loss 53.405327,Time used 0.007998s\n",
      "batch 3230, train_loss 56.598381,Time used 0.008003s\n",
      "batch 3231, train_loss 57.072807,Time used 0.008000s\n",
      "batch 3232, train_loss 63.210686,Time used 0.005000s\n",
      "batch 3233, train_loss 61.513542,Time used 0.007037s\n",
      "batch 3234, train_loss 45.376736,Time used 0.007000s\n",
      "batch 3235, train_loss 49.890816,Time used 0.005966s\n",
      "batch 3236, train_loss 48.908657,Time used 0.007025s\n",
      "batch 3237, train_loss 58.243435,Time used 0.004977s\n",
      "batch 3238, train_loss 60.541695,Time used 0.005042s\n",
      "batch 3239, train_loss 57.352451,Time used 0.004988s\n",
      "batch 3240, train_loss 48.005775,Time used 0.004973s\n",
      "batch 3241, train_loss 58.547176,Time used 0.005002s\n",
      "batch 3242, train_loss 54.963036,Time used 0.004998s\n",
      "batch 3243, train_loss 55.258110,Time used 0.005002s\n",
      "batch 3244, train_loss 58.782597,Time used 0.005002s\n",
      "batch 3245, train_loss 61.278267,Time used 0.004959s\n",
      "batch 3246, train_loss 51.365604,Time used 0.005037s\n",
      "batch 3247, train_loss 44.393379,Time used 0.004962s\n",
      "batch 3248, train_loss 49.890057,Time used 0.007037s\n",
      "batch 3249, train_loss 59.576527,Time used 0.005001s\n",
      "batch 3250, train_loss 41.451805,Time used 0.004966s\n",
      "batch 3251, train_loss 61.323673,Time used 0.007033s\n",
      "batch 3252, train_loss 48.504929,Time used 0.004967s\n",
      "batch 3253, train_loss 64.863289,Time used 0.005999s\n",
      "batch 3254, train_loss 57.524879,Time used 0.007039s\n",
      "batch 3255, train_loss 63.608585,Time used 0.004963s\n",
      "batch 3256, train_loss 70.626503,Time used 0.004996s\n",
      "batch 3257, train_loss 63.482307,Time used 0.005001s\n",
      "batch 3258, train_loss 57.033424,Time used 0.004999s\n",
      "batch 3259, train_loss 59.174900,Time used 0.006003s\n",
      "batch 3260, train_loss 49.792179,Time used 0.005002s\n",
      "batch 3261, train_loss 55.900066,Time used 0.007034s\n",
      "batch 3262, train_loss 70.231834,Time used 0.005999s\n",
      "batch 3263, train_loss 66.361061,Time used 0.005001s\n",
      "batch 3264, train_loss 41.542416,Time used 0.004999s\n",
      "batch 3265, train_loss 52.029125,Time used 0.004998s\n",
      "batch 3266, train_loss 57.321430,Time used 0.005020s\n",
      "batch 3267, train_loss 53.188488,Time used 0.005013s\n",
      "batch 3268, train_loss 50.538048,Time used 0.004965s\n",
      "batch 3269, train_loss 62.394943,Time used 0.006003s\n",
      "batch 3270, train_loss 59.658974,Time used 0.005029s\n",
      "batch 3271, train_loss 66.081635,Time used 0.007004s\n",
      "batch 3272, train_loss 53.800205,Time used 0.004996s\n",
      "batch 3273, train_loss 52.582119,Time used 0.005003s\n",
      "batch 3274, train_loss 64.665077,Time used 0.005004s\n",
      "batch 3275, train_loss 55.306599,Time used 0.004997s\n",
      "batch 3276, train_loss 65.364220,Time used 0.008002s\n",
      "batch 3277, train_loss 62.358593,Time used 0.007000s\n",
      "batch 3278, train_loss 49.095451,Time used 0.004961s\n",
      "batch 3279, train_loss 61.076988,Time used 0.003994s\n",
      "batch 3280, train_loss 67.565552,Time used 0.005970s\n",
      "batch 3281, train_loss 44.680920,Time used 0.005033s\n",
      "batch 3282, train_loss 52.403744,Time used 0.004004s\n",
      "batch 3283, train_loss 53.755939,Time used 0.005000s\n",
      "batch 3284, train_loss 56.917637,Time used 0.005994s\n",
      "batch 3285, train_loss 55.658760,Time used 0.003995s\n",
      "batch 3286, train_loss 53.899403,Time used 0.004997s\n",
      "batch 3287, train_loss 60.541290,Time used 0.004966s\n",
      "batch 3288, train_loss 49.752838,Time used 0.004001s\n",
      "batch 3289, train_loss 56.342541,Time used 0.005000s\n",
      "batch 3290, train_loss 68.756790,Time used 0.004000s\n",
      "batch 3291, train_loss 52.089657,Time used 0.005008s\n",
      "batch 3292, train_loss 60.289490,Time used 0.006996s\n",
      "batch 3293, train_loss 54.924637,Time used 0.006998s\n",
      "batch 3294, train_loss 51.910183,Time used 0.005013s\n",
      "batch 3295, train_loss 46.623943,Time used 0.006020s\n",
      "batch 3296, train_loss 65.691925,Time used 0.004966s\n",
      "batch 3297, train_loss 51.283344,Time used 0.005034s\n",
      "batch 3298, train_loss 66.534164,Time used 0.006003s\n",
      "batch 3299, train_loss 42.959431,Time used 0.003998s\n",
      "batch 3300, train_loss 54.345310,Time used 0.004999s\n",
      "***************************test_batch 3300, test_rmse_loss 8.615509,test_mae_loss 3.711319,test_mape_loss 60.505882,Time used 0.016972s\n",
      "batch 3301, train_loss 55.240128,Time used 0.006000s\n",
      "batch 3302, train_loss 63.328873,Time used 0.004999s\n",
      "batch 3303, train_loss 52.700592,Time used 0.004996s\n",
      "batch 3304, train_loss 68.187820,Time used 0.005001s\n",
      "batch 3305, train_loss 58.639584,Time used 0.005000s\n",
      "batch 3306, train_loss 66.695137,Time used 0.005004s\n",
      "batch 3307, train_loss 56.761200,Time used 0.005000s\n",
      "batch 3308, train_loss 62.025803,Time used 0.005998s\n",
      "batch 3309, train_loss 55.814869,Time used 0.007997s\n",
      "batch 3310, train_loss 45.802586,Time used 0.005002s\n",
      "batch 3311, train_loss 56.113728,Time used 0.007045s\n",
      "batch 3312, train_loss 42.460415,Time used 0.004956s\n",
      "batch 3313, train_loss 54.784622,Time used 0.004030s\n",
      "batch 3314, train_loss 58.936092,Time used 0.006036s\n",
      "batch 3315, train_loss 56.110554,Time used 0.007961s\n",
      "batch 3316, train_loss 57.353016,Time used 0.005001s\n",
      "batch 3317, train_loss 59.237392,Time used 0.005000s\n",
      "batch 3318, train_loss 67.722374,Time used 0.005006s\n",
      "batch 3319, train_loss 48.419338,Time used 0.005031s\n",
      "batch 3320, train_loss 46.477093,Time used 0.005002s\n",
      "batch 3321, train_loss 49.176525,Time used 0.005961s\n",
      "batch 3322, train_loss 63.674152,Time used 0.005000s\n",
      "batch 3323, train_loss 62.790138,Time used 0.005003s\n",
      "batch 3324, train_loss 55.727417,Time used 0.005005s\n",
      "batch 3325, train_loss 51.962677,Time used 0.005994s\n",
      "batch 3326, train_loss 50.068619,Time used 0.006028s\n",
      "batch 3327, train_loss 62.932175,Time used 0.004999s\n",
      "batch 3328, train_loss 56.154472,Time used 0.005001s\n",
      "batch 3329, train_loss 57.512608,Time used 0.005977s\n",
      "batch 3330, train_loss 51.996563,Time used 0.005001s\n",
      "batch 3331, train_loss 72.861534,Time used 0.005000s\n",
      "batch 3332, train_loss 63.790623,Time used 0.005002s\n",
      "batch 3333, train_loss 55.767109,Time used 0.004998s\n",
      "batch 3334, train_loss 49.670048,Time used 0.005001s\n",
      "batch 3335, train_loss 49.754601,Time used 0.006000s\n",
      "batch 3336, train_loss 48.274712,Time used 0.005001s\n",
      "batch 3337, train_loss 54.020901,Time used 0.007991s\n",
      "batch 3338, train_loss 50.250980,Time used 0.007000s\n",
      "batch 3339, train_loss 66.174332,Time used 0.007998s\n",
      "batch 3340, train_loss 52.389999,Time used 0.005001s\n",
      "batch 3341, train_loss 63.815891,Time used 0.006000s\n",
      "batch 3342, train_loss 54.319553,Time used 0.005001s\n",
      "batch 3343, train_loss 57.690079,Time used 0.005000s\n",
      "batch 3344, train_loss 53.363884,Time used 0.006002s\n",
      "batch 3345, train_loss 68.469017,Time used 0.006001s\n",
      "batch 3346, train_loss 67.446152,Time used 0.004999s\n",
      "batch 3347, train_loss 64.528931,Time used 0.005000s\n",
      "batch 3348, train_loss 49.595898,Time used 0.005998s\n",
      "batch 3349, train_loss 58.361542,Time used 0.005002s\n",
      "batch 3350, train_loss 63.938320,Time used 0.005000s\n",
      "batch 3351, train_loss 51.854088,Time used 0.006001s\n",
      "batch 3352, train_loss 58.220600,Time used 0.007002s\n",
      "batch 3353, train_loss 42.567429,Time used 0.007998s\n",
      "batch 3354, train_loss 42.462303,Time used 0.008001s\n",
      "batch 3355, train_loss 55.460888,Time used 0.005000s\n",
      "batch 3356, train_loss 57.619877,Time used 0.007999s\n",
      "batch 3357, train_loss 42.858746,Time used 0.005999s\n",
      "batch 3358, train_loss 63.919346,Time used 0.005000s\n",
      "batch 3359, train_loss 48.003727,Time used 0.010002s\n",
      "batch 3360, train_loss 58.786011,Time used 0.008998s\n",
      "batch 3361, train_loss 66.670662,Time used 0.007001s\n",
      "batch 3362, train_loss 58.538525,Time used 0.007998s\n",
      "batch 3363, train_loss 49.982975,Time used 0.007001s\n",
      "batch 3364, train_loss 50.902130,Time used 0.004998s\n",
      "batch 3365, train_loss 52.889843,Time used 0.005000s\n",
      "batch 3366, train_loss 47.030457,Time used 0.004000s\n",
      "batch 3367, train_loss 51.097492,Time used 0.006001s\n",
      "batch 3368, train_loss 56.600586,Time used 0.005000s\n",
      "batch 3369, train_loss 40.024971,Time used 0.004000s\n",
      "batch 3370, train_loss 57.751892,Time used 0.005002s\n",
      "batch 3371, train_loss 51.501751,Time used 0.003999s\n",
      "batch 3372, train_loss 42.964825,Time used 0.003999s\n",
      "batch 3373, train_loss 49.391106,Time used 0.005003s\n",
      "batch 3374, train_loss 51.688988,Time used 0.005998s\n",
      "batch 3375, train_loss 57.938709,Time used 0.005001s\n",
      "batch 3376, train_loss 69.400528,Time used 0.005998s\n",
      "batch 3377, train_loss 60.935329,Time used 0.008001s\n",
      "batch 3378, train_loss 55.146065,Time used 0.004000s\n",
      "batch 3379, train_loss 60.195015,Time used 0.005999s\n",
      "batch 3380, train_loss 74.163315,Time used 0.005000s\n",
      "batch 3381, train_loss 53.841282,Time used 0.004001s\n",
      "batch 3382, train_loss 65.292534,Time used 0.006003s\n",
      "batch 3383, train_loss 56.205647,Time used 0.006998s\n",
      "batch 3384, train_loss 62.027596,Time used 0.007000s\n",
      "batch 3385, train_loss 53.394955,Time used 0.006999s\n",
      "batch 3386, train_loss 60.867023,Time used 0.005001s\n",
      "batch 3387, train_loss 54.214264,Time used 0.005002s\n",
      "batch 3388, train_loss 49.170967,Time used 0.005998s\n",
      "batch 3389, train_loss 53.196281,Time used 0.004000s\n",
      "batch 3390, train_loss 61.884113,Time used 0.004000s\n",
      "batch 3391, train_loss 60.221920,Time used 0.005002s\n",
      "batch 3392, train_loss 60.264790,Time used 0.005001s\n",
      "batch 3393, train_loss 53.134991,Time used 0.005002s\n",
      "batch 3394, train_loss 62.626190,Time used 0.004999s\n",
      "batch 3395, train_loss 57.159088,Time used 0.005000s\n",
      "batch 3396, train_loss 51.631611,Time used 0.005035s\n",
      "batch 3397, train_loss 62.936920,Time used 0.005961s\n",
      "batch 3398, train_loss 40.019421,Time used 0.005042s\n",
      "batch 3399, train_loss 52.216152,Time used 0.004997s\n",
      "batch 3400, train_loss 56.131920,Time used 0.005997s\n",
      "***************************test_batch 3400, test_rmse_loss 8.582500,test_mae_loss 3.688420,test_mape_loss 59.474555,Time used 0.017968s\n",
      "batch 3401, train_loss 54.200790,Time used 0.004999s\n",
      "batch 3402, train_loss 58.039021,Time used 0.005001s\n",
      "batch 3403, train_loss 47.609695,Time used 0.005035s\n",
      "batch 3404, train_loss 59.061985,Time used 0.004999s\n",
      "batch 3405, train_loss 68.828888,Time used 0.004966s\n",
      "batch 3406, train_loss 53.671230,Time used 0.006999s\n",
      "batch 3407, train_loss 45.834030,Time used 0.005034s\n",
      "batch 3408, train_loss 59.671291,Time used 0.005002s\n",
      "batch 3409, train_loss 56.091637,Time used 0.006001s\n",
      "batch 3410, train_loss 55.305882,Time used 0.009036s\n",
      "batch 3411, train_loss 49.411255,Time used 0.005000s\n",
      "batch 3412, train_loss 55.960754,Time used 0.006968s\n",
      "batch 3413, train_loss 54.833477,Time used 0.008994s\n",
      "batch 3414, train_loss 63.555618,Time used 0.009000s\n",
      "batch 3415, train_loss 53.580994,Time used 0.004033s\n",
      "batch 3416, train_loss 47.978924,Time used 0.003963s\n",
      "batch 3417, train_loss 39.440205,Time used 0.007030s\n",
      "batch 3418, train_loss 54.056492,Time used 0.004002s\n",
      "batch 3419, train_loss 49.023846,Time used 0.003988s\n",
      "batch 3420, train_loss 56.919418,Time used 0.005968s\n",
      "batch 3421, train_loss 51.860653,Time used 0.005003s\n",
      "batch 3422, train_loss 55.864109,Time used 0.005011s\n",
      "batch 3423, train_loss 68.618706,Time used 0.005990s\n",
      "batch 3424, train_loss 40.273979,Time used 0.005031s\n",
      "batch 3425, train_loss 52.068447,Time used 0.004997s\n",
      "batch 3426, train_loss 54.317135,Time used 0.005972s\n",
      "batch 3427, train_loss 52.415131,Time used 0.004998s\n",
      "batch 3428, train_loss 74.135818,Time used 0.005030s\n",
      "batch 3429, train_loss 66.586365,Time used 0.005973s\n",
      "batch 3430, train_loss 58.201408,Time used 0.004996s\n",
      "batch 3431, train_loss 62.424408,Time used 0.004039s\n",
      "batch 3432, train_loss 58.035934,Time used 0.004999s\n",
      "batch 3433, train_loss 49.039871,Time used 0.005035s\n",
      "batch 3434, train_loss 57.772762,Time used 0.007967s\n",
      "batch 3435, train_loss 52.360493,Time used 0.004999s\n",
      "batch 3436, train_loss 54.651794,Time used 0.004998s\n",
      "batch 3437, train_loss 53.035748,Time used 0.008037s\n",
      "batch 3438, train_loss 38.374786,Time used 0.006964s\n",
      "batch 3439, train_loss 58.386028,Time used 0.006999s\n",
      "batch 3440, train_loss 56.711124,Time used 0.008001s\n",
      "batch 3441, train_loss 50.571148,Time used 0.008000s\n",
      "batch 3442, train_loss 70.591919,Time used 0.007000s\n",
      "batch 3443, train_loss 59.233845,Time used 0.006002s\n",
      "batch 3444, train_loss 55.722691,Time used 0.005001s\n",
      "batch 3445, train_loss 59.073647,Time used 0.005997s\n",
      "batch 3446, train_loss 51.659000,Time used 0.005035s\n",
      "batch 3447, train_loss 59.152683,Time used 0.004965s\n",
      "batch 3448, train_loss 53.021339,Time used 0.006001s\n",
      "batch 3449, train_loss 53.315845,Time used 0.006001s\n",
      "batch 3450, train_loss 62.590736,Time used 0.006001s\n",
      "batch 3451, train_loss 52.172825,Time used 0.004996s\n",
      "batch 3452, train_loss 60.905514,Time used 0.004000s\n",
      "batch 3453, train_loss 53.332993,Time used 0.005001s\n",
      "batch 3454, train_loss 59.305157,Time used 0.005002s\n",
      "batch 3455, train_loss 45.916904,Time used 0.004999s\n",
      "batch 3456, train_loss 59.342110,Time used 0.006001s\n",
      "batch 3457, train_loss 52.273006,Time used 0.007966s\n",
      "batch 3458, train_loss 60.528229,Time used 0.005001s\n",
      "batch 3459, train_loss 56.202721,Time used 0.004998s\n",
      "batch 3460, train_loss 59.915062,Time used 0.007000s\n",
      "batch 3461, train_loss 57.378696,Time used 0.005033s\n",
      "batch 3462, train_loss 57.438202,Time used 0.003965s\n",
      "batch 3463, train_loss 65.296440,Time used 0.005962s\n",
      "batch 3464, train_loss 61.458195,Time used 0.005000s\n",
      "batch 3465, train_loss 52.527897,Time used 0.005038s\n",
      "batch 3466, train_loss 46.218143,Time used 0.004999s\n",
      "batch 3467, train_loss 58.721134,Time used 0.005966s\n",
      "batch 3468, train_loss 51.518902,Time used 0.005999s\n",
      "batch 3469, train_loss 55.782093,Time used 0.005035s\n",
      "batch 3470, train_loss 59.103477,Time used 0.004968s\n",
      "batch 3471, train_loss 44.878521,Time used 0.005999s\n",
      "batch 3472, train_loss 49.757568,Time used 0.007038s\n",
      "batch 3473, train_loss 58.826694,Time used 0.004991s\n",
      "batch 3474, train_loss 50.939877,Time used 0.004999s\n",
      "batch 3475, train_loss 50.343349,Time used 0.005969s\n",
      "batch 3476, train_loss 46.885162,Time used 0.005036s\n",
      "batch 3477, train_loss 56.869568,Time used 0.004998s\n",
      "batch 3478, train_loss 54.697582,Time used 0.004996s\n",
      "batch 3479, train_loss 56.713528,Time used 0.005036s\n",
      "batch 3480, train_loss 58.229950,Time used 0.003999s\n",
      "batch 3481, train_loss 53.672184,Time used 0.006002s\n",
      "batch 3482, train_loss 59.251278,Time used 0.007035s\n",
      "batch 3483, train_loss 48.594925,Time used 0.004964s\n",
      "batch 3484, train_loss 55.962494,Time used 0.006001s\n",
      "batch 3485, train_loss 49.043903,Time used 0.005034s\n",
      "batch 3486, train_loss 63.135105,Time used 0.004999s\n",
      "batch 3487, train_loss 59.174965,Time used 0.005000s\n",
      "batch 3488, train_loss 56.327702,Time used 0.004966s\n",
      "batch 3489, train_loss 52.636421,Time used 0.005039s\n",
      "batch 3490, train_loss 50.623936,Time used 0.004996s\n",
      "batch 3491, train_loss 58.629608,Time used 0.005000s\n",
      "batch 3492, train_loss 58.238270,Time used 0.007018s\n",
      "batch 3493, train_loss 47.576942,Time used 0.007951s\n",
      "batch 3494, train_loss 59.121410,Time used 0.008030s\n",
      "batch 3495, train_loss 43.192818,Time used 0.006964s\n",
      "batch 3496, train_loss 62.765732,Time used 0.004036s\n",
      "batch 3497, train_loss 54.410423,Time used 0.005005s\n",
      "batch 3498, train_loss 47.195190,Time used 0.004969s\n",
      "batch 3499, train_loss 64.298134,Time used 0.006041s\n",
      "batch 3500, train_loss 52.600647,Time used 0.004997s\n",
      "***************************test_batch 3500, test_rmse_loss 8.531659,test_mae_loss 3.668661,test_mape_loss 59.432098,Time used 0.025963s\n",
      "batch 3501, train_loss 58.764874,Time used 0.008041s\n",
      "batch 3502, train_loss 52.718815,Time used 0.007995s\n",
      "batch 3503, train_loss 51.053528,Time used 0.004997s\n",
      "batch 3504, train_loss 58.691269,Time used 0.006999s\n",
      "batch 3505, train_loss 53.388855,Time used 0.005998s\n",
      "batch 3506, train_loss 49.998924,Time used 0.005000s\n",
      "batch 3507, train_loss 56.705185,Time used 0.005000s\n",
      "batch 3508, train_loss 53.153843,Time used 0.006002s\n",
      "batch 3509, train_loss 55.540817,Time used 0.008037s\n",
      "batch 3510, train_loss 55.117485,Time used 0.006958s\n",
      "batch 3511, train_loss 60.692375,Time used 0.003999s\n",
      "batch 3512, train_loss 57.182751,Time used 0.003998s\n",
      "batch 3513, train_loss 67.107689,Time used 0.007004s\n",
      "batch 3514, train_loss 55.665436,Time used 0.008013s\n",
      "batch 3515, train_loss 63.796230,Time used 0.005998s\n",
      "batch 3516, train_loss 54.117069,Time used 0.004985s\n",
      "batch 3517, train_loss 61.178879,Time used 0.005001s\n",
      "batch 3518, train_loss 46.617901,Time used 0.005000s\n",
      "batch 3519, train_loss 50.737843,Time used 0.004999s\n",
      "batch 3520, train_loss 55.911854,Time used 0.006004s\n",
      "batch 3521, train_loss 53.827789,Time used 0.005998s\n",
      "batch 3522, train_loss 61.080631,Time used 0.003999s\n",
      "batch 3523, train_loss 56.485611,Time used 0.004998s\n",
      "batch 3524, train_loss 46.170967,Time used 0.006007s\n",
      "batch 3525, train_loss 49.185856,Time used 0.004994s\n",
      "batch 3526, train_loss 49.321453,Time used 0.005001s\n",
      "batch 3527, train_loss 44.851910,Time used 0.005004s\n",
      "batch 3528, train_loss 55.490070,Time used 0.005031s\n",
      "batch 3529, train_loss 52.213421,Time used 0.008000s\n",
      "batch 3530, train_loss 49.569820,Time used 0.005000s\n",
      "batch 3531, train_loss 46.119148,Time used 0.006997s\n",
      "batch 3532, train_loss 50.948116,Time used 0.007999s\n",
      "batch 3533, train_loss 47.228447,Time used 0.007002s\n",
      "batch 3534, train_loss 47.077229,Time used 0.004997s\n",
      "batch 3535, train_loss 52.758739,Time used 0.005001s\n",
      "batch 3536, train_loss 54.330616,Time used 0.006999s\n",
      "batch 3537, train_loss 60.001488,Time used 0.005000s\n",
      "batch 3538, train_loss 53.112434,Time used 0.005000s\n",
      "batch 3539, train_loss 48.803101,Time used 0.005001s\n",
      "batch 3540, train_loss 61.287075,Time used 0.004999s\n",
      "batch 3541, train_loss 55.214474,Time used 0.006000s\n",
      "batch 3542, train_loss 47.483627,Time used 0.005001s\n",
      "batch 3543, train_loss 54.591755,Time used 0.004999s\n",
      "batch 3544, train_loss 59.852707,Time used 0.006002s\n",
      "batch 3545, train_loss 57.422115,Time used 0.005016s\n",
      "batch 3546, train_loss 52.225594,Time used 0.004983s\n",
      "batch 3547, train_loss 64.622101,Time used 0.007036s\n",
      "batch 3548, train_loss 58.264580,Time used 0.004998s\n",
      "batch 3549, train_loss 57.728947,Time used 0.006969s\n",
      "batch 3550, train_loss 53.994301,Time used 0.005002s\n",
      "batch 3551, train_loss 57.448105,Time used 0.006031s\n",
      "batch 3552, train_loss 67.583359,Time used 0.004967s\n",
      "batch 3553, train_loss 51.414963,Time used 0.005000s\n",
      "batch 3554, train_loss 59.799305,Time used 0.005002s\n",
      "batch 3555, train_loss 53.979275,Time used 0.004999s\n",
      "batch 3556, train_loss 60.763115,Time used 0.005999s\n",
      "batch 3557, train_loss 45.454472,Time used 0.007036s\n",
      "batch 3558, train_loss 52.176731,Time used 0.006004s\n",
      "batch 3559, train_loss 54.920292,Time used 0.007997s\n",
      "batch 3560, train_loss 56.778843,Time used 0.007002s\n",
      "batch 3561, train_loss 48.467937,Time used 0.007001s\n",
      "batch 3562, train_loss 55.603619,Time used 0.004998s\n",
      "batch 3563, train_loss 48.461491,Time used 0.005037s\n",
      "batch 3564, train_loss 51.487495,Time used 0.005964s\n",
      "batch 3565, train_loss 60.513111,Time used 0.003998s\n",
      "batch 3566, train_loss 43.180683,Time used 0.005001s\n",
      "batch 3567, train_loss 55.086945,Time used 0.005998s\n",
      "batch 3568, train_loss 58.341473,Time used 0.004997s\n",
      "batch 3569, train_loss 50.577541,Time used 0.005000s\n",
      "batch 3570, train_loss 56.575169,Time used 0.005003s\n",
      "batch 3571, train_loss 55.081852,Time used 0.005002s\n",
      "batch 3572, train_loss 57.155254,Time used 0.004998s\n",
      "batch 3573, train_loss 58.812542,Time used 0.005000s\n",
      "batch 3574, train_loss 52.013020,Time used 0.006002s\n",
      "batch 3575, train_loss 54.953590,Time used 0.004997s\n",
      "batch 3576, train_loss 62.555374,Time used 0.004999s\n",
      "batch 3577, train_loss 48.297775,Time used 0.007002s\n",
      "batch 3578, train_loss 57.592888,Time used 0.005999s\n",
      "batch 3579, train_loss 50.558998,Time used 0.005999s\n",
      "batch 3580, train_loss 58.178749,Time used 0.006997s\n",
      "batch 3581, train_loss 48.262302,Time used 0.006002s\n",
      "batch 3582, train_loss 52.175995,Time used 0.005997s\n",
      "batch 3583, train_loss 50.116405,Time used 0.005002s\n",
      "batch 3584, train_loss 54.572285,Time used 0.005000s\n",
      "batch 3585, train_loss 52.599342,Time used 0.006001s\n",
      "batch 3586, train_loss 44.245468,Time used 0.004999s\n",
      "batch 3587, train_loss 52.189789,Time used 0.005000s\n",
      "batch 3588, train_loss 52.253216,Time used 0.005001s\n",
      "batch 3589, train_loss 64.386993,Time used 0.005994s\n",
      "batch 3590, train_loss 60.988930,Time used 0.005999s\n",
      "batch 3591, train_loss 53.490746,Time used 0.005000s\n",
      "batch 3592, train_loss 55.295727,Time used 0.004999s\n",
      "batch 3593, train_loss 54.907658,Time used 0.005000s\n",
      "batch 3594, train_loss 53.975510,Time used 0.005002s\n",
      "batch 3595, train_loss 56.430336,Time used 0.004999s\n",
      "batch 3596, train_loss 65.578476,Time used 0.008000s\n",
      "batch 3597, train_loss 46.871696,Time used 0.007000s\n",
      "batch 3598, train_loss 50.204689,Time used 0.004999s\n",
      "batch 3599, train_loss 57.815861,Time used 0.005000s\n",
      "batch 3600, train_loss 58.306755,Time used 0.005001s\n",
      "***************************test_batch 3600, test_rmse_loss 8.422947,test_mae_loss 3.636563,test_mape_loss 59.927117,Time used 0.020999s\n",
      "batch 3601, train_loss 56.743885,Time used 0.006003s\n",
      "batch 3602, train_loss 65.284554,Time used 0.007999s\n",
      "batch 3603, train_loss 50.238514,Time used 0.005000s\n",
      "batch 3604, train_loss 54.875790,Time used 0.005998s\n",
      "batch 3605, train_loss 53.961639,Time used 0.005001s\n",
      "batch 3606, train_loss 51.110229,Time used 0.004999s\n",
      "batch 3607, train_loss 49.035683,Time used 0.006001s\n",
      "batch 3608, train_loss 49.387863,Time used 0.006000s\n",
      "batch 3609, train_loss 52.447292,Time used 0.004999s\n",
      "batch 3610, train_loss 49.158531,Time used 0.005000s\n",
      "batch 3611, train_loss 50.834713,Time used 0.005001s\n",
      "batch 3612, train_loss 51.733643,Time used 0.004997s\n",
      "batch 3613, train_loss 51.294819,Time used 0.008001s\n",
      "batch 3614, train_loss 54.656719,Time used 0.004999s\n",
      "batch 3615, train_loss 53.935829,Time used 0.005003s\n",
      "batch 3616, train_loss 54.691490,Time used 0.007998s\n",
      "batch 3617, train_loss 57.487934,Time used 0.006999s\n",
      "batch 3618, train_loss 46.795948,Time used 0.005999s\n",
      "batch 3619, train_loss 69.545212,Time used 0.004998s\n",
      "batch 3620, train_loss 59.362793,Time used 0.006000s\n",
      "batch 3621, train_loss 46.689594,Time used 0.008006s\n",
      "batch 3622, train_loss 47.912392,Time used 0.006996s\n",
      "batch 3623, train_loss 58.212517,Time used 0.004999s\n",
      "batch 3624, train_loss 59.642212,Time used 0.005001s\n",
      "batch 3625, train_loss 58.674419,Time used 0.007998s\n",
      "batch 3626, train_loss 54.246231,Time used 0.008003s\n",
      "batch 3627, train_loss 50.246662,Time used 0.004997s\n",
      "batch 3628, train_loss 59.914436,Time used 0.006001s\n",
      "batch 3629, train_loss 51.340668,Time used 0.004998s\n",
      "batch 3630, train_loss 44.211422,Time used 0.006001s\n",
      "batch 3631, train_loss 63.347988,Time used 0.005037s\n",
      "batch 3632, train_loss 58.712437,Time used 0.004968s\n",
      "batch 3633, train_loss 53.092590,Time used 0.005031s\n",
      "batch 3634, train_loss 41.428303,Time used 0.005965s\n",
      "batch 3635, train_loss 54.631165,Time used 0.007008s\n",
      "batch 3636, train_loss 57.861488,Time used 0.004990s\n",
      "batch 3637, train_loss 50.167488,Time used 0.008039s\n",
      "batch 3638, train_loss 45.586563,Time used 0.005999s\n",
      "batch 3639, train_loss 55.115623,Time used 0.006999s\n",
      "batch 3640, train_loss 56.467571,Time used 0.006969s\n",
      "batch 3641, train_loss 65.037766,Time used 0.006967s\n",
      "batch 3642, train_loss 52.011456,Time used 0.006000s\n",
      "batch 3643, train_loss 45.613022,Time used 0.006995s\n",
      "batch 3644, train_loss 58.726856,Time used 0.007003s\n",
      "batch 3645, train_loss 62.949844,Time used 0.007000s\n",
      "batch 3646, train_loss 47.962898,Time used 0.008004s\n",
      "batch 3647, train_loss 56.718815,Time used 0.008000s\n",
      "batch 3648, train_loss 46.059490,Time used 0.005000s\n",
      "batch 3649, train_loss 65.886353,Time used 0.005996s\n",
      "batch 3650, train_loss 52.780357,Time used 0.005000s\n",
      "batch 3651, train_loss 60.682182,Time used 0.007000s\n",
      "batch 3652, train_loss 52.983307,Time used 0.005000s\n",
      "batch 3653, train_loss 59.153782,Time used 0.005000s\n",
      "batch 3654, train_loss 47.813877,Time used 0.005002s\n",
      "batch 3655, train_loss 53.921951,Time used 0.005038s\n",
      "batch 3656, train_loss 48.859879,Time used 0.005000s\n",
      "batch 3657, train_loss 43.887344,Time used 0.004993s\n",
      "batch 3658, train_loss 55.112488,Time used 0.005963s\n",
      "batch 3659, train_loss 60.847000,Time used 0.005000s\n",
      "batch 3660, train_loss 53.710304,Time used 0.005001s\n",
      "batch 3661, train_loss 64.364815,Time used 0.005000s\n",
      "batch 3662, train_loss 55.786182,Time used 0.005000s\n",
      "batch 3663, train_loss 58.969910,Time used 0.005000s\n",
      "batch 3664, train_loss 56.521591,Time used 0.005034s\n",
      "batch 3665, train_loss 36.670227,Time used 0.004032s\n",
      "batch 3666, train_loss 49.383572,Time used 0.006970s\n",
      "batch 3667, train_loss 52.266171,Time used 0.006999s\n",
      "batch 3668, train_loss 53.933449,Time used 0.005028s\n",
      "batch 3669, train_loss 53.645813,Time used 0.008972s\n",
      "batch 3670, train_loss 49.552757,Time used 0.008001s\n",
      "batch 3671, train_loss 45.233891,Time used 0.007999s\n",
      "batch 3672, train_loss 54.121300,Time used 0.004999s\n",
      "batch 3673, train_loss 54.656876,Time used 0.004964s\n",
      "batch 3674, train_loss 55.594467,Time used 0.005002s\n",
      "batch 3675, train_loss 52.153412,Time used 0.004999s\n",
      "batch 3676, train_loss 45.290485,Time used 0.006001s\n",
      "batch 3677, train_loss 57.988407,Time used 0.004999s\n",
      "batch 3678, train_loss 49.780174,Time used 0.006000s\n",
      "batch 3679, train_loss 51.471943,Time used 0.007046s\n",
      "batch 3680, train_loss 43.073887,Time used 0.006951s\n",
      "batch 3681, train_loss 54.014488,Time used 0.007001s\n",
      "batch 3682, train_loss 58.300179,Time used 0.007002s\n",
      "batch 3683, train_loss 61.140675,Time used 0.004998s\n",
      "batch 3684, train_loss 57.859943,Time used 0.005001s\n",
      "batch 3685, train_loss 60.754311,Time used 0.004999s\n",
      "batch 3686, train_loss 50.538738,Time used 0.005034s\n",
      "batch 3687, train_loss 63.158260,Time used 0.008005s\n",
      "batch 3688, train_loss 52.959858,Time used 0.005996s\n",
      "batch 3689, train_loss 52.058437,Time used 0.004000s\n",
      "batch 3690, train_loss 48.825809,Time used 0.003964s\n",
      "batch 3691, train_loss 53.077034,Time used 0.006002s\n",
      "batch 3692, train_loss 49.095142,Time used 0.004999s\n",
      "batch 3693, train_loss 63.547169,Time used 0.005000s\n",
      "batch 3694, train_loss 47.265850,Time used 0.005000s\n",
      "batch 3695, train_loss 47.023960,Time used 0.007033s\n",
      "batch 3696, train_loss 50.946266,Time used 0.006999s\n",
      "batch 3697, train_loss 53.153214,Time used 0.007000s\n",
      "batch 3698, train_loss 57.287086,Time used 0.007997s\n",
      "batch 3699, train_loss 55.996796,Time used 0.008000s\n",
      "batch 3700, train_loss 56.787666,Time used 0.007001s\n",
      "***************************test_batch 3700, test_rmse_loss 8.456895,test_mae_loss 3.637419,test_mape_loss 58.715445,Time used 0.026003s\n",
      "batch 3701, train_loss 60.601707,Time used 0.006997s\n",
      "batch 3702, train_loss 43.693142,Time used 0.004997s\n",
      "batch 3703, train_loss 46.829399,Time used 0.007004s\n",
      "batch 3704, train_loss 54.274200,Time used 0.007999s\n",
      "batch 3705, train_loss 49.721203,Time used 0.006004s\n",
      "batch 3706, train_loss 53.844334,Time used 0.004999s\n",
      "batch 3707, train_loss 52.673061,Time used 0.003997s\n",
      "batch 3708, train_loss 43.086044,Time used 0.006969s\n",
      "batch 3709, train_loss 62.615742,Time used 0.006997s\n",
      "batch 3710, train_loss 60.449303,Time used 0.007000s\n",
      "batch 3711, train_loss 51.650707,Time used 0.005997s\n",
      "batch 3712, train_loss 56.236710,Time used 0.005033s\n",
      "batch 3713, train_loss 56.100060,Time used 0.004971s\n",
      "batch 3714, train_loss 56.594959,Time used 0.004998s\n",
      "batch 3715, train_loss 59.265610,Time used 0.005039s\n",
      "batch 3716, train_loss 45.039879,Time used 0.006963s\n",
      "batch 3717, train_loss 61.492126,Time used 0.004999s\n",
      "batch 3718, train_loss 48.636734,Time used 0.004998s\n",
      "batch 3719, train_loss 46.509159,Time used 0.006001s\n",
      "batch 3720, train_loss 43.042751,Time used 0.005999s\n",
      "batch 3721, train_loss 47.251057,Time used 0.005000s\n",
      "batch 3722, train_loss 48.480312,Time used 0.004997s\n",
      "batch 3723, train_loss 46.331848,Time used 0.005969s\n",
      "batch 3724, train_loss 51.798199,Time used 0.007997s\n",
      "batch 3725, train_loss 55.068802,Time used 0.006999s\n",
      "batch 3726, train_loss 53.837166,Time used 0.004999s\n",
      "batch 3727, train_loss 57.242886,Time used 0.006001s\n",
      "batch 3728, train_loss 63.183529,Time used 0.004999s\n",
      "batch 3729, train_loss 43.563026,Time used 0.004999s\n",
      "batch 3730, train_loss 57.886578,Time used 0.005000s\n",
      "batch 3731, train_loss 54.316505,Time used 0.006006s\n",
      "batch 3732, train_loss 43.665508,Time used 0.004998s\n",
      "batch 3733, train_loss 45.146400,Time used 0.005034s\n",
      "batch 3734, train_loss 65.530663,Time used 0.006015s\n",
      "batch 3735, train_loss 58.869034,Time used 0.007985s\n",
      "batch 3736, train_loss 54.003021,Time used 0.007967s\n",
      "batch 3737, train_loss 47.985111,Time used 0.005027s\n",
      "batch 3738, train_loss 40.802013,Time used 0.005004s\n",
      "batch 3739, train_loss 55.097347,Time used 0.004003s\n",
      "batch 3740, train_loss 57.490967,Time used 0.004994s\n",
      "batch 3741, train_loss 62.207104,Time used 0.004975s\n",
      "batch 3742, train_loss 56.815113,Time used 0.005030s\n",
      "batch 3743, train_loss 46.844475,Time used 0.004963s\n",
      "batch 3744, train_loss 57.608196,Time used 0.004003s\n",
      "batch 3745, train_loss 52.085117,Time used 0.003999s\n",
      "batch 3746, train_loss 59.461391,Time used 0.004999s\n",
      "batch 3747, train_loss 52.402348,Time used 0.004966s\n",
      "batch 3748, train_loss 60.725998,Time used 0.005033s\n",
      "batch 3749, train_loss 51.686485,Time used 0.005002s\n",
      "batch 3750, train_loss 56.549583,Time used 0.005003s\n",
      "batch 3751, train_loss 58.892639,Time used 0.004997s\n",
      "batch 3752, train_loss 58.446636,Time used 0.005999s\n",
      "batch 3753, train_loss 53.670326,Time used 0.004964s\n",
      "batch 3754, train_loss 50.316101,Time used 0.005998s\n",
      "batch 3755, train_loss 39.721474,Time used 0.005002s\n",
      "batch 3756, train_loss 48.794594,Time used 0.004999s\n",
      "batch 3757, train_loss 58.462414,Time used 0.007001s\n",
      "batch 3758, train_loss 50.763199,Time used 0.005000s\n",
      "batch 3759, train_loss 59.129490,Time used 0.005000s\n",
      "batch 3760, train_loss 56.483448,Time used 0.006000s\n",
      "batch 3761, train_loss 53.069679,Time used 0.005001s\n",
      "batch 3762, train_loss 38.893051,Time used 0.008001s\n",
      "batch 3763, train_loss 42.443367,Time used 0.005000s\n",
      "batch 3764, train_loss 58.644615,Time used 0.005034s\n",
      "batch 3765, train_loss 52.282314,Time used 0.005968s\n",
      "batch 3766, train_loss 52.976261,Time used 0.003998s\n",
      "batch 3767, train_loss 56.176201,Time used 0.005000s\n",
      "batch 3768, train_loss 43.864368,Time used 0.004999s\n",
      "batch 3769, train_loss 52.517185,Time used 0.005000s\n",
      "batch 3770, train_loss 48.518959,Time used 0.006037s\n",
      "batch 3771, train_loss 57.591190,Time used 0.007966s\n",
      "batch 3772, train_loss 59.225578,Time used 0.005035s\n",
      "batch 3773, train_loss 56.222626,Time used 0.004994s\n",
      "batch 3774, train_loss 49.366234,Time used 0.005006s\n",
      "batch 3775, train_loss 55.380211,Time used 0.003994s\n",
      "batch 3776, train_loss 43.490635,Time used 0.007966s\n",
      "batch 3777, train_loss 66.989723,Time used 0.007000s\n",
      "batch 3778, train_loss 47.303520,Time used 0.006003s\n",
      "batch 3779, train_loss 57.359013,Time used 0.004998s\n",
      "batch 3780, train_loss 58.024406,Time used 0.005000s\n",
      "batch 3781, train_loss 52.659142,Time used 0.005005s\n",
      "batch 3782, train_loss 54.889740,Time used 0.005033s\n",
      "batch 3783, train_loss 48.834900,Time used 0.004999s\n",
      "batch 3784, train_loss 52.655647,Time used 0.005000s\n",
      "batch 3785, train_loss 46.162659,Time used 0.005002s\n",
      "batch 3786, train_loss 44.268791,Time used 0.004998s\n",
      "batch 3787, train_loss 55.791210,Time used 0.005011s\n",
      "batch 3788, train_loss 49.261936,Time used 0.004954s\n",
      "batch 3789, train_loss 48.800709,Time used 0.005001s\n",
      "batch 3790, train_loss 46.718472,Time used 0.005003s\n",
      "batch 3791, train_loss 50.919262,Time used 0.004998s\n",
      "batch 3792, train_loss 61.515633,Time used 0.005001s\n",
      "batch 3793, train_loss 60.921490,Time used 0.005001s\n",
      "batch 3794, train_loss 47.414108,Time used 0.005996s\n",
      "batch 3795, train_loss 61.343601,Time used 0.007998s\n",
      "batch 3796, train_loss 54.496040,Time used 0.007006s\n",
      "batch 3797, train_loss 45.037689,Time used 0.006034s\n",
      "batch 3798, train_loss 55.884209,Time used 0.004963s\n",
      "batch 3799, train_loss 57.554008,Time used 0.005033s\n",
      "batch 3800, train_loss 54.376488,Time used 0.005002s\n",
      "***************************test_batch 3800, test_rmse_loss 8.418921,test_mae_loss 3.621024,test_mape_loss 58.535811,Time used 0.021999s\n",
      "batch 3801, train_loss 53.761131,Time used 0.004968s\n",
      "batch 3802, train_loss 58.632240,Time used 0.006999s\n",
      "batch 3803, train_loss 40.547348,Time used 0.008000s\n",
      "batch 3804, train_loss 51.187862,Time used 0.005000s\n",
      "batch 3805, train_loss 55.508312,Time used 0.007002s\n",
      "batch 3806, train_loss 44.914452,Time used 0.007040s\n",
      "batch 3807, train_loss 54.103527,Time used 0.004995s\n",
      "batch 3808, train_loss 49.132439,Time used 0.005000s\n",
      "batch 3809, train_loss 45.501400,Time used 0.005001s\n",
      "batch 3810, train_loss 61.163471,Time used 0.007960s\n",
      "batch 3811, train_loss 45.940617,Time used 0.004000s\n",
      "batch 3812, train_loss 52.924171,Time used 0.007001s\n",
      "batch 3813, train_loss 52.376614,Time used 0.005000s\n",
      "batch 3814, train_loss 49.255169,Time used 0.004001s\n",
      "batch 3815, train_loss 50.073154,Time used 0.005021s\n",
      "batch 3816, train_loss 55.792076,Time used 0.005010s\n",
      "batch 3817, train_loss 41.836685,Time used 0.005997s\n",
      "batch 3818, train_loss 49.786739,Time used 0.005034s\n",
      "batch 3819, train_loss 61.362648,Time used 0.004963s\n",
      "batch 3820, train_loss 40.385357,Time used 0.007999s\n",
      "batch 3821, train_loss 54.197567,Time used 0.005002s\n",
      "batch 3822, train_loss 56.574825,Time used 0.006006s\n",
      "batch 3823, train_loss 49.120720,Time used 0.005032s\n",
      "batch 3824, train_loss 52.569420,Time used 0.006002s\n",
      "batch 3825, train_loss 42.729404,Time used 0.006961s\n",
      "batch 3826, train_loss 45.695824,Time used 0.007004s\n",
      "batch 3827, train_loss 45.848965,Time used 0.006032s\n",
      "batch 3828, train_loss 64.961594,Time used 0.005002s\n",
      "batch 3829, train_loss 53.469296,Time used 0.004964s\n",
      "batch 3830, train_loss 64.279053,Time used 0.007999s\n",
      "batch 3831, train_loss 57.747215,Time used 0.005002s\n",
      "batch 3832, train_loss 52.030579,Time used 0.005000s\n",
      "batch 3833, train_loss 63.054325,Time used 0.004996s\n",
      "batch 3834, train_loss 47.357998,Time used 0.004998s\n",
      "batch 3835, train_loss 51.234493,Time used 0.004000s\n",
      "batch 3836, train_loss 57.517620,Time used 0.005001s\n",
      "batch 3837, train_loss 52.496037,Time used 0.005005s\n",
      "batch 3838, train_loss 56.499104,Time used 0.007001s\n",
      "batch 3839, train_loss 44.342945,Time used 0.008037s\n",
      "batch 3840, train_loss 46.554161,Time used 0.007000s\n",
      "batch 3841, train_loss 49.556271,Time used 0.007000s\n",
      "batch 3842, train_loss 57.874168,Time used 0.007005s\n",
      "batch 3843, train_loss 49.020969,Time used 0.005001s\n",
      "batch 3844, train_loss 46.614517,Time used 0.006002s\n",
      "batch 3845, train_loss 55.158627,Time used 0.007998s\n",
      "batch 3846, train_loss 42.981476,Time used 0.007002s\n",
      "batch 3847, train_loss 45.564289,Time used 0.004997s\n",
      "batch 3848, train_loss 63.012871,Time used 0.005001s\n",
      "batch 3849, train_loss 43.566364,Time used 0.006004s\n",
      "batch 3850, train_loss 51.419353,Time used 0.008000s\n",
      "batch 3851, train_loss 48.719635,Time used 0.006999s\n",
      "batch 3852, train_loss 47.373768,Time used 0.004965s\n",
      "batch 3853, train_loss 52.091980,Time used 0.007000s\n",
      "batch 3854, train_loss 56.567230,Time used 0.007996s\n",
      "batch 3855, train_loss 51.765606,Time used 0.005998s\n",
      "batch 3856, train_loss 61.099236,Time used 0.008965s\n",
      "batch 3857, train_loss 56.908257,Time used 0.006998s\n",
      "batch 3858, train_loss 47.761669,Time used 0.008038s\n",
      "batch 3859, train_loss 54.124992,Time used 0.004963s\n",
      "batch 3860, train_loss 52.644753,Time used 0.007038s\n",
      "batch 3861, train_loss 55.123501,Time used 0.004994s\n",
      "batch 3862, train_loss 59.456730,Time used 0.004969s\n",
      "batch 3863, train_loss 57.646847,Time used 0.005000s\n",
      "batch 3864, train_loss 41.678493,Time used 0.005036s\n",
      "batch 3865, train_loss 45.088734,Time used 0.008000s\n",
      "batch 3866, train_loss 57.210167,Time used 0.008001s\n",
      "batch 3867, train_loss 55.524899,Time used 0.007999s\n",
      "batch 3868, train_loss 47.470993,Time used 0.009026s\n",
      "batch 3869, train_loss 54.809551,Time used 0.008013s\n",
      "batch 3870, train_loss 55.176155,Time used 0.008013s\n",
      "batch 3871, train_loss 60.201660,Time used 0.007962s\n",
      "batch 3872, train_loss 55.209896,Time used 0.005999s\n",
      "batch 3873, train_loss 49.226486,Time used 0.005005s\n",
      "batch 3874, train_loss 41.690224,Time used 0.005999s\n",
      "batch 3875, train_loss 55.374889,Time used 0.006996s\n",
      "batch 3876, train_loss 51.188721,Time used 0.006004s\n",
      "batch 3877, train_loss 45.119789,Time used 0.004996s\n",
      "batch 3878, train_loss 64.180717,Time used 0.005000s\n",
      "batch 3879, train_loss 55.801769,Time used 0.009000s\n",
      "batch 3880, train_loss 52.954048,Time used 0.008004s\n",
      "batch 3881, train_loss 44.662373,Time used 0.007000s\n",
      "batch 3882, train_loss 40.913815,Time used 0.004997s\n",
      "batch 3883, train_loss 47.939152,Time used 0.005000s\n",
      "batch 3884, train_loss 54.292625,Time used 0.005002s\n",
      "batch 3885, train_loss 50.374413,Time used 0.006000s\n",
      "batch 3886, train_loss 55.130676,Time used 0.005030s\n",
      "batch 3887, train_loss 55.017036,Time used 0.004968s\n",
      "batch 3888, train_loss 47.880341,Time used 0.004999s\n",
      "batch 3889, train_loss 52.362011,Time used 0.005958s\n",
      "batch 3890, train_loss 50.207417,Time used 0.005002s\n",
      "batch 3891, train_loss 54.981285,Time used 0.005000s\n",
      "batch 3892, train_loss 54.187881,Time used 0.007004s\n",
      "batch 3893, train_loss 39.162651,Time used 0.004999s\n",
      "batch 3894, train_loss 49.604324,Time used 0.006001s\n",
      "batch 3895, train_loss 54.583580,Time used 0.006003s\n",
      "batch 3896, train_loss 50.759010,Time used 0.004998s\n",
      "batch 3897, train_loss 47.565525,Time used 0.005003s\n",
      "batch 3898, train_loss 51.652920,Time used 0.004996s\n",
      "batch 3899, train_loss 49.912960,Time used 0.005000s\n",
      "batch 3900, train_loss 51.798267,Time used 0.008038s\n",
      "***************************test_batch 3900, test_rmse_loss 8.281959,test_mae_loss 3.579547,test_mape_loss 59.098116,Time used 0.021033s\n",
      "batch 3901, train_loss 51.674068,Time used 0.005968s\n",
      "batch 3902, train_loss 50.626484,Time used 0.005999s\n",
      "batch 3903, train_loss 50.622154,Time used 0.006001s\n",
      "batch 3904, train_loss 49.485550,Time used 0.005001s\n",
      "batch 3905, train_loss 70.341118,Time used 0.008034s\n",
      "batch 3906, train_loss 59.998917,Time used 0.005966s\n",
      "batch 3907, train_loss 43.020473,Time used 0.005002s\n",
      "batch 3908, train_loss 41.148403,Time used 0.005000s\n",
      "batch 3909, train_loss 47.566734,Time used 0.005996s\n",
      "batch 3910, train_loss 57.690151,Time used 0.005000s\n",
      "batch 3911, train_loss 52.135242,Time used 0.006000s\n",
      "batch 3912, train_loss 57.593876,Time used 0.005001s\n",
      "batch 3913, train_loss 53.451252,Time used 0.005997s\n",
      "batch 3914, train_loss 51.612328,Time used 0.005034s\n",
      "batch 3915, train_loss 55.438526,Time used 0.005001s\n",
      "batch 3916, train_loss 50.234829,Time used 0.004966s\n",
      "batch 3917, train_loss 46.622906,Time used 0.005035s\n",
      "batch 3918, train_loss 49.871891,Time used 0.005000s\n",
      "batch 3919, train_loss 59.651989,Time used 0.005965s\n",
      "batch 3920, train_loss 45.675560,Time used 0.006034s\n",
      "batch 3921, train_loss 52.613071,Time used 0.004969s\n",
      "batch 3922, train_loss 47.803219,Time used 0.005999s\n",
      "batch 3923, train_loss 57.981060,Time used 0.007034s\n",
      "batch 3924, train_loss 50.986259,Time used 0.006003s\n",
      "batch 3925, train_loss 60.829834,Time used 0.004993s\n",
      "batch 3926, train_loss 47.000519,Time used 0.005013s\n",
      "batch 3927, train_loss 47.861553,Time used 0.004990s\n",
      "batch 3928, train_loss 48.497051,Time used 0.006964s\n",
      "batch 3929, train_loss 59.882607,Time used 0.005000s\n",
      "batch 3930, train_loss 43.304081,Time used 0.007000s\n",
      "batch 3931, train_loss 48.804623,Time used 0.005035s\n",
      "batch 3932, train_loss 61.762611,Time used 0.005002s\n",
      "batch 3933, train_loss 43.187401,Time used 0.007023s\n",
      "batch 3934, train_loss 55.562481,Time used 0.005012s\n",
      "batch 3935, train_loss 49.439636,Time used 0.005967s\n",
      "batch 3936, train_loss 46.438286,Time used 0.005031s\n",
      "batch 3937, train_loss 56.684727,Time used 0.006990s\n",
      "batch 3938, train_loss 59.881653,Time used 0.007998s\n",
      "batch 3939, train_loss 46.373257,Time used 0.007041s\n",
      "batch 3940, train_loss 53.202732,Time used 0.004004s\n",
      "batch 3941, train_loss 42.236862,Time used 0.004029s\n",
      "batch 3942, train_loss 58.296963,Time used 0.005000s\n",
      "batch 3943, train_loss 51.352608,Time used 0.004961s\n",
      "batch 3944, train_loss 38.474148,Time used 0.004035s\n",
      "batch 3945, train_loss 46.918167,Time used 0.006964s\n",
      "batch 3946, train_loss 48.340553,Time used 0.007999s\n",
      "batch 3947, train_loss 49.708286,Time used 0.007000s\n",
      "batch 3948, train_loss 55.696533,Time used 0.005998s\n",
      "batch 3949, train_loss 57.447170,Time used 0.006001s\n",
      "batch 3950, train_loss 52.114407,Time used 0.006003s\n",
      "batch 3951, train_loss 52.577026,Time used 0.004030s\n",
      "batch 3952, train_loss 51.585217,Time used 0.003965s\n",
      "batch 3953, train_loss 52.731495,Time used 0.006003s\n",
      "batch 3954, train_loss 49.266724,Time used 0.005035s\n",
      "batch 3955, train_loss 45.336403,Time used 0.005962s\n",
      "batch 3956, train_loss 47.713764,Time used 0.005036s\n",
      "batch 3957, train_loss 49.941971,Time used 0.006000s\n",
      "batch 3958, train_loss 49.885612,Time used 0.004964s\n",
      "batch 3959, train_loss 56.669369,Time used 0.007999s\n",
      "batch 3960, train_loss 57.774380,Time used 0.005000s\n",
      "batch 3961, train_loss 60.250740,Time used 0.008001s\n",
      "batch 3962, train_loss 49.341579,Time used 0.006002s\n",
      "batch 3963, train_loss 46.255741,Time used 0.007000s\n",
      "batch 3964, train_loss 51.226269,Time used 0.008040s\n",
      "batch 3965, train_loss 53.400421,Time used 0.007995s\n",
      "batch 3966, train_loss 39.836891,Time used 0.005001s\n",
      "batch 3967, train_loss 58.342728,Time used 0.005964s\n",
      "batch 3968, train_loss 53.443268,Time used 0.005001s\n",
      "batch 3969, train_loss 44.863930,Time used 0.004999s\n",
      "batch 3970, train_loss 51.390160,Time used 0.005002s\n",
      "batch 3971, train_loss 50.667522,Time used 0.005004s\n",
      "batch 3972, train_loss 47.262302,Time used 0.004998s\n",
      "batch 3973, train_loss 46.454964,Time used 0.006000s\n",
      "batch 3974, train_loss 50.699306,Time used 0.005001s\n",
      "batch 3975, train_loss 56.554256,Time used 0.006996s\n",
      "batch 3976, train_loss 46.752605,Time used 0.005999s\n",
      "batch 3977, train_loss 50.197529,Time used 0.007004s\n",
      "batch 3978, train_loss 51.623413,Time used 0.008996s\n",
      "batch 3979, train_loss 48.301098,Time used 0.008001s\n",
      "batch 3980, train_loss 58.354439,Time used 0.007000s\n",
      "batch 3981, train_loss 50.115772,Time used 0.006040s\n",
      "batch 3982, train_loss 50.820843,Time used 0.006997s\n",
      "batch 3983, train_loss 56.993809,Time used 0.005965s\n",
      "batch 3984, train_loss 53.325939,Time used 0.005033s\n",
      "batch 3985, train_loss 42.992626,Time used 0.005984s\n",
      "batch 3986, train_loss 50.225597,Time used 0.005964s\n",
      "batch 3987, train_loss 41.801338,Time used 0.005001s\n",
      "batch 3988, train_loss 54.477158,Time used 0.006000s\n",
      "batch 3989, train_loss 42.430527,Time used 0.005001s\n",
      "batch 3990, train_loss 56.316811,Time used 0.004999s\n",
      "batch 3991, train_loss 43.940273,Time used 0.006002s\n",
      "batch 3992, train_loss 49.880520,Time used 0.007026s\n",
      "batch 3993, train_loss 57.443970,Time used 0.004000s\n",
      "batch 3994, train_loss 64.227585,Time used 0.004966s\n",
      "batch 3995, train_loss 43.988991,Time used 0.005000s\n",
      "batch 3996, train_loss 54.797787,Time used 0.004999s\n",
      "batch 3997, train_loss 44.254677,Time used 0.005000s\n",
      "batch 3998, train_loss 63.141132,Time used 0.005001s\n",
      "batch 3999, train_loss 50.644623,Time used 0.005035s\n",
      "batch 4000, train_loss 54.852695,Time used 0.007963s\n",
      "***************************test_batch 4000, test_rmse_loss 8.214234,test_mae_loss 3.556631,test_mape_loss 58.736936,Time used 0.017035s\n",
      "batch 4001, train_loss 51.577309,Time used 0.006966s\n",
      "batch 4002, train_loss 54.533127,Time used 0.007998s\n",
      "batch 4003, train_loss 45.344780,Time used 0.006999s\n",
      "batch 4004, train_loss 45.787109,Time used 0.008006s\n",
      "batch 4005, train_loss 55.501858,Time used 0.005035s\n",
      "batch 4006, train_loss 53.565231,Time used 0.004968s\n",
      "batch 4007, train_loss 46.510960,Time used 0.005031s\n",
      "batch 4008, train_loss 46.487888,Time used 0.004012s\n",
      "batch 4009, train_loss 63.110729,Time used 0.004997s\n",
      "batch 4010, train_loss 58.075588,Time used 0.005001s\n",
      "batch 4011, train_loss 45.339996,Time used 0.006004s\n",
      "batch 4012, train_loss 45.958282,Time used 0.004999s\n",
      "batch 4013, train_loss 51.365860,Time used 0.005001s\n",
      "batch 4014, train_loss 43.618130,Time used 0.005996s\n",
      "batch 4015, train_loss 59.831848,Time used 0.006999s\n",
      "batch 4016, train_loss 40.290874,Time used 0.006999s\n",
      "batch 4017, train_loss 41.334244,Time used 0.007038s\n",
      "batch 4018, train_loss 56.847736,Time used 0.005002s\n",
      "batch 4019, train_loss 44.365543,Time used 0.005962s\n",
      "batch 4020, train_loss 55.621349,Time used 0.005000s\n",
      "batch 4021, train_loss 36.535095,Time used 0.005998s\n",
      "batch 4022, train_loss 48.714809,Time used 0.006004s\n",
      "batch 4023, train_loss 42.181335,Time used 0.004998s\n",
      "batch 4024, train_loss 50.747074,Time used 0.008000s\n",
      "batch 4025, train_loss 57.157688,Time used 0.005002s\n",
      "batch 4026, train_loss 47.642014,Time used 0.004997s\n",
      "batch 4027, train_loss 48.107719,Time used 0.006038s\n",
      "batch 4028, train_loss 49.863667,Time used 0.006999s\n",
      "batch 4029, train_loss 56.959122,Time used 0.004963s\n",
      "batch 4030, train_loss 45.626137,Time used 0.006004s\n",
      "batch 4031, train_loss 47.563374,Time used 0.004037s\n",
      "batch 4032, train_loss 54.806049,Time used 0.004999s\n",
      "batch 4033, train_loss 43.787914,Time used 0.006999s\n",
      "batch 4034, train_loss 53.221592,Time used 0.006003s\n",
      "batch 4035, train_loss 37.861355,Time used 0.004998s\n",
      "batch 4036, train_loss 44.291275,Time used 0.007003s\n",
      "batch 4037, train_loss 43.328522,Time used 0.004995s\n",
      "batch 4038, train_loss 56.011566,Time used 0.003998s\n",
      "batch 4039, train_loss 56.576077,Time used 0.006003s\n",
      "batch 4040, train_loss 53.630478,Time used 0.004999s\n",
      "batch 4041, train_loss 42.777828,Time used 0.005002s\n",
      "batch 4042, train_loss 43.086498,Time used 0.007002s\n",
      "batch 4043, train_loss 52.047165,Time used 0.007020s\n",
      "batch 4044, train_loss 55.826305,Time used 0.004962s\n",
      "batch 4045, train_loss 57.765171,Time used 0.007039s\n",
      "batch 4046, train_loss 48.343460,Time used 0.007961s\n",
      "batch 4047, train_loss 43.839539,Time used 0.005035s\n",
      "batch 4048, train_loss 40.783108,Time used 0.004997s\n",
      "batch 4049, train_loss 43.048470,Time used 0.004968s\n",
      "batch 4050, train_loss 50.161915,Time used 0.006000s\n",
      "batch 4051, train_loss 49.664928,Time used 0.004998s\n",
      "batch 4052, train_loss 50.563667,Time used 0.006040s\n",
      "batch 4053, train_loss 57.226151,Time used 0.004971s\n",
      "batch 4054, train_loss 43.622295,Time used 0.007998s\n",
      "batch 4055, train_loss 51.094990,Time used 0.004996s\n",
      "batch 4056, train_loss 57.235767,Time used 0.005000s\n",
      "batch 4057, train_loss 51.058647,Time used 0.005034s\n",
      "batch 4058, train_loss 53.655205,Time used 0.006966s\n",
      "batch 4059, train_loss 45.892567,Time used 0.008036s\n",
      "batch 4060, train_loss 34.383732,Time used 0.004993s\n",
      "batch 4061, train_loss 39.485519,Time used 0.005969s\n",
      "batch 4062, train_loss 51.479687,Time used 0.007000s\n",
      "batch 4063, train_loss 51.739727,Time used 0.005002s\n",
      "batch 4064, train_loss 44.410439,Time used 0.005031s\n",
      "batch 4065, train_loss 49.120697,Time used 0.005002s\n",
      "batch 4066, train_loss 45.747051,Time used 0.005033s\n",
      "batch 4067, train_loss 60.330807,Time used 0.005001s\n",
      "batch 4068, train_loss 52.721230,Time used 0.004968s\n",
      "batch 4069, train_loss 47.332726,Time used 0.005033s\n",
      "batch 4070, train_loss 49.097816,Time used 0.006999s\n",
      "batch 4071, train_loss 45.544483,Time used 0.005000s\n",
      "batch 4072, train_loss 57.231327,Time used 0.005000s\n",
      "batch 4073, train_loss 45.294380,Time used 0.004998s\n",
      "batch 4074, train_loss 45.786602,Time used 0.004000s\n",
      "batch 4075, train_loss 47.233749,Time used 0.003966s\n",
      "batch 4076, train_loss 59.220676,Time used 0.005031s\n",
      "batch 4077, train_loss 48.598347,Time used 0.005001s\n",
      "batch 4078, train_loss 50.186745,Time used 0.005966s\n",
      "batch 4079, train_loss 42.481323,Time used 0.005999s\n",
      "batch 4080, train_loss 47.037136,Time used 0.005001s\n",
      "batch 4081, train_loss 49.255470,Time used 0.008004s\n",
      "batch 4082, train_loss 48.096817,Time used 0.008032s\n",
      "batch 4083, train_loss 45.657551,Time used 0.007964s\n",
      "batch 4084, train_loss 45.356674,Time used 0.005001s\n",
      "batch 4085, train_loss 50.755272,Time used 0.005000s\n",
      "batch 4086, train_loss 41.810997,Time used 0.004997s\n",
      "batch 4087, train_loss 50.004265,Time used 0.004000s\n",
      "batch 4088, train_loss 42.717915,Time used 0.005000s\n",
      "batch 4089, train_loss 49.801678,Time used 0.005032s\n",
      "batch 4090, train_loss 41.694729,Time used 0.003998s\n",
      "batch 4091, train_loss 51.635574,Time used 0.005003s\n",
      "batch 4092, train_loss 57.244656,Time used 0.004961s\n",
      "batch 4093, train_loss 50.145157,Time used 0.005004s\n",
      "batch 4094, train_loss 52.499657,Time used 0.004000s\n",
      "batch 4095, train_loss 44.622723,Time used 0.005000s\n",
      "batch 4096, train_loss 50.748257,Time used 0.003999s\n",
      "batch 4097, train_loss 52.215481,Time used 0.005000s\n",
      "batch 4098, train_loss 46.958492,Time used 0.006001s\n",
      "batch 4099, train_loss 46.483955,Time used 0.007999s\n",
      "batch 4100, train_loss 49.064251,Time used 0.005000s\n",
      "***************************test_batch 4100, test_rmse_loss 8.067407,test_mae_loss 3.499390,test_mape_loss 57.746622,Time used 0.018999s\n",
      "batch 4101, train_loss 43.024475,Time used 0.009038s\n",
      "batch 4102, train_loss 47.806107,Time used 0.004963s\n",
      "batch 4103, train_loss 50.500061,Time used 0.004994s\n",
      "batch 4104, train_loss 46.335293,Time used 0.004999s\n",
      "batch 4105, train_loss 45.889545,Time used 0.008001s\n",
      "batch 4106, train_loss 53.115253,Time used 0.006966s\n",
      "batch 4107, train_loss 46.231781,Time used 0.005996s\n",
      "batch 4108, train_loss 50.417515,Time used 0.005965s\n",
      "batch 4109, train_loss 54.421741,Time used 0.005002s\n",
      "batch 4110, train_loss 40.977055,Time used 0.005001s\n",
      "batch 4111, train_loss 53.656883,Time used 0.007999s\n",
      "batch 4112, train_loss 42.871548,Time used 0.006998s\n",
      "batch 4113, train_loss 51.798565,Time used 0.007001s\n",
      "batch 4114, train_loss 42.915455,Time used 0.007000s\n",
      "batch 4115, train_loss 47.289425,Time used 0.006002s\n",
      "batch 4116, train_loss 50.356682,Time used 0.004028s\n",
      "batch 4117, train_loss 48.602081,Time used 0.005972s\n",
      "batch 4118, train_loss 41.645767,Time used 0.005000s\n",
      "batch 4119, train_loss 51.508217,Time used 0.005028s\n",
      "batch 4120, train_loss 46.250530,Time used 0.005001s\n",
      "batch 4121, train_loss 58.529408,Time used 0.005966s\n",
      "batch 4122, train_loss 36.478077,Time used 0.004999s\n",
      "batch 4123, train_loss 54.438606,Time used 0.005002s\n",
      "batch 4124, train_loss 37.064159,Time used 0.005032s\n",
      "batch 4125, train_loss 51.839806,Time used 0.005005s\n",
      "batch 4126, train_loss 51.181808,Time used 0.004967s\n",
      "batch 4127, train_loss 43.134659,Time used 0.005031s\n",
      "batch 4128, train_loss 44.893269,Time used 0.005967s\n",
      "batch 4129, train_loss 42.296822,Time used 0.005032s\n",
      "batch 4130, train_loss 37.893452,Time used 0.005002s\n",
      "batch 4131, train_loss 50.855484,Time used 0.004967s\n",
      "batch 4132, train_loss 37.368797,Time used 0.008999s\n",
      "batch 4133, train_loss 43.714581,Time used 0.005996s\n",
      "batch 4134, train_loss 54.213993,Time used 0.006000s\n",
      "batch 4135, train_loss 52.718914,Time used 0.004999s\n",
      "batch 4136, train_loss 46.817715,Time used 0.005000s\n",
      "batch 4137, train_loss 41.966774,Time used 0.006002s\n",
      "batch 4138, train_loss 50.823181,Time used 0.005035s\n",
      "batch 4139, train_loss 41.052761,Time used 0.004966s\n",
      "batch 4140, train_loss 56.004162,Time used 0.005000s\n",
      "batch 4141, train_loss 49.341915,Time used 0.004001s\n",
      "batch 4142, train_loss 39.152061,Time used 0.004002s\n",
      "batch 4143, train_loss 53.456024,Time used 0.004965s\n",
      "batch 4144, train_loss 54.504555,Time used 0.004999s\n",
      "batch 4145, train_loss 50.140549,Time used 0.004999s\n",
      "batch 4146, train_loss 55.975246,Time used 0.005000s\n",
      "batch 4147, train_loss 39.142326,Time used 0.004999s\n",
      "batch 4148, train_loss 47.506603,Time used 0.004999s\n",
      "batch 4149, train_loss 51.006847,Time used 0.006005s\n",
      "batch 4150, train_loss 38.690819,Time used 0.005031s\n",
      "batch 4151, train_loss 49.462154,Time used 0.005004s\n",
      "batch 4152, train_loss 54.524693,Time used 0.006965s\n",
      "batch 4153, train_loss 51.474407,Time used 0.004997s\n",
      "batch 4154, train_loss 54.613605,Time used 0.007030s\n",
      "batch 4155, train_loss 35.140972,Time used 0.005036s\n",
      "batch 4156, train_loss 56.386894,Time used 0.005000s\n",
      "batch 4157, train_loss 51.157017,Time used 0.004999s\n",
      "batch 4158, train_loss 55.154697,Time used 0.004969s\n",
      "batch 4159, train_loss 47.474403,Time used 0.006033s\n",
      "batch 4160, train_loss 48.868595,Time used 0.003999s\n",
      "batch 4161, train_loss 47.176159,Time used 0.005000s\n",
      "batch 4162, train_loss 40.086418,Time used 0.004996s\n",
      "batch 4163, train_loss 47.716492,Time used 0.006000s\n",
      "batch 4164, train_loss 47.896732,Time used 0.005000s\n",
      "batch 4165, train_loss 40.543724,Time used 0.005000s\n",
      "batch 4166, train_loss 44.152611,Time used 0.003998s\n",
      "batch 4167, train_loss 47.049076,Time used 0.005002s\n",
      "batch 4168, train_loss 57.445324,Time used 0.005964s\n",
      "batch 4169, train_loss 44.502644,Time used 0.005000s\n",
      "batch 4170, train_loss 48.193096,Time used 0.006035s\n",
      "batch 4171, train_loss 44.138588,Time used 0.005970s\n",
      "batch 4172, train_loss 45.246750,Time used 0.007994s\n",
      "batch 4173, train_loss 41.658577,Time used 0.006003s\n",
      "batch 4174, train_loss 43.987671,Time used 0.007034s\n",
      "batch 4175, train_loss 51.588326,Time used 0.005000s\n",
      "batch 4176, train_loss 40.482365,Time used 0.004998s\n",
      "batch 4177, train_loss 51.504543,Time used 0.006037s\n",
      "batch 4178, train_loss 49.000423,Time used 0.003996s\n",
      "batch 4179, train_loss 43.880360,Time used 0.003996s\n",
      "batch 4180, train_loss 46.837032,Time used 0.005008s\n",
      "batch 4181, train_loss 47.792885,Time used 0.004960s\n",
      "batch 4182, train_loss 35.862114,Time used 0.004998s\n",
      "batch 4183, train_loss 54.473064,Time used 0.007000s\n",
      "batch 4184, train_loss 48.256207,Time used 0.005002s\n",
      "batch 4185, train_loss 40.870365,Time used 0.005000s\n",
      "batch 4186, train_loss 56.119431,Time used 0.008002s\n",
      "batch 4187, train_loss 41.409801,Time used 0.007999s\n",
      "batch 4188, train_loss 36.477108,Time used 0.006997s\n",
      "batch 4189, train_loss 41.978146,Time used 0.008034s\n",
      "batch 4190, train_loss 50.821743,Time used 0.005000s\n",
      "batch 4191, train_loss 48.950886,Time used 0.006999s\n",
      "batch 4192, train_loss 39.954620,Time used 0.007002s\n",
      "batch 4193, train_loss 45.729473,Time used 0.006970s\n",
      "batch 4194, train_loss 46.032753,Time used 0.004993s\n",
      "batch 4195, train_loss 49.590107,Time used 0.004962s\n",
      "batch 4196, train_loss 49.375347,Time used 0.005998s\n",
      "batch 4197, train_loss 44.051037,Time used 0.006002s\n",
      "batch 4198, train_loss 54.206776,Time used 0.008000s\n",
      "batch 4199, train_loss 55.102097,Time used 0.005037s\n",
      "batch 4200, train_loss 47.375095,Time used 0.006001s\n",
      "***************************test_batch 4200, test_rmse_loss 7.999737,test_mae_loss 3.466441,test_mape_loss 57.161799,Time used 0.021961s\n",
      "batch 4201, train_loss 43.647903,Time used 0.007005s\n",
      "batch 4202, train_loss 39.594952,Time used 0.007996s\n",
      "batch 4203, train_loss 48.411873,Time used 0.006002s\n",
      "batch 4204, train_loss 51.333797,Time used 0.005997s\n",
      "batch 4205, train_loss 41.094398,Time used 0.005039s\n",
      "batch 4206, train_loss 43.684628,Time used 0.006958s\n",
      "batch 4207, train_loss 34.531380,Time used 0.006001s\n",
      "batch 4208, train_loss 56.753357,Time used 0.008000s\n",
      "batch 4209, train_loss 53.355385,Time used 0.006001s\n",
      "batch 4210, train_loss 45.867081,Time used 0.006001s\n",
      "batch 4211, train_loss 39.295235,Time used 0.005997s\n",
      "batch 4212, train_loss 48.469460,Time used 0.006001s\n",
      "batch 4213, train_loss 49.137962,Time used 0.007001s\n",
      "batch 4214, train_loss 48.255753,Time used 0.006003s\n",
      "batch 4215, train_loss 43.820953,Time used 0.007998s\n",
      "batch 4216, train_loss 52.070358,Time used 0.006999s\n",
      "batch 4217, train_loss 51.562710,Time used 0.008003s\n",
      "batch 4218, train_loss 55.126499,Time used 0.006999s\n",
      "batch 4219, train_loss 45.789349,Time used 0.008999s\n",
      "batch 4220, train_loss 47.371029,Time used 0.007998s\n",
      "batch 4221, train_loss 47.377689,Time used 0.006999s\n",
      "batch 4222, train_loss 44.750416,Time used 0.004999s\n",
      "batch 4223, train_loss 39.609619,Time used 0.006002s\n",
      "batch 4224, train_loss 49.964020,Time used 0.007998s\n",
      "batch 4225, train_loss 44.060528,Time used 0.006998s\n",
      "batch 4226, train_loss 60.579895,Time used 0.007999s\n",
      "batch 4227, train_loss 47.763454,Time used 0.004999s\n",
      "batch 4228, train_loss 30.324499,Time used 0.004999s\n",
      "batch 4229, train_loss 45.458324,Time used 0.004001s\n",
      "batch 4230, train_loss 57.506706,Time used 0.006002s\n",
      "batch 4231, train_loss 41.083767,Time used 0.005001s\n",
      "batch 4232, train_loss 58.952915,Time used 0.004000s\n",
      "batch 4233, train_loss 44.750858,Time used 0.005002s\n",
      "batch 4234, train_loss 45.397354,Time used 0.004999s\n",
      "batch 4235, train_loss 38.092464,Time used 0.004000s\n",
      "batch 4236, train_loss 40.081753,Time used 0.005002s\n",
      "batch 4237, train_loss 41.333012,Time used 0.006001s\n",
      "batch 4238, train_loss 42.886017,Time used 0.007001s\n",
      "batch 4239, train_loss 43.180786,Time used 0.005000s\n",
      "batch 4240, train_loss 46.694115,Time used 0.005000s\n",
      "batch 4241, train_loss 47.759441,Time used 0.005999s\n",
      "batch 4242, train_loss 56.662796,Time used 0.004997s\n",
      "batch 4243, train_loss 43.406025,Time used 0.005001s\n",
      "batch 4244, train_loss 40.801727,Time used 0.006000s\n",
      "batch 4245, train_loss 47.819653,Time used 0.005000s\n",
      "batch 4246, train_loss 48.202885,Time used 0.003999s\n",
      "batch 4247, train_loss 57.208233,Time used 0.006001s\n",
      "batch 4248, train_loss 45.272896,Time used 0.003999s\n",
      "batch 4249, train_loss 37.654499,Time used 0.004999s\n",
      "batch 4250, train_loss 45.338318,Time used 0.006001s\n",
      "batch 4251, train_loss 49.508846,Time used 0.008000s\n",
      "batch 4252, train_loss 35.478668,Time used 0.004999s\n",
      "batch 4253, train_loss 40.855171,Time used 0.005001s\n",
      "batch 4254, train_loss 48.231171,Time used 0.006001s\n",
      "batch 4255, train_loss 43.894264,Time used 0.005000s\n",
      "batch 4256, train_loss 37.169071,Time used 0.006000s\n",
      "batch 4257, train_loss 54.397896,Time used 0.006000s\n",
      "batch 4258, train_loss 36.946541,Time used 0.007000s\n",
      "batch 4259, train_loss 54.015743,Time used 0.005000s\n",
      "batch 4260, train_loss 52.080765,Time used 0.006003s\n",
      "batch 4261, train_loss 43.394604,Time used 0.005999s\n",
      "batch 4262, train_loss 52.699177,Time used 0.004997s\n",
      "batch 4263, train_loss 47.899971,Time used 0.004998s\n",
      "batch 4264, train_loss 42.832653,Time used 0.005000s\n",
      "batch 4265, train_loss 53.727070,Time used 0.005000s\n",
      "batch 4266, train_loss 38.234642,Time used 0.003997s\n",
      "batch 4267, train_loss 65.598152,Time used 0.003998s\n",
      "batch 4268, train_loss 43.767868,Time used 0.006002s\n",
      "batch 4269, train_loss 49.325920,Time used 0.004998s\n",
      "batch 4270, train_loss 46.167755,Time used 0.005002s\n",
      "batch 4271, train_loss 48.099934,Time used 0.006998s\n",
      "batch 4272, train_loss 43.046417,Time used 0.004001s\n",
      "batch 4273, train_loss 50.908688,Time used 0.006001s\n",
      "batch 4274, train_loss 49.214439,Time used 0.004999s\n",
      "batch 4275, train_loss 49.110039,Time used 0.003999s\n",
      "batch 4276, train_loss 38.587139,Time used 0.007001s\n",
      "batch 4277, train_loss 49.498936,Time used 0.005003s\n",
      "batch 4278, train_loss 47.023067,Time used 0.005000s\n",
      "batch 4279, train_loss 43.643013,Time used 0.005998s\n",
      "batch 4280, train_loss 39.047310,Time used 0.004998s\n",
      "batch 4281, train_loss 52.886425,Time used 0.005000s\n",
      "batch 4282, train_loss 50.091808,Time used 0.007035s\n",
      "batch 4283, train_loss 38.416668,Time used 0.005003s\n",
      "batch 4284, train_loss 60.430721,Time used 0.004036s\n",
      "batch 4285, train_loss 41.638268,Time used 0.005000s\n",
      "batch 4286, train_loss 41.994267,Time used 0.004996s\n",
      "batch 4287, train_loss 42.952915,Time used 0.006001s\n",
      "batch 4288, train_loss 41.408154,Time used 0.004997s\n",
      "batch 4289, train_loss 53.938454,Time used 0.006998s\n",
      "batch 4290, train_loss 48.925678,Time used 0.007007s\n",
      "batch 4291, train_loss 38.798275,Time used 0.009995s\n",
      "batch 4292, train_loss 50.127979,Time used 0.006999s\n",
      "batch 4293, train_loss 50.594479,Time used 0.006035s\n",
      "batch 4294, train_loss 46.941147,Time used 0.004967s\n",
      "batch 4295, train_loss 38.609444,Time used 0.005000s\n",
      "batch 4296, train_loss 40.335632,Time used 0.005033s\n",
      "batch 4297, train_loss 43.188320,Time used 0.008035s\n",
      "batch 4298, train_loss 48.861938,Time used 0.004969s\n",
      "batch 4299, train_loss 33.361916,Time used 0.004998s\n",
      "batch 4300, train_loss 52.321377,Time used 0.004999s\n",
      "***************************test_batch 4300, test_rmse_loss 7.927339,test_mae_loss 3.442827,test_mape_loss 57.068507,Time used 0.017033s\n",
      "batch 4301, train_loss 50.306576,Time used 0.005003s\n",
      "batch 4302, train_loss 38.485451,Time used 0.004040s\n",
      "batch 4303, train_loss 44.239815,Time used 0.005962s\n",
      "batch 4304, train_loss 43.182751,Time used 0.005039s\n",
      "batch 4305, train_loss 51.394993,Time used 0.004962s\n",
      "batch 4306, train_loss 39.059799,Time used 0.005032s\n",
      "batch 4307, train_loss 47.244816,Time used 0.005007s\n",
      "batch 4308, train_loss 40.254295,Time used 0.004957s\n",
      "batch 4309, train_loss 47.781952,Time used 0.005000s\n",
      "batch 4310, train_loss 38.497375,Time used 0.003999s\n",
      "batch 4311, train_loss 50.303101,Time used 0.005007s\n",
      "batch 4312, train_loss 46.259270,Time used 0.004034s\n",
      "batch 4313, train_loss 45.611652,Time used 0.005998s\n",
      "batch 4314, train_loss 51.713943,Time used 0.004965s\n",
      "batch 4315, train_loss 38.497086,Time used 0.005000s\n",
      "batch 4316, train_loss 47.939003,Time used 0.005007s\n",
      "batch 4317, train_loss 50.905537,Time used 0.007993s\n",
      "batch 4318, train_loss 47.638145,Time used 0.007999s\n",
      "batch 4319, train_loss 55.092922,Time used 0.008002s\n",
      "batch 4320, train_loss 48.645710,Time used 0.004999s\n",
      "batch 4321, train_loss 40.813908,Time used 0.004966s\n",
      "batch 4322, train_loss 46.856583,Time used 0.004000s\n",
      "batch 4323, train_loss 46.502781,Time used 0.004996s\n",
      "batch 4324, train_loss 41.991615,Time used 0.004999s\n",
      "batch 4325, train_loss 53.335514,Time used 0.004000s\n",
      "batch 4326, train_loss 46.478458,Time used 0.005964s\n",
      "batch 4327, train_loss 45.377914,Time used 0.005034s\n",
      "batch 4328, train_loss 39.757084,Time used 0.004006s\n",
      "batch 4329, train_loss 52.139568,Time used 0.005961s\n",
      "batch 4330, train_loss 40.190292,Time used 0.008001s\n",
      "batch 4331, train_loss 44.916195,Time used 0.008001s\n",
      "batch 4332, train_loss 41.307388,Time used 0.006999s\n",
      "batch 4333, train_loss 46.589859,Time used 0.005000s\n",
      "batch 4334, train_loss 43.845348,Time used 0.006000s\n",
      "batch 4335, train_loss 44.608334,Time used 0.005000s\n",
      "batch 4336, train_loss 51.214539,Time used 0.004000s\n",
      "batch 4337, train_loss 52.943497,Time used 0.005997s\n",
      "batch 4338, train_loss 40.380760,Time used 0.004004s\n",
      "batch 4339, train_loss 45.453243,Time used 0.005035s\n",
      "batch 4340, train_loss 49.499294,Time used 0.005961s\n",
      "batch 4341, train_loss 51.484035,Time used 0.005000s\n",
      "batch 4342, train_loss 46.259293,Time used 0.004998s\n",
      "batch 4343, train_loss 44.080177,Time used 0.006001s\n",
      "batch 4344, train_loss 40.951595,Time used 0.004999s\n",
      "batch 4345, train_loss 43.280167,Time used 0.004999s\n",
      "batch 4346, train_loss 46.674225,Time used 0.005000s\n",
      "batch 4347, train_loss 36.662071,Time used 0.007001s\n",
      "batch 4348, train_loss 42.878193,Time used 0.006001s\n",
      "batch 4349, train_loss 43.001301,Time used 0.007002s\n",
      "batch 4350, train_loss 43.360062,Time used 0.005000s\n",
      "batch 4351, train_loss 41.995220,Time used 0.005998s\n",
      "batch 4352, train_loss 47.177212,Time used 0.004996s\n",
      "batch 4353, train_loss 50.512871,Time used 0.005000s\n",
      "batch 4354, train_loss 51.738903,Time used 0.005000s\n",
      "batch 4355, train_loss 43.905930,Time used 0.006038s\n",
      "batch 4356, train_loss 45.010529,Time used 0.004964s\n",
      "batch 4357, train_loss 49.643719,Time used 0.007999s\n",
      "batch 4358, train_loss 43.376598,Time used 0.007000s\n",
      "batch 4359, train_loss 35.325249,Time used 0.005001s\n",
      "batch 4360, train_loss 43.737385,Time used 0.003999s\n",
      "batch 4361, train_loss 48.444820,Time used 0.005000s\n",
      "batch 4362, train_loss 65.880630,Time used 0.005000s\n",
      "batch 4363, train_loss 45.517471,Time used 0.004999s\n",
      "batch 4364, train_loss 47.014145,Time used 0.004999s\n",
      "batch 4365, train_loss 47.325222,Time used 0.007002s\n",
      "batch 4366, train_loss 43.929649,Time used 0.005001s\n",
      "batch 4367, train_loss 36.874802,Time used 0.004004s\n",
      "batch 4368, train_loss 48.590324,Time used 0.005000s\n",
      "batch 4369, train_loss 38.179504,Time used 0.004997s\n",
      "batch 4370, train_loss 42.068726,Time used 0.006001s\n",
      "batch 4371, train_loss 38.867466,Time used 0.006005s\n",
      "batch 4372, train_loss 51.453861,Time used 0.005000s\n",
      "batch 4373, train_loss 44.744488,Time used 0.005997s\n",
      "batch 4374, train_loss 48.134640,Time used 0.005000s\n",
      "batch 4375, train_loss 51.681076,Time used 0.005000s\n",
      "batch 4376, train_loss 46.709217,Time used 0.006001s\n",
      "batch 4377, train_loss 46.494774,Time used 0.004997s\n",
      "batch 4378, train_loss 57.391560,Time used 0.005000s\n",
      "batch 4379, train_loss 38.643749,Time used 0.006003s\n",
      "batch 4380, train_loss 36.321693,Time used 0.006999s\n",
      "batch 4381, train_loss 50.653713,Time used 0.007000s\n",
      "batch 4382, train_loss 42.959087,Time used 0.009033s\n",
      "batch 4383, train_loss 44.966419,Time used 0.007002s\n",
      "batch 4384, train_loss 39.763752,Time used 0.004998s\n",
      "batch 4385, train_loss 44.650188,Time used 0.004998s\n",
      "batch 4386, train_loss 49.649456,Time used 0.005003s\n",
      "batch 4387, train_loss 46.466503,Time used 0.005997s\n",
      "batch 4388, train_loss 42.445202,Time used 0.005000s\n",
      "batch 4389, train_loss 46.018757,Time used 0.006999s\n",
      "batch 4390, train_loss 54.219933,Time used 0.007039s\n",
      "batch 4391, train_loss 44.914436,Time used 0.005961s\n",
      "batch 4392, train_loss 40.113277,Time used 0.005000s\n",
      "batch 4393, train_loss 43.457485,Time used 0.007004s\n",
      "batch 4394, train_loss 48.381866,Time used 0.006002s\n",
      "batch 4395, train_loss 64.164597,Time used 0.007993s\n",
      "batch 4396, train_loss 51.503407,Time used 0.005001s\n",
      "batch 4397, train_loss 43.233322,Time used 0.007003s\n",
      "batch 4398, train_loss 50.892941,Time used 0.004999s\n",
      "batch 4399, train_loss 39.488598,Time used 0.009001s\n",
      "batch 4400, train_loss 43.246185,Time used 0.005040s\n",
      "***************************test_batch 4400, test_rmse_loss 7.839169,test_mae_loss 3.412333,test_mape_loss 56.935132,Time used 0.023959s\n",
      "batch 4401, train_loss 46.568020,Time used 0.008000s\n",
      "batch 4402, train_loss 45.289963,Time used 0.007001s\n",
      "batch 4403, train_loss 39.565487,Time used 0.009008s\n",
      "batch 4404, train_loss 42.186588,Time used 0.006991s\n",
      "batch 4405, train_loss 46.476570,Time used 0.005999s\n",
      "batch 4406, train_loss 55.335701,Time used 0.006998s\n",
      "batch 4407, train_loss 43.559429,Time used 0.004998s\n",
      "batch 4408, train_loss 38.167309,Time used 0.006001s\n",
      "batch 4409, train_loss 41.951485,Time used 0.004997s\n",
      "batch 4410, train_loss 44.047848,Time used 0.007001s\n",
      "batch 4411, train_loss 44.996593,Time used 0.004997s\n",
      "batch 4412, train_loss 36.785851,Time used 0.005000s\n",
      "batch 4413, train_loss 39.515450,Time used 0.006001s\n",
      "batch 4414, train_loss 44.393612,Time used 0.005000s\n",
      "batch 4415, train_loss 40.602654,Time used 0.006003s\n",
      "batch 4416, train_loss 48.665237,Time used 0.004996s\n",
      "batch 4417, train_loss 40.073151,Time used 0.007002s\n",
      "batch 4418, train_loss 41.722652,Time used 0.006007s\n",
      "batch 4419, train_loss 53.806049,Time used 0.006993s\n",
      "batch 4420, train_loss 34.811981,Time used 0.004997s\n",
      "batch 4421, train_loss 43.653160,Time used 0.005000s\n",
      "batch 4422, train_loss 41.862030,Time used 0.006001s\n",
      "batch 4423, train_loss 42.558842,Time used 0.004999s\n",
      "batch 4424, train_loss 53.785645,Time used 0.005999s\n",
      "batch 4425, train_loss 54.447723,Time used 0.007000s\n",
      "batch 4426, train_loss 40.563480,Time used 0.004999s\n",
      "batch 4427, train_loss 46.871208,Time used 0.006001s\n",
      "batch 4428, train_loss 47.002594,Time used 0.006999s\n",
      "batch 4429, train_loss 46.207298,Time used 0.007001s\n",
      "batch 4430, train_loss 41.894764,Time used 0.007997s\n",
      "batch 4431, train_loss 47.474056,Time used 0.007999s\n",
      "batch 4432, train_loss 50.736473,Time used 0.007000s\n",
      "batch 4433, train_loss 46.866989,Time used 0.005001s\n",
      "batch 4434, train_loss 43.102039,Time used 0.008001s\n",
      "batch 4435, train_loss 44.739761,Time used 0.005998s\n",
      "batch 4436, train_loss 48.477161,Time used 0.004998s\n",
      "batch 4437, train_loss 41.257324,Time used 0.005000s\n",
      "batch 4438, train_loss 41.079155,Time used 0.006000s\n",
      "batch 4439, train_loss 38.287407,Time used 0.005998s\n",
      "batch 4440, train_loss 47.062023,Time used 0.005002s\n",
      "batch 4441, train_loss 37.425598,Time used 0.009003s\n",
      "batch 4442, train_loss 45.197506,Time used 0.006996s\n",
      "batch 4443, train_loss 47.154987,Time used 0.008000s\n",
      "batch 4444, train_loss 37.288338,Time used 0.005001s\n",
      "batch 4445, train_loss 41.266560,Time used 0.006004s\n",
      "batch 4446, train_loss 50.560493,Time used 0.008033s\n",
      "batch 4447, train_loss 45.407532,Time used 0.007962s\n",
      "batch 4448, train_loss 40.232967,Time used 0.004000s\n",
      "batch 4449, train_loss 45.040665,Time used 0.005002s\n",
      "batch 4450, train_loss 45.576923,Time used 0.006044s\n",
      "batch 4451, train_loss 53.947445,Time used 0.007041s\n",
      "batch 4452, train_loss 38.817459,Time used 0.004032s\n",
      "batch 4453, train_loss 48.837734,Time used 0.005965s\n",
      "batch 4454, train_loss 41.578651,Time used 0.003999s\n",
      "batch 4455, train_loss 49.371933,Time used 0.006035s\n",
      "batch 4456, train_loss 44.065845,Time used 0.006995s\n",
      "batch 4457, train_loss 45.232838,Time used 0.008006s\n",
      "batch 4458, train_loss 56.522686,Time used 0.004960s\n",
      "batch 4459, train_loss 41.889729,Time used 0.004002s\n",
      "batch 4460, train_loss 33.757542,Time used 0.005007s\n",
      "batch 4461, train_loss 50.192158,Time used 0.006019s\n",
      "batch 4462, train_loss 44.191673,Time used 0.004973s\n",
      "batch 4463, train_loss 39.868916,Time used 0.006003s\n",
      "batch 4464, train_loss 50.295864,Time used 0.007997s\n",
      "batch 4465, train_loss 41.523609,Time used 0.006031s\n",
      "batch 4466, train_loss 52.437386,Time used 0.005000s\n",
      "batch 4467, train_loss 48.831425,Time used 0.005966s\n",
      "batch 4468, train_loss 52.170643,Time used 0.005003s\n",
      "batch 4469, train_loss 41.462097,Time used 0.004002s\n",
      "batch 4470, train_loss 41.329098,Time used 0.008036s\n",
      "batch 4471, train_loss 46.540817,Time used 0.004996s\n",
      "batch 4472, train_loss 42.723217,Time used 0.005000s\n",
      "batch 4473, train_loss 43.223572,Time used 0.004999s\n",
      "batch 4474, train_loss 53.544167,Time used 0.005001s\n",
      "batch 4475, train_loss 51.579391,Time used 0.004998s\n",
      "batch 4476, train_loss 34.984470,Time used 0.004038s\n",
      "batch 4477, train_loss 44.151783,Time used 0.004001s\n",
      "batch 4478, train_loss 45.969849,Time used 0.005000s\n",
      "batch 4479, train_loss 43.229755,Time used 0.006000s\n",
      "batch 4480, train_loss 38.519051,Time used 0.005000s\n",
      "batch 4481, train_loss 52.635994,Time used 0.004001s\n",
      "batch 4482, train_loss 52.564999,Time used 0.007966s\n",
      "batch 4483, train_loss 39.559677,Time used 0.005001s\n",
      "batch 4484, train_loss 37.961384,Time used 0.004000s\n",
      "batch 4485, train_loss 44.327393,Time used 0.006029s\n",
      "batch 4486, train_loss 42.758629,Time used 0.005000s\n",
      "batch 4487, train_loss 37.719162,Time used 0.005001s\n",
      "batch 4488, train_loss 39.511620,Time used 0.004966s\n",
      "batch 4489, train_loss 48.406204,Time used 0.006006s\n",
      "batch 4490, train_loss 48.735954,Time used 0.005001s\n",
      "batch 4491, train_loss 47.438946,Time used 0.006000s\n",
      "batch 4492, train_loss 43.150116,Time used 0.006002s\n",
      "batch 4493, train_loss 52.561901,Time used 0.007994s\n",
      "batch 4494, train_loss 35.967499,Time used 0.005999s\n",
      "batch 4495, train_loss 47.156586,Time used 0.005001s\n",
      "batch 4496, train_loss 38.192333,Time used 0.004999s\n",
      "batch 4497, train_loss 37.460644,Time used 0.006003s\n",
      "batch 4498, train_loss 47.105747,Time used 0.005000s\n",
      "batch 4499, train_loss 47.760616,Time used 0.005002s\n",
      "batch 4500, train_loss 44.215405,Time used 0.005996s\n",
      "***************************test_batch 4500, test_rmse_loss 7.836465,test_mae_loss 3.409402,test_mape_loss 56.484640,Time used 0.017005s\n",
      "batch 4501, train_loss 42.838570,Time used 0.005000s\n",
      "batch 4502, train_loss 42.075821,Time used 0.005002s\n",
      "batch 4503, train_loss 38.469456,Time used 0.007998s\n",
      "batch 4504, train_loss 42.343021,Time used 0.006999s\n",
      "batch 4505, train_loss 43.426151,Time used 0.006034s\n",
      "batch 4506, train_loss 39.645695,Time used 0.003993s\n",
      "batch 4507, train_loss 43.788052,Time used 0.005003s\n",
      "batch 4508, train_loss 41.919174,Time used 0.006000s\n",
      "batch 4509, train_loss 52.258850,Time used 0.005001s\n",
      "batch 4510, train_loss 45.220791,Time used 0.005000s\n",
      "batch 4511, train_loss 49.832867,Time used 0.007963s\n",
      "batch 4512, train_loss 45.657307,Time used 0.004999s\n",
      "batch 4513, train_loss 55.134460,Time used 0.004997s\n",
      "batch 4514, train_loss 45.711063,Time used 0.005000s\n",
      "batch 4515, train_loss 40.639519,Time used 0.005000s\n",
      "batch 4516, train_loss 42.784515,Time used 0.004997s\n",
      "batch 4517, train_loss 48.386379,Time used 0.005000s\n",
      "batch 4518, train_loss 38.177658,Time used 0.005001s\n",
      "batch 4519, train_loss 47.119602,Time used 0.005001s\n",
      "batch 4520, train_loss 41.850708,Time used 0.005002s\n",
      "batch 4521, train_loss 53.316952,Time used 0.006998s\n",
      "batch 4522, train_loss 44.053658,Time used 0.005000s\n",
      "batch 4523, train_loss 34.496956,Time used 0.005001s\n",
      "batch 4524, train_loss 43.991314,Time used 0.005998s\n",
      "batch 4525, train_loss 43.180954,Time used 0.005001s\n",
      "batch 4526, train_loss 36.362793,Time used 0.004997s\n",
      "batch 4527, train_loss 49.213253,Time used 0.005003s\n",
      "batch 4528, train_loss 44.495117,Time used 0.004998s\n",
      "batch 4529, train_loss 53.050972,Time used 0.005000s\n",
      "batch 4530, train_loss 40.884315,Time used 0.005014s\n",
      "batch 4531, train_loss 40.905788,Time used 0.004988s\n",
      "batch 4532, train_loss 55.908730,Time used 0.005000s\n",
      "batch 4533, train_loss 38.591900,Time used 0.004998s\n",
      "batch 4534, train_loss 37.268108,Time used 0.005000s\n",
      "batch 4535, train_loss 39.746357,Time used 0.005000s\n",
      "batch 4536, train_loss 45.674026,Time used 0.006002s\n",
      "batch 4537, train_loss 43.664516,Time used 0.005995s\n",
      "batch 4538, train_loss 47.669411,Time used 0.005003s\n",
      "batch 4539, train_loss 37.733948,Time used 0.006997s\n",
      "batch 4540, train_loss 48.014683,Time used 0.005002s\n",
      "batch 4541, train_loss 40.106358,Time used 0.004999s\n",
      "batch 4542, train_loss 41.303371,Time used 0.006003s\n",
      "batch 4543, train_loss 36.775658,Time used 0.004997s\n",
      "batch 4544, train_loss 46.836155,Time used 0.005001s\n",
      "batch 4545, train_loss 42.212681,Time used 0.005000s\n",
      "batch 4546, train_loss 46.051838,Time used 0.005034s\n",
      "batch 4547, train_loss 40.508114,Time used 0.004970s\n",
      "batch 4548, train_loss 40.022518,Time used 0.005995s\n",
      "batch 4549, train_loss 53.547867,Time used 0.006998s\n",
      "batch 4550, train_loss 49.828594,Time used 0.008005s\n",
      "batch 4551, train_loss 46.286354,Time used 0.008035s\n",
      "batch 4552, train_loss 41.809666,Time used 0.007963s\n",
      "batch 4553, train_loss 38.021351,Time used 0.005004s\n",
      "batch 4554, train_loss 47.718704,Time used 0.005994s\n",
      "batch 4555, train_loss 36.020767,Time used 0.004999s\n",
      "batch 4556, train_loss 45.780788,Time used 0.004999s\n",
      "batch 4557, train_loss 47.689377,Time used 0.006001s\n",
      "batch 4558, train_loss 47.080616,Time used 0.006001s\n",
      "batch 4559, train_loss 51.047813,Time used 0.006000s\n",
      "batch 4560, train_loss 41.677116,Time used 0.005000s\n",
      "batch 4561, train_loss 48.989555,Time used 0.005000s\n",
      "batch 4562, train_loss 34.963490,Time used 0.003995s\n",
      "batch 4563, train_loss 38.536465,Time used 0.007031s\n",
      "batch 4564, train_loss 48.861603,Time used 0.005004s\n",
      "batch 4565, train_loss 44.464859,Time used 0.005964s\n",
      "batch 4566, train_loss 43.128349,Time used 0.006999s\n",
      "batch 4567, train_loss 41.546021,Time used 0.006001s\n",
      "batch 4568, train_loss 40.312283,Time used 0.007002s\n",
      "batch 4569, train_loss 47.003983,Time used 0.007034s\n",
      "batch 4570, train_loss 47.715752,Time used 0.005964s\n",
      "batch 4571, train_loss 49.730747,Time used 0.006038s\n",
      "batch 4572, train_loss 44.881264,Time used 0.004965s\n",
      "batch 4573, train_loss 41.689720,Time used 0.006000s\n",
      "batch 4574, train_loss 40.964897,Time used 0.004999s\n",
      "batch 4575, train_loss 39.652687,Time used 0.005001s\n",
      "batch 4576, train_loss 38.458447,Time used 0.004998s\n",
      "batch 4577, train_loss 54.002300,Time used 0.004999s\n",
      "batch 4578, train_loss 44.301521,Time used 0.004999s\n",
      "batch 4579, train_loss 40.336384,Time used 0.004999s\n",
      "batch 4580, train_loss 41.742809,Time used 0.005001s\n",
      "batch 4581, train_loss 45.593452,Time used 0.006037s\n",
      "batch 4582, train_loss 41.080982,Time used 0.005970s\n",
      "batch 4583, train_loss 49.467308,Time used 0.005000s\n",
      "batch 4584, train_loss 45.990288,Time used 0.004994s\n",
      "batch 4585, train_loss 39.218693,Time used 0.006963s\n",
      "batch 4586, train_loss 38.808231,Time used 0.005002s\n",
      "batch 4587, train_loss 48.183388,Time used 0.005000s\n",
      "batch 4588, train_loss 41.810299,Time used 0.005033s\n",
      "batch 4589, train_loss 41.136108,Time used 0.004969s\n",
      "batch 4590, train_loss 43.303886,Time used 0.006031s\n",
      "batch 4591, train_loss 35.188141,Time used 0.005000s\n",
      "batch 4592, train_loss 41.770893,Time used 0.004966s\n",
      "batch 4593, train_loss 42.846035,Time used 0.005037s\n",
      "batch 4594, train_loss 45.806034,Time used 0.004960s\n",
      "batch 4595, train_loss 50.554756,Time used 0.005000s\n",
      "batch 4596, train_loss 42.151718,Time used 0.005002s\n",
      "batch 4597, train_loss 42.044975,Time used 0.006004s\n",
      "batch 4598, train_loss 50.744705,Time used 0.005001s\n",
      "batch 4599, train_loss 36.891319,Time used 0.004001s\n",
      "batch 4600, train_loss 32.751614,Time used 0.005000s\n",
      "***************************test_batch 4600, test_rmse_loss 7.803357,test_mae_loss 3.395306,test_mape_loss 56.279626,Time used 0.017998s\n",
      "batch 4601, train_loss 50.604767,Time used 0.005000s\n",
      "batch 4602, train_loss 43.645737,Time used 0.005000s\n",
      "batch 4603, train_loss 45.901276,Time used 0.008000s\n",
      "batch 4604, train_loss 47.063190,Time used 0.008000s\n",
      "batch 4605, train_loss 59.141129,Time used 0.005001s\n",
      "batch 4606, train_loss 41.097153,Time used 0.004996s\n",
      "batch 4607, train_loss 39.159119,Time used 0.004996s\n",
      "batch 4608, train_loss 48.997086,Time used 0.004998s\n",
      "batch 4609, train_loss 49.871113,Time used 0.009002s\n",
      "batch 4610, train_loss 46.234688,Time used 0.007003s\n",
      "batch 4611, train_loss 45.448742,Time used 0.006996s\n",
      "batch 4612, train_loss 46.443378,Time used 0.004998s\n",
      "batch 4613, train_loss 39.683960,Time used 0.005000s\n",
      "batch 4614, train_loss 44.700771,Time used 0.005005s\n",
      "batch 4615, train_loss 45.038864,Time used 0.005000s\n",
      "batch 4616, train_loss 41.470135,Time used 0.005000s\n",
      "batch 4617, train_loss 45.079750,Time used 0.006997s\n",
      "batch 4618, train_loss 36.167843,Time used 0.005039s\n",
      "batch 4619, train_loss 38.126648,Time used 0.004998s\n",
      "batch 4620, train_loss 53.988274,Time used 0.004998s\n",
      "batch 4621, train_loss 40.704491,Time used 0.004999s\n",
      "batch 4622, train_loss 46.264576,Time used 0.004969s\n",
      "batch 4623, train_loss 48.653263,Time used 0.005038s\n",
      "batch 4624, train_loss 41.655186,Time used 0.004993s\n",
      "batch 4625, train_loss 37.292461,Time used 0.003964s\n",
      "batch 4626, train_loss 36.304337,Time used 0.006003s\n",
      "batch 4627, train_loss 44.725384,Time used 0.005001s\n",
      "batch 4628, train_loss 51.248608,Time used 0.005000s\n",
      "batch 4629, train_loss 36.452019,Time used 0.005033s\n",
      "batch 4630, train_loss 44.262802,Time used 0.004965s\n",
      "batch 4631, train_loss 46.951832,Time used 0.005036s\n",
      "batch 4632, train_loss 38.050991,Time used 0.005000s\n",
      "batch 4633, train_loss 52.131561,Time used 0.006998s\n",
      "batch 4634, train_loss 40.394691,Time used 0.003964s\n",
      "batch 4635, train_loss 49.872437,Time used 0.004999s\n",
      "batch 4636, train_loss 44.122311,Time used 0.004000s\n",
      "batch 4637, train_loss 42.202312,Time used 0.006999s\n",
      "batch 4638, train_loss 41.195778,Time used 0.007999s\n",
      "batch 4639, train_loss 51.184921,Time used 0.005999s\n",
      "batch 4640, train_loss 42.536758,Time used 0.007000s\n",
      "batch 4641, train_loss 48.206146,Time used 0.005002s\n",
      "batch 4642, train_loss 42.818195,Time used 0.005001s\n",
      "batch 4643, train_loss 45.706993,Time used 0.005000s\n",
      "batch 4644, train_loss 35.124290,Time used 0.008000s\n",
      "batch 4645, train_loss 44.871483,Time used 0.005003s\n",
      "batch 4646, train_loss 39.405281,Time used 0.006997s\n",
      "batch 4647, train_loss 47.719448,Time used 0.005998s\n",
      "batch 4648, train_loss 43.084709,Time used 0.004000s\n",
      "batch 4649, train_loss 43.399700,Time used 0.005003s\n",
      "batch 4650, train_loss 43.505997,Time used 0.007030s\n",
      "batch 4651, train_loss 46.848743,Time used 0.006000s\n",
      "batch 4652, train_loss 45.415752,Time used 0.004964s\n",
      "batch 4653, train_loss 33.011398,Time used 0.004999s\n",
      "batch 4654, train_loss 40.900181,Time used 0.005000s\n",
      "batch 4655, train_loss 35.128021,Time used 0.006000s\n",
      "batch 4656, train_loss 41.638420,Time used 0.005000s\n",
      "batch 4657, train_loss 40.739693,Time used 0.008033s\n",
      "batch 4658, train_loss 54.339661,Time used 0.004969s\n",
      "batch 4659, train_loss 48.694195,Time used 0.004998s\n",
      "batch 4660, train_loss 47.682091,Time used 0.008000s\n",
      "batch 4661, train_loss 38.502750,Time used 0.006002s\n",
      "batch 4662, train_loss 39.636108,Time used 0.006034s\n",
      "batch 4663, train_loss 39.858070,Time used 0.004992s\n",
      "batch 4664, train_loss 43.117962,Time used 0.005007s\n",
      "batch 4665, train_loss 41.112095,Time used 0.005967s\n",
      "batch 4666, train_loss 42.621475,Time used 0.005000s\n",
      "batch 4667, train_loss 41.463497,Time used 0.004999s\n",
      "batch 4668, train_loss 44.753448,Time used 0.005033s\n",
      "batch 4669, train_loss 46.558357,Time used 0.005001s\n",
      "batch 4670, train_loss 43.500725,Time used 0.004968s\n",
      "batch 4671, train_loss 45.742802,Time used 0.007036s\n",
      "batch 4672, train_loss 39.171490,Time used 0.005965s\n",
      "batch 4673, train_loss 31.488571,Time used 0.006997s\n",
      "batch 4674, train_loss 37.236790,Time used 0.006001s\n",
      "batch 4675, train_loss 54.706791,Time used 0.008004s\n",
      "batch 4676, train_loss 49.606720,Time used 0.005033s\n",
      "batch 4677, train_loss 49.364723,Time used 0.005963s\n",
      "batch 4678, train_loss 42.229210,Time used 0.007000s\n",
      "batch 4679, train_loss 34.067165,Time used 0.005037s\n",
      "batch 4680, train_loss 40.391521,Time used 0.005007s\n",
      "batch 4681, train_loss 43.960976,Time used 0.005002s\n",
      "batch 4682, train_loss 49.959595,Time used 0.004965s\n",
      "batch 4683, train_loss 31.831583,Time used 0.007033s\n",
      "batch 4684, train_loss 37.645885,Time used 0.005000s\n",
      "batch 4685, train_loss 44.500095,Time used 0.004998s\n",
      "batch 4686, train_loss 42.637611,Time used 0.005004s\n",
      "batch 4687, train_loss 37.545158,Time used 0.004997s\n",
      "batch 4688, train_loss 42.563114,Time used 0.005969s\n",
      "batch 4689, train_loss 37.734333,Time used 0.004999s\n",
      "batch 4690, train_loss 43.175442,Time used 0.005032s\n",
      "batch 4691, train_loss 45.248222,Time used 0.004964s\n",
      "batch 4692, train_loss 49.690800,Time used 0.004999s\n",
      "batch 4693, train_loss 40.200596,Time used 0.006000s\n",
      "batch 4694, train_loss 37.283386,Time used 0.005044s\n",
      "batch 4695, train_loss 45.944004,Time used 0.004994s\n",
      "batch 4696, train_loss 48.854782,Time used 0.005000s\n",
      "batch 4697, train_loss 44.458981,Time used 0.004967s\n",
      "batch 4698, train_loss 48.172577,Time used 0.005031s\n",
      "batch 4699, train_loss 44.615261,Time used 0.005000s\n",
      "batch 4700, train_loss 44.887665,Time used 0.005969s\n",
      "***************************test_batch 4700, test_rmse_loss 7.723475,test_mae_loss 3.373548,test_mape_loss 56.335897,Time used 0.016997s\n",
      "batch 4701, train_loss 40.895184,Time used 0.005999s\n",
      "batch 4702, train_loss 45.307533,Time used 0.005000s\n",
      "batch 4703, train_loss 40.756088,Time used 0.005002s\n",
      "batch 4704, train_loss 45.152992,Time used 0.005000s\n",
      "batch 4705, train_loss 45.450100,Time used 0.007965s\n",
      "batch 4706, train_loss 47.391216,Time used 0.007997s\n",
      "batch 4707, train_loss 56.996857,Time used 0.004001s\n",
      "batch 4708, train_loss 32.772720,Time used 0.004000s\n",
      "batch 4709, train_loss 48.209019,Time used 0.006005s\n",
      "batch 4710, train_loss 42.220089,Time used 0.006999s\n",
      "batch 4711, train_loss 48.933990,Time used 0.007001s\n",
      "batch 4712, train_loss 38.912067,Time used 0.004996s\n",
      "batch 4713, train_loss 37.743275,Time used 0.005036s\n",
      "batch 4714, train_loss 39.710129,Time used 0.004974s\n",
      "batch 4715, train_loss 46.374668,Time used 0.006027s\n",
      "batch 4716, train_loss 44.273785,Time used 0.004004s\n",
      "batch 4717, train_loss 37.813385,Time used 0.004966s\n",
      "batch 4718, train_loss 42.894848,Time used 0.006032s\n",
      "batch 4719, train_loss 38.832981,Time used 0.005001s\n",
      "batch 4720, train_loss 48.874310,Time used 0.005006s\n",
      "batch 4721, train_loss 37.773983,Time used 0.004990s\n",
      "batch 4722, train_loss 36.639572,Time used 0.003989s\n",
      "batch 4723, train_loss 39.988323,Time used 0.005000s\n",
      "batch 4724, train_loss 43.070721,Time used 0.005965s\n",
      "batch 4725, train_loss 41.212421,Time used 0.004001s\n",
      "batch 4726, train_loss 50.815941,Time used 0.006000s\n",
      "batch 4727, train_loss 39.321655,Time used 0.008043s\n",
      "batch 4728, train_loss 42.837051,Time used 0.004997s\n",
      "batch 4729, train_loss 49.095806,Time used 0.007998s\n",
      "batch 4730, train_loss 45.149303,Time used 0.005000s\n",
      "batch 4731, train_loss 46.063293,Time used 0.005000s\n",
      "batch 4732, train_loss 45.710045,Time used 0.004002s\n",
      "batch 4733, train_loss 41.766228,Time used 0.005003s\n",
      "batch 4734, train_loss 46.929493,Time used 0.004996s\n",
      "batch 4735, train_loss 35.378963,Time used 0.006006s\n",
      "batch 4736, train_loss 37.738213,Time used 0.008034s\n",
      "batch 4737, train_loss 42.275410,Time used 0.006960s\n",
      "batch 4738, train_loss 34.028004,Time used 0.006003s\n",
      "batch 4739, train_loss 47.957569,Time used 0.007998s\n",
      "batch 4740, train_loss 39.439571,Time used 0.005000s\n",
      "batch 4741, train_loss 38.782238,Time used 0.008002s\n",
      "batch 4742, train_loss 43.468624,Time used 0.006001s\n",
      "batch 4743, train_loss 29.559139,Time used 0.006998s\n",
      "batch 4744, train_loss 35.932686,Time used 0.007998s\n",
      "batch 4745, train_loss 43.662231,Time used 0.008003s\n",
      "batch 4746, train_loss 45.823021,Time used 0.008035s\n",
      "batch 4747, train_loss 44.387699,Time used 0.005998s\n",
      "batch 4748, train_loss 39.286556,Time used 0.004999s\n",
      "batch 4749, train_loss 42.350559,Time used 0.006001s\n",
      "batch 4750, train_loss 45.876556,Time used 0.004999s\n",
      "batch 4751, train_loss 50.956852,Time used 0.005967s\n",
      "batch 4752, train_loss 54.607098,Time used 0.007033s\n",
      "batch 4753, train_loss 41.951183,Time used 0.004999s\n",
      "batch 4754, train_loss 40.450359,Time used 0.006998s\n",
      "batch 4755, train_loss 43.541325,Time used 0.005001s\n",
      "batch 4756, train_loss 38.451241,Time used 0.004999s\n",
      "batch 4757, train_loss 39.406315,Time used 0.005002s\n",
      "batch 4758, train_loss 38.802395,Time used 0.007003s\n",
      "batch 4759, train_loss 49.954281,Time used 0.005000s\n",
      "batch 4760, train_loss 39.253147,Time used 0.004996s\n",
      "batch 4761, train_loss 45.272663,Time used 0.005000s\n",
      "batch 4762, train_loss 32.586418,Time used 0.005005s\n",
      "batch 4763, train_loss 45.012733,Time used 0.008997s\n",
      "batch 4764, train_loss 54.298973,Time used 0.007997s\n",
      "batch 4765, train_loss 40.574551,Time used 0.008034s\n",
      "batch 4766, train_loss 48.210266,Time used 0.006968s\n",
      "batch 4767, train_loss 48.025902,Time used 0.008031s\n",
      "batch 4768, train_loss 44.722710,Time used 0.005000s\n",
      "batch 4769, train_loss 54.778072,Time used 0.006000s\n",
      "batch 4770, train_loss 38.398636,Time used 0.005000s\n",
      "batch 4771, train_loss 38.917229,Time used 0.004968s\n",
      "batch 4772, train_loss 41.328362,Time used 0.005031s\n",
      "batch 4773, train_loss 37.484917,Time used 0.004970s\n",
      "batch 4774, train_loss 44.475456,Time used 0.005034s\n",
      "batch 4775, train_loss 44.537640,Time used 0.004965s\n",
      "batch 4776, train_loss 31.302488,Time used 0.005000s\n",
      "batch 4777, train_loss 45.326752,Time used 0.005994s\n",
      "batch 4778, train_loss 38.962521,Time used 0.008000s\n",
      "batch 4779, train_loss 42.653088,Time used 0.006003s\n",
      "batch 4780, train_loss 41.878292,Time used 0.006000s\n",
      "batch 4781, train_loss 38.743382,Time used 0.006000s\n",
      "batch 4782, train_loss 28.449814,Time used 0.007003s\n",
      "batch 4783, train_loss 37.284370,Time used 0.008037s\n",
      "batch 4784, train_loss 43.837013,Time used 0.006965s\n",
      "batch 4785, train_loss 42.553406,Time used 0.007036s\n",
      "batch 4786, train_loss 48.512177,Time used 0.004961s\n",
      "batch 4787, train_loss 47.588921,Time used 0.004999s\n",
      "batch 4788, train_loss 40.959496,Time used 0.005000s\n",
      "batch 4789, train_loss 49.946487,Time used 0.005002s\n",
      "batch 4790, train_loss 42.866600,Time used 0.006000s\n",
      "batch 4791, train_loss 40.758575,Time used 0.004999s\n",
      "batch 4792, train_loss 47.957687,Time used 0.005003s\n",
      "batch 4793, train_loss 42.886028,Time used 0.005000s\n",
      "batch 4794, train_loss 37.238068,Time used 0.005001s\n",
      "batch 4795, train_loss 44.882919,Time used 0.004999s\n",
      "batch 4796, train_loss 37.774189,Time used 0.006998s\n",
      "batch 4797, train_loss 46.262180,Time used 0.008039s\n",
      "batch 4798, train_loss 45.671707,Time used 0.007997s\n",
      "batch 4799, train_loss 43.282539,Time used 0.005001s\n",
      "batch 4800, train_loss 42.840385,Time used 0.004966s\n",
      "***************************test_batch 4800, test_rmse_loss 7.730026,test_mae_loss 3.371465,test_mape_loss 55.728490,Time used 0.018005s\n",
      "batch 4801, train_loss 43.880379,Time used 0.005001s\n",
      "batch 4802, train_loss 47.417816,Time used 0.005997s\n",
      "batch 4803, train_loss 39.714344,Time used 0.004001s\n",
      "batch 4804, train_loss 39.657112,Time used 0.005032s\n",
      "batch 4805, train_loss 44.244041,Time used 0.004965s\n",
      "batch 4806, train_loss 54.140244,Time used 0.005031s\n",
      "batch 4807, train_loss 33.913490,Time used 0.006001s\n",
      "batch 4808, train_loss 48.763607,Time used 0.007003s\n",
      "batch 4809, train_loss 39.372673,Time used 0.004996s\n",
      "batch 4810, train_loss 37.203358,Time used 0.005000s\n",
      "batch 4811, train_loss 44.890907,Time used 0.004967s\n",
      "batch 4812, train_loss 40.912113,Time used 0.004999s\n",
      "batch 4813, train_loss 43.962791,Time used 0.005002s\n",
      "batch 4814, train_loss 40.295982,Time used 0.008003s\n",
      "batch 4815, train_loss 49.499653,Time used 0.007998s\n",
      "batch 4816, train_loss 31.188122,Time used 0.004996s\n",
      "batch 4817, train_loss 44.385899,Time used 0.005000s\n",
      "batch 4818, train_loss 54.363506,Time used 0.005002s\n",
      "batch 4819, train_loss 35.518333,Time used 0.005001s\n",
      "batch 4820, train_loss 37.426720,Time used 0.005001s\n",
      "batch 4821, train_loss 39.261711,Time used 0.006000s\n",
      "batch 4822, train_loss 37.355846,Time used 0.007999s\n",
      "batch 4823, train_loss 43.695679,Time used 0.007001s\n",
      "batch 4824, train_loss 44.600712,Time used 0.007023s\n",
      "batch 4825, train_loss 38.412251,Time used 0.008000s\n",
      "batch 4826, train_loss 49.016239,Time used 0.005001s\n",
      "batch 4827, train_loss 39.946709,Time used 0.005996s\n",
      "batch 4828, train_loss 48.987778,Time used 0.005001s\n",
      "batch 4829, train_loss 50.473850,Time used 0.005000s\n",
      "batch 4830, train_loss 38.314240,Time used 0.006037s\n",
      "batch 4831, train_loss 45.219311,Time used 0.004000s\n",
      "batch 4832, train_loss 41.233765,Time used 0.003999s\n",
      "batch 4833, train_loss 43.158287,Time used 0.004998s\n",
      "batch 4834, train_loss 42.600819,Time used 0.005002s\n",
      "batch 4835, train_loss 42.520061,Time used 0.004964s\n",
      "batch 4836, train_loss 43.771626,Time used 0.005033s\n",
      "batch 4837, train_loss 40.320839,Time used 0.005000s\n",
      "batch 4838, train_loss 39.541393,Time used 0.004969s\n",
      "batch 4839, train_loss 39.859604,Time used 0.005001s\n",
      "batch 4840, train_loss 42.393677,Time used 0.005997s\n",
      "batch 4841, train_loss 43.984028,Time used 0.006999s\n",
      "batch 4842, train_loss 39.379040,Time used 0.004966s\n",
      "batch 4843, train_loss 36.745243,Time used 0.005031s\n",
      "batch 4844, train_loss 39.615356,Time used 0.004966s\n",
      "batch 4845, train_loss 46.091801,Time used 0.004031s\n",
      "batch 4846, train_loss 44.012398,Time used 0.005002s\n",
      "batch 4847, train_loss 36.859821,Time used 0.005967s\n",
      "batch 4848, train_loss 39.358208,Time used 0.004031s\n",
      "batch 4849, train_loss 41.158382,Time used 0.004943s\n",
      "batch 4850, train_loss 45.886589,Time used 0.005003s\n",
      "batch 4851, train_loss 36.883064,Time used 0.006000s\n",
      "batch 4852, train_loss 44.061901,Time used 0.005001s\n",
      "batch 4853, train_loss 45.092434,Time used 0.007033s\n",
      "batch 4854, train_loss 38.078720,Time used 0.004964s\n",
      "batch 4855, train_loss 37.199966,Time used 0.004997s\n",
      "batch 4856, train_loss 32.772423,Time used 0.005000s\n",
      "batch 4857, train_loss 37.581543,Time used 0.006000s\n",
      "batch 4858, train_loss 39.014866,Time used 0.005003s\n",
      "batch 4859, train_loss 42.798641,Time used 0.005030s\n",
      "batch 4860, train_loss 35.820114,Time used 0.003999s\n",
      "batch 4861, train_loss 45.329788,Time used 0.004962s\n",
      "batch 4862, train_loss 46.218327,Time used 0.005037s\n",
      "batch 4863, train_loss 52.955563,Time used 0.004001s\n",
      "batch 4864, train_loss 39.149357,Time used 0.006999s\n",
      "batch 4865, train_loss 48.176861,Time used 0.004999s\n",
      "batch 4866, train_loss 41.063725,Time used 0.004969s\n",
      "batch 4867, train_loss 42.012283,Time used 0.006999s\n",
      "batch 4868, train_loss 45.463917,Time used 0.004000s\n",
      "batch 4869, train_loss 39.235168,Time used 0.004001s\n",
      "batch 4870, train_loss 45.409424,Time used 0.005034s\n",
      "batch 4871, train_loss 46.247311,Time used 0.004963s\n",
      "batch 4872, train_loss 41.055065,Time used 0.004998s\n",
      "batch 4873, train_loss 38.257420,Time used 0.004999s\n",
      "batch 4874, train_loss 39.546936,Time used 0.004000s\n",
      "batch 4875, train_loss 47.784355,Time used 0.006008s\n",
      "batch 4876, train_loss 50.547031,Time used 0.004997s\n",
      "batch 4877, train_loss 38.342731,Time used 0.006999s\n",
      "batch 4878, train_loss 37.816006,Time used 0.007998s\n",
      "batch 4879, train_loss 43.404022,Time used 0.008002s\n",
      "batch 4880, train_loss 37.606415,Time used 0.007998s\n",
      "batch 4881, train_loss 41.238667,Time used 0.005001s\n",
      "batch 4882, train_loss 37.316029,Time used 0.006001s\n",
      "batch 4883, train_loss 44.280518,Time used 0.004997s\n",
      "batch 4884, train_loss 36.096241,Time used 0.005001s\n",
      "batch 4885, train_loss 61.455841,Time used 0.007998s\n",
      "batch 4886, train_loss 42.625690,Time used 0.006000s\n",
      "batch 4887, train_loss 38.836575,Time used 0.006002s\n",
      "batch 4888, train_loss 36.826256,Time used 0.007001s\n",
      "batch 4889, train_loss 42.053642,Time used 0.005996s\n",
      "batch 4890, train_loss 38.992348,Time used 0.005002s\n",
      "batch 4891, train_loss 48.367744,Time used 0.004998s\n",
      "batch 4892, train_loss 34.872616,Time used 0.006037s\n",
      "batch 4893, train_loss 45.918282,Time used 0.005030s\n",
      "batch 4894, train_loss 39.516712,Time used 0.004999s\n",
      "batch 4895, train_loss 45.760406,Time used 0.005000s\n",
      "batch 4896, train_loss 37.995914,Time used 0.005010s\n",
      "batch 4897, train_loss 43.576420,Time used 0.004000s\n",
      "batch 4898, train_loss 34.032524,Time used 0.004998s\n",
      "batch 4899, train_loss 47.797409,Time used 0.006001s\n",
      "batch 4900, train_loss 38.332775,Time used 0.005036s\n",
      "***************************test_batch 4900, test_rmse_loss 7.688851,test_mae_loss 3.358349,test_mape_loss 55.765308,Time used 0.020967s\n",
      "batch 4901, train_loss 38.387730,Time used 0.004995s\n",
      "batch 4902, train_loss 41.288506,Time used 0.005000s\n",
      "batch 4903, train_loss 31.789274,Time used 0.003999s\n",
      "batch 4904, train_loss 43.788200,Time used 0.006037s\n",
      "batch 4905, train_loss 39.440567,Time used 0.004998s\n",
      "batch 4906, train_loss 42.684635,Time used 0.004999s\n",
      "batch 4907, train_loss 51.776142,Time used 0.006969s\n",
      "batch 4908, train_loss 36.649319,Time used 0.006999s\n",
      "batch 4909, train_loss 50.566620,Time used 0.007028s\n",
      "batch 4910, train_loss 41.104794,Time used 0.007003s\n",
      "batch 4911, train_loss 36.044983,Time used 0.006963s\n",
      "batch 4912, train_loss 46.103142,Time used 0.006001s\n",
      "batch 4913, train_loss 36.683998,Time used 0.006999s\n",
      "batch 4914, train_loss 43.484325,Time used 0.007037s\n",
      "batch 4915, train_loss 38.513519,Time used 0.005967s\n",
      "batch 4916, train_loss 46.184834,Time used 0.007999s\n",
      "batch 4917, train_loss 44.750038,Time used 0.006998s\n",
      "batch 4918, train_loss 45.545826,Time used 0.006003s\n",
      "batch 4919, train_loss 42.045307,Time used 0.009998s\n",
      "batch 4920, train_loss 41.772232,Time used 0.007000s\n",
      "batch 4921, train_loss 37.833481,Time used 0.004995s\n",
      "batch 4922, train_loss 40.032761,Time used 0.005003s\n",
      "batch 4923, train_loss 37.491623,Time used 0.005033s\n",
      "batch 4924, train_loss 40.139614,Time used 0.004998s\n",
      "batch 4925, train_loss 50.261887,Time used 0.006964s\n",
      "batch 4926, train_loss 42.803761,Time used 0.007000s\n",
      "batch 4927, train_loss 46.060566,Time used 0.006003s\n",
      "batch 4928, train_loss 38.848728,Time used 0.005031s\n",
      "batch 4929, train_loss 43.086517,Time used 0.006006s\n",
      "batch 4930, train_loss 43.709919,Time used 0.004964s\n",
      "batch 4931, train_loss 39.993404,Time used 0.005000s\n",
      "batch 4932, train_loss 40.152634,Time used 0.005000s\n",
      "batch 4933, train_loss 29.349630,Time used 0.005995s\n",
      "batch 4934, train_loss 41.462551,Time used 0.005001s\n",
      "batch 4935, train_loss 48.033859,Time used 0.005001s\n",
      "batch 4936, train_loss 36.061207,Time used 0.005002s\n",
      "batch 4937, train_loss 47.567322,Time used 0.005001s\n",
      "batch 4938, train_loss 48.737713,Time used 0.004998s\n",
      "batch 4939, train_loss 45.091175,Time used 0.004999s\n",
      "batch 4940, train_loss 40.563068,Time used 0.004999s\n",
      "batch 4941, train_loss 44.537685,Time used 0.005000s\n",
      "batch 4942, train_loss 42.859261,Time used 0.005999s\n",
      "batch 4943, train_loss 39.635521,Time used 0.006003s\n",
      "batch 4944, train_loss 34.804325,Time used 0.005000s\n",
      "batch 4945, train_loss 44.602615,Time used 0.004999s\n",
      "batch 4946, train_loss 50.952461,Time used 0.007993s\n",
      "batch 4947, train_loss 41.006302,Time used 0.005000s\n",
      "batch 4948, train_loss 40.729340,Time used 0.005000s\n",
      "batch 4949, train_loss 46.935020,Time used 0.005035s\n",
      "batch 4950, train_loss 43.774765,Time used 0.005002s\n",
      "batch 4951, train_loss 40.435837,Time used 0.004966s\n",
      "batch 4952, train_loss 38.163734,Time used 0.005002s\n",
      "batch 4953, train_loss 38.916092,Time used 0.005028s\n",
      "batch 4954, train_loss 44.128128,Time used 0.005000s\n",
      "batch 4955, train_loss 37.205524,Time used 0.005970s\n",
      "batch 4956, train_loss 45.625877,Time used 0.005035s\n",
      "batch 4957, train_loss 41.166088,Time used 0.004005s\n",
      "batch 4958, train_loss 44.260937,Time used 0.005998s\n",
      "batch 4959, train_loss 37.364956,Time used 0.003996s\n",
      "batch 4960, train_loss 48.155872,Time used 0.003998s\n",
      "batch 4961, train_loss 44.186180,Time used 0.008966s\n",
      "batch 4962, train_loss 33.883541,Time used 0.005000s\n",
      "batch 4963, train_loss 39.234390,Time used 0.006001s\n",
      "batch 4964, train_loss 36.384293,Time used 0.004999s\n",
      "batch 4965, train_loss 38.385838,Time used 0.007000s\n",
      "batch 4966, train_loss 33.564480,Time used 0.005002s\n",
      "batch 4967, train_loss 39.584408,Time used 0.005998s\n",
      "batch 4968, train_loss 47.338936,Time used 0.004000s\n",
      "batch 4969, train_loss 48.461254,Time used 0.006999s\n",
      "batch 4970, train_loss 49.259853,Time used 0.006001s\n",
      "batch 4971, train_loss 43.909763,Time used 0.007037s\n",
      "batch 4972, train_loss 35.181492,Time used 0.006962s\n",
      "batch 4973, train_loss 42.717705,Time used 0.005000s\n",
      "batch 4974, train_loss 38.232121,Time used 0.005000s\n",
      "batch 4975, train_loss 43.012238,Time used 0.005039s\n",
      "batch 4976, train_loss 44.197742,Time used 0.008000s\n",
      "batch 4977, train_loss 45.122654,Time used 0.006000s\n",
      "batch 4978, train_loss 35.243523,Time used 0.004961s\n",
      "batch 4979, train_loss 47.055557,Time used 0.004997s\n",
      "batch 4980, train_loss 39.289341,Time used 0.006005s\n",
      "batch 4981, train_loss 36.014542,Time used 0.007998s\n",
      "batch 4982, train_loss 44.898369,Time used 0.006037s\n",
      "batch 4983, train_loss 43.904602,Time used 0.007959s\n",
      "batch 4984, train_loss 41.171333,Time used 0.007000s\n",
      "batch 4985, train_loss 42.519604,Time used 0.006001s\n",
      "batch 4986, train_loss 32.907661,Time used 0.005001s\n",
      "batch 4987, train_loss 38.812237,Time used 0.004003s\n",
      "batch 4988, train_loss 37.283798,Time used 0.006994s\n",
      "batch 4989, train_loss 37.118866,Time used 0.004001s\n",
      "batch 4990, train_loss 38.921913,Time used 0.004999s\n",
      "batch 4991, train_loss 42.359444,Time used 0.008001s\n",
      "batch 4992, train_loss 45.568615,Time used 0.008000s\n",
      "batch 4993, train_loss 39.502579,Time used 0.009000s\n",
      "batch 4994, train_loss 31.532316,Time used 0.006000s\n",
      "batch 4995, train_loss 43.476448,Time used 0.005998s\n",
      "batch 4996, train_loss 35.846493,Time used 0.005999s\n",
      "batch 4997, train_loss 39.539040,Time used 0.007002s\n",
      "batch 4998, train_loss 45.547062,Time used 0.005997s\n",
      "batch 4999, train_loss 47.394367,Time used 0.007001s\n",
      "batch 5000, train_loss 38.940647,Time used 0.006998s\n",
      "***************************test_batch 5000, test_rmse_loss 7.660436,test_mae_loss 3.352417,test_mape_loss 55.728419,Time used 0.027999s\n",
      "batch 5001, train_loss 41.048378,Time used 0.006001s\n",
      "batch 5002, train_loss 49.795357,Time used 0.004998s\n",
      "batch 5003, train_loss 37.480576,Time used 0.005001s\n",
      "batch 5004, train_loss 37.813530,Time used 0.005998s\n",
      "batch 5005, train_loss 40.964363,Time used 0.005001s\n",
      "batch 5006, train_loss 44.410488,Time used 0.005000s\n",
      "batch 5007, train_loss 40.134571,Time used 0.005999s\n",
      "batch 5008, train_loss 41.978107,Time used 0.005000s\n",
      "batch 5009, train_loss 37.157860,Time used 0.004000s\n",
      "batch 5010, train_loss 50.714516,Time used 0.007000s\n",
      "batch 5011, train_loss 42.272919,Time used 0.005001s\n",
      "batch 5012, train_loss 36.131294,Time used 0.005037s\n",
      "batch 5013, train_loss 46.879013,Time used 0.005965s\n",
      "batch 5014, train_loss 41.008518,Time used 0.005014s\n",
      "batch 5015, train_loss 39.531517,Time used 0.003999s\n",
      "batch 5016, train_loss 40.869881,Time used 0.005999s\n",
      "batch 5017, train_loss 36.810013,Time used 0.005999s\n",
      "batch 5018, train_loss 44.394215,Time used 0.004002s\n",
      "batch 5019, train_loss 44.071903,Time used 0.003999s\n",
      "batch 5020, train_loss 39.405899,Time used 0.007963s\n",
      "batch 5021, train_loss 34.604992,Time used 0.006999s\n",
      "batch 5022, train_loss 50.589928,Time used 0.008008s\n",
      "batch 5023, train_loss 39.174797,Time used 0.004996s\n",
      "batch 5024, train_loss 45.563595,Time used 0.004038s\n",
      "batch 5025, train_loss 45.005875,Time used 0.006998s\n",
      "batch 5026, train_loss 47.010979,Time used 0.005998s\n",
      "batch 5027, train_loss 38.294872,Time used 0.005964s\n",
      "batch 5028, train_loss 35.921528,Time used 0.004999s\n",
      "batch 5029, train_loss 39.390633,Time used 0.004999s\n",
      "batch 5030, train_loss 33.567577,Time used 0.005004s\n",
      "batch 5031, train_loss 49.846714,Time used 0.005031s\n",
      "batch 5032, train_loss 38.887798,Time used 0.004965s\n",
      "batch 5033, train_loss 38.381138,Time used 0.005034s\n",
      "batch 5034, train_loss 40.703346,Time used 0.006000s\n",
      "batch 5035, train_loss 36.009037,Time used 0.004999s\n",
      "batch 5036, train_loss 44.081917,Time used 0.005001s\n",
      "batch 5037, train_loss 42.075687,Time used 0.005000s\n",
      "batch 5038, train_loss 41.811314,Time used 0.006965s\n",
      "batch 5039, train_loss 39.800262,Time used 0.004002s\n",
      "batch 5040, train_loss 41.823898,Time used 0.004997s\n",
      "batch 5041, train_loss 42.859852,Time used 0.005003s\n",
      "batch 5042, train_loss 47.100826,Time used 0.007032s\n",
      "batch 5043, train_loss 45.334461,Time used 0.004966s\n",
      "batch 5044, train_loss 39.729950,Time used 0.005000s\n",
      "batch 5045, train_loss 30.525551,Time used 0.003999s\n",
      "batch 5046, train_loss 39.534447,Time used 0.005999s\n",
      "batch 5047, train_loss 41.461552,Time used 0.005000s\n",
      "batch 5048, train_loss 37.938694,Time used 0.005009s\n",
      "batch 5049, train_loss 46.097855,Time used 0.006991s\n",
      "batch 5050, train_loss 42.966164,Time used 0.007002s\n",
      "batch 5051, train_loss 42.158794,Time used 0.006032s\n",
      "batch 5052, train_loss 34.139069,Time used 0.004999s\n",
      "batch 5053, train_loss 38.777351,Time used 0.005002s\n",
      "batch 5054, train_loss 42.348160,Time used 0.005964s\n",
      "batch 5055, train_loss 45.515606,Time used 0.005000s\n",
      "batch 5056, train_loss 45.188923,Time used 0.005000s\n",
      "batch 5057, train_loss 41.423485,Time used 0.008000s\n",
      "batch 5058, train_loss 46.089737,Time used 0.004997s\n",
      "batch 5059, train_loss 39.285995,Time used 0.006003s\n",
      "batch 5060, train_loss 38.233604,Time used 0.007999s\n",
      "batch 5061, train_loss 43.159954,Time used 0.006002s\n",
      "batch 5062, train_loss 37.088261,Time used 0.006001s\n",
      "batch 5063, train_loss 35.491241,Time used 0.005034s\n",
      "batch 5064, train_loss 41.799454,Time used 0.005964s\n",
      "batch 5065, train_loss 39.993675,Time used 0.006967s\n",
      "batch 5066, train_loss 38.990566,Time used 0.006002s\n",
      "batch 5067, train_loss 40.458576,Time used 0.005000s\n",
      "batch 5068, train_loss 44.187672,Time used 0.005002s\n",
      "batch 5069, train_loss 40.533321,Time used 0.005033s\n",
      "batch 5070, train_loss 37.121754,Time used 0.004999s\n",
      "batch 5071, train_loss 44.824928,Time used 0.004967s\n",
      "batch 5072, train_loss 40.885868,Time used 0.005000s\n",
      "batch 5073, train_loss 42.818371,Time used 0.004000s\n",
      "batch 5074, train_loss 43.008076,Time used 0.007999s\n",
      "batch 5075, train_loss 54.023945,Time used 0.009997s\n",
      "batch 5076, train_loss 39.956192,Time used 0.006026s\n",
      "batch 5077, train_loss 46.182487,Time used 0.005974s\n",
      "batch 5078, train_loss 41.063850,Time used 0.005000s\n",
      "batch 5079, train_loss 36.571434,Time used 0.007001s\n",
      "batch 5080, train_loss 39.013138,Time used 0.006003s\n",
      "batch 5081, train_loss 36.325462,Time used 0.007994s\n",
      "batch 5082, train_loss 40.277554,Time used 0.008000s\n",
      "batch 5083, train_loss 43.256397,Time used 0.007002s\n",
      "batch 5084, train_loss 41.516781,Time used 0.007035s\n",
      "batch 5085, train_loss 39.856899,Time used 0.007964s\n",
      "batch 5086, train_loss 33.674488,Time used 0.007000s\n",
      "batch 5087, train_loss 36.183739,Time used 0.006000s\n",
      "batch 5088, train_loss 41.340115,Time used 0.006000s\n",
      "batch 5089, train_loss 51.962978,Time used 0.006003s\n",
      "batch 5090, train_loss 38.911026,Time used 0.008001s\n",
      "batch 5091, train_loss 44.103138,Time used 0.008000s\n",
      "batch 5092, train_loss 45.806831,Time used 0.006000s\n",
      "batch 5093, train_loss 37.555874,Time used 0.005000s\n",
      "batch 5094, train_loss 39.023102,Time used 0.005000s\n",
      "batch 5095, train_loss 44.086887,Time used 0.005001s\n",
      "batch 5096, train_loss 32.549759,Time used 0.006996s\n",
      "batch 5097, train_loss 43.864883,Time used 0.005001s\n",
      "batch 5098, train_loss 47.468868,Time used 0.007000s\n",
      "batch 5099, train_loss 41.667088,Time used 0.005003s\n",
      "batch 5100, train_loss 38.824780,Time used 0.004996s\n",
      "***************************test_batch 5100, test_rmse_loss 7.632078,test_mae_loss 3.339570,test_mape_loss 55.363353,Time used 0.018004s\n",
      "batch 5101, train_loss 46.492661,Time used 0.006995s\n",
      "batch 5102, train_loss 45.070267,Time used 0.005002s\n",
      "batch 5103, train_loss 39.941246,Time used 0.005000s\n",
      "batch 5104, train_loss 40.911480,Time used 0.005999s\n",
      "batch 5105, train_loss 41.395977,Time used 0.005038s\n",
      "batch 5106, train_loss 36.621849,Time used 0.005998s\n",
      "batch 5107, train_loss 31.470430,Time used 0.006000s\n",
      "batch 5108, train_loss 36.484306,Time used 0.004966s\n",
      "batch 5109, train_loss 37.734982,Time used 0.003997s\n",
      "batch 5110, train_loss 38.061172,Time used 0.005964s\n",
      "batch 5111, train_loss 37.362175,Time used 0.006033s\n",
      "batch 5112, train_loss 41.628429,Time used 0.005995s\n",
      "batch 5113, train_loss 42.272366,Time used 0.005001s\n",
      "batch 5114, train_loss 38.806114,Time used 0.008005s\n",
      "batch 5115, train_loss 43.569279,Time used 0.005995s\n",
      "batch 5116, train_loss 42.425533,Time used 0.007999s\n",
      "batch 5117, train_loss 38.143772,Time used 0.005000s\n",
      "batch 5118, train_loss 37.447994,Time used 0.005000s\n",
      "batch 5119, train_loss 37.605297,Time used 0.005038s\n",
      "batch 5120, train_loss 44.169643,Time used 0.005000s\n",
      "batch 5121, train_loss 36.828667,Time used 0.005000s\n",
      "batch 5122, train_loss 35.489994,Time used 0.005997s\n",
      "batch 5123, train_loss 38.766468,Time used 0.005000s\n",
      "batch 5124, train_loss 41.409523,Time used 0.004000s\n",
      "batch 5125, train_loss 42.043427,Time used 0.007038s\n",
      "batch 5126, train_loss 36.252010,Time used 0.004996s\n",
      "batch 5127, train_loss 44.502022,Time used 0.005003s\n",
      "batch 5128, train_loss 36.520218,Time used 0.006999s\n",
      "batch 5129, train_loss 38.310356,Time used 0.007971s\n",
      "batch 5130, train_loss 42.228741,Time used 0.004994s\n",
      "batch 5131, train_loss 38.200089,Time used 0.006033s\n",
      "batch 5132, train_loss 43.608555,Time used 0.005003s\n",
      "batch 5133, train_loss 52.300499,Time used 0.004965s\n",
      "batch 5134, train_loss 36.380119,Time used 0.006999s\n",
      "batch 5135, train_loss 51.830433,Time used 0.006002s\n",
      "batch 5136, train_loss 36.853794,Time used 0.007001s\n",
      "batch 5137, train_loss 31.881752,Time used 0.006001s\n",
      "batch 5138, train_loss 41.735378,Time used 0.005998s\n",
      "batch 5139, train_loss 35.006313,Time used 0.006039s\n",
      "batch 5140, train_loss 36.968555,Time used 0.005002s\n",
      "batch 5141, train_loss 35.647480,Time used 0.004996s\n",
      "batch 5142, train_loss 37.410328,Time used 0.006965s\n",
      "batch 5143, train_loss 30.489195,Time used 0.005999s\n",
      "batch 5144, train_loss 42.848042,Time used 0.006999s\n",
      "batch 5145, train_loss 57.081589,Time used 0.006036s\n",
      "batch 5146, train_loss 48.791428,Time used 0.007965s\n",
      "batch 5147, train_loss 38.161495,Time used 0.006001s\n",
      "batch 5148, train_loss 40.732418,Time used 0.005000s\n",
      "batch 5149, train_loss 32.963478,Time used 0.006997s\n",
      "batch 5150, train_loss 44.057716,Time used 0.005001s\n",
      "batch 5151, train_loss 46.363773,Time used 0.005000s\n",
      "batch 5152, train_loss 44.915176,Time used 0.010036s\n",
      "batch 5153, train_loss 45.156807,Time used 0.007008s\n",
      "batch 5154, train_loss 37.020134,Time used 0.004991s\n",
      "batch 5155, train_loss 40.373112,Time used 0.005002s\n",
      "batch 5156, train_loss 44.716640,Time used 0.005996s\n",
      "batch 5157, train_loss 38.528622,Time used 0.008008s\n",
      "batch 5158, train_loss 40.460972,Time used 0.006996s\n",
      "batch 5159, train_loss 33.896156,Time used 0.005001s\n",
      "batch 5160, train_loss 48.103783,Time used 0.004964s\n",
      "batch 5161, train_loss 32.846336,Time used 0.006039s\n",
      "batch 5162, train_loss 36.616714,Time used 0.007964s\n",
      "batch 5163, train_loss 45.751064,Time used 0.005036s\n",
      "batch 5164, train_loss 42.284843,Time used 0.005004s\n",
      "batch 5165, train_loss 43.670475,Time used 0.004959s\n",
      "batch 5166, train_loss 37.395123,Time used 0.006002s\n",
      "batch 5167, train_loss 38.514668,Time used 0.005000s\n",
      "batch 5168, train_loss 52.324955,Time used 0.005001s\n",
      "batch 5169, train_loss 32.823826,Time used 0.005000s\n",
      "batch 5170, train_loss 42.396080,Time used 0.004999s\n",
      "batch 5171, train_loss 41.002426,Time used 0.005028s\n",
      "batch 5172, train_loss 44.152714,Time used 0.005971s\n",
      "batch 5173, train_loss 39.402008,Time used 0.005000s\n",
      "batch 5174, train_loss 42.090855,Time used 0.005996s\n",
      "batch 5175, train_loss 34.615303,Time used 0.005002s\n",
      "batch 5176, train_loss 32.425659,Time used 0.006002s\n",
      "batch 5177, train_loss 36.003609,Time used 0.004995s\n",
      "batch 5178, train_loss 41.086349,Time used 0.005000s\n",
      "batch 5179, train_loss 43.224594,Time used 0.008000s\n",
      "batch 5180, train_loss 35.005291,Time used 0.005000s\n",
      "batch 5181, train_loss 46.132660,Time used 0.006001s\n",
      "batch 5182, train_loss 44.478512,Time used 0.004999s\n",
      "batch 5183, train_loss 39.610619,Time used 0.004999s\n",
      "batch 5184, train_loss 46.359039,Time used 0.005002s\n",
      "batch 5185, train_loss 39.155182,Time used 0.005001s\n",
      "batch 5186, train_loss 41.291363,Time used 0.004999s\n",
      "batch 5187, train_loss 32.612206,Time used 0.005001s\n",
      "batch 5188, train_loss 47.433331,Time used 0.005030s\n",
      "batch 5189, train_loss 39.943516,Time used 0.004001s\n",
      "batch 5190, train_loss 36.601353,Time used 0.004999s\n",
      "batch 5191, train_loss 34.887863,Time used 0.003996s\n",
      "batch 5192, train_loss 37.562832,Time used 0.005000s\n",
      "batch 5193, train_loss 40.588604,Time used 0.005000s\n",
      "batch 5194, train_loss 37.725018,Time used 0.005002s\n",
      "batch 5195, train_loss 45.633995,Time used 0.006998s\n",
      "batch 5196, train_loss 40.734711,Time used 0.006000s\n",
      "batch 5197, train_loss 46.658993,Time used 0.006998s\n",
      "batch 5198, train_loss 41.510372,Time used 0.004998s\n",
      "batch 5199, train_loss 38.346363,Time used 0.006002s\n",
      "batch 5200, train_loss 38.935238,Time used 0.008029s\n",
      "***************************test_batch 5200, test_rmse_loss 7.588327,test_mae_loss 3.327922,test_mape_loss 55.365373,Time used 0.017001s\n",
      "batch 5201, train_loss 36.123745,Time used 0.006032s\n",
      "batch 5202, train_loss 44.988056,Time used 0.005003s\n",
      "batch 5203, train_loss 42.502396,Time used 0.003997s\n",
      "batch 5204, train_loss 36.531578,Time used 0.006971s\n",
      "batch 5205, train_loss 47.038094,Time used 0.007001s\n",
      "batch 5206, train_loss 43.872326,Time used 0.006996s\n",
      "batch 5207, train_loss 39.017090,Time used 0.005999s\n",
      "batch 5208, train_loss 37.596687,Time used 0.005003s\n",
      "batch 5209, train_loss 36.906765,Time used 0.004996s\n",
      "batch 5210, train_loss 42.956589,Time used 0.006002s\n",
      "batch 5211, train_loss 43.710403,Time used 0.006003s\n",
      "batch 5212, train_loss 49.436794,Time used 0.006997s\n",
      "batch 5213, train_loss 39.677429,Time used 0.007999s\n",
      "batch 5214, train_loss 36.637238,Time used 0.004000s\n",
      "batch 5215, train_loss 38.094006,Time used 0.005002s\n",
      "batch 5216, train_loss 39.556877,Time used 0.004997s\n",
      "batch 5217, train_loss 37.782925,Time used 0.005000s\n",
      "batch 5218, train_loss 43.039787,Time used 0.006001s\n",
      "batch 5219, train_loss 40.639080,Time used 0.005002s\n",
      "batch 5220, train_loss 36.685928,Time used 0.003999s\n",
      "batch 5221, train_loss 48.455574,Time used 0.005002s\n",
      "batch 5222, train_loss 42.974541,Time used 0.008001s\n",
      "batch 5223, train_loss 29.967005,Time used 0.007000s\n",
      "batch 5224, train_loss 41.434952,Time used 0.006999s\n",
      "batch 5225, train_loss 34.073116,Time used 0.014001s\n",
      "batch 5226, train_loss 38.444885,Time used 0.010999s\n",
      "batch 5227, train_loss 38.923100,Time used 0.008999s\n",
      "batch 5228, train_loss 41.891270,Time used 0.016037s\n",
      "batch 5229, train_loss 42.883774,Time used 0.008002s\n",
      "batch 5230, train_loss 41.579594,Time used 0.004998s\n",
      "batch 5231, train_loss 38.969528,Time used 0.005963s\n",
      "batch 5232, train_loss 39.837826,Time used 0.006003s\n",
      "batch 5233, train_loss 32.334019,Time used 0.004998s\n",
      "batch 5234, train_loss 42.495930,Time used 0.004995s\n",
      "batch 5235, train_loss 51.632668,Time used 0.006007s\n",
      "batch 5236, train_loss 38.710831,Time used 0.004998s\n",
      "batch 5237, train_loss 34.797916,Time used 0.005999s\n",
      "batch 5238, train_loss 39.606468,Time used 0.005997s\n",
      "batch 5239, train_loss 39.228668,Time used 0.005002s\n",
      "batch 5240, train_loss 41.685974,Time used 0.004997s\n",
      "batch 5241, train_loss 43.075977,Time used 0.006004s\n",
      "batch 5242, train_loss 37.873569,Time used 0.004999s\n",
      "batch 5243, train_loss 39.260166,Time used 0.005000s\n",
      "batch 5244, train_loss 41.384369,Time used 0.006998s\n",
      "batch 5245, train_loss 32.228374,Time used 0.007000s\n",
      "batch 5246, train_loss 41.053802,Time used 0.008000s\n",
      "batch 5247, train_loss 42.347309,Time used 0.004998s\n",
      "batch 5248, train_loss 43.068195,Time used 0.004004s\n",
      "batch 5249, train_loss 39.457382,Time used 0.005002s\n",
      "batch 5250, train_loss 40.423595,Time used 0.004997s\n",
      "batch 5251, train_loss 41.352150,Time used 0.006001s\n",
      "batch 5252, train_loss 39.784058,Time used 0.007036s\n",
      "batch 5253, train_loss 41.636059,Time used 0.004999s\n",
      "batch 5254, train_loss 43.225193,Time used 0.004002s\n",
      "batch 5255, train_loss 35.650078,Time used 0.009037s\n",
      "batch 5256, train_loss 39.098557,Time used 0.006962s\n",
      "batch 5257, train_loss 45.968895,Time used 0.005038s\n",
      "batch 5258, train_loss 46.184681,Time used 0.007964s\n",
      "batch 5259, train_loss 35.165031,Time used 0.007004s\n",
      "batch 5260, train_loss 40.765224,Time used 0.004997s\n",
      "batch 5261, train_loss 44.294876,Time used 0.005996s\n",
      "batch 5262, train_loss 32.050861,Time used 0.006003s\n",
      "batch 5263, train_loss 33.249615,Time used 0.007001s\n",
      "batch 5264, train_loss 38.420624,Time used 0.005997s\n",
      "batch 5265, train_loss 48.358749,Time used 0.006004s\n",
      "batch 5266, train_loss 38.704948,Time used 0.005999s\n",
      "batch 5267, train_loss 40.458019,Time used 0.006996s\n",
      "batch 5268, train_loss 37.355255,Time used 0.005000s\n",
      "batch 5269, train_loss 40.163525,Time used 0.005001s\n",
      "batch 5270, train_loss 40.547924,Time used 0.005003s\n",
      "batch 5271, train_loss 41.228512,Time used 0.004999s\n",
      "batch 5272, train_loss 34.955631,Time used 0.004999s\n",
      "batch 5273, train_loss 52.484722,Time used 0.007001s\n",
      "batch 5274, train_loss 34.047092,Time used 0.005002s\n",
      "batch 5275, train_loss 31.600475,Time used 0.006002s\n",
      "batch 5276, train_loss 38.663700,Time used 0.007997s\n",
      "batch 5277, train_loss 37.043488,Time used 0.007003s\n",
      "batch 5278, train_loss 38.485718,Time used 0.005040s\n",
      "batch 5279, train_loss 42.304359,Time used 0.003994s\n",
      "batch 5280, train_loss 46.516556,Time used 0.005002s\n",
      "batch 5281, train_loss 43.395451,Time used 0.006001s\n",
      "batch 5282, train_loss 35.007275,Time used 0.006980s\n",
      "batch 5283, train_loss 42.998142,Time used 0.004016s\n",
      "batch 5284, train_loss 44.995285,Time used 0.003998s\n",
      "batch 5285, train_loss 42.443089,Time used 0.004966s\n",
      "batch 5286, train_loss 40.420803,Time used 0.005031s\n",
      "batch 5287, train_loss 37.293941,Time used 0.005966s\n",
      "batch 5288, train_loss 33.592518,Time used 0.004997s\n",
      "batch 5289, train_loss 38.665024,Time used 0.005000s\n",
      "batch 5290, train_loss 44.261780,Time used 0.006001s\n",
      "batch 5291, train_loss 38.377151,Time used 0.006001s\n",
      "batch 5292, train_loss 38.806808,Time used 0.004999s\n",
      "batch 5293, train_loss 46.037991,Time used 0.006000s\n",
      "batch 5294, train_loss 35.180695,Time used 0.007005s\n",
      "batch 5295, train_loss 43.083145,Time used 0.007998s\n",
      "batch 5296, train_loss 37.328182,Time used 0.008000s\n",
      "batch 5297, train_loss 40.336792,Time used 0.005038s\n",
      "batch 5298, train_loss 39.312794,Time used 0.004999s\n",
      "batch 5299, train_loss 40.693130,Time used 0.004999s\n",
      "batch 5300, train_loss 38.551086,Time used 0.005962s\n",
      "***************************test_batch 5300, test_rmse_loss 7.563373,test_mae_loss 3.319620,test_mape_loss 55.059251,Time used 0.018000s\n",
      "batch 5301, train_loss 37.140335,Time used 0.006001s\n",
      "batch 5302, train_loss 41.555237,Time used 0.005001s\n",
      "batch 5303, train_loss 37.765522,Time used 0.005036s\n",
      "batch 5304, train_loss 38.245998,Time used 0.003999s\n",
      "batch 5305, train_loss 35.287941,Time used 0.004960s\n",
      "batch 5306, train_loss 32.348259,Time used 0.004999s\n",
      "batch 5307, train_loss 46.358051,Time used 0.005001s\n",
      "batch 5308, train_loss 36.345730,Time used 0.008002s\n",
      "batch 5309, train_loss 38.732899,Time used 0.007000s\n",
      "batch 5310, train_loss 41.132885,Time used 0.006033s\n",
      "batch 5311, train_loss 37.904335,Time used 0.005004s\n",
      "batch 5312, train_loss 40.980118,Time used 0.004994s\n",
      "batch 5313, train_loss 39.151974,Time used 0.004967s\n",
      "batch 5314, train_loss 45.448044,Time used 0.005000s\n",
      "batch 5315, train_loss 43.132923,Time used 0.004001s\n",
      "batch 5316, train_loss 38.274796,Time used 0.006035s\n",
      "batch 5317, train_loss 46.741280,Time used 0.006999s\n",
      "batch 5318, train_loss 43.570553,Time used 0.005999s\n",
      "batch 5319, train_loss 42.010139,Time used 0.005963s\n",
      "batch 5320, train_loss 41.478043,Time used 0.005000s\n",
      "batch 5321, train_loss 38.105392,Time used 0.006000s\n",
      "batch 5322, train_loss 33.297676,Time used 0.005038s\n",
      "batch 5323, train_loss 35.431694,Time used 0.005000s\n",
      "batch 5324, train_loss 42.208164,Time used 0.004962s\n",
      "batch 5325, train_loss 36.178856,Time used 0.008007s\n",
      "batch 5326, train_loss 36.564186,Time used 0.005995s\n",
      "batch 5327, train_loss 35.965141,Time used 0.005039s\n",
      "batch 5328, train_loss 47.386223,Time used 0.004963s\n",
      "batch 5329, train_loss 34.107155,Time used 0.004965s\n",
      "batch 5330, train_loss 46.399940,Time used 0.005035s\n",
      "batch 5331, train_loss 36.857288,Time used 0.005000s\n",
      "batch 5332, train_loss 32.224609,Time used 0.004968s\n",
      "batch 5333, train_loss 38.356441,Time used 0.005000s\n",
      "batch 5334, train_loss 42.481152,Time used 0.005001s\n",
      "batch 5335, train_loss 46.122948,Time used 0.005000s\n",
      "batch 5336, train_loss 43.698109,Time used 0.005035s\n",
      "batch 5337, train_loss 39.146271,Time used 0.005961s\n",
      "batch 5338, train_loss 44.804996,Time used 0.005038s\n",
      "batch 5339, train_loss 41.616150,Time used 0.007000s\n",
      "batch 5340, train_loss 38.491493,Time used 0.004963s\n",
      "batch 5341, train_loss 30.717442,Time used 0.005997s\n",
      "batch 5342, train_loss 31.479280,Time used 0.003999s\n",
      "batch 5343, train_loss 36.898998,Time used 0.004001s\n",
      "batch 5344, train_loss 40.940258,Time used 0.006999s\n",
      "batch 5345, train_loss 45.065853,Time used 0.003999s\n",
      "batch 5346, train_loss 46.847836,Time used 0.007039s\n",
      "batch 5347, train_loss 42.415443,Time used 0.005003s\n",
      "batch 5348, train_loss 43.265972,Time used 0.004994s\n",
      "batch 5349, train_loss 38.869671,Time used 0.005966s\n",
      "batch 5350, train_loss 32.869976,Time used 0.005000s\n",
      "batch 5351, train_loss 36.552048,Time used 0.005033s\n",
      "batch 5352, train_loss 40.782780,Time used 0.004968s\n",
      "batch 5353, train_loss 50.720726,Time used 0.005999s\n",
      "batch 5354, train_loss 37.202282,Time used 0.006007s\n",
      "batch 5355, train_loss 40.409828,Time used 0.005993s\n",
      "batch 5356, train_loss 36.974972,Time used 0.008044s\n",
      "batch 5357, train_loss 42.130085,Time used 0.004993s\n",
      "batch 5358, train_loss 40.116432,Time used 0.006967s\n",
      "batch 5359, train_loss 37.829803,Time used 0.005997s\n",
      "batch 5360, train_loss 36.718075,Time used 0.003999s\n",
      "batch 5361, train_loss 36.282619,Time used 0.004002s\n",
      "batch 5362, train_loss 40.637215,Time used 0.006999s\n",
      "batch 5363, train_loss 47.918911,Time used 0.005001s\n",
      "batch 5364, train_loss 38.957970,Time used 0.004999s\n",
      "batch 5365, train_loss 37.960995,Time used 0.007033s\n",
      "batch 5366, train_loss 33.024757,Time used 0.004969s\n",
      "batch 5367, train_loss 36.163528,Time used 0.005994s\n",
      "batch 5368, train_loss 36.256767,Time used 0.005000s\n",
      "batch 5369, train_loss 39.799294,Time used 0.005000s\n",
      "batch 5370, train_loss 39.964836,Time used 0.005003s\n",
      "batch 5371, train_loss 41.980457,Time used 0.008000s\n",
      "batch 5372, train_loss 40.037624,Time used 0.005003s\n",
      "batch 5373, train_loss 35.396309,Time used 0.005022s\n",
      "batch 5374, train_loss 38.458565,Time used 0.003999s\n",
      "batch 5375, train_loss 37.654907,Time used 0.005967s\n",
      "batch 5376, train_loss 45.802666,Time used 0.007996s\n",
      "batch 5377, train_loss 42.140980,Time used 0.005998s\n",
      "batch 5378, train_loss 41.639912,Time used 0.004000s\n",
      "batch 5379, train_loss 38.459511,Time used 0.005004s\n",
      "batch 5380, train_loss 34.288010,Time used 0.005034s\n",
      "batch 5381, train_loss 38.204647,Time used 0.004996s\n",
      "batch 5382, train_loss 33.339935,Time used 0.005972s\n",
      "batch 5383, train_loss 40.985435,Time used 0.009999s\n",
      "batch 5384, train_loss 39.993008,Time used 0.007035s\n",
      "batch 5385, train_loss 42.226669,Time used 0.004964s\n",
      "batch 5386, train_loss 39.684967,Time used 0.005996s\n",
      "batch 5387, train_loss 39.382214,Time used 0.005004s\n",
      "batch 5388, train_loss 37.222420,Time used 0.006001s\n",
      "batch 5389, train_loss 39.035542,Time used 0.005001s\n",
      "batch 5390, train_loss 36.282200,Time used 0.006001s\n",
      "batch 5391, train_loss 35.878708,Time used 0.004995s\n",
      "batch 5392, train_loss 35.985867,Time used 0.005038s\n",
      "batch 5393, train_loss 42.547028,Time used 0.005968s\n",
      "batch 5394, train_loss 45.085903,Time used 0.005030s\n",
      "batch 5395, train_loss 37.442142,Time used 0.004968s\n",
      "batch 5396, train_loss 45.949467,Time used 0.004995s\n",
      "batch 5397, train_loss 39.893246,Time used 0.005001s\n",
      "batch 5398, train_loss 37.429630,Time used 0.004999s\n",
      "batch 5399, train_loss 41.314495,Time used 0.005041s\n",
      "batch 5400, train_loss 40.694553,Time used 0.004997s\n",
      "***************************test_batch 5400, test_rmse_loss 7.545469,test_mae_loss 3.313885,test_mape_loss 54.860153,Time used 0.016963s\n",
      "batch 5401, train_loss 39.387161,Time used 0.006035s\n",
      "batch 5402, train_loss 43.323841,Time used 0.005964s\n",
      "batch 5403, train_loss 37.264629,Time used 0.005008s\n",
      "batch 5404, train_loss 47.719051,Time used 0.004997s\n",
      "batch 5405, train_loss 36.991299,Time used 0.005000s\n",
      "batch 5406, train_loss 37.159367,Time used 0.004000s\n",
      "batch 5407, train_loss 50.145573,Time used 0.005996s\n",
      "batch 5408, train_loss 34.620190,Time used 0.005000s\n",
      "batch 5409, train_loss 31.865923,Time used 0.006039s\n",
      "batch 5410, train_loss 39.037930,Time used 0.004961s\n",
      "batch 5411, train_loss 38.910629,Time used 0.006038s\n",
      "batch 5412, train_loss 40.242729,Time used 0.005003s\n",
      "batch 5413, train_loss 39.271603,Time used 0.007965s\n",
      "batch 5414, train_loss 46.902714,Time used 0.006004s\n",
      "batch 5415, train_loss 41.457294,Time used 0.005030s\n",
      "batch 5416, train_loss 38.945904,Time used 0.004998s\n",
      "batch 5417, train_loss 39.206829,Time used 0.005967s\n",
      "batch 5418, train_loss 36.450699,Time used 0.005033s\n",
      "batch 5419, train_loss 33.083698,Time used 0.004999s\n",
      "batch 5420, train_loss 28.524975,Time used 0.005000s\n",
      "batch 5421, train_loss 38.135818,Time used 0.004997s\n",
      "batch 5422, train_loss 42.475426,Time used 0.003999s\n",
      "batch 5423, train_loss 43.130894,Time used 0.003964s\n",
      "batch 5424, train_loss 38.916924,Time used 0.007002s\n",
      "batch 5425, train_loss 37.402004,Time used 0.004995s\n",
      "batch 5426, train_loss 32.962334,Time used 0.005003s\n",
      "batch 5427, train_loss 38.001160,Time used 0.006037s\n",
      "batch 5428, train_loss 40.352108,Time used 0.005000s\n",
      "batch 5429, train_loss 47.264145,Time used 0.006003s\n",
      "batch 5430, train_loss 38.630444,Time used 0.007962s\n",
      "batch 5431, train_loss 40.006027,Time used 0.007002s\n",
      "batch 5432, train_loss 35.380627,Time used 0.007997s\n",
      "batch 5433, train_loss 36.533787,Time used 0.008002s\n",
      "batch 5434, train_loss 37.094471,Time used 0.008000s\n",
      "batch 5435, train_loss 45.868752,Time used 0.006999s\n",
      "batch 5436, train_loss 48.618317,Time used 0.008001s\n",
      "batch 5437, train_loss 42.722836,Time used 0.005997s\n",
      "batch 5438, train_loss 37.070557,Time used 0.010001s\n",
      "batch 5439, train_loss 38.783756,Time used 0.009001s\n",
      "batch 5440, train_loss 30.984426,Time used 0.007999s\n",
      "batch 5441, train_loss 35.241138,Time used 0.008003s\n",
      "batch 5442, train_loss 38.913876,Time used 0.007998s\n",
      "batch 5443, train_loss 30.498716,Time used 0.008000s\n",
      "batch 5444, train_loss 39.909798,Time used 0.009003s\n",
      "batch 5445, train_loss 44.194263,Time used 0.007997s\n",
      "batch 5446, train_loss 40.229259,Time used 0.007998s\n",
      "batch 5447, train_loss 41.815426,Time used 0.009000s\n",
      "batch 5448, train_loss 41.848576,Time used 0.007999s\n",
      "batch 5449, train_loss 43.633106,Time used 0.007998s\n",
      "batch 5450, train_loss 46.654888,Time used 0.007999s\n",
      "batch 5451, train_loss 46.743519,Time used 0.008001s\n",
      "batch 5452, train_loss 32.442432,Time used 0.006997s\n",
      "batch 5453, train_loss 45.454296,Time used 0.005999s\n",
      "batch 5454, train_loss 41.250324,Time used 0.007003s\n",
      "batch 5455, train_loss 35.454739,Time used 0.009000s\n",
      "batch 5456, train_loss 43.114929,Time used 0.007999s\n",
      "batch 5457, train_loss 32.470520,Time used 0.008002s\n",
      "batch 5458, train_loss 36.669094,Time used 0.007998s\n",
      "batch 5459, train_loss 38.854179,Time used 0.009001s\n",
      "batch 5460, train_loss 37.918995,Time used 0.006997s\n",
      "batch 5461, train_loss 31.165070,Time used 0.006999s\n",
      "batch 5462, train_loss 41.076176,Time used 0.007999s\n",
      "batch 5463, train_loss 47.756145,Time used 0.009001s\n",
      "batch 5464, train_loss 32.119534,Time used 0.006999s\n",
      "batch 5465, train_loss 43.884941,Time used 0.007000s\n",
      "batch 5466, train_loss 33.178532,Time used 0.008998s\n",
      "batch 5467, train_loss 32.339470,Time used 0.008001s\n",
      "batch 5468, train_loss 39.404587,Time used 0.007004s\n",
      "batch 5469, train_loss 39.046803,Time used 0.007998s\n",
      "batch 5470, train_loss 38.711861,Time used 0.005001s\n",
      "batch 5471, train_loss 34.793385,Time used 0.007999s\n",
      "batch 5472, train_loss 43.584755,Time used 0.007999s\n",
      "batch 5473, train_loss 41.542343,Time used 0.007999s\n",
      "batch 5474, train_loss 39.351856,Time used 0.009001s\n",
      "batch 5475, train_loss 43.178791,Time used 0.010000s\n",
      "batch 5476, train_loss 42.736248,Time used 0.010000s\n",
      "batch 5477, train_loss 32.014561,Time used 0.008999s\n",
      "batch 5478, train_loss 37.772621,Time used 0.016000s\n",
      "batch 5479, train_loss 41.948887,Time used 0.009000s\n",
      "batch 5480, train_loss 39.745148,Time used 0.010000s\n",
      "batch 5481, train_loss 39.335453,Time used 0.009001s\n",
      "batch 5482, train_loss 37.989292,Time used 0.009001s\n",
      "batch 5483, train_loss 37.531670,Time used 0.008002s\n",
      "batch 5484, train_loss 40.372849,Time used 0.007997s\n",
      "batch 5485, train_loss 37.955582,Time used 0.009000s\n",
      "batch 5486, train_loss 46.826565,Time used 0.006001s\n",
      "batch 5487, train_loss 37.090797,Time used 0.007004s\n",
      "batch 5488, train_loss 35.821625,Time used 0.006998s\n",
      "batch 5489, train_loss 42.976757,Time used 0.008002s\n",
      "batch 5490, train_loss 39.920097,Time used 0.008999s\n",
      "batch 5491, train_loss 39.449699,Time used 0.007997s\n",
      "batch 5492, train_loss 32.397255,Time used 0.008004s\n",
      "batch 5493, train_loss 36.504887,Time used 0.008998s\n",
      "batch 5494, train_loss 35.876492,Time used 0.006001s\n",
      "batch 5495, train_loss 40.547115,Time used 0.008998s\n",
      "batch 5496, train_loss 36.592838,Time used 0.008999s\n",
      "batch 5497, train_loss 34.044884,Time used 0.009003s\n",
      "batch 5498, train_loss 42.673943,Time used 0.005999s\n",
      "batch 5499, train_loss 42.180187,Time used 0.007001s\n",
      "batch 5500, train_loss 38.139824,Time used 0.008999s\n",
      "***************************test_batch 5500, test_rmse_loss 7.482933,test_mae_loss 3.295097,test_mape_loss 55.014983,Time used 0.030007s\n",
      "batch 5501, train_loss 45.049099,Time used 0.006995s\n",
      "batch 5502, train_loss 42.392181,Time used 0.005000s\n",
      "batch 5503, train_loss 33.450424,Time used 0.005999s\n",
      "batch 5504, train_loss 37.282013,Time used 0.006999s\n",
      "batch 5505, train_loss 44.189930,Time used 0.008000s\n",
      "batch 5506, train_loss 35.516693,Time used 0.005000s\n",
      "batch 5507, train_loss 39.913353,Time used 0.006006s\n",
      "batch 5508, train_loss 43.602684,Time used 0.008999s\n",
      "batch 5509, train_loss 40.335415,Time used 0.005999s\n",
      "batch 5510, train_loss 32.583057,Time used 0.004999s\n",
      "batch 5511, train_loss 52.263256,Time used 0.005000s\n",
      "batch 5512, train_loss 38.936066,Time used 0.007000s\n",
      "batch 5513, train_loss 36.654869,Time used 0.006001s\n",
      "batch 5514, train_loss 37.007828,Time used 0.006999s\n",
      "batch 5515, train_loss 36.595764,Time used 0.004998s\n",
      "batch 5516, train_loss 38.189411,Time used 0.004002s\n",
      "batch 5517, train_loss 36.468777,Time used 0.005002s\n",
      "batch 5518, train_loss 40.924702,Time used 0.003997s\n",
      "batch 5519, train_loss 33.854351,Time used 0.006000s\n",
      "batch 5520, train_loss 30.152485,Time used 0.003999s\n",
      "batch 5521, train_loss 38.186665,Time used 0.005030s\n",
      "batch 5522, train_loss 39.968506,Time used 0.004965s\n",
      "batch 5523, train_loss 39.660362,Time used 0.004998s\n",
      "batch 5524, train_loss 37.975128,Time used 0.005001s\n",
      "batch 5525, train_loss 36.755783,Time used 0.005000s\n",
      "batch 5526, train_loss 40.136078,Time used 0.004999s\n",
      "batch 5527, train_loss 34.971592,Time used 0.005002s\n",
      "batch 5528, train_loss 41.929440,Time used 0.004999s\n",
      "batch 5529, train_loss 36.302856,Time used 0.005000s\n",
      "batch 5530, train_loss 40.311924,Time used 0.005002s\n",
      "batch 5531, train_loss 37.924107,Time used 0.004996s\n",
      "batch 5532, train_loss 42.446419,Time used 0.007001s\n",
      "batch 5533, train_loss 35.209270,Time used 0.005002s\n",
      "batch 5534, train_loss 41.612259,Time used 0.005000s\n",
      "batch 5535, train_loss 38.370712,Time used 0.004999s\n",
      "batch 5536, train_loss 39.786610,Time used 0.007001s\n",
      "batch 5537, train_loss 38.826885,Time used 0.006000s\n",
      "batch 5538, train_loss 47.787182,Time used 0.005998s\n",
      "batch 5539, train_loss 39.543530,Time used 0.006002s\n",
      "batch 5540, train_loss 30.036921,Time used 0.004998s\n",
      "batch 5541, train_loss 34.615192,Time used 0.004001s\n",
      "batch 5542, train_loss 37.541012,Time used 0.005000s\n",
      "batch 5543, train_loss 36.957634,Time used 0.004998s\n",
      "batch 5544, train_loss 42.373306,Time used 0.005000s\n",
      "batch 5545, train_loss 47.183357,Time used 0.004997s\n",
      "batch 5546, train_loss 38.817596,Time used 0.004999s\n",
      "batch 5547, train_loss 40.418900,Time used 0.005000s\n",
      "batch 5548, train_loss 43.208546,Time used 0.005002s\n",
      "batch 5549, train_loss 45.990376,Time used 0.005000s\n",
      "batch 5550, train_loss 38.839001,Time used 0.006001s\n",
      "batch 5551, train_loss 44.231079,Time used 0.004997s\n",
      "batch 5552, train_loss 37.053249,Time used 0.005000s\n",
      "batch 5553, train_loss 38.381584,Time used 0.005036s\n",
      "batch 5554, train_loss 38.331322,Time used 0.005966s\n",
      "batch 5555, train_loss 39.537991,Time used 0.008036s\n",
      "batch 5556, train_loss 37.065544,Time used 0.006963s\n",
      "batch 5557, train_loss 30.907898,Time used 0.004999s\n",
      "batch 5558, train_loss 28.686569,Time used 0.005001s\n",
      "batch 5559, train_loss 34.254299,Time used 0.006007s\n",
      "batch 5560, train_loss 38.093735,Time used 0.008032s\n",
      "batch 5561, train_loss 38.997898,Time used 0.005998s\n",
      "batch 5562, train_loss 38.768188,Time used 0.005000s\n",
      "batch 5563, train_loss 38.774311,Time used 0.004963s\n",
      "batch 5564, train_loss 34.886795,Time used 0.006997s\n",
      "batch 5565, train_loss 34.560413,Time used 0.005998s\n",
      "batch 5566, train_loss 30.299818,Time used 0.005000s\n",
      "batch 5567, train_loss 45.173874,Time used 0.005997s\n",
      "batch 5568, train_loss 44.562435,Time used 0.005033s\n",
      "batch 5569, train_loss 40.134525,Time used 0.006007s\n",
      "batch 5570, train_loss 28.391634,Time used 0.004997s\n",
      "batch 5571, train_loss 42.061989,Time used 0.004960s\n",
      "batch 5572, train_loss 43.147156,Time used 0.005999s\n",
      "batch 5573, train_loss 36.765583,Time used 0.005001s\n",
      "batch 5574, train_loss 37.998840,Time used 0.008006s\n",
      "batch 5575, train_loss 41.357697,Time used 0.008968s\n",
      "batch 5576, train_loss 39.546028,Time used 0.004998s\n",
      "batch 5577, train_loss 45.783806,Time used 0.005995s\n",
      "batch 5578, train_loss 40.860672,Time used 0.005001s\n",
      "batch 5579, train_loss 36.384308,Time used 0.004999s\n",
      "batch 5580, train_loss 38.156765,Time used 0.005000s\n",
      "batch 5581, train_loss 40.143539,Time used 0.005003s\n",
      "batch 5582, train_loss 36.512039,Time used 0.007001s\n",
      "batch 5583, train_loss 49.080925,Time used 0.006998s\n",
      "batch 5584, train_loss 35.661121,Time used 0.004992s\n",
      "batch 5585, train_loss 31.386915,Time used 0.005004s\n",
      "batch 5586, train_loss 36.814018,Time used 0.005001s\n",
      "batch 5587, train_loss 37.285118,Time used 0.005000s\n",
      "batch 5588, train_loss 37.365131,Time used 0.004000s\n",
      "batch 5589, train_loss 37.130840,Time used 0.005001s\n",
      "batch 5590, train_loss 37.895901,Time used 0.005000s\n",
      "batch 5591, train_loss 37.127918,Time used 0.004999s\n",
      "batch 5592, train_loss 36.848667,Time used 0.006001s\n",
      "batch 5593, train_loss 40.368919,Time used 0.008001s\n",
      "batch 5594, train_loss 38.255852,Time used 0.005998s\n",
      "batch 5595, train_loss 38.202770,Time used 0.007002s\n",
      "batch 5596, train_loss 36.106060,Time used 0.005998s\n",
      "batch 5597, train_loss 40.501785,Time used 0.004999s\n",
      "batch 5598, train_loss 36.445564,Time used 0.005017s\n",
      "batch 5599, train_loss 37.864632,Time used 0.006983s\n",
      "batch 5600, train_loss 42.326801,Time used 0.006999s\n",
      "***************************test_batch 5600, test_rmse_loss 7.439940,test_mae_loss 3.285088,test_mape_loss 55.002652,Time used 0.018001s\n",
      "batch 5601, train_loss 39.164249,Time used 0.005999s\n",
      "batch 5602, train_loss 38.163277,Time used 0.004000s\n",
      "batch 5603, train_loss 32.989330,Time used 0.005001s\n",
      "batch 5604, train_loss 41.850327,Time used 0.006002s\n",
      "batch 5605, train_loss 34.754887,Time used 0.005001s\n",
      "batch 5606, train_loss 44.406792,Time used 0.004997s\n",
      "batch 5607, train_loss 41.216831,Time used 0.004998s\n",
      "batch 5608, train_loss 36.369011,Time used 0.005001s\n",
      "batch 5609, train_loss 35.912838,Time used 0.006038s\n",
      "batch 5610, train_loss 38.153774,Time used 0.004998s\n",
      "batch 5611, train_loss 39.457829,Time used 0.005002s\n",
      "batch 5612, train_loss 44.938580,Time used 0.006966s\n",
      "batch 5613, train_loss 36.054260,Time used 0.004998s\n",
      "batch 5614, train_loss 37.877594,Time used 0.004033s\n",
      "batch 5615, train_loss 38.108189,Time used 0.005000s\n",
      "batch 5616, train_loss 32.187599,Time used 0.004970s\n",
      "batch 5617, train_loss 37.609016,Time used 0.004966s\n",
      "batch 5618, train_loss 37.482414,Time used 0.005000s\n",
      "batch 5619, train_loss 40.647953,Time used 0.005999s\n",
      "batch 5620, train_loss 42.102551,Time used 0.004998s\n",
      "batch 5621, train_loss 34.055271,Time used 0.004999s\n",
      "batch 5622, train_loss 43.553539,Time used 0.006000s\n",
      "batch 5623, train_loss 42.568871,Time used 0.007001s\n",
      "batch 5624, train_loss 35.563469,Time used 0.006999s\n",
      "batch 5625, train_loss 35.783447,Time used 0.006000s\n",
      "batch 5626, train_loss 44.929825,Time used 0.005038s\n",
      "batch 5627, train_loss 41.581375,Time used 0.005999s\n",
      "batch 5628, train_loss 42.049107,Time used 0.005004s\n",
      "batch 5629, train_loss 27.178696,Time used 0.004998s\n",
      "batch 5630, train_loss 33.447731,Time used 0.006004s\n",
      "batch 5631, train_loss 40.961334,Time used 0.004995s\n",
      "batch 5632, train_loss 35.320484,Time used 0.004967s\n",
      "batch 5633, train_loss 45.383602,Time used 0.005033s\n",
      "batch 5634, train_loss 31.494194,Time used 0.005961s\n",
      "batch 5635, train_loss 45.231064,Time used 0.005000s\n",
      "batch 5636, train_loss 38.959869,Time used 0.004000s\n",
      "batch 5637, train_loss 39.949505,Time used 0.007000s\n",
      "batch 5638, train_loss 42.890335,Time used 0.006999s\n",
      "batch 5639, train_loss 32.871841,Time used 0.007000s\n",
      "batch 5640, train_loss 27.600359,Time used 0.006999s\n",
      "batch 5641, train_loss 44.276508,Time used 0.005001s\n",
      "batch 5642, train_loss 39.712944,Time used 0.005000s\n",
      "batch 5643, train_loss 37.622066,Time used 0.006002s\n",
      "batch 5644, train_loss 37.221489,Time used 0.007997s\n",
      "batch 5645, train_loss 37.894367,Time used 0.008038s\n",
      "batch 5646, train_loss 38.939983,Time used 0.005000s\n",
      "batch 5647, train_loss 39.913441,Time used 0.004998s\n",
      "batch 5648, train_loss 32.680275,Time used 0.006964s\n",
      "batch 5649, train_loss 38.896999,Time used 0.005999s\n",
      "batch 5650, train_loss 42.024323,Time used 0.006002s\n",
      "batch 5651, train_loss 41.332554,Time used 0.006001s\n",
      "batch 5652, train_loss 39.511120,Time used 0.007997s\n",
      "batch 5653, train_loss 39.865025,Time used 0.007001s\n",
      "batch 5654, train_loss 33.982357,Time used 0.005001s\n",
      "batch 5655, train_loss 43.629097,Time used 0.007997s\n",
      "batch 5656, train_loss 35.929768,Time used 0.008000s\n",
      "batch 5657, train_loss 33.832535,Time used 0.005000s\n",
      "batch 5658, train_loss 44.103268,Time used 0.006002s\n",
      "batch 5659, train_loss 36.985771,Time used 0.005003s\n",
      "batch 5660, train_loss 36.136475,Time used 0.005000s\n",
      "batch 5661, train_loss 37.423203,Time used 0.006000s\n",
      "batch 5662, train_loss 37.370518,Time used 0.007001s\n",
      "batch 5663, train_loss 35.858440,Time used 0.005036s\n",
      "batch 5664, train_loss 32.317745,Time used 0.005999s\n",
      "batch 5665, train_loss 34.933662,Time used 0.004998s\n",
      "batch 5666, train_loss 35.414783,Time used 0.005000s\n",
      "batch 5667, train_loss 32.046013,Time used 0.005002s\n",
      "batch 5668, train_loss 34.026028,Time used 0.009998s\n",
      "batch 5669, train_loss 32.892208,Time used 0.005000s\n",
      "batch 5670, train_loss 38.262619,Time used 0.004033s\n",
      "batch 5671, train_loss 28.848452,Time used 0.003999s\n",
      "batch 5672, train_loss 43.055973,Time used 0.005000s\n",
      "batch 5673, train_loss 44.758850,Time used 0.005997s\n",
      "batch 5674, train_loss 39.307171,Time used 0.005002s\n",
      "batch 5675, train_loss 43.169388,Time used 0.005038s\n",
      "batch 5676, train_loss 34.067986,Time used 0.004960s\n",
      "batch 5677, train_loss 44.974434,Time used 0.005001s\n",
      "batch 5678, train_loss 36.579742,Time used 0.005000s\n",
      "batch 5679, train_loss 43.749302,Time used 0.007000s\n",
      "batch 5680, train_loss 39.600521,Time used 0.008000s\n",
      "batch 5681, train_loss 40.771198,Time used 0.008001s\n",
      "batch 5682, train_loss 36.734646,Time used 0.005001s\n",
      "batch 5683, train_loss 36.462475,Time used 0.008000s\n",
      "batch 5684, train_loss 37.374893,Time used 0.005000s\n",
      "batch 5685, train_loss 47.340603,Time used 0.006998s\n",
      "batch 5686, train_loss 35.422638,Time used 0.005001s\n",
      "batch 5687, train_loss 38.600384,Time used 0.004998s\n",
      "batch 5688, train_loss 36.228199,Time used 0.004999s\n",
      "batch 5689, train_loss 40.948681,Time used 0.004998s\n",
      "batch 5690, train_loss 42.644886,Time used 0.006999s\n",
      "batch 5691, train_loss 41.297718,Time used 0.005001s\n",
      "batch 5692, train_loss 35.503223,Time used 0.006000s\n",
      "batch 5693, train_loss 36.216408,Time used 0.004999s\n",
      "batch 5694, train_loss 37.973705,Time used 0.005001s\n",
      "batch 5695, train_loss 33.782383,Time used 0.004999s\n",
      "batch 5696, train_loss 38.000423,Time used 0.005001s\n",
      "batch 5697, train_loss 35.474983,Time used 0.004998s\n",
      "batch 5698, train_loss 39.667046,Time used 0.005000s\n",
      "batch 5699, train_loss 30.323313,Time used 0.005001s\n",
      "batch 5700, train_loss 32.967838,Time used 0.004999s\n",
      "***************************test_batch 5700, test_rmse_loss 7.440664,test_mae_loss 3.281491,test_mape_loss 54.606872,Time used 0.018000s\n",
      "batch 5701, train_loss 40.069149,Time used 0.005003s\n",
      "batch 5702, train_loss 30.800447,Time used 0.005997s\n",
      "batch 5703, train_loss 36.904156,Time used 0.005000s\n",
      "batch 5704, train_loss 37.111515,Time used 0.005002s\n",
      "batch 5705, train_loss 46.560970,Time used 0.004998s\n",
      "batch 5706, train_loss 36.089367,Time used 0.005000s\n",
      "batch 5707, train_loss 33.702030,Time used 0.006003s\n",
      "batch 5708, train_loss 34.644512,Time used 0.007998s\n",
      "batch 5709, train_loss 43.702068,Time used 0.006999s\n",
      "batch 5710, train_loss 39.233948,Time used 0.008000s\n",
      "batch 5711, train_loss 50.323063,Time used 0.005001s\n",
      "batch 5712, train_loss 39.047115,Time used 0.006001s\n",
      "batch 5713, train_loss 34.831932,Time used 0.004997s\n",
      "batch 5714, train_loss 39.033630,Time used 0.008000s\n",
      "batch 5715, train_loss 37.794193,Time used 0.004999s\n",
      "batch 5716, train_loss 40.440815,Time used 0.005999s\n",
      "batch 5717, train_loss 37.614830,Time used 0.005001s\n",
      "batch 5718, train_loss 38.590858,Time used 0.004998s\n",
      "batch 5719, train_loss 46.329247,Time used 0.007001s\n",
      "batch 5720, train_loss 37.465500,Time used 0.005001s\n",
      "batch 5721, train_loss 37.227287,Time used 0.004999s\n",
      "batch 5722, train_loss 30.596046,Time used 0.005005s\n",
      "batch 5723, train_loss 37.303078,Time used 0.005000s\n",
      "batch 5724, train_loss 40.488667,Time used 0.004998s\n",
      "batch 5725, train_loss 37.323101,Time used 0.007998s\n",
      "batch 5726, train_loss 34.215481,Time used 0.005000s\n",
      "batch 5727, train_loss 49.782459,Time used 0.006000s\n",
      "batch 5728, train_loss 40.989376,Time used 0.005005s\n",
      "batch 5729, train_loss 34.184322,Time used 0.004996s\n",
      "batch 5730, train_loss 39.024830,Time used 0.006001s\n",
      "batch 5731, train_loss 40.173172,Time used 0.005000s\n",
      "batch 5732, train_loss 35.173950,Time used 0.005001s\n",
      "batch 5733, train_loss 32.552204,Time used 0.004998s\n",
      "batch 5734, train_loss 38.863323,Time used 0.005001s\n",
      "batch 5735, train_loss 37.745590,Time used 0.005002s\n",
      "batch 5736, train_loss 32.339878,Time used 0.007997s\n",
      "batch 5737, train_loss 37.208282,Time used 0.004998s\n",
      "batch 5738, train_loss 40.943027,Time used 0.005001s\n",
      "batch 5739, train_loss 35.926041,Time used 0.007001s\n",
      "batch 5740, train_loss 36.189926,Time used 0.004998s\n",
      "batch 5741, train_loss 33.506371,Time used 0.005000s\n",
      "batch 5742, train_loss 38.420532,Time used 0.005998s\n",
      "batch 5743, train_loss 37.469566,Time used 0.005999s\n",
      "batch 5744, train_loss 42.211109,Time used 0.008003s\n",
      "batch 5745, train_loss 35.620926,Time used 0.005999s\n",
      "batch 5746, train_loss 38.729378,Time used 0.005998s\n",
      "batch 5747, train_loss 36.891319,Time used 0.008002s\n",
      "batch 5748, train_loss 37.838936,Time used 0.005001s\n",
      "batch 5749, train_loss 35.151218,Time used 0.008000s\n",
      "batch 5750, train_loss 33.640942,Time used 0.007998s\n",
      "batch 5751, train_loss 34.391914,Time used 0.006004s\n",
      "batch 5752, train_loss 38.084766,Time used 0.007996s\n",
      "batch 5753, train_loss 36.973240,Time used 0.006001s\n",
      "batch 5754, train_loss 36.678204,Time used 0.004999s\n",
      "batch 5755, train_loss 44.911968,Time used 0.005000s\n",
      "batch 5756, train_loss 39.639332,Time used 0.008001s\n",
      "batch 5757, train_loss 43.894970,Time used 0.005000s\n",
      "batch 5758, train_loss 37.112003,Time used 0.006001s\n",
      "batch 5759, train_loss 33.914417,Time used 0.004998s\n",
      "batch 5760, train_loss 43.187096,Time used 0.005000s\n",
      "batch 5761, train_loss 31.146784,Time used 0.005001s\n",
      "batch 5762, train_loss 40.562897,Time used 0.005998s\n",
      "batch 5763, train_loss 41.817928,Time used 0.005000s\n",
      "batch 5764, train_loss 33.909706,Time used 0.005001s\n",
      "batch 5765, train_loss 33.792488,Time used 0.005000s\n",
      "batch 5766, train_loss 34.992825,Time used 0.007000s\n",
      "batch 5767, train_loss 46.158741,Time used 0.007998s\n",
      "batch 5768, train_loss 41.254627,Time used 0.007999s\n",
      "batch 5769, train_loss 41.747925,Time used 0.006000s\n",
      "batch 5770, train_loss 33.561611,Time used 0.007001s\n",
      "batch 5771, train_loss 35.626480,Time used 0.005003s\n",
      "batch 5772, train_loss 37.258396,Time used 0.005998s\n",
      "batch 5773, train_loss 33.291965,Time used 0.006000s\n",
      "batch 5774, train_loss 51.385273,Time used 0.005003s\n",
      "batch 5775, train_loss 31.930389,Time used 0.007998s\n",
      "batch 5776, train_loss 38.292881,Time used 0.004999s\n",
      "batch 5777, train_loss 41.445271,Time used 0.005001s\n",
      "batch 5778, train_loss 38.729973,Time used 0.005002s\n",
      "batch 5779, train_loss 41.444084,Time used 0.005999s\n",
      "batch 5780, train_loss 30.380304,Time used 0.006999s\n",
      "batch 5781, train_loss 37.082012,Time used 0.005000s\n",
      "batch 5782, train_loss 36.008354,Time used 0.005004s\n",
      "batch 5783, train_loss 35.838181,Time used 0.005999s\n",
      "batch 5784, train_loss 38.530643,Time used 0.007997s\n",
      "batch 5785, train_loss 43.043701,Time used 0.005001s\n",
      "batch 5786, train_loss 33.711483,Time used 0.005000s\n",
      "batch 5787, train_loss 33.275742,Time used 0.005000s\n",
      "batch 5788, train_loss 37.218750,Time used 0.005000s\n",
      "batch 5789, train_loss 35.330681,Time used 0.004998s\n",
      "batch 5790, train_loss 35.352066,Time used 0.005000s\n",
      "batch 5791, train_loss 33.580830,Time used 0.005000s\n",
      "batch 5792, train_loss 37.994850,Time used 0.008002s\n",
      "batch 5793, train_loss 36.516537,Time used 0.006001s\n",
      "batch 5794, train_loss 33.994480,Time used 0.005000s\n",
      "batch 5795, train_loss 36.417889,Time used 0.005000s\n",
      "batch 5796, train_loss 43.774803,Time used 0.007000s\n",
      "batch 5797, train_loss 37.708214,Time used 0.006999s\n",
      "batch 5798, train_loss 37.728962,Time used 0.006999s\n",
      "batch 5799, train_loss 39.125145,Time used 0.003997s\n",
      "batch 5800, train_loss 32.110847,Time used 0.005002s\n",
      "***************************test_batch 5800, test_rmse_loss 7.417470,test_mae_loss 3.274049,test_mape_loss 54.351352,Time used 0.026002s\n",
      "batch 5801, train_loss 36.989841,Time used 0.005000s\n",
      "batch 5802, train_loss 36.384872,Time used 0.005996s\n",
      "batch 5803, train_loss 37.843117,Time used 0.005000s\n",
      "batch 5804, train_loss 38.715321,Time used 0.004999s\n",
      "batch 5805, train_loss 47.573357,Time used 0.008002s\n",
      "batch 5806, train_loss 38.344398,Time used 0.008002s\n",
      "batch 5807, train_loss 41.320431,Time used 0.004996s\n",
      "batch 5808, train_loss 40.918285,Time used 0.005000s\n",
      "batch 5809, train_loss 34.141293,Time used 0.004998s\n",
      "batch 5810, train_loss 32.992779,Time used 0.005001s\n",
      "batch 5811, train_loss 38.587845,Time used 0.007004s\n",
      "batch 5812, train_loss 32.342430,Time used 0.005002s\n",
      "batch 5813, train_loss 29.331879,Time used 0.005996s\n",
      "batch 5814, train_loss 36.309937,Time used 0.006001s\n",
      "batch 5815, train_loss 41.487957,Time used 0.008001s\n",
      "batch 5816, train_loss 33.735184,Time used 0.005997s\n",
      "batch 5817, train_loss 40.081905,Time used 0.007999s\n",
      "batch 5818, train_loss 35.148773,Time used 0.008000s\n",
      "batch 5819, train_loss 41.236244,Time used 0.005001s\n",
      "batch 5820, train_loss 31.093151,Time used 0.005000s\n",
      "batch 5821, train_loss 40.159817,Time used 0.005006s\n",
      "batch 5822, train_loss 35.400692,Time used 0.008999s\n",
      "batch 5823, train_loss 37.947216,Time used 0.006998s\n",
      "batch 5824, train_loss 38.668804,Time used 0.004999s\n",
      "batch 5825, train_loss 34.414455,Time used 0.005000s\n",
      "batch 5826, train_loss 32.983891,Time used 0.007000s\n",
      "batch 5827, train_loss 46.961666,Time used 0.004999s\n",
      "batch 5828, train_loss 43.366871,Time used 0.007001s\n",
      "batch 5829, train_loss 40.265923,Time used 0.005999s\n",
      "batch 5830, train_loss 44.068317,Time used 0.008000s\n",
      "batch 5831, train_loss 39.045376,Time used 0.008000s\n",
      "batch 5832, train_loss 43.114059,Time used 0.004999s\n",
      "batch 5833, train_loss 38.341404,Time used 0.004998s\n",
      "batch 5834, train_loss 45.503635,Time used 0.006003s\n",
      "batch 5835, train_loss 36.365734,Time used 0.006997s\n",
      "batch 5836, train_loss 36.981861,Time used 0.005037s\n",
      "batch 5837, train_loss 40.052277,Time used 0.007962s\n",
      "batch 5838, train_loss 35.556519,Time used 0.005001s\n",
      "batch 5839, train_loss 46.690182,Time used 0.006001s\n",
      "batch 5840, train_loss 31.979692,Time used 0.007998s\n",
      "batch 5841, train_loss 39.272491,Time used 0.007004s\n",
      "batch 5842, train_loss 42.520676,Time used 0.005000s\n",
      "batch 5843, train_loss 38.401546,Time used 0.005998s\n",
      "batch 5844, train_loss 36.484230,Time used 0.005001s\n",
      "batch 5845, train_loss 37.413261,Time used 0.006003s\n",
      "batch 5846, train_loss 29.348316,Time used 0.005002s\n",
      "batch 5847, train_loss 35.810753,Time used 0.004997s\n",
      "batch 5848, train_loss 32.736107,Time used 0.005000s\n",
      "batch 5849, train_loss 37.105877,Time used 0.004998s\n",
      "batch 5850, train_loss 28.312458,Time used 0.005004s\n",
      "batch 5851, train_loss 38.107456,Time used 0.005999s\n",
      "batch 5852, train_loss 44.162083,Time used 0.004998s\n",
      "batch 5853, train_loss 40.148098,Time used 0.005999s\n",
      "batch 5854, train_loss 37.694225,Time used 0.008000s\n",
      "batch 5855, train_loss 36.341976,Time used 0.006000s\n",
      "batch 5856, train_loss 34.656242,Time used 0.006000s\n",
      "batch 5857, train_loss 42.814796,Time used 0.007998s\n",
      "batch 5858, train_loss 31.704550,Time used 0.005999s\n",
      "batch 5859, train_loss 31.253508,Time used 0.006001s\n",
      "batch 5860, train_loss 34.432793,Time used 0.008000s\n",
      "batch 5861, train_loss 38.711079,Time used 0.006000s\n",
      "batch 5862, train_loss 38.969467,Time used 0.004998s\n",
      "batch 5863, train_loss 37.836109,Time used 0.005004s\n",
      "batch 5864, train_loss 37.196407,Time used 0.007034s\n",
      "batch 5865, train_loss 42.742226,Time used 0.004999s\n",
      "batch 5866, train_loss 40.631931,Time used 0.005003s\n",
      "batch 5867, train_loss 34.962132,Time used 0.004966s\n",
      "batch 5868, train_loss 38.852615,Time used 0.005032s\n",
      "batch 5869, train_loss 36.252560,Time used 0.005000s\n",
      "batch 5870, train_loss 30.214838,Time used 0.004999s\n",
      "batch 5871, train_loss 34.877884,Time used 0.004995s\n",
      "batch 5872, train_loss 36.427437,Time used 0.004029s\n",
      "batch 5873, train_loss 47.262154,Time used 0.006003s\n",
      "batch 5874, train_loss 41.640495,Time used 0.005002s\n",
      "batch 5875, train_loss 37.669426,Time used 0.004995s\n",
      "batch 5876, train_loss 37.429340,Time used 0.005000s\n",
      "batch 5877, train_loss 41.707493,Time used 0.007967s\n",
      "batch 5878, train_loss 36.314171,Time used 0.004999s\n",
      "batch 5879, train_loss 35.224720,Time used 0.006999s\n",
      "batch 5880, train_loss 32.824036,Time used 0.005000s\n",
      "batch 5881, train_loss 33.627117,Time used 0.004999s\n",
      "batch 5882, train_loss 38.444534,Time used 0.005001s\n",
      "batch 5883, train_loss 40.761505,Time used 0.006002s\n",
      "batch 5884, train_loss 35.793884,Time used 0.008000s\n",
      "batch 5885, train_loss 37.089420,Time used 0.007002s\n",
      "batch 5886, train_loss 36.258163,Time used 0.006997s\n",
      "batch 5887, train_loss 42.159908,Time used 0.006001s\n",
      "batch 5888, train_loss 33.603325,Time used 0.006001s\n",
      "batch 5889, train_loss 36.992645,Time used 0.004999s\n",
      "batch 5890, train_loss 34.338055,Time used 0.007000s\n",
      "batch 5891, train_loss 34.834423,Time used 0.004999s\n",
      "batch 5892, train_loss 40.698837,Time used 0.005002s\n",
      "batch 5893, train_loss 43.360023,Time used 0.006999s\n",
      "batch 5894, train_loss 41.599159,Time used 0.007998s\n",
      "batch 5895, train_loss 39.962337,Time used 0.004999s\n",
      "batch 5896, train_loss 38.508835,Time used 0.004999s\n",
      "batch 5897, train_loss 32.716045,Time used 0.006003s\n",
      "batch 5898, train_loss 37.522846,Time used 0.005002s\n",
      "batch 5899, train_loss 36.103027,Time used 0.004998s\n",
      "batch 5900, train_loss 33.731678,Time used 0.006034s\n",
      "***************************test_batch 5900, test_rmse_loss 7.397513,test_mae_loss 3.267180,test_mape_loss 54.310672,Time used 0.018969s\n",
      "batch 5901, train_loss 39.505184,Time used 0.005996s\n",
      "batch 5902, train_loss 33.666573,Time used 0.005003s\n",
      "batch 5903, train_loss 40.438011,Time used 0.006996s\n",
      "batch 5904, train_loss 34.076824,Time used 0.004999s\n",
      "batch 5905, train_loss 32.262257,Time used 0.005002s\n",
      "batch 5906, train_loss 42.645924,Time used 0.005998s\n",
      "batch 5907, train_loss 44.083546,Time used 0.005996s\n",
      "batch 5908, train_loss 40.558514,Time used 0.007000s\n",
      "batch 5909, train_loss 38.263447,Time used 0.008003s\n",
      "batch 5910, train_loss 36.059738,Time used 0.006999s\n",
      "batch 5911, train_loss 41.201523,Time used 0.008003s\n",
      "batch 5912, train_loss 35.319817,Time used 0.005000s\n",
      "batch 5913, train_loss 43.811596,Time used 0.007001s\n",
      "batch 5914, train_loss 31.565166,Time used 0.007998s\n",
      "batch 5915, train_loss 37.191895,Time used 0.009000s\n",
      "batch 5916, train_loss 33.094509,Time used 0.008000s\n",
      "batch 5917, train_loss 38.802994,Time used 0.005999s\n",
      "batch 5918, train_loss 33.574299,Time used 0.005004s\n",
      "batch 5919, train_loss 36.001255,Time used 0.004997s\n",
      "batch 5920, train_loss 33.279236,Time used 0.007004s\n",
      "batch 5921, train_loss 43.696140,Time used 0.008034s\n",
      "batch 5922, train_loss 34.976414,Time used 0.005965s\n",
      "batch 5923, train_loss 39.884415,Time used 0.004999s\n",
      "batch 5924, train_loss 38.704243,Time used 0.005000s\n",
      "batch 5925, train_loss 36.771500,Time used 0.007997s\n",
      "batch 5926, train_loss 33.141712,Time used 0.005000s\n",
      "batch 5927, train_loss 35.262863,Time used 0.006002s\n",
      "batch 5928, train_loss 33.596081,Time used 0.005000s\n",
      "batch 5929, train_loss 29.851477,Time used 0.004996s\n",
      "batch 5930, train_loss 33.637173,Time used 0.005999s\n",
      "batch 5931, train_loss 36.187840,Time used 0.005000s\n",
      "batch 5932, train_loss 38.356441,Time used 0.006043s\n",
      "batch 5933, train_loss 36.493587,Time used 0.004995s\n",
      "batch 5934, train_loss 35.180893,Time used 0.005965s\n",
      "batch 5935, train_loss 43.311436,Time used 0.007998s\n",
      "batch 5936, train_loss 36.890240,Time used 0.005000s\n",
      "batch 5937, train_loss 38.368671,Time used 0.006002s\n",
      "batch 5938, train_loss 35.165455,Time used 0.004999s\n",
      "batch 5939, train_loss 37.528885,Time used 0.006001s\n",
      "batch 5940, train_loss 38.529190,Time used 0.005007s\n",
      "batch 5941, train_loss 39.701363,Time used 0.004999s\n",
      "batch 5942, train_loss 35.162445,Time used 0.004999s\n",
      "batch 5943, train_loss 34.682949,Time used 0.004998s\n",
      "batch 5944, train_loss 37.849995,Time used 0.004998s\n",
      "batch 5945, train_loss 43.386871,Time used 0.004997s\n",
      "batch 5946, train_loss 37.719692,Time used 0.005001s\n",
      "batch 5947, train_loss 29.646494,Time used 0.006000s\n",
      "batch 5948, train_loss 41.609970,Time used 0.004999s\n",
      "batch 5949, train_loss 41.533340,Time used 0.005002s\n",
      "batch 5950, train_loss 39.219975,Time used 0.004999s\n",
      "batch 5951, train_loss 37.630733,Time used 0.005004s\n",
      "batch 5952, train_loss 34.684071,Time used 0.005996s\n",
      "batch 5953, train_loss 40.547646,Time used 0.005001s\n",
      "batch 5954, train_loss 37.000652,Time used 0.006000s\n",
      "batch 5955, train_loss 39.442524,Time used 0.005000s\n",
      "batch 5956, train_loss 27.620169,Time used 0.004999s\n",
      "batch 5957, train_loss 39.822132,Time used 0.005000s\n",
      "batch 5958, train_loss 39.029613,Time used 0.006005s\n",
      "batch 5959, train_loss 31.743101,Time used 0.004998s\n",
      "batch 5960, train_loss 31.436985,Time used 0.005002s\n",
      "batch 5961, train_loss 38.951283,Time used 0.007032s\n",
      "batch 5962, train_loss 34.876293,Time used 0.007000s\n",
      "batch 5963, train_loss 33.738686,Time used 0.007966s\n",
      "batch 5964, train_loss 34.516602,Time used 0.007037s\n",
      "batch 5965, train_loss 41.325909,Time used 0.004997s\n",
      "batch 5966, train_loss 42.334000,Time used 0.005961s\n",
      "batch 5967, train_loss 40.233521,Time used 0.004999s\n",
      "batch 5968, train_loss 41.338818,Time used 0.006000s\n",
      "batch 5969, train_loss 33.659767,Time used 0.005037s\n",
      "batch 5970, train_loss 37.431828,Time used 0.005002s\n",
      "batch 5971, train_loss 31.065268,Time used 0.005965s\n",
      "batch 5972, train_loss 38.841164,Time used 0.005001s\n",
      "batch 5973, train_loss 34.590405,Time used 0.007035s\n",
      "batch 5974, train_loss 35.793427,Time used 0.009965s\n",
      "batch 5975, train_loss 38.338844,Time used 0.008997s\n",
      "batch 5976, train_loss 48.040241,Time used 0.007000s\n",
      "batch 5977, train_loss 34.273438,Time used 0.007998s\n",
      "batch 5978, train_loss 30.286871,Time used 0.006001s\n",
      "batch 5979, train_loss 34.153065,Time used 0.005001s\n",
      "batch 5980, train_loss 48.776886,Time used 0.005033s\n",
      "batch 5981, train_loss 38.651081,Time used 0.005968s\n",
      "batch 5982, train_loss 36.332794,Time used 0.005998s\n",
      "batch 5983, train_loss 40.819130,Time used 0.004999s\n",
      "batch 5984, train_loss 37.937569,Time used 0.004999s\n",
      "batch 5985, train_loss 32.916180,Time used 0.005999s\n",
      "batch 5986, train_loss 38.989372,Time used 0.006003s\n",
      "batch 5987, train_loss 30.595888,Time used 0.004997s\n",
      "batch 5988, train_loss 39.305481,Time used 0.005041s\n",
      "batch 5989, train_loss 37.794342,Time used 0.005996s\n",
      "batch 5990, train_loss 37.805325,Time used 0.007020s\n",
      "batch 5991, train_loss 36.770145,Time used 0.004981s\n",
      "batch 5992, train_loss 39.829853,Time used 0.005005s\n",
      "batch 5993, train_loss 41.379570,Time used 0.006998s\n",
      "batch 5994, train_loss 35.714649,Time used 0.007000s\n",
      "batch 5995, train_loss 34.232758,Time used 0.007998s\n",
      "batch 5996, train_loss 37.877174,Time used 0.005998s\n",
      "batch 5997, train_loss 43.024738,Time used 0.005000s\n",
      "batch 5998, train_loss 32.718838,Time used 0.004998s\n",
      "batch 5999, train_loss 32.228367,Time used 0.007001s\n",
      "batch 6000, train_loss 36.186626,Time used 0.007001s\n",
      "***************************test_batch 6000, test_rmse_loss 7.349970,test_mae_loss 3.256170,test_mape_loss 54.406894,Time used 0.018004s\n",
      "batch 6001, train_loss 43.506413,Time used 0.005032s\n",
      "batch 6002, train_loss 39.121056,Time used 0.005002s\n",
      "batch 6003, train_loss 31.422182,Time used 0.004998s\n",
      "batch 6004, train_loss 36.391743,Time used 0.005999s\n",
      "batch 6005, train_loss 34.186363,Time used 0.005003s\n",
      "batch 6006, train_loss 33.822952,Time used 0.004964s\n",
      "batch 6007, train_loss 34.774956,Time used 0.005002s\n",
      "batch 6008, train_loss 38.083469,Time used 0.004999s\n",
      "batch 6009, train_loss 40.686619,Time used 0.005000s\n",
      "batch 6010, train_loss 43.771935,Time used 0.006001s\n",
      "batch 6011, train_loss 37.399590,Time used 0.006034s\n",
      "batch 6012, train_loss 37.051685,Time used 0.007031s\n",
      "batch 6013, train_loss 31.503263,Time used 0.004979s\n",
      "batch 6014, train_loss 34.169266,Time used 0.004031s\n",
      "batch 6015, train_loss 40.191811,Time used 0.005002s\n",
      "batch 6016, train_loss 36.654030,Time used 0.006965s\n",
      "batch 6017, train_loss 40.399120,Time used 0.004996s\n",
      "batch 6018, train_loss 33.491543,Time used 0.006003s\n",
      "batch 6019, train_loss 37.248074,Time used 0.004996s\n",
      "batch 6020, train_loss 39.994572,Time used 0.005000s\n",
      "batch 6021, train_loss 32.563942,Time used 0.005000s\n",
      "batch 6022, train_loss 36.779469,Time used 0.005002s\n",
      "batch 6023, train_loss 39.323990,Time used 0.006000s\n",
      "batch 6024, train_loss 33.306293,Time used 0.005000s\n",
      "batch 6025, train_loss 45.217327,Time used 0.005034s\n",
      "batch 6026, train_loss 31.934679,Time used 0.005001s\n",
      "batch 6027, train_loss 37.487198,Time used 0.006009s\n",
      "batch 6028, train_loss 34.587231,Time used 0.005991s\n",
      "batch 6029, train_loss 31.201590,Time used 0.009967s\n",
      "batch 6030, train_loss 41.093464,Time used 0.005002s\n",
      "batch 6031, train_loss 37.039970,Time used 0.006998s\n",
      "batch 6032, train_loss 37.996845,Time used 0.005997s\n",
      "batch 6033, train_loss 33.430717,Time used 0.004999s\n",
      "batch 6034, train_loss 37.816811,Time used 0.006002s\n",
      "batch 6035, train_loss 30.993734,Time used 0.005035s\n",
      "batch 6036, train_loss 37.984962,Time used 0.005000s\n",
      "batch 6037, train_loss 35.057133,Time used 0.005001s\n",
      "batch 6038, train_loss 38.329247,Time used 0.005032s\n",
      "batch 6039, train_loss 38.303173,Time used 0.005006s\n",
      "batch 6040, train_loss 32.067814,Time used 0.004993s\n",
      "batch 6041, train_loss 38.178486,Time used 0.005001s\n",
      "batch 6042, train_loss 32.794777,Time used 0.005005s\n",
      "batch 6043, train_loss 37.124943,Time used 0.004994s\n",
      "batch 6044, train_loss 37.718639,Time used 0.005001s\n",
      "batch 6045, train_loss 33.500229,Time used 0.004966s\n",
      "batch 6046, train_loss 42.723034,Time used 0.005034s\n",
      "batch 6047, train_loss 36.552551,Time used 0.004999s\n",
      "batch 6048, train_loss 45.950325,Time used 0.004966s\n",
      "batch 6049, train_loss 35.636410,Time used 0.005034s\n",
      "batch 6050, train_loss 39.376850,Time used 0.004998s\n",
      "batch 6051, train_loss 37.716080,Time used 0.005035s\n",
      "batch 6052, train_loss 32.448833,Time used 0.004963s\n",
      "batch 6053, train_loss 39.628181,Time used 0.006005s\n",
      "batch 6054, train_loss 34.542210,Time used 0.004999s\n",
      "batch 6055, train_loss 31.765511,Time used 0.005000s\n",
      "batch 6056, train_loss 28.608232,Time used 0.005000s\n",
      "batch 6057, train_loss 33.138256,Time used 0.006994s\n",
      "batch 6058, train_loss 26.691689,Time used 0.006000s\n",
      "batch 6059, train_loss 37.935772,Time used 0.005004s\n",
      "batch 6060, train_loss 40.006096,Time used 0.005000s\n",
      "batch 6061, train_loss 36.304585,Time used 0.005000s\n",
      "batch 6062, train_loss 37.663712,Time used 0.005003s\n",
      "batch 6063, train_loss 34.375526,Time used 0.005032s\n",
      "batch 6064, train_loss 45.256756,Time used 0.009967s\n",
      "batch 6065, train_loss 33.941391,Time used 0.005998s\n",
      "batch 6066, train_loss 36.589996,Time used 0.007000s\n",
      "batch 6067, train_loss 36.995197,Time used 0.008037s\n",
      "batch 6068, train_loss 43.320068,Time used 0.004966s\n",
      "batch 6069, train_loss 36.664635,Time used 0.008032s\n",
      "batch 6070, train_loss 37.700932,Time used 0.005000s\n",
      "batch 6071, train_loss 44.191566,Time used 0.004965s\n",
      "batch 6072, train_loss 42.498692,Time used 0.004999s\n",
      "batch 6073, train_loss 32.912251,Time used 0.005004s\n",
      "batch 6074, train_loss 36.179306,Time used 0.004998s\n",
      "batch 6075, train_loss 37.648418,Time used 0.006000s\n",
      "batch 6076, train_loss 34.091412,Time used 0.005035s\n",
      "batch 6077, train_loss 35.726692,Time used 0.005000s\n",
      "batch 6078, train_loss 35.473866,Time used 0.005000s\n",
      "batch 6079, train_loss 31.739317,Time used 0.006999s\n",
      "batch 6080, train_loss 40.434967,Time used 0.004999s\n",
      "batch 6081, train_loss 37.808292,Time used 0.005000s\n",
      "batch 6082, train_loss 46.246342,Time used 0.006968s\n",
      "batch 6083, train_loss 42.370266,Time used 0.007998s\n",
      "batch 6084, train_loss 31.259083,Time used 0.007997s\n",
      "batch 6085, train_loss 40.249023,Time used 0.008000s\n",
      "batch 6086, train_loss 37.723293,Time used 0.007000s\n",
      "batch 6087, train_loss 32.309574,Time used 0.004999s\n",
      "batch 6088, train_loss 35.532284,Time used 0.004999s\n",
      "batch 6089, train_loss 31.578144,Time used 0.006998s\n",
      "batch 6090, train_loss 38.584263,Time used 0.006001s\n",
      "batch 6091, train_loss 35.679607,Time used 0.006002s\n",
      "batch 6092, train_loss 40.646042,Time used 0.005002s\n",
      "batch 6093, train_loss 36.672981,Time used 0.015996s\n",
      "batch 6094, train_loss 35.702400,Time used 0.007003s\n",
      "batch 6095, train_loss 32.883083,Time used 0.005996s\n",
      "batch 6096, train_loss 41.397415,Time used 0.004999s\n",
      "batch 6097, train_loss 31.830111,Time used 0.004994s\n",
      "batch 6098, train_loss 37.021839,Time used 0.004999s\n",
      "batch 6099, train_loss 35.291874,Time used 0.005968s\n",
      "batch 6100, train_loss 38.990067,Time used 0.006000s\n",
      "***************************test_batch 6100, test_rmse_loss 7.374798,test_mae_loss 3.263372,test_mape_loss 54.046348,Time used 0.025034s\n",
      "batch 6101, train_loss 34.679070,Time used 0.005001s\n",
      "batch 6102, train_loss 35.998775,Time used 0.008966s\n",
      "batch 6103, train_loss 35.194664,Time used 0.005001s\n",
      "batch 6104, train_loss 40.326576,Time used 0.006000s\n",
      "batch 6105, train_loss 32.773666,Time used 0.007036s\n",
      "batch 6106, train_loss 39.448853,Time used 0.007962s\n",
      "batch 6107, train_loss 34.709923,Time used 0.006037s\n",
      "batch 6108, train_loss 34.509766,Time used 0.007998s\n",
      "batch 6109, train_loss 38.560665,Time used 0.008003s\n",
      "batch 6110, train_loss 29.052263,Time used 0.007964s\n",
      "batch 6111, train_loss 34.226311,Time used 0.007000s\n",
      "batch 6112, train_loss 38.057518,Time used 0.005042s\n",
      "batch 6113, train_loss 41.267025,Time used 0.005996s\n",
      "batch 6114, train_loss 34.512608,Time used 0.005000s\n",
      "batch 6115, train_loss 38.768764,Time used 0.006000s\n",
      "batch 6116, train_loss 42.013931,Time used 0.004994s\n",
      "batch 6117, train_loss 34.821877,Time used 0.006002s\n",
      "batch 6118, train_loss 35.495358,Time used 0.004964s\n",
      "batch 6119, train_loss 44.525211,Time used 0.006036s\n",
      "batch 6120, train_loss 37.407043,Time used 0.007006s\n",
      "batch 6121, train_loss 40.876339,Time used 0.008967s\n",
      "batch 6122, train_loss 38.250320,Time used 0.005997s\n",
      "batch 6123, train_loss 37.423496,Time used 0.007001s\n",
      "batch 6124, train_loss 31.797588,Time used 0.008998s\n",
      "batch 6125, train_loss 34.838894,Time used 0.006039s\n",
      "batch 6126, train_loss 34.510605,Time used 0.005999s\n",
      "batch 6127, train_loss 45.037075,Time used 0.005000s\n",
      "batch 6128, train_loss 37.993763,Time used 0.004968s\n",
      "batch 6129, train_loss 32.030056,Time used 0.005999s\n",
      "batch 6130, train_loss 29.002281,Time used 0.006000s\n",
      "batch 6131, train_loss 34.435467,Time used 0.005995s\n",
      "batch 6132, train_loss 38.064991,Time used 0.005000s\n",
      "batch 6133, train_loss 33.740761,Time used 0.007038s\n",
      "batch 6134, train_loss 39.664070,Time used 0.005000s\n",
      "batch 6135, train_loss 39.421665,Time used 0.005003s\n",
      "batch 6136, train_loss 34.787003,Time used 0.006999s\n",
      "batch 6137, train_loss 34.538628,Time used 0.005967s\n",
      "batch 6138, train_loss 39.251709,Time used 0.005999s\n",
      "batch 6139, train_loss 38.804783,Time used 0.003997s\n",
      "batch 6140, train_loss 32.339924,Time used 0.006002s\n",
      "batch 6141, train_loss 32.920876,Time used 0.005998s\n",
      "batch 6142, train_loss 37.766987,Time used 0.005003s\n",
      "batch 6143, train_loss 37.880520,Time used 0.004967s\n",
      "batch 6144, train_loss 41.971863,Time used 0.008034s\n",
      "batch 6145, train_loss 34.552921,Time used 0.008996s\n",
      "batch 6146, train_loss 37.136257,Time used 0.005003s\n",
      "batch 6147, train_loss 38.302914,Time used 0.005959s\n",
      "batch 6148, train_loss 32.292477,Time used 0.005000s\n",
      "batch 6149, train_loss 36.083263,Time used 0.005000s\n",
      "batch 6150, train_loss 36.630371,Time used 0.005006s\n",
      "batch 6151, train_loss 36.969032,Time used 0.007032s\n",
      "batch 6152, train_loss 30.919832,Time used 0.006964s\n",
      "batch 6153, train_loss 35.693230,Time used 0.004998s\n",
      "batch 6154, train_loss 37.655464,Time used 0.005001s\n",
      "batch 6155, train_loss 36.968258,Time used 0.005002s\n",
      "batch 6156, train_loss 37.549995,Time used 0.005000s\n",
      "batch 6157, train_loss 38.869930,Time used 0.004998s\n",
      "batch 6158, train_loss 33.332150,Time used 0.006002s\n",
      "batch 6159, train_loss 36.690445,Time used 0.004998s\n",
      "batch 6160, train_loss 33.556381,Time used 0.007034s\n",
      "batch 6161, train_loss 42.546555,Time used 0.004999s\n",
      "batch 6162, train_loss 35.960091,Time used 0.005003s\n",
      "batch 6163, train_loss 37.286777,Time used 0.004997s\n",
      "batch 6164, train_loss 41.299438,Time used 0.008002s\n",
      "batch 6165, train_loss 33.492210,Time used 0.004966s\n",
      "batch 6166, train_loss 39.094936,Time used 0.005000s\n",
      "batch 6167, train_loss 37.286430,Time used 0.005998s\n",
      "batch 6168, train_loss 34.857899,Time used 0.005002s\n",
      "batch 6169, train_loss 33.809895,Time used 0.004997s\n",
      "batch 6170, train_loss 34.804150,Time used 0.006035s\n",
      "batch 6171, train_loss 38.639645,Time used 0.008001s\n",
      "batch 6172, train_loss 41.678520,Time used 0.004966s\n",
      "batch 6173, train_loss 39.429375,Time used 0.006000s\n",
      "batch 6174, train_loss 36.170338,Time used 0.008039s\n",
      "batch 6175, train_loss 33.963234,Time used 0.004998s\n",
      "batch 6176, train_loss 39.114128,Time used 0.004962s\n",
      "batch 6177, train_loss 42.266930,Time used 0.005033s\n",
      "batch 6178, train_loss 32.112812,Time used 0.003997s\n",
      "batch 6179, train_loss 29.343990,Time used 0.005966s\n",
      "batch 6180, train_loss 35.043198,Time used 0.006997s\n",
      "batch 6181, train_loss 37.695206,Time used 0.006039s\n",
      "batch 6182, train_loss 27.933884,Time used 0.005006s\n",
      "batch 6183, train_loss 37.928349,Time used 0.005000s\n",
      "batch 6184, train_loss 36.731861,Time used 0.004959s\n",
      "batch 6185, train_loss 40.296062,Time used 0.006001s\n",
      "batch 6186, train_loss 33.011982,Time used 0.004997s\n",
      "batch 6187, train_loss 40.964436,Time used 0.005038s\n",
      "batch 6188, train_loss 36.214462,Time used 0.005994s\n",
      "batch 6189, train_loss 36.249035,Time used 0.005004s\n",
      "batch 6190, train_loss 37.700520,Time used 0.006963s\n",
      "batch 6191, train_loss 33.425251,Time used 0.006999s\n",
      "batch 6192, train_loss 38.998840,Time used 0.006001s\n",
      "batch 6193, train_loss 29.723717,Time used 0.004999s\n",
      "batch 6194, train_loss 34.352394,Time used 0.005000s\n",
      "batch 6195, train_loss 42.402481,Time used 0.005000s\n",
      "batch 6196, train_loss 34.027664,Time used 0.006999s\n",
      "batch 6197, train_loss 37.656952,Time used 0.008000s\n",
      "batch 6198, train_loss 36.309212,Time used 0.007001s\n",
      "batch 6199, train_loss 33.957325,Time used 0.007033s\n",
      "batch 6200, train_loss 38.658886,Time used 0.006976s\n",
      "***************************test_batch 6200, test_rmse_loss 7.311703,test_mae_loss 3.242222,test_mape_loss 54.033622,Time used 0.028995s\n",
      "batch 6201, train_loss 37.617435,Time used 0.006042s\n",
      "batch 6202, train_loss 30.446003,Time used 0.004957s\n",
      "batch 6203, train_loss 40.205734,Time used 0.005000s\n",
      "batch 6204, train_loss 36.378544,Time used 0.004997s\n",
      "batch 6205, train_loss 37.588596,Time used 0.005000s\n",
      "batch 6206, train_loss 37.102928,Time used 0.005000s\n",
      "batch 6207, train_loss 34.834938,Time used 0.006002s\n",
      "batch 6208, train_loss 37.760250,Time used 0.003998s\n",
      "batch 6209, train_loss 32.979637,Time used 0.004000s\n",
      "batch 6210, train_loss 37.834240,Time used 0.004998s\n",
      "batch 6211, train_loss 37.777863,Time used 0.005000s\n",
      "batch 6212, train_loss 36.416874,Time used 0.005037s\n",
      "batch 6213, train_loss 33.617550,Time used 0.004966s\n",
      "batch 6214, train_loss 39.618950,Time used 0.004999s\n",
      "batch 6215, train_loss 41.171478,Time used 0.006000s\n",
      "batch 6216, train_loss 33.006989,Time used 0.005042s\n",
      "batch 6217, train_loss 29.011585,Time used 0.005004s\n",
      "batch 6218, train_loss 35.919044,Time used 0.006040s\n",
      "batch 6219, train_loss 35.228096,Time used 0.004992s\n",
      "batch 6220, train_loss 43.667595,Time used 0.004968s\n",
      "batch 6221, train_loss 34.885799,Time used 0.007994s\n",
      "batch 6222, train_loss 34.889431,Time used 0.005001s\n",
      "batch 6223, train_loss 30.360493,Time used 0.004999s\n",
      "batch 6224, train_loss 35.634880,Time used 0.006001s\n",
      "batch 6225, train_loss 38.555134,Time used 0.004999s\n",
      "batch 6226, train_loss 33.309872,Time used 0.006005s\n",
      "batch 6227, train_loss 43.167007,Time used 0.005034s\n",
      "batch 6228, train_loss 34.589092,Time used 0.006004s\n",
      "batch 6229, train_loss 36.648029,Time used 0.004959s\n",
      "batch 6230, train_loss 30.558256,Time used 0.006999s\n",
      "batch 6231, train_loss 40.211971,Time used 0.004999s\n",
      "batch 6232, train_loss 34.663242,Time used 0.008000s\n",
      "batch 6233, train_loss 32.081860,Time used 0.008000s\n",
      "batch 6234, train_loss 40.563942,Time used 0.008002s\n",
      "batch 6235, train_loss 41.504768,Time used 0.007998s\n",
      "batch 6236, train_loss 35.913719,Time used 0.008004s\n",
      "batch 6237, train_loss 38.830460,Time used 0.007033s\n",
      "batch 6238, train_loss 36.292351,Time used 0.005000s\n",
      "batch 6239, train_loss 36.365879,Time used 0.004965s\n",
      "batch 6240, train_loss 37.477123,Time used 0.005033s\n",
      "batch 6241, train_loss 32.288067,Time used 0.007038s\n",
      "batch 6242, train_loss 37.749977,Time used 0.005001s\n",
      "batch 6243, train_loss 32.279461,Time used 0.004966s\n",
      "batch 6244, train_loss 39.721951,Time used 0.005999s\n",
      "batch 6245, train_loss 41.496056,Time used 0.005998s\n",
      "batch 6246, train_loss 32.379265,Time used 0.004998s\n",
      "batch 6247, train_loss 30.949459,Time used 0.006000s\n",
      "batch 6248, train_loss 37.674866,Time used 0.005000s\n",
      "batch 6249, train_loss 44.045738,Time used 0.005000s\n",
      "batch 6250, train_loss 42.632610,Time used 0.005998s\n",
      "batch 6251, train_loss 35.887897,Time used 0.005000s\n",
      "batch 6252, train_loss 33.635574,Time used 0.005000s\n",
      "batch 6253, train_loss 32.161793,Time used 0.008999s\n",
      "batch 6254, train_loss 35.481014,Time used 0.007000s\n",
      "batch 6255, train_loss 38.982685,Time used 0.007002s\n",
      "batch 6256, train_loss 38.584320,Time used 0.006000s\n",
      "batch 6257, train_loss 33.249462,Time used 0.007036s\n",
      "batch 6258, train_loss 38.707130,Time used 0.005997s\n",
      "batch 6259, train_loss 36.063786,Time used 0.005003s\n",
      "batch 6260, train_loss 35.392056,Time used 0.005999s\n",
      "batch 6261, train_loss 31.237190,Time used 0.008034s\n",
      "batch 6262, train_loss 36.505981,Time used 0.004986s\n",
      "batch 6263, train_loss 34.220921,Time used 0.004997s\n",
      "batch 6264, train_loss 37.130203,Time used 0.005001s\n",
      "batch 6265, train_loss 30.106123,Time used 0.005000s\n",
      "batch 6266, train_loss 32.590771,Time used 0.006968s\n",
      "batch 6267, train_loss 34.655293,Time used 0.007998s\n",
      "batch 6268, train_loss 39.909016,Time used 0.008034s\n",
      "batch 6269, train_loss 37.009754,Time used 0.008003s\n",
      "batch 6270, train_loss 31.294657,Time used 0.005965s\n",
      "batch 6271, train_loss 35.807877,Time used 0.004999s\n",
      "batch 6272, train_loss 33.943413,Time used 0.005000s\n",
      "batch 6273, train_loss 37.446918,Time used 0.006035s\n",
      "batch 6274, train_loss 31.326153,Time used 0.005035s\n",
      "batch 6275, train_loss 44.839626,Time used 0.004963s\n",
      "batch 6276, train_loss 40.270180,Time used 0.008004s\n",
      "batch 6277, train_loss 40.766632,Time used 0.009001s\n",
      "batch 6278, train_loss 31.581326,Time used 0.006000s\n",
      "batch 6279, train_loss 37.980076,Time used 0.005002s\n",
      "batch 6280, train_loss 33.395519,Time used 0.005002s\n",
      "batch 6281, train_loss 44.386826,Time used 0.005000s\n",
      "batch 6282, train_loss 40.332371,Time used 0.005002s\n",
      "batch 6283, train_loss 33.339306,Time used 0.005998s\n",
      "batch 6284, train_loss 31.614202,Time used 0.004999s\n",
      "batch 6285, train_loss 34.714767,Time used 0.005004s\n",
      "batch 6286, train_loss 36.570061,Time used 0.006998s\n",
      "batch 6287, train_loss 34.485729,Time used 0.006997s\n",
      "batch 6288, train_loss 39.038513,Time used 0.005002s\n",
      "batch 6289, train_loss 40.445488,Time used 0.005996s\n",
      "batch 6290, train_loss 36.372665,Time used 0.005001s\n",
      "batch 6291, train_loss 32.705383,Time used 0.004999s\n",
      "batch 6292, train_loss 35.043362,Time used 0.005000s\n",
      "batch 6293, train_loss 32.582939,Time used 0.005038s\n",
      "batch 6294, train_loss 39.485241,Time used 0.005000s\n",
      "batch 6295, train_loss 40.308506,Time used 0.005998s\n",
      "batch 6296, train_loss 33.690510,Time used 0.005002s\n",
      "batch 6297, train_loss 36.002983,Time used 0.004999s\n",
      "batch 6298, train_loss 36.129211,Time used 0.004965s\n",
      "batch 6299, train_loss 32.633942,Time used 0.004996s\n",
      "batch 6300, train_loss 30.578943,Time used 0.005000s\n",
      "***************************test_batch 6300, test_rmse_loss 7.241195,test_mae_loss 3.223424,test_mape_loss 54.399581,Time used 0.023006s\n",
      "batch 6301, train_loss 34.731098,Time used 0.006999s\n",
      "batch 6302, train_loss 35.864605,Time used 0.005000s\n",
      "batch 6303, train_loss 35.076954,Time used 0.006035s\n",
      "batch 6304, train_loss 38.056961,Time used 0.005002s\n",
      "batch 6305, train_loss 35.580860,Time used 0.004000s\n",
      "batch 6306, train_loss 39.978798,Time used 0.006962s\n",
      "batch 6307, train_loss 38.334076,Time used 0.007003s\n",
      "batch 6308, train_loss 38.774933,Time used 0.007998s\n",
      "batch 6309, train_loss 32.415089,Time used 0.008003s\n",
      "batch 6310, train_loss 36.057503,Time used 0.005999s\n",
      "batch 6311, train_loss 35.828342,Time used 0.004997s\n",
      "batch 6312, train_loss 38.205395,Time used 0.006999s\n",
      "batch 6313, train_loss 32.431229,Time used 0.005999s\n",
      "batch 6314, train_loss 39.073208,Time used 0.005001s\n",
      "batch 6315, train_loss 32.760811,Time used 0.006000s\n",
      "batch 6316, train_loss 38.670471,Time used 0.005001s\n",
      "batch 6317, train_loss 34.619041,Time used 0.005001s\n",
      "batch 6318, train_loss 33.309715,Time used 0.005000s\n",
      "batch 6319, train_loss 33.852753,Time used 0.005000s\n",
      "batch 6320, train_loss 35.291840,Time used 0.008000s\n",
      "batch 6321, train_loss 30.548540,Time used 0.006041s\n",
      "batch 6322, train_loss 28.936598,Time used 0.004960s\n",
      "batch 6323, train_loss 34.843891,Time used 0.005003s\n",
      "batch 6324, train_loss 38.492310,Time used 0.005998s\n",
      "batch 6325, train_loss 37.030983,Time used 0.004996s\n",
      "batch 6326, train_loss 37.693264,Time used 0.005001s\n",
      "batch 6327, train_loss 35.901669,Time used 0.008000s\n",
      "batch 6328, train_loss 41.994904,Time used 0.006001s\n",
      "batch 6329, train_loss 37.085457,Time used 0.008000s\n",
      "batch 6330, train_loss 38.601173,Time used 0.006999s\n",
      "batch 6331, train_loss 32.951729,Time used 0.005001s\n",
      "batch 6332, train_loss 34.608593,Time used 0.004999s\n",
      "batch 6333, train_loss 39.459625,Time used 0.006000s\n",
      "batch 6334, train_loss 40.681976,Time used 0.005000s\n",
      "batch 6335, train_loss 38.590916,Time used 0.005000s\n",
      "batch 6336, train_loss 35.029499,Time used 0.008005s\n",
      "batch 6337, train_loss 33.084427,Time used 0.006000s\n",
      "batch 6338, train_loss 37.475361,Time used 0.005001s\n",
      "batch 6339, train_loss 32.707771,Time used 0.004998s\n",
      "batch 6340, train_loss 31.860941,Time used 0.006035s\n",
      "batch 6341, train_loss 38.168522,Time used 0.004998s\n",
      "batch 6342, train_loss 38.599205,Time used 0.006001s\n",
      "batch 6343, train_loss 30.277267,Time used 0.004970s\n",
      "batch 6344, train_loss 35.829979,Time used 0.005000s\n",
      "batch 6345, train_loss 34.222321,Time used 0.005001s\n",
      "batch 6346, train_loss 37.836285,Time used 0.005001s\n",
      "batch 6347, train_loss 38.276947,Time used 0.004963s\n",
      "batch 6348, train_loss 38.879864,Time used 0.006036s\n",
      "batch 6349, train_loss 34.666824,Time used 0.004998s\n",
      "batch 6350, train_loss 35.786102,Time used 0.004999s\n",
      "batch 6351, train_loss 33.134323,Time used 0.006003s\n",
      "batch 6352, train_loss 43.715088,Time used 0.005003s\n",
      "batch 6353, train_loss 34.021339,Time used 0.004961s\n",
      "batch 6354, train_loss 28.095198,Time used 0.007000s\n",
      "batch 6355, train_loss 41.472713,Time used 0.006998s\n",
      "batch 6356, train_loss 33.591381,Time used 0.004998s\n",
      "batch 6357, train_loss 40.035053,Time used 0.005013s\n",
      "batch 6358, train_loss 37.439884,Time used 0.004998s\n",
      "batch 6359, train_loss 39.163097,Time used 0.005968s\n",
      "batch 6360, train_loss 32.566139,Time used 0.006000s\n",
      "batch 6361, train_loss 38.428936,Time used 0.004993s\n",
      "batch 6362, train_loss 39.946529,Time used 0.005000s\n",
      "batch 6363, train_loss 35.267120,Time used 0.005039s\n",
      "batch 6364, train_loss 34.213840,Time used 0.007031s\n",
      "batch 6365, train_loss 32.204090,Time used 0.005002s\n",
      "batch 6366, train_loss 38.678276,Time used 0.005000s\n",
      "batch 6367, train_loss 37.857975,Time used 0.005001s\n",
      "batch 6368, train_loss 36.235100,Time used 0.005013s\n",
      "batch 6369, train_loss 26.058285,Time used 0.005985s\n",
      "batch 6370, train_loss 27.014591,Time used 0.004967s\n",
      "batch 6371, train_loss 40.532330,Time used 0.005002s\n",
      "batch 6372, train_loss 37.352379,Time used 0.005998s\n",
      "batch 6373, train_loss 37.358166,Time used 0.008003s\n",
      "batch 6374, train_loss 35.088600,Time used 0.005998s\n",
      "batch 6375, train_loss 29.982290,Time used 0.005037s\n",
      "batch 6376, train_loss 38.652203,Time used 0.005965s\n",
      "batch 6377, train_loss 36.422482,Time used 0.005033s\n",
      "batch 6378, train_loss 37.857151,Time used 0.007998s\n",
      "batch 6379, train_loss 39.601711,Time used 0.005000s\n",
      "batch 6380, train_loss 39.628597,Time used 0.005001s\n",
      "batch 6381, train_loss 34.594624,Time used 0.005977s\n",
      "batch 6382, train_loss 35.571751,Time used 0.004034s\n",
      "batch 6383, train_loss 37.411469,Time used 0.004967s\n",
      "batch 6384, train_loss 32.877796,Time used 0.005000s\n",
      "batch 6385, train_loss 29.301691,Time used 0.005032s\n",
      "batch 6386, train_loss 33.746716,Time used 0.005005s\n",
      "batch 6387, train_loss 31.686087,Time used 0.004995s\n",
      "batch 6388, train_loss 37.411522,Time used 0.006965s\n",
      "batch 6389, train_loss 33.209896,Time used 0.008036s\n",
      "batch 6390, train_loss 38.161346,Time used 0.007967s\n",
      "batch 6391, train_loss 32.796093,Time used 0.006001s\n",
      "batch 6392, train_loss 26.322475,Time used 0.005033s\n",
      "batch 6393, train_loss 36.356209,Time used 0.004999s\n",
      "batch 6394, train_loss 40.460205,Time used 0.005998s\n",
      "batch 6395, train_loss 32.280399,Time used 0.005000s\n",
      "batch 6396, train_loss 40.078430,Time used 0.005002s\n",
      "batch 6397, train_loss 36.034710,Time used 0.004965s\n",
      "batch 6398, train_loss 40.815815,Time used 0.007997s\n",
      "batch 6399, train_loss 30.032114,Time used 0.004999s\n",
      "batch 6400, train_loss 34.239071,Time used 0.006001s\n",
      "***************************test_batch 6400, test_rmse_loss 7.285426,test_mae_loss 3.235115,test_mape_loss 53.840133,Time used 0.024004s\n",
      "batch 6401, train_loss 40.041988,Time used 0.005000s\n",
      "batch 6402, train_loss 39.023540,Time used 0.008031s\n",
      "batch 6403, train_loss 41.607967,Time used 0.004997s\n",
      "batch 6404, train_loss 40.643272,Time used 0.006966s\n",
      "batch 6405, train_loss 38.961548,Time used 0.007034s\n",
      "batch 6406, train_loss 31.324383,Time used 0.005968s\n",
      "batch 6407, train_loss 39.263279,Time used 0.005000s\n",
      "batch 6408, train_loss 33.694920,Time used 0.003999s\n",
      "batch 6409, train_loss 32.432423,Time used 0.004999s\n",
      "batch 6410, train_loss 42.479416,Time used 0.007037s\n",
      "batch 6411, train_loss 34.379551,Time used 0.006000s\n",
      "batch 6412, train_loss 32.552086,Time used 0.008002s\n",
      "batch 6413, train_loss 33.463375,Time used 0.005000s\n",
      "batch 6414, train_loss 36.680161,Time used 0.005000s\n",
      "batch 6415, train_loss 38.006817,Time used 0.005002s\n",
      "batch 6416, train_loss 39.083466,Time used 0.004961s\n",
      "batch 6417, train_loss 34.033062,Time used 0.006001s\n",
      "batch 6418, train_loss 37.058628,Time used 0.005005s\n",
      "batch 6419, train_loss 37.264126,Time used 0.006003s\n",
      "batch 6420, train_loss 29.297976,Time used 0.004995s\n",
      "batch 6421, train_loss 37.658089,Time used 0.006036s\n",
      "batch 6422, train_loss 42.381332,Time used 0.007000s\n",
      "batch 6423, train_loss 37.752636,Time used 0.006995s\n",
      "batch 6424, train_loss 32.813194,Time used 0.005000s\n",
      "batch 6425, train_loss 36.714916,Time used 0.006001s\n",
      "batch 6426, train_loss 29.336613,Time used 0.006998s\n",
      "batch 6427, train_loss 36.339001,Time used 0.008001s\n",
      "batch 6428, train_loss 35.764870,Time used 0.009005s\n",
      "batch 6429, train_loss 41.119804,Time used 0.010998s\n",
      "batch 6430, train_loss 35.733887,Time used 0.007001s\n",
      "batch 6431, train_loss 29.353661,Time used 0.007033s\n",
      "batch 6432, train_loss 33.877514,Time used 0.005966s\n",
      "batch 6433, train_loss 38.378529,Time used 0.007031s\n",
      "batch 6434, train_loss 38.745621,Time used 0.005002s\n",
      "batch 6435, train_loss 35.999371,Time used 0.004964s\n",
      "batch 6436, train_loss 32.025131,Time used 0.004992s\n",
      "batch 6437, train_loss 41.035385,Time used 0.005004s\n",
      "batch 6438, train_loss 30.935930,Time used 0.005997s\n",
      "batch 6439, train_loss 37.356335,Time used 0.005001s\n",
      "batch 6440, train_loss 39.542088,Time used 0.005002s\n",
      "batch 6441, train_loss 29.750891,Time used 0.005998s\n",
      "batch 6442, train_loss 37.290916,Time used 0.004963s\n",
      "batch 6443, train_loss 28.038336,Time used 0.005000s\n",
      "batch 6444, train_loss 29.100918,Time used 0.005002s\n",
      "batch 6445, train_loss 38.098011,Time used 0.006999s\n",
      "batch 6446, train_loss 38.002541,Time used 0.005001s\n",
      "batch 6447, train_loss 31.516041,Time used 0.006006s\n",
      "batch 6448, train_loss 31.661345,Time used 0.005031s\n",
      "batch 6449, train_loss 35.693237,Time used 0.005000s\n",
      "batch 6450, train_loss 36.446110,Time used 0.005969s\n",
      "batch 6451, train_loss 42.946091,Time used 0.008038s\n",
      "batch 6452, train_loss 39.861858,Time used 0.004960s\n",
      "batch 6453, train_loss 31.858877,Time used 0.005034s\n",
      "batch 6454, train_loss 34.795448,Time used 0.005002s\n",
      "batch 6455, train_loss 37.961399,Time used 0.005961s\n",
      "batch 6456, train_loss 37.352367,Time used 0.005000s\n",
      "batch 6457, train_loss 34.919010,Time used 0.005000s\n",
      "batch 6458, train_loss 36.834026,Time used 0.004996s\n",
      "batch 6459, train_loss 32.886002,Time used 0.007000s\n",
      "batch 6460, train_loss 39.122627,Time used 0.006000s\n",
      "batch 6461, train_loss 33.413826,Time used 0.005000s\n",
      "batch 6462, train_loss 32.530685,Time used 0.006004s\n",
      "batch 6463, train_loss 31.421011,Time used 0.005001s\n",
      "batch 6464, train_loss 41.991291,Time used 0.005000s\n",
      "batch 6465, train_loss 32.518311,Time used 0.005002s\n",
      "batch 6466, train_loss 33.131325,Time used 0.004998s\n",
      "batch 6467, train_loss 31.805222,Time used 0.005035s\n",
      "batch 6468, train_loss 38.471909,Time used 0.005965s\n",
      "batch 6469, train_loss 43.294079,Time used 0.006037s\n",
      "batch 6470, train_loss 38.044670,Time used 0.004962s\n",
      "batch 6471, train_loss 35.895603,Time used 0.005033s\n",
      "batch 6472, train_loss 36.303398,Time used 0.005000s\n",
      "batch 6473, train_loss 33.453426,Time used 0.005036s\n",
      "batch 6474, train_loss 34.503067,Time used 0.005963s\n",
      "batch 6475, train_loss 40.627609,Time used 0.005001s\n",
      "batch 6476, train_loss 33.307037,Time used 0.005000s\n",
      "batch 6477, train_loss 32.295181,Time used 0.005997s\n",
      "batch 6478, train_loss 35.353718,Time used 0.005002s\n",
      "batch 6479, train_loss 36.601570,Time used 0.005036s\n",
      "batch 6480, train_loss 33.447815,Time used 0.004966s\n",
      "batch 6481, train_loss 39.102024,Time used 0.005036s\n",
      "batch 6482, train_loss 32.949615,Time used 0.005962s\n",
      "batch 6483, train_loss 39.133400,Time used 0.005000s\n",
      "batch 6484, train_loss 37.574135,Time used 0.008004s\n",
      "batch 6485, train_loss 41.566422,Time used 0.004999s\n",
      "batch 6486, train_loss 36.089069,Time used 0.004998s\n",
      "batch 6487, train_loss 34.820393,Time used 0.006998s\n",
      "batch 6488, train_loss 37.309383,Time used 0.008001s\n",
      "batch 6489, train_loss 33.261894,Time used 0.005006s\n",
      "batch 6490, train_loss 37.750175,Time used 0.005998s\n",
      "batch 6491, train_loss 33.583099,Time used 0.007004s\n",
      "batch 6492, train_loss 35.062603,Time used 0.005031s\n",
      "batch 6493, train_loss 33.563759,Time used 0.005002s\n",
      "batch 6494, train_loss 30.868900,Time used 0.005963s\n",
      "batch 6495, train_loss 32.885162,Time used 0.005003s\n",
      "batch 6496, train_loss 37.114017,Time used 0.005041s\n",
      "batch 6497, train_loss 52.370316,Time used 0.004962s\n",
      "batch 6498, train_loss 31.037268,Time used 0.006032s\n",
      "batch 6499, train_loss 31.882633,Time used 0.004999s\n",
      "batch 6500, train_loss 28.664362,Time used 0.005035s\n",
      "***************************test_batch 6500, test_rmse_loss 7.270747,test_mae_loss 3.230935,test_mape_loss 53.832965,Time used 0.016962s\n",
      "batch 6501, train_loss 34.727337,Time used 0.004999s\n",
      "batch 6502, train_loss 32.080898,Time used 0.006002s\n",
      "batch 6503, train_loss 35.377571,Time used 0.005001s\n",
      "batch 6504, train_loss 30.900347,Time used 0.006032s\n",
      "batch 6505, train_loss 38.769119,Time used 0.006001s\n",
      "batch 6506, train_loss 35.935905,Time used 0.005001s\n",
      "batch 6507, train_loss 39.361198,Time used 0.004996s\n",
      "batch 6508, train_loss 35.134048,Time used 0.005966s\n",
      "batch 6509, train_loss 36.932182,Time used 0.005000s\n",
      "batch 6510, train_loss 36.127453,Time used 0.004999s\n",
      "batch 6511, train_loss 32.801662,Time used 0.006000s\n",
      "batch 6512, train_loss 32.492012,Time used 0.006000s\n",
      "batch 6513, train_loss 33.194279,Time used 0.006002s\n",
      "batch 6514, train_loss 31.037165,Time used 0.005000s\n",
      "batch 6515, train_loss 34.725266,Time used 0.007999s\n",
      "batch 6516, train_loss 42.658802,Time used 0.006002s\n",
      "batch 6517, train_loss 36.064991,Time used 0.006002s\n",
      "batch 6518, train_loss 31.644388,Time used 0.005998s\n",
      "batch 6519, train_loss 30.883202,Time used 0.006999s\n",
      "batch 6520, train_loss 36.605804,Time used 0.005999s\n",
      "batch 6521, train_loss 35.320240,Time used 0.006002s\n",
      "batch 6522, train_loss 33.858753,Time used 0.004999s\n",
      "batch 6523, train_loss 33.205467,Time used 0.005000s\n",
      "batch 6524, train_loss 32.519142,Time used 0.007034s\n",
      "batch 6525, train_loss 39.607998,Time used 0.005019s\n",
      "batch 6526, train_loss 34.703083,Time used 0.004996s\n",
      "batch 6527, train_loss 31.343851,Time used 0.007999s\n",
      "batch 6528, train_loss 43.977444,Time used 0.005002s\n",
      "batch 6529, train_loss 35.360443,Time used 0.005964s\n",
      "batch 6530, train_loss 37.942837,Time used 0.006033s\n",
      "batch 6531, train_loss 38.038975,Time used 0.005001s\n",
      "batch 6532, train_loss 36.525925,Time used 0.005003s\n",
      "batch 6533, train_loss 40.015022,Time used 0.006998s\n",
      "batch 6534, train_loss 39.113518,Time used 0.007966s\n",
      "batch 6535, train_loss 29.390953,Time used 0.008034s\n",
      "batch 6536, train_loss 33.217239,Time used 0.005003s\n",
      "batch 6537, train_loss 33.501362,Time used 0.005033s\n",
      "batch 6538, train_loss 35.381260,Time used 0.004998s\n",
      "batch 6539, train_loss 34.590363,Time used 0.005000s\n",
      "batch 6540, train_loss 26.226105,Time used 0.005000s\n",
      "batch 6541, train_loss 39.263611,Time used 0.006963s\n",
      "batch 6542, train_loss 36.552036,Time used 0.005002s\n",
      "batch 6543, train_loss 37.715950,Time used 0.005999s\n",
      "batch 6544, train_loss 34.979485,Time used 0.005000s\n",
      "batch 6545, train_loss 38.659962,Time used 0.005000s\n",
      "batch 6546, train_loss 39.811073,Time used 0.007007s\n",
      "batch 6547, train_loss 35.950146,Time used 0.006031s\n",
      "batch 6548, train_loss 33.894249,Time used 0.007964s\n",
      "batch 6549, train_loss 31.435713,Time used 0.005999s\n",
      "batch 6550, train_loss 37.467716,Time used 0.004999s\n",
      "batch 6551, train_loss 33.208168,Time used 0.005036s\n",
      "batch 6552, train_loss 28.588234,Time used 0.004999s\n",
      "batch 6553, train_loss 36.927364,Time used 0.007032s\n",
      "batch 6554, train_loss 36.896984,Time used 0.004998s\n",
      "batch 6555, train_loss 33.497314,Time used 0.005002s\n",
      "batch 6556, train_loss 32.186783,Time used 0.005998s\n",
      "batch 6557, train_loss 29.729496,Time used 0.004966s\n",
      "batch 6558, train_loss 35.780079,Time used 0.007037s\n",
      "batch 6559, train_loss 32.292656,Time used 0.005005s\n",
      "batch 6560, train_loss 33.712193,Time used 0.004994s\n",
      "batch 6561, train_loss 29.162027,Time used 0.004967s\n",
      "batch 6562, train_loss 36.668968,Time used 0.006001s\n",
      "batch 6563, train_loss 38.468750,Time used 0.004998s\n",
      "batch 6564, train_loss 45.313457,Time used 0.005001s\n",
      "batch 6565, train_loss 38.148708,Time used 0.004999s\n",
      "batch 6566, train_loss 31.428068,Time used 0.006002s\n",
      "batch 6567, train_loss 37.986969,Time used 0.004998s\n",
      "batch 6568, train_loss 32.511478,Time used 0.005000s\n",
      "batch 6569, train_loss 35.111889,Time used 0.005997s\n",
      "batch 6570, train_loss 38.116112,Time used 0.006999s\n",
      "batch 6571, train_loss 31.097744,Time used 0.005000s\n",
      "batch 6572, train_loss 33.243645,Time used 0.006007s\n",
      "batch 6573, train_loss 38.167587,Time used 0.004994s\n",
      "batch 6574, train_loss 34.542332,Time used 0.005998s\n",
      "batch 6575, train_loss 37.151085,Time used 0.007005s\n",
      "batch 6576, train_loss 36.858990,Time used 0.004994s\n",
      "batch 6577, train_loss 30.455023,Time used 0.004999s\n",
      "batch 6578, train_loss 35.862022,Time used 0.006038s\n",
      "batch 6579, train_loss 35.397789,Time used 0.006965s\n",
      "batch 6580, train_loss 31.569601,Time used 0.008032s\n",
      "batch 6581, train_loss 39.128960,Time used 0.006965s\n",
      "batch 6582, train_loss 30.820652,Time used 0.004999s\n",
      "batch 6583, train_loss 34.869236,Time used 0.004000s\n",
      "batch 6584, train_loss 39.951241,Time used 0.006002s\n",
      "batch 6585, train_loss 31.636335,Time used 0.007001s\n",
      "batch 6586, train_loss 28.732157,Time used 0.006001s\n",
      "batch 6587, train_loss 42.618008,Time used 0.005033s\n",
      "batch 6588, train_loss 34.414207,Time used 0.005000s\n",
      "batch 6589, train_loss 40.571148,Time used 0.004996s\n",
      "batch 6590, train_loss 34.198109,Time used 0.008966s\n",
      "batch 6591, train_loss 34.410061,Time used 0.005000s\n",
      "batch 6592, train_loss 29.394758,Time used 0.008999s\n",
      "batch 6593, train_loss 36.051544,Time used 0.007000s\n",
      "batch 6594, train_loss 29.027571,Time used 0.006997s\n",
      "batch 6595, train_loss 37.097282,Time used 0.008000s\n",
      "batch 6596, train_loss 38.228867,Time used 0.006002s\n",
      "batch 6597, train_loss 34.917397,Time used 0.008000s\n",
      "batch 6598, train_loss 39.121460,Time used 0.005997s\n",
      "batch 6599, train_loss 32.963696,Time used 0.007002s\n",
      "batch 6600, train_loss 42.409805,Time used 0.007000s\n",
      "***************************test_batch 6600, test_rmse_loss 7.251890,test_mae_loss 3.223337,test_mape_loss 53.581553,Time used 0.020999s\n",
      "batch 6601, train_loss 33.616085,Time used 0.007999s\n",
      "batch 6602, train_loss 34.159702,Time used 0.007002s\n",
      "batch 6603, train_loss 35.637535,Time used 0.005999s\n",
      "batch 6604, train_loss 36.244724,Time used 0.005998s\n",
      "batch 6605, train_loss 35.589588,Time used 0.007000s\n",
      "batch 6606, train_loss 34.800556,Time used 0.005003s\n",
      "batch 6607, train_loss 38.342903,Time used 0.005999s\n",
      "batch 6608, train_loss 35.435501,Time used 0.004998s\n",
      "batch 6609, train_loss 28.526001,Time used 0.006001s\n",
      "batch 6610, train_loss 38.977768,Time used 0.004999s\n",
      "batch 6611, train_loss 34.870174,Time used 0.006000s\n",
      "batch 6612, train_loss 30.619143,Time used 0.005038s\n",
      "batch 6613, train_loss 36.413956,Time used 0.005003s\n",
      "batch 6614, train_loss 34.796326,Time used 0.004999s\n",
      "batch 6615, train_loss 36.861710,Time used 0.006037s\n",
      "batch 6616, train_loss 33.682419,Time used 0.004997s\n",
      "batch 6617, train_loss 35.847588,Time used 0.004999s\n",
      "batch 6618, train_loss 35.056946,Time used 0.006002s\n",
      "batch 6619, train_loss 39.834412,Time used 0.005001s\n",
      "batch 6620, train_loss 29.675165,Time used 0.004997s\n",
      "batch 6621, train_loss 30.634129,Time used 0.006971s\n",
      "batch 6622, train_loss 41.436420,Time used 0.004995s\n",
      "batch 6623, train_loss 41.981941,Time used 0.004999s\n",
      "batch 6624, train_loss 28.032391,Time used 0.004001s\n",
      "batch 6625, train_loss 25.571148,Time used 0.004999s\n",
      "batch 6626, train_loss 33.942650,Time used 0.006001s\n",
      "batch 6627, train_loss 43.879383,Time used 0.007004s\n",
      "batch 6628, train_loss 28.835623,Time used 0.007034s\n",
      "batch 6629, train_loss 35.583614,Time used 0.006960s\n",
      "batch 6630, train_loss 31.041115,Time used 0.006001s\n",
      "batch 6631, train_loss 44.169830,Time used 0.006995s\n",
      "batch 6632, train_loss 33.875294,Time used 0.008000s\n",
      "batch 6633, train_loss 32.300781,Time used 0.006001s\n",
      "batch 6634, train_loss 33.469437,Time used 0.004999s\n",
      "batch 6635, train_loss 31.565878,Time used 0.005033s\n",
      "batch 6636, train_loss 38.844082,Time used 0.006002s\n",
      "batch 6637, train_loss 31.178400,Time used 0.004999s\n",
      "batch 6638, train_loss 42.931538,Time used 0.003966s\n",
      "batch 6639, train_loss 28.219229,Time used 0.005969s\n",
      "batch 6640, train_loss 38.758537,Time used 0.005001s\n",
      "batch 6641, train_loss 39.452457,Time used 0.005000s\n",
      "batch 6642, train_loss 35.265099,Time used 0.007998s\n",
      "batch 6643, train_loss 26.690647,Time used 0.007035s\n",
      "batch 6644, train_loss 39.387234,Time used 0.004969s\n",
      "batch 6645, train_loss 33.396709,Time used 0.004998s\n",
      "batch 6646, train_loss 38.820408,Time used 0.005000s\n",
      "batch 6647, train_loss 37.136261,Time used 0.005003s\n",
      "batch 6648, train_loss 34.947994,Time used 0.005034s\n",
      "batch 6649, train_loss 35.560455,Time used 0.008001s\n",
      "batch 6650, train_loss 33.020939,Time used 0.006045s\n",
      "batch 6651, train_loss 32.086269,Time used 0.004993s\n",
      "batch 6652, train_loss 42.773746,Time used 0.007999s\n",
      "batch 6653, train_loss 30.250950,Time used 0.005961s\n",
      "batch 6654, train_loss 42.372902,Time used 0.005002s\n",
      "batch 6655, train_loss 32.633701,Time used 0.004998s\n",
      "batch 6656, train_loss 33.457458,Time used 0.005000s\n",
      "batch 6657, train_loss 35.849911,Time used 0.005000s\n",
      "batch 6658, train_loss 29.113544,Time used 0.005000s\n",
      "batch 6659, train_loss 33.732277,Time used 0.007000s\n",
      "batch 6660, train_loss 29.082420,Time used 0.006999s\n",
      "batch 6661, train_loss 31.941034,Time used 0.006999s\n",
      "batch 6662, train_loss 32.437492,Time used 0.005001s\n",
      "batch 6663, train_loss 42.218384,Time used 0.007999s\n",
      "batch 6664, train_loss 32.820854,Time used 0.005004s\n",
      "batch 6665, train_loss 45.098576,Time used 0.005001s\n",
      "batch 6666, train_loss 37.696873,Time used 0.006999s\n",
      "batch 6667, train_loss 36.570522,Time used 0.008000s\n",
      "batch 6668, train_loss 36.020119,Time used 0.007036s\n",
      "batch 6669, train_loss 31.276739,Time used 0.005998s\n",
      "batch 6670, train_loss 38.152035,Time used 0.004969s\n",
      "batch 6671, train_loss 35.649483,Time used 0.005999s\n",
      "batch 6672, train_loss 27.936323,Time used 0.007999s\n",
      "batch 6673, train_loss 37.476898,Time used 0.005966s\n",
      "batch 6674, train_loss 37.502937,Time used 0.005002s\n",
      "batch 6675, train_loss 28.537506,Time used 0.005000s\n",
      "batch 6676, train_loss 29.180979,Time used 0.004002s\n",
      "batch 6677, train_loss 33.043949,Time used 0.005001s\n",
      "batch 6678, train_loss 28.182009,Time used 0.005000s\n",
      "batch 6679, train_loss 31.164635,Time used 0.005000s\n",
      "batch 6680, train_loss 32.924606,Time used 0.005000s\n",
      "batch 6681, train_loss 30.908754,Time used 0.005996s\n",
      "batch 6682, train_loss 36.326145,Time used 0.005001s\n",
      "batch 6683, train_loss 30.818275,Time used 0.007043s\n",
      "batch 6684, train_loss 39.396812,Time used 0.005994s\n",
      "batch 6685, train_loss 32.760258,Time used 0.004966s\n",
      "batch 6686, train_loss 34.235374,Time used 0.005036s\n",
      "batch 6687, train_loss 32.164398,Time used 0.004996s\n",
      "batch 6688, train_loss 40.303619,Time used 0.005999s\n",
      "batch 6689, train_loss 37.021404,Time used 0.006001s\n",
      "batch 6690, train_loss 43.181168,Time used 0.005000s\n",
      "batch 6691, train_loss 33.567257,Time used 0.006000s\n",
      "batch 6692, train_loss 43.273937,Time used 0.006000s\n",
      "batch 6693, train_loss 33.329178,Time used 0.005000s\n",
      "batch 6694, train_loss 39.227531,Time used 0.006002s\n",
      "batch 6695, train_loss 37.006691,Time used 0.010999s\n",
      "batch 6696, train_loss 34.873676,Time used 0.006997s\n",
      "batch 6697, train_loss 36.233036,Time used 0.004997s\n",
      "batch 6698, train_loss 31.809790,Time used 0.005967s\n",
      "batch 6699, train_loss 40.053566,Time used 0.005036s\n",
      "batch 6700, train_loss 30.030262,Time used 0.004997s\n",
      "***************************test_batch 6700, test_rmse_loss 7.197328,test_mae_loss 3.207125,test_mape_loss 53.693661,Time used 0.023966s\n",
      "batch 6701, train_loss 42.653999,Time used 0.005004s\n",
      "batch 6702, train_loss 37.128643,Time used 0.006033s\n",
      "batch 6703, train_loss 34.813866,Time used 0.006001s\n",
      "batch 6704, train_loss 39.332672,Time used 0.005965s\n",
      "batch 6705, train_loss 30.993959,Time used 0.007033s\n",
      "batch 6706, train_loss 28.597670,Time used 0.007969s\n",
      "batch 6707, train_loss 34.178745,Time used 0.005998s\n",
      "batch 6708, train_loss 32.723526,Time used 0.005041s\n",
      "batch 6709, train_loss 36.286602,Time used 0.004994s\n",
      "batch 6710, train_loss 37.127689,Time used 0.005000s\n",
      "batch 6711, train_loss 38.136192,Time used 0.005000s\n",
      "batch 6712, train_loss 31.083950,Time used 0.004968s\n",
      "batch 6713, train_loss 36.151546,Time used 0.004999s\n",
      "batch 6714, train_loss 32.203339,Time used 0.004998s\n",
      "batch 6715, train_loss 31.020002,Time used 0.006001s\n",
      "batch 6716, train_loss 31.216574,Time used 0.004999s\n",
      "batch 6717, train_loss 33.217716,Time used 0.005000s\n",
      "batch 6718, train_loss 36.618885,Time used 0.005001s\n",
      "batch 6719, train_loss 40.870506,Time used 0.004999s\n",
      "batch 6720, train_loss 32.094940,Time used 0.004997s\n",
      "batch 6721, train_loss 35.462772,Time used 0.007997s\n",
      "batch 6722, train_loss 29.273758,Time used 0.005003s\n",
      "batch 6723, train_loss 40.879570,Time used 0.006032s\n",
      "batch 6724, train_loss 36.489326,Time used 0.005000s\n",
      "batch 6725, train_loss 32.169666,Time used 0.005006s\n",
      "batch 6726, train_loss 34.340126,Time used 0.006994s\n",
      "batch 6727, train_loss 32.084179,Time used 0.005005s\n",
      "batch 6728, train_loss 30.929384,Time used 0.004994s\n",
      "batch 6729, train_loss 35.120220,Time used 0.005968s\n",
      "batch 6730, train_loss 37.079620,Time used 0.005040s\n",
      "batch 6731, train_loss 36.740753,Time used 0.004997s\n",
      "batch 6732, train_loss 29.339712,Time used 0.007958s\n",
      "batch 6733, train_loss 36.185005,Time used 0.005000s\n",
      "batch 6734, train_loss 30.367537,Time used 0.006040s\n",
      "batch 6735, train_loss 31.758934,Time used 0.004999s\n",
      "batch 6736, train_loss 31.626932,Time used 0.004999s\n",
      "batch 6737, train_loss 31.062679,Time used 0.006002s\n",
      "batch 6738, train_loss 33.781948,Time used 0.004999s\n",
      "batch 6739, train_loss 38.794365,Time used 0.005960s\n",
      "batch 6740, train_loss 35.828171,Time used 0.008002s\n",
      "batch 6741, train_loss 40.438057,Time used 0.008001s\n",
      "batch 6742, train_loss 36.410347,Time used 0.006998s\n",
      "batch 6743, train_loss 39.456711,Time used 0.004999s\n",
      "batch 6744, train_loss 37.582451,Time used 0.005004s\n",
      "batch 6745, train_loss 31.765585,Time used 0.006000s\n",
      "batch 6746, train_loss 33.480820,Time used 0.006964s\n",
      "batch 6747, train_loss 36.626671,Time used 0.006001s\n",
      "batch 6748, train_loss 39.044357,Time used 0.007001s\n",
      "batch 6749, train_loss 37.559483,Time used 0.006999s\n",
      "batch 6750, train_loss 33.841389,Time used 0.007003s\n",
      "batch 6751, train_loss 41.854702,Time used 0.004994s\n",
      "batch 6752, train_loss 34.899914,Time used 0.005001s\n",
      "batch 6753, train_loss 32.399479,Time used 0.005002s\n",
      "batch 6754, train_loss 37.610813,Time used 0.005997s\n",
      "batch 6755, train_loss 35.369331,Time used 0.006000s\n",
      "batch 6756, train_loss 37.927708,Time used 0.006000s\n",
      "batch 6757, train_loss 27.508823,Time used 0.005000s\n",
      "batch 6758, train_loss 36.137272,Time used 0.004999s\n",
      "batch 6759, train_loss 35.282631,Time used 0.007003s\n",
      "batch 6760, train_loss 31.345118,Time used 0.005997s\n",
      "batch 6761, train_loss 29.941345,Time used 0.006003s\n",
      "batch 6762, train_loss 31.416605,Time used 0.005005s\n",
      "batch 6763, train_loss 33.437336,Time used 0.005997s\n",
      "batch 6764, train_loss 35.082008,Time used 0.007999s\n",
      "batch 6765, train_loss 35.418213,Time used 0.008001s\n",
      "batch 6766, train_loss 40.379860,Time used 0.008000s\n",
      "batch 6767, train_loss 32.452282,Time used 0.006000s\n",
      "batch 6768, train_loss 30.377676,Time used 0.005996s\n",
      "batch 6769, train_loss 39.956894,Time used 0.009000s\n",
      "batch 6770, train_loss 35.395897,Time used 0.007999s\n",
      "batch 6771, train_loss 35.167408,Time used 0.008001s\n",
      "batch 6772, train_loss 40.963230,Time used 0.008002s\n",
      "batch 6773, train_loss 38.498558,Time used 0.007999s\n",
      "batch 6774, train_loss 31.509077,Time used 0.005003s\n",
      "batch 6775, train_loss 29.584505,Time used 0.007000s\n",
      "batch 6776, train_loss 35.871716,Time used 0.004999s\n",
      "batch 6777, train_loss 29.874786,Time used 0.005000s\n",
      "batch 6778, train_loss 37.278030,Time used 0.006038s\n",
      "batch 6779, train_loss 35.711330,Time used 0.005968s\n",
      "batch 6780, train_loss 30.031309,Time used 0.005032s\n",
      "batch 6781, train_loss 35.840370,Time used 0.004964s\n",
      "batch 6782, train_loss 35.501411,Time used 0.005035s\n",
      "batch 6783, train_loss 38.811253,Time used 0.004999s\n",
      "batch 6784, train_loss 40.791679,Time used 0.005038s\n",
      "batch 6785, train_loss 30.232195,Time used 0.004965s\n",
      "batch 6786, train_loss 31.983768,Time used 0.005996s\n",
      "batch 6787, train_loss 30.352770,Time used 0.005998s\n",
      "batch 6788, train_loss 35.092308,Time used 0.007999s\n",
      "batch 6789, train_loss 35.112278,Time used 0.005000s\n",
      "batch 6790, train_loss 31.939484,Time used 0.005001s\n",
      "batch 6791, train_loss 30.721300,Time used 0.005000s\n",
      "batch 6792, train_loss 33.191856,Time used 0.006000s\n",
      "batch 6793, train_loss 32.152203,Time used 0.004997s\n",
      "batch 6794, train_loss 30.674246,Time used 0.005001s\n",
      "batch 6795, train_loss 29.240990,Time used 0.005998s\n",
      "batch 6796, train_loss 37.081749,Time used 0.005999s\n",
      "batch 6797, train_loss 32.868340,Time used 0.005002s\n",
      "batch 6798, train_loss 33.392757,Time used 0.004998s\n",
      "batch 6799, train_loss 38.504406,Time used 0.006003s\n",
      "batch 6800, train_loss 35.646687,Time used 0.005036s\n",
      "***************************test_batch 6800, test_rmse_loss 7.163662,test_mae_loss 3.198559,test_mape_loss 53.881029,Time used 0.017966s\n",
      "batch 6801, train_loss 35.663944,Time used 0.007997s\n",
      "batch 6802, train_loss 31.394894,Time used 0.004997s\n",
      "batch 6803, train_loss 39.375660,Time used 0.008003s\n",
      "batch 6804, train_loss 32.430305,Time used 0.004998s\n",
      "batch 6805, train_loss 31.601706,Time used 0.006000s\n",
      "batch 6806, train_loss 40.572746,Time used 0.006000s\n",
      "batch 6807, train_loss 38.790619,Time used 0.005000s\n",
      "batch 6808, train_loss 36.245232,Time used 0.006002s\n",
      "batch 6809, train_loss 30.733953,Time used 0.004998s\n",
      "batch 6810, train_loss 36.215309,Time used 0.005000s\n",
      "batch 6811, train_loss 37.176884,Time used 0.005002s\n",
      "batch 6812, train_loss 28.717876,Time used 0.006998s\n",
      "batch 6813, train_loss 34.786999,Time used 0.004999s\n",
      "batch 6814, train_loss 37.282478,Time used 0.005002s\n",
      "batch 6815, train_loss 37.880493,Time used 0.004998s\n",
      "batch 6816, train_loss 29.732735,Time used 0.004002s\n",
      "batch 6817, train_loss 34.539169,Time used 0.004997s\n",
      "batch 6818, train_loss 35.990189,Time used 0.005000s\n",
      "batch 6819, train_loss 30.803471,Time used 0.006004s\n",
      "batch 6820, train_loss 23.645210,Time used 0.015000s\n",
      "batch 6821, train_loss 35.046406,Time used 0.007000s\n",
      "batch 6822, train_loss 33.500702,Time used 0.008001s\n",
      "batch 6823, train_loss 32.578625,Time used 0.005999s\n",
      "batch 6824, train_loss 42.332840,Time used 0.005002s\n",
      "batch 6825, train_loss 42.245731,Time used 0.006999s\n",
      "batch 6826, train_loss 33.258759,Time used 0.008000s\n",
      "batch 6827, train_loss 36.757114,Time used 0.007997s\n",
      "batch 6828, train_loss 37.918633,Time used 0.007003s\n",
      "batch 6829, train_loss 36.074867,Time used 0.006004s\n",
      "batch 6830, train_loss 34.439960,Time used 0.005993s\n",
      "batch 6831, train_loss 38.643345,Time used 0.005000s\n",
      "batch 6832, train_loss 35.331867,Time used 0.008001s\n",
      "batch 6833, train_loss 28.643145,Time used 0.005000s\n",
      "batch 6834, train_loss 33.617764,Time used 0.006005s\n",
      "batch 6835, train_loss 31.304638,Time used 0.005996s\n",
      "batch 6836, train_loss 38.831528,Time used 0.004998s\n",
      "batch 6837, train_loss 35.196468,Time used 0.004996s\n",
      "batch 6838, train_loss 30.909290,Time used 0.005999s\n",
      "batch 6839, train_loss 33.123158,Time used 0.004999s\n",
      "batch 6840, train_loss 31.828444,Time used 0.005002s\n",
      "batch 6841, train_loss 34.913670,Time used 0.006999s\n",
      "batch 6842, train_loss 38.347698,Time used 0.008001s\n",
      "batch 6843, train_loss 28.736502,Time used 0.006997s\n",
      "batch 6844, train_loss 27.682909,Time used 0.005999s\n",
      "batch 6845, train_loss 31.555481,Time used 0.005001s\n",
      "batch 6846, train_loss 30.798344,Time used 0.007002s\n",
      "batch 6847, train_loss 37.019531,Time used 0.004998s\n",
      "batch 6848, train_loss 33.895702,Time used 0.005003s\n",
      "batch 6849, train_loss 30.409472,Time used 0.005999s\n",
      "batch 6850, train_loss 36.422264,Time used 0.005001s\n",
      "batch 6851, train_loss 30.414473,Time used 0.005998s\n",
      "batch 6852, train_loss 38.810478,Time used 0.004997s\n",
      "batch 6853, train_loss 36.756023,Time used 0.004999s\n",
      "batch 6854, train_loss 44.258404,Time used 0.006000s\n",
      "batch 6855, train_loss 28.284260,Time used 0.007000s\n",
      "batch 6856, train_loss 39.027225,Time used 0.006000s\n",
      "batch 6857, train_loss 35.007740,Time used 0.006002s\n",
      "batch 6858, train_loss 36.772751,Time used 0.007998s\n",
      "batch 6859, train_loss 32.898029,Time used 0.007004s\n",
      "batch 6860, train_loss 35.447933,Time used 0.006997s\n",
      "batch 6861, train_loss 28.369566,Time used 0.008001s\n",
      "batch 6862, train_loss 32.147888,Time used 0.005001s\n",
      "batch 6863, train_loss 38.169392,Time used 0.005001s\n",
      "batch 6864, train_loss 38.385456,Time used 0.007003s\n",
      "batch 6865, train_loss 32.530056,Time used 0.005998s\n",
      "batch 6866, train_loss 42.321838,Time used 0.004999s\n",
      "batch 6867, train_loss 26.720358,Time used 0.005000s\n",
      "batch 6868, train_loss 34.463737,Time used 0.005996s\n",
      "batch 6869, train_loss 39.365025,Time used 0.006000s\n",
      "batch 6870, train_loss 32.911846,Time used 0.004999s\n",
      "batch 6871, train_loss 35.216564,Time used 0.005004s\n",
      "batch 6872, train_loss 36.380020,Time used 0.005000s\n",
      "batch 6873, train_loss 35.593895,Time used 0.005033s\n",
      "batch 6874, train_loss 33.878368,Time used 0.004968s\n",
      "batch 6875, train_loss 37.905418,Time used 0.004999s\n",
      "batch 6876, train_loss 33.265774,Time used 0.005000s\n",
      "batch 6877, train_loss 31.666729,Time used 0.005034s\n",
      "batch 6878, train_loss 34.150299,Time used 0.004999s\n",
      "batch 6879, train_loss 36.852226,Time used 0.004964s\n",
      "batch 6880, train_loss 33.618538,Time used 0.006000s\n",
      "batch 6881, train_loss 41.018555,Time used 0.005000s\n",
      "batch 6882, train_loss 32.531181,Time used 0.006000s\n",
      "batch 6883, train_loss 28.073957,Time used 0.007039s\n",
      "batch 6884, train_loss 33.258595,Time used 0.004037s\n",
      "batch 6885, train_loss 31.291782,Time used 0.005963s\n",
      "batch 6886, train_loss 31.674059,Time used 0.004998s\n",
      "batch 6887, train_loss 34.374992,Time used 0.006000s\n",
      "batch 6888, train_loss 34.207668,Time used 0.006000s\n",
      "batch 6889, train_loss 42.571472,Time used 0.010003s\n",
      "batch 6890, train_loss 33.548698,Time used 0.008999s\n",
      "batch 6891, train_loss 33.330521,Time used 0.008000s\n",
      "batch 6892, train_loss 37.788597,Time used 0.006001s\n",
      "batch 6893, train_loss 28.660419,Time used 0.005035s\n",
      "batch 6894, train_loss 31.039991,Time used 0.007004s\n",
      "batch 6895, train_loss 33.311752,Time used 0.007966s\n",
      "batch 6896, train_loss 30.954226,Time used 0.005999s\n",
      "batch 6897, train_loss 34.055237,Time used 0.008041s\n",
      "batch 6898, train_loss 32.683403,Time used 0.004998s\n",
      "batch 6899, train_loss 30.387157,Time used 0.006004s\n",
      "batch 6900, train_loss 31.382597,Time used 0.004960s\n",
      "***************************test_batch 6900, test_rmse_loss 7.158949,test_mae_loss 3.196091,test_mape_loss 53.704618,Time used 0.018034s\n",
      "batch 6901, train_loss 35.396545,Time used 0.005001s\n",
      "batch 6902, train_loss 33.652767,Time used 0.005998s\n",
      "batch 6903, train_loss 37.744713,Time used 0.007000s\n",
      "batch 6904, train_loss 37.468960,Time used 0.005004s\n",
      "batch 6905, train_loss 23.214293,Time used 0.005964s\n",
      "batch 6906, train_loss 37.912857,Time used 0.006036s\n",
      "batch 6907, train_loss 40.291508,Time used 0.004963s\n",
      "batch 6908, train_loss 39.416111,Time used 0.005033s\n",
      "batch 6909, train_loss 34.722347,Time used 0.005002s\n",
      "batch 6910, train_loss 35.144817,Time used 0.004967s\n",
      "batch 6911, train_loss 32.596775,Time used 0.005998s\n",
      "batch 6912, train_loss 34.995152,Time used 0.004997s\n",
      "batch 6913, train_loss 29.198950,Time used 0.007000s\n",
      "batch 6914, train_loss 30.952368,Time used 0.004998s\n",
      "batch 6915, train_loss 30.149162,Time used 0.005001s\n",
      "batch 6916, train_loss 33.844654,Time used 0.008002s\n",
      "batch 6917, train_loss 41.273670,Time used 0.008003s\n",
      "batch 6918, train_loss 32.868599,Time used 0.006996s\n",
      "batch 6919, train_loss 33.399715,Time used 0.004999s\n",
      "batch 6920, train_loss 32.136761,Time used 0.005008s\n",
      "batch 6921, train_loss 36.397602,Time used 0.005997s\n",
      "batch 6922, train_loss 39.634850,Time used 0.005000s\n",
      "batch 6923, train_loss 33.045135,Time used 0.005035s\n",
      "batch 6924, train_loss 31.710733,Time used 0.005966s\n",
      "batch 6925, train_loss 37.593132,Time used 0.006033s\n",
      "batch 6926, train_loss 35.852261,Time used 0.006962s\n",
      "batch 6927, train_loss 37.040234,Time used 0.008001s\n",
      "batch 6928, train_loss 35.074387,Time used 0.007001s\n",
      "batch 6929, train_loss 36.121449,Time used 0.006002s\n",
      "batch 6930, train_loss 33.079208,Time used 0.005997s\n",
      "batch 6931, train_loss 30.203512,Time used 0.006003s\n",
      "batch 6932, train_loss 36.940655,Time used 0.008000s\n",
      "batch 6933, train_loss 33.229630,Time used 0.005999s\n",
      "batch 6934, train_loss 30.791265,Time used 0.006001s\n",
      "batch 6935, train_loss 34.894470,Time used 0.006997s\n",
      "batch 6936, train_loss 34.600021,Time used 0.007998s\n",
      "batch 6937, train_loss 33.387360,Time used 0.008000s\n",
      "batch 6938, train_loss 34.640972,Time used 0.005999s\n",
      "batch 6939, train_loss 25.600458,Time used 0.006999s\n",
      "batch 6940, train_loss 38.249897,Time used 0.005998s\n",
      "batch 6941, train_loss 39.523552,Time used 0.005999s\n",
      "batch 6942, train_loss 38.922798,Time used 0.005000s\n",
      "batch 6943, train_loss 37.939159,Time used 0.006000s\n",
      "batch 6944, train_loss 31.931999,Time used 0.008000s\n",
      "batch 6945, train_loss 28.241505,Time used 0.005002s\n",
      "batch 6946, train_loss 34.531319,Time used 0.006000s\n",
      "batch 6947, train_loss 30.083050,Time used 0.005000s\n",
      "batch 6948, train_loss 36.896088,Time used 0.005998s\n",
      "batch 6949, train_loss 31.351177,Time used 0.005001s\n",
      "batch 6950, train_loss 34.544785,Time used 0.004038s\n",
      "batch 6951, train_loss 33.507408,Time used 0.005001s\n",
      "batch 6952, train_loss 29.997240,Time used 0.004968s\n",
      "batch 6953, train_loss 34.189571,Time used 0.005033s\n",
      "batch 6954, train_loss 31.148605,Time used 0.006999s\n",
      "batch 6955, train_loss 31.009491,Time used 0.006007s\n",
      "batch 6956, train_loss 38.740665,Time used 0.004997s\n",
      "batch 6957, train_loss 31.581297,Time used 0.004997s\n",
      "batch 6958, train_loss 42.370281,Time used 0.004999s\n",
      "batch 6959, train_loss 39.260265,Time used 0.005963s\n",
      "batch 6960, train_loss 31.266832,Time used 0.006000s\n",
      "batch 6961, train_loss 30.251432,Time used 0.005036s\n",
      "batch 6962, train_loss 37.292866,Time used 0.006002s\n",
      "batch 6963, train_loss 31.098625,Time used 0.004963s\n",
      "batch 6964, train_loss 37.834015,Time used 0.006002s\n",
      "batch 6965, train_loss 37.023956,Time used 0.004999s\n",
      "batch 6966, train_loss 42.080032,Time used 0.005000s\n",
      "batch 6967, train_loss 31.051559,Time used 0.004963s\n",
      "batch 6968, train_loss 35.297245,Time used 0.006000s\n",
      "batch 6969, train_loss 36.404076,Time used 0.005001s\n",
      "batch 6970, train_loss 34.460049,Time used 0.005003s\n",
      "batch 6971, train_loss 31.763987,Time used 0.005044s\n",
      "batch 6972, train_loss 32.762051,Time used 0.004992s\n",
      "batch 6973, train_loss 31.043598,Time used 0.005962s\n",
      "batch 6974, train_loss 30.464294,Time used 0.005004s\n",
      "batch 6975, train_loss 34.942959,Time used 0.005001s\n",
      "batch 6976, train_loss 30.858435,Time used 0.006996s\n",
      "batch 6977, train_loss 35.302521,Time used 0.008005s\n",
      "batch 6978, train_loss 31.797678,Time used 0.006999s\n",
      "batch 6979, train_loss 34.554276,Time used 0.007999s\n",
      "batch 6980, train_loss 41.388981,Time used 0.005998s\n",
      "batch 6981, train_loss 34.336655,Time used 0.006000s\n",
      "batch 6982, train_loss 30.998091,Time used 0.005038s\n",
      "batch 6983, train_loss 32.561581,Time used 0.005964s\n",
      "batch 6984, train_loss 31.562895,Time used 0.005003s\n",
      "batch 6985, train_loss 30.531925,Time used 0.008032s\n",
      "batch 6986, train_loss 35.593075,Time used 0.004999s\n",
      "batch 6987, train_loss 38.153214,Time used 0.005999s\n",
      "batch 6988, train_loss 35.275021,Time used 0.005003s\n",
      "batch 6989, train_loss 29.232899,Time used 0.004998s\n",
      "batch 6990, train_loss 29.182762,Time used 0.004998s\n",
      "batch 6991, train_loss 34.178272,Time used 0.005000s\n",
      "batch 6992, train_loss 32.100460,Time used 0.005968s\n",
      "batch 6993, train_loss 35.481823,Time used 0.007031s\n",
      "batch 6994, train_loss 32.995701,Time used 0.004969s\n",
      "batch 6995, train_loss 30.267416,Time used 0.006034s\n",
      "batch 6996, train_loss 38.294731,Time used 0.005997s\n",
      "batch 6997, train_loss 43.348766,Time used 0.008002s\n",
      "batch 6998, train_loss 32.450001,Time used 0.006004s\n",
      "batch 6999, train_loss 34.384109,Time used 0.004997s\n",
      "batch 7000, train_loss 37.021042,Time used 0.005960s\n",
      "***************************test_batch 7000, test_rmse_loss 7.170103,test_mae_loss 3.197411,test_mape_loss 53.336790,Time used 0.020000s\n",
      "batch 7001, train_loss 34.156525,Time used 0.005000s\n",
      "batch 7002, train_loss 27.541752,Time used 0.005000s\n",
      "batch 7003, train_loss 36.557022,Time used 0.005001s\n",
      "batch 7004, train_loss 34.753220,Time used 0.004994s\n",
      "batch 7005, train_loss 33.993172,Time used 0.004998s\n",
      "batch 7006, train_loss 33.674587,Time used 0.007998s\n",
      "batch 7007, train_loss 34.606964,Time used 0.004999s\n",
      "batch 7008, train_loss 32.507889,Time used 0.006002s\n",
      "batch 7009, train_loss 32.789871,Time used 0.005995s\n",
      "batch 7010, train_loss 30.507294,Time used 0.005000s\n",
      "batch 7011, train_loss 36.551136,Time used 0.005004s\n",
      "batch 7012, train_loss 38.292965,Time used 0.004000s\n",
      "batch 7013, train_loss 30.807795,Time used 0.007999s\n",
      "batch 7014, train_loss 33.785110,Time used 0.004966s\n",
      "batch 7015, train_loss 29.424427,Time used 0.005003s\n",
      "batch 7016, train_loss 34.640190,Time used 0.005000s\n",
      "batch 7017, train_loss 36.277489,Time used 0.005000s\n",
      "batch 7018, train_loss 28.113581,Time used 0.006000s\n",
      "batch 7019, train_loss 35.165878,Time used 0.006033s\n",
      "batch 7020, train_loss 29.918068,Time used 0.005000s\n",
      "batch 7021, train_loss 28.798611,Time used 0.007003s\n",
      "batch 7022, train_loss 33.727486,Time used 0.007998s\n",
      "batch 7023, train_loss 45.356525,Time used 0.006967s\n",
      "batch 7024, train_loss 34.253464,Time used 0.008000s\n",
      "batch 7025, train_loss 28.744772,Time used 0.004998s\n",
      "batch 7026, train_loss 30.537584,Time used 0.005998s\n",
      "batch 7027, train_loss 41.261387,Time used 0.005000s\n",
      "batch 7028, train_loss 29.606771,Time used 0.005001s\n",
      "batch 7029, train_loss 30.627884,Time used 0.006005s\n",
      "batch 7030, train_loss 31.327881,Time used 0.005033s\n",
      "batch 7031, train_loss 42.373455,Time used 0.004962s\n",
      "batch 7032, train_loss 42.245705,Time used 0.005000s\n",
      "batch 7033, train_loss 33.512463,Time used 0.008000s\n",
      "batch 7034, train_loss 40.825684,Time used 0.005001s\n",
      "batch 7035, train_loss 29.418608,Time used 0.006038s\n",
      "batch 7036, train_loss 38.519665,Time used 0.004997s\n",
      "batch 7037, train_loss 30.069948,Time used 0.006005s\n",
      "batch 7038, train_loss 28.934378,Time used 0.005000s\n",
      "batch 7039, train_loss 34.974068,Time used 0.004994s\n",
      "batch 7040, train_loss 28.108974,Time used 0.005968s\n",
      "batch 7041, train_loss 35.887962,Time used 0.007000s\n",
      "batch 7042, train_loss 30.029966,Time used 0.009998s\n",
      "batch 7043, train_loss 33.959194,Time used 0.005999s\n",
      "batch 7044, train_loss 29.768135,Time used 0.005002s\n",
      "batch 7045, train_loss 34.411354,Time used 0.005002s\n",
      "batch 7046, train_loss 35.844715,Time used 0.004954s\n",
      "batch 7047, train_loss 35.418297,Time used 0.005001s\n",
      "batch 7048, train_loss 40.091282,Time used 0.005999s\n",
      "batch 7049, train_loss 32.076740,Time used 0.007001s\n",
      "batch 7050, train_loss 31.805313,Time used 0.005004s\n",
      "batch 7051, train_loss 31.664276,Time used 0.006001s\n",
      "batch 7052, train_loss 40.142033,Time used 0.005031s\n",
      "batch 7053, train_loss 33.495506,Time used 0.006000s\n",
      "batch 7054, train_loss 30.789539,Time used 0.005001s\n",
      "batch 7055, train_loss 32.993347,Time used 0.005000s\n",
      "batch 7056, train_loss 40.860844,Time used 0.005002s\n",
      "batch 7057, train_loss 29.287251,Time used 0.005000s\n",
      "batch 7058, train_loss 34.923477,Time used 0.005001s\n",
      "batch 7059, train_loss 31.512873,Time used 0.004999s\n",
      "batch 7060, train_loss 33.320099,Time used 0.008032s\n",
      "batch 7061, train_loss 37.211075,Time used 0.007966s\n",
      "batch 7062, train_loss 27.345568,Time used 0.005002s\n",
      "batch 7063, train_loss 37.549107,Time used 0.005000s\n",
      "batch 7064, train_loss 25.476923,Time used 0.004997s\n",
      "batch 7065, train_loss 34.939030,Time used 0.005999s\n",
      "batch 7066, train_loss 33.819016,Time used 0.007005s\n",
      "batch 7067, train_loss 29.491154,Time used 0.004997s\n",
      "batch 7068, train_loss 35.129848,Time used 0.007003s\n",
      "batch 7069, train_loss 35.337143,Time used 0.007999s\n",
      "batch 7070, train_loss 37.514900,Time used 0.007998s\n",
      "batch 7071, train_loss 26.917122,Time used 0.004999s\n",
      "batch 7072, train_loss 37.974869,Time used 0.005000s\n",
      "batch 7073, train_loss 34.130482,Time used 0.004999s\n",
      "batch 7074, train_loss 36.160439,Time used 0.006006s\n",
      "batch 7075, train_loss 32.344963,Time used 0.004999s\n",
      "batch 7076, train_loss 36.352943,Time used 0.005000s\n",
      "batch 7077, train_loss 34.120026,Time used 0.004996s\n",
      "batch 7078, train_loss 36.897579,Time used 0.006003s\n",
      "batch 7079, train_loss 35.221878,Time used 0.004997s\n",
      "batch 7080, train_loss 38.860798,Time used 0.005035s\n",
      "batch 7081, train_loss 37.275967,Time used 0.004964s\n",
      "batch 7082, train_loss 30.505934,Time used 0.006002s\n",
      "batch 7083, train_loss 33.631481,Time used 0.005999s\n",
      "batch 7084, train_loss 34.049660,Time used 0.004998s\n",
      "batch 7085, train_loss 32.361588,Time used 0.005002s\n",
      "batch 7086, train_loss 32.473576,Time used 0.006005s\n",
      "batch 7087, train_loss 39.187649,Time used 0.004991s\n",
      "batch 7088, train_loss 33.826149,Time used 0.005000s\n",
      "batch 7089, train_loss 37.496258,Time used 0.005999s\n",
      "batch 7090, train_loss 26.810547,Time used 0.006000s\n",
      "batch 7091, train_loss 37.662491,Time used 0.005001s\n",
      "batch 7092, train_loss 36.608250,Time used 0.007000s\n",
      "batch 7093, train_loss 31.458460,Time used 0.008000s\n",
      "batch 7094, train_loss 36.440178,Time used 0.007996s\n",
      "batch 7095, train_loss 30.125353,Time used 0.005002s\n",
      "batch 7096, train_loss 34.153606,Time used 0.004998s\n",
      "batch 7097, train_loss 31.012133,Time used 0.006000s\n",
      "batch 7098, train_loss 30.155615,Time used 0.005000s\n",
      "batch 7099, train_loss 37.431564,Time used 0.006003s\n",
      "batch 7100, train_loss 38.606903,Time used 0.005000s\n",
      "***************************test_batch 7100, test_rmse_loss 7.154219,test_mae_loss 3.193475,test_mape_loss 53.396141,Time used 0.025000s\n",
      "batch 7101, train_loss 32.139431,Time used 0.004998s\n",
      "batch 7102, train_loss 36.467464,Time used 0.006999s\n",
      "batch 7103, train_loss 33.585991,Time used 0.007010s\n",
      "batch 7104, train_loss 26.742590,Time used 0.007990s\n",
      "batch 7105, train_loss 36.589024,Time used 0.004998s\n",
      "batch 7106, train_loss 25.958883,Time used 0.006001s\n",
      "batch 7107, train_loss 32.809223,Time used 0.006998s\n",
      "batch 7108, train_loss 38.478943,Time used 0.004999s\n",
      "batch 7109, train_loss 32.321373,Time used 0.007002s\n",
      "batch 7110, train_loss 27.516542,Time used 0.006999s\n",
      "batch 7111, train_loss 33.468739,Time used 0.005002s\n",
      "batch 7112, train_loss 30.401688,Time used 0.006999s\n",
      "batch 7113, train_loss 32.813049,Time used 0.008037s\n",
      "batch 7114, train_loss 34.043751,Time used 0.007000s\n",
      "batch 7115, train_loss 34.567490,Time used 0.005963s\n",
      "batch 7116, train_loss 38.927521,Time used 0.005001s\n",
      "batch 7117, train_loss 40.589554,Time used 0.004999s\n",
      "batch 7118, train_loss 36.327831,Time used 0.008001s\n",
      "batch 7119, train_loss 34.740368,Time used 0.008002s\n",
      "batch 7120, train_loss 32.799774,Time used 0.005002s\n",
      "batch 7121, train_loss 33.271694,Time used 0.005000s\n",
      "batch 7122, train_loss 29.025301,Time used 0.005000s\n",
      "batch 7123, train_loss 32.787701,Time used 0.005999s\n",
      "batch 7124, train_loss 32.347717,Time used 0.004999s\n",
      "batch 7125, train_loss 34.799866,Time used 0.005000s\n",
      "batch 7126, train_loss 33.440540,Time used 0.008000s\n",
      "batch 7127, train_loss 29.505707,Time used 0.007001s\n",
      "batch 7128, train_loss 42.026772,Time used 0.004998s\n",
      "batch 7129, train_loss 34.476006,Time used 0.005999s\n",
      "batch 7130, train_loss 36.469498,Time used 0.005000s\n",
      "batch 7131, train_loss 30.877663,Time used 0.005001s\n",
      "batch 7132, train_loss 36.632019,Time used 0.005005s\n",
      "batch 7133, train_loss 31.889742,Time used 0.004002s\n",
      "batch 7134, train_loss 33.132187,Time used 0.005997s\n",
      "batch 7135, train_loss 36.626343,Time used 0.005036s\n",
      "batch 7136, train_loss 33.289955,Time used 0.004999s\n",
      "batch 7137, train_loss 31.478437,Time used 0.005003s\n",
      "batch 7138, train_loss 30.185467,Time used 0.005035s\n",
      "batch 7139, train_loss 30.542912,Time used 0.004999s\n",
      "batch 7140, train_loss 38.085621,Time used 0.004968s\n",
      "batch 7141, train_loss 35.474358,Time used 0.004998s\n",
      "batch 7142, train_loss 32.994892,Time used 0.004999s\n",
      "batch 7143, train_loss 35.983932,Time used 0.010000s\n",
      "batch 7144, train_loss 38.777294,Time used 0.007999s\n",
      "batch 7145, train_loss 27.754921,Time used 0.009000s\n",
      "batch 7146, train_loss 32.355247,Time used 0.009001s\n",
      "batch 7147, train_loss 30.323368,Time used 0.009001s\n",
      "batch 7148, train_loss 34.703228,Time used 0.006000s\n",
      "batch 7149, train_loss 34.895672,Time used 0.007998s\n",
      "batch 7150, train_loss 34.620338,Time used 0.008998s\n",
      "batch 7151, train_loss 34.391586,Time used 0.009001s\n",
      "batch 7152, train_loss 32.207127,Time used 0.006001s\n",
      "batch 7153, train_loss 34.408188,Time used 0.007001s\n",
      "batch 7154, train_loss 31.682241,Time used 0.008001s\n",
      "batch 7155, train_loss 32.383389,Time used 0.006000s\n",
      "batch 7156, train_loss 32.924835,Time used 0.009000s\n",
      "batch 7157, train_loss 34.446087,Time used 0.009000s\n",
      "batch 7158, train_loss 30.926283,Time used 0.010000s\n",
      "batch 7159, train_loss 30.525349,Time used 0.009001s\n",
      "batch 7160, train_loss 31.728361,Time used 0.006000s\n",
      "batch 7161, train_loss 34.906925,Time used 0.007000s\n",
      "batch 7162, train_loss 36.876240,Time used 0.006999s\n",
      "batch 7163, train_loss 43.756065,Time used 0.006000s\n",
      "batch 7164, train_loss 34.403805,Time used 0.009002s\n",
      "batch 7165, train_loss 31.668055,Time used 0.008999s\n",
      "batch 7166, train_loss 28.484808,Time used 0.009000s\n",
      "batch 7167, train_loss 37.365746,Time used 0.008999s\n",
      "batch 7168, train_loss 33.012238,Time used 0.010000s\n",
      "batch 7169, train_loss 32.183014,Time used 0.019003s\n",
      "batch 7170, train_loss 35.387547,Time used 0.008998s\n",
      "batch 7171, train_loss 41.121960,Time used 0.009001s\n",
      "batch 7172, train_loss 36.393509,Time used 0.007997s\n",
      "batch 7173, train_loss 27.847891,Time used 0.008999s\n",
      "batch 7174, train_loss 29.224016,Time used 0.008001s\n",
      "batch 7175, train_loss 32.939842,Time used 0.006002s\n",
      "batch 7176, train_loss 32.064236,Time used 0.007998s\n",
      "batch 7177, train_loss 31.628008,Time used 0.009003s\n",
      "batch 7178, train_loss 31.262924,Time used 0.009997s\n",
      "batch 7179, train_loss 30.894077,Time used 0.017000s\n",
      "batch 7180, train_loss 35.439545,Time used 0.009000s\n",
      "batch 7181, train_loss 34.717293,Time used 0.018000s\n",
      "batch 7182, train_loss 34.000118,Time used 0.008000s\n",
      "batch 7183, train_loss 35.243740,Time used 0.009002s\n",
      "batch 7184, train_loss 33.491394,Time used 0.010002s\n",
      "batch 7185, train_loss 34.397141,Time used 0.008999s\n",
      "batch 7186, train_loss 40.877941,Time used 0.009002s\n",
      "batch 7187, train_loss 43.390251,Time used 0.008997s\n",
      "batch 7188, train_loss 38.176571,Time used 0.009000s\n",
      "batch 7189, train_loss 41.085812,Time used 0.008998s\n",
      "batch 7190, train_loss 34.255844,Time used 0.007000s\n",
      "batch 7191, train_loss 30.789072,Time used 0.007000s\n",
      "batch 7192, train_loss 29.993153,Time used 0.008999s\n",
      "batch 7193, train_loss 32.857346,Time used 0.009001s\n",
      "batch 7194, train_loss 32.675587,Time used 0.008998s\n",
      "batch 7195, train_loss 31.104406,Time used 0.008003s\n",
      "batch 7196, train_loss 31.768095,Time used 0.007001s\n",
      "batch 7197, train_loss 28.417086,Time used 0.007001s\n",
      "batch 7198, train_loss 27.168289,Time used 0.009999s\n",
      "batch 7199, train_loss 29.351124,Time used 0.008000s\n",
      "batch 7200, train_loss 32.641617,Time used 0.006000s\n",
      "***************************test_batch 7200, test_rmse_loss 7.134556,test_mae_loss 3.185559,test_mape_loss 53.404779,Time used 0.028002s\n",
      "batch 7201, train_loss 32.203350,Time used 0.009000s\n",
      "batch 7202, train_loss 42.025509,Time used 0.009000s\n",
      "batch 7203, train_loss 41.931694,Time used 0.006000s\n",
      "batch 7204, train_loss 28.718037,Time used 0.005002s\n",
      "batch 7205, train_loss 36.251446,Time used 0.005998s\n",
      "batch 7206, train_loss 28.458515,Time used 0.006000s\n",
      "batch 7207, train_loss 33.051895,Time used 0.007002s\n",
      "batch 7208, train_loss 34.145370,Time used 0.006001s\n",
      "batch 7209, train_loss 25.872898,Time used 0.004999s\n",
      "batch 7210, train_loss 38.566441,Time used 0.007999s\n",
      "batch 7211, train_loss 31.121218,Time used 0.006001s\n",
      "batch 7212, train_loss 29.558058,Time used 0.004999s\n",
      "batch 7213, train_loss 34.851166,Time used 0.006999s\n",
      "batch 7214, train_loss 33.403389,Time used 0.008001s\n",
      "batch 7215, train_loss 32.881432,Time used 0.008002s\n",
      "batch 7216, train_loss 30.772020,Time used 0.005998s\n",
      "batch 7217, train_loss 32.511650,Time used 0.005000s\n",
      "batch 7218, train_loss 32.571865,Time used 0.004999s\n",
      "batch 7219, train_loss 36.891891,Time used 0.005000s\n",
      "batch 7220, train_loss 30.104553,Time used 0.004999s\n",
      "batch 7221, train_loss 35.499477,Time used 0.006002s\n",
      "batch 7222, train_loss 30.325615,Time used 0.006001s\n",
      "batch 7223, train_loss 35.925037,Time used 0.004999s\n",
      "batch 7224, train_loss 37.306061,Time used 0.005002s\n",
      "batch 7225, train_loss 36.054211,Time used 0.006946s\n",
      "batch 7226, train_loss 33.649120,Time used 0.006000s\n",
      "batch 7227, train_loss 31.952841,Time used 0.005000s\n",
      "batch 7228, train_loss 35.684765,Time used 0.005002s\n",
      "batch 7229, train_loss 37.921223,Time used 0.005002s\n",
      "batch 7230, train_loss 35.004601,Time used 0.005997s\n",
      "batch 7231, train_loss 34.699444,Time used 0.005004s\n",
      "batch 7232, train_loss 30.851810,Time used 0.007996s\n",
      "batch 7233, train_loss 33.618118,Time used 0.006001s\n",
      "batch 7234, train_loss 34.567184,Time used 0.005999s\n",
      "batch 7235, train_loss 24.765841,Time used 0.005001s\n",
      "batch 7236, train_loss 28.650822,Time used 0.005000s\n",
      "batch 7237, train_loss 30.664457,Time used 0.004999s\n",
      "batch 7238, train_loss 32.648769,Time used 0.006999s\n",
      "batch 7239, train_loss 34.789494,Time used 0.008001s\n",
      "batch 7240, train_loss 37.613358,Time used 0.008000s\n",
      "batch 7241, train_loss 41.422848,Time used 0.007999s\n",
      "batch 7242, train_loss 39.793247,Time used 0.007003s\n",
      "batch 7243, train_loss 30.202526,Time used 0.006000s\n",
      "batch 7244, train_loss 31.980093,Time used 0.005998s\n",
      "batch 7245, train_loss 28.738579,Time used 0.006003s\n",
      "batch 7246, train_loss 31.461714,Time used 0.004999s\n",
      "batch 7247, train_loss 34.246159,Time used 0.005998s\n",
      "batch 7248, train_loss 31.937275,Time used 0.006004s\n",
      "batch 7249, train_loss 31.471367,Time used 0.006997s\n",
      "batch 7250, train_loss 30.742180,Time used 0.006000s\n",
      "batch 7251, train_loss 37.971806,Time used 0.005001s\n",
      "batch 7252, train_loss 29.219437,Time used 0.005000s\n",
      "batch 7253, train_loss 29.846935,Time used 0.005000s\n",
      "batch 7254, train_loss 30.247732,Time used 0.005001s\n",
      "batch 7255, train_loss 33.751186,Time used 0.006000s\n",
      "batch 7256, train_loss 32.602871,Time used 0.006000s\n",
      "batch 7257, train_loss 34.860619,Time used 0.007000s\n",
      "batch 7258, train_loss 31.677816,Time used 0.006996s\n",
      "batch 7259, train_loss 30.999197,Time used 0.007002s\n",
      "batch 7260, train_loss 36.233807,Time used 0.006999s\n",
      "batch 7261, train_loss 34.000401,Time used 0.008000s\n",
      "batch 7262, train_loss 28.851305,Time used 0.007000s\n",
      "batch 7263, train_loss 32.332977,Time used 0.004999s\n",
      "batch 7264, train_loss 30.569836,Time used 0.006005s\n",
      "batch 7265, train_loss 32.632343,Time used 0.008036s\n",
      "batch 7266, train_loss 33.340424,Time used 0.007979s\n",
      "batch 7267, train_loss 43.925522,Time used 0.005011s\n",
      "batch 7268, train_loss 35.584934,Time used 0.005000s\n",
      "batch 7269, train_loss 38.941521,Time used 0.005008s\n",
      "batch 7270, train_loss 32.569595,Time used 0.005003s\n",
      "batch 7271, train_loss 31.791553,Time used 0.003966s\n",
      "batch 7272, train_loss 37.803047,Time used 0.004965s\n",
      "batch 7273, train_loss 36.980118,Time used 0.005001s\n",
      "batch 7274, train_loss 36.236546,Time used 0.006036s\n",
      "batch 7275, train_loss 29.843334,Time used 0.004966s\n",
      "batch 7276, train_loss 35.049610,Time used 0.005033s\n",
      "batch 7277, train_loss 37.253479,Time used 0.005001s\n",
      "batch 7278, train_loss 34.603924,Time used 0.004004s\n",
      "batch 7279, train_loss 31.717518,Time used 0.006957s\n",
      "batch 7280, train_loss 35.466362,Time used 0.006000s\n",
      "batch 7281, train_loss 34.925968,Time used 0.004999s\n",
      "batch 7282, train_loss 34.337639,Time used 0.005005s\n",
      "batch 7283, train_loss 31.524479,Time used 0.005001s\n",
      "batch 7284, train_loss 34.574364,Time used 0.004999s\n",
      "batch 7285, train_loss 31.326279,Time used 0.005999s\n",
      "batch 7286, train_loss 35.841404,Time used 0.008001s\n",
      "batch 7287, train_loss 32.169662,Time used 0.006001s\n",
      "batch 7288, train_loss 29.934340,Time used 0.005000s\n",
      "batch 7289, train_loss 28.800846,Time used 0.005002s\n",
      "batch 7290, train_loss 40.038628,Time used 0.006996s\n",
      "batch 7291, train_loss 25.182344,Time used 0.005001s\n",
      "batch 7292, train_loss 28.781023,Time used 0.005002s\n",
      "batch 7293, train_loss 29.413715,Time used 0.008001s\n",
      "batch 7294, train_loss 33.848068,Time used 0.006000s\n",
      "batch 7295, train_loss 36.402493,Time used 0.005000s\n",
      "batch 7296, train_loss 36.234295,Time used 0.004999s\n",
      "batch 7297, train_loss 29.277857,Time used 0.004996s\n",
      "batch 7298, train_loss 33.637062,Time used 0.007000s\n",
      "batch 7299, train_loss 32.143051,Time used 0.006038s\n",
      "batch 7300, train_loss 41.216167,Time used 0.005001s\n",
      "***************************test_batch 7300, test_rmse_loss 7.131924,test_mae_loss 3.184278,test_mape_loss 53.206952,Time used 0.022967s\n",
      "batch 7301, train_loss 38.420471,Time used 0.005999s\n",
      "batch 7302, train_loss 31.943647,Time used 0.004000s\n",
      "batch 7303, train_loss 33.879551,Time used 0.004998s\n",
      "batch 7304, train_loss 30.313398,Time used 0.004998s\n",
      "batch 7305, train_loss 36.501301,Time used 0.004000s\n",
      "batch 7306, train_loss 32.901279,Time used 0.007000s\n",
      "batch 7307, train_loss 33.250191,Time used 0.005037s\n",
      "batch 7308, train_loss 31.820805,Time used 0.005003s\n",
      "batch 7309, train_loss 31.801762,Time used 0.005965s\n",
      "batch 7310, train_loss 34.121880,Time used 0.007001s\n",
      "batch 7311, train_loss 28.480484,Time used 0.008000s\n",
      "batch 7312, train_loss 25.568020,Time used 0.005996s\n",
      "batch 7313, train_loss 34.911724,Time used 0.005001s\n",
      "batch 7314, train_loss 35.043613,Time used 0.008001s\n",
      "batch 7315, train_loss 26.924648,Time used 0.008002s\n",
      "batch 7316, train_loss 34.951138,Time used 0.005999s\n",
      "batch 7317, train_loss 34.697033,Time used 0.005000s\n",
      "batch 7318, train_loss 37.366600,Time used 0.005000s\n",
      "batch 7319, train_loss 34.931385,Time used 0.006998s\n",
      "batch 7320, train_loss 35.526836,Time used 0.008003s\n",
      "batch 7321, train_loss 38.790169,Time used 0.005998s\n",
      "batch 7322, train_loss 29.859896,Time used 0.005002s\n",
      "batch 7323, train_loss 27.706888,Time used 0.006001s\n",
      "batch 7324, train_loss 27.913782,Time used 0.004998s\n",
      "batch 7325, train_loss 32.990589,Time used 0.006001s\n",
      "batch 7326, train_loss 30.064684,Time used 0.005000s\n",
      "batch 7327, train_loss 35.078442,Time used 0.005000s\n",
      "batch 7328, train_loss 38.396832,Time used 0.008000s\n",
      "batch 7329, train_loss 32.871525,Time used 0.005000s\n",
      "batch 7330, train_loss 30.032555,Time used 0.005000s\n",
      "batch 7331, train_loss 30.584572,Time used 0.007002s\n",
      "batch 7332, train_loss 38.110615,Time used 0.007994s\n",
      "batch 7333, train_loss 34.982922,Time used 0.005002s\n",
      "batch 7334, train_loss 31.496500,Time used 0.005027s\n",
      "batch 7335, train_loss 29.230717,Time used 0.005970s\n",
      "batch 7336, train_loss 35.962273,Time used 0.004999s\n",
      "batch 7337, train_loss 37.362186,Time used 0.005035s\n",
      "batch 7338, train_loss 29.349453,Time used 0.005963s\n",
      "batch 7339, train_loss 37.828918,Time used 0.005034s\n",
      "batch 7340, train_loss 31.049358,Time used 0.005963s\n",
      "batch 7341, train_loss 39.911041,Time used 0.005005s\n",
      "batch 7342, train_loss 32.309769,Time used 0.008000s\n",
      "batch 7343, train_loss 30.112888,Time used 0.005996s\n",
      "batch 7344, train_loss 35.720451,Time used 0.006000s\n",
      "batch 7345, train_loss 29.635080,Time used 0.006004s\n",
      "batch 7346, train_loss 31.303942,Time used 0.005998s\n",
      "batch 7347, train_loss 32.268600,Time used 0.005999s\n",
      "batch 7348, train_loss 37.233730,Time used 0.005000s\n",
      "batch 7349, train_loss 35.249989,Time used 0.005001s\n",
      "batch 7350, train_loss 32.318062,Time used 0.005002s\n",
      "batch 7351, train_loss 29.559233,Time used 0.005000s\n",
      "batch 7352, train_loss 29.289455,Time used 0.005002s\n",
      "batch 7353, train_loss 36.667648,Time used 0.006996s\n",
      "batch 7354, train_loss 31.427525,Time used 0.005000s\n",
      "batch 7355, train_loss 35.214951,Time used 0.005001s\n",
      "batch 7356, train_loss 29.086824,Time used 0.005001s\n",
      "batch 7357, train_loss 38.614086,Time used 0.005000s\n",
      "batch 7358, train_loss 32.822132,Time used 0.004999s\n",
      "batch 7359, train_loss 33.304386,Time used 0.005001s\n",
      "batch 7360, train_loss 38.669285,Time used 0.006000s\n",
      "batch 7361, train_loss 32.144512,Time used 0.005001s\n",
      "batch 7362, train_loss 33.003792,Time used 0.004999s\n",
      "batch 7363, train_loss 33.006569,Time used 0.006000s\n",
      "batch 7364, train_loss 29.478991,Time used 0.005000s\n",
      "batch 7365, train_loss 35.066814,Time used 0.004998s\n",
      "batch 7366, train_loss 37.072208,Time used 0.006999s\n",
      "batch 7367, train_loss 27.777510,Time used 0.005002s\n",
      "batch 7368, train_loss 36.813648,Time used 0.004998s\n",
      "batch 7369, train_loss 34.262543,Time used 0.006001s\n",
      "batch 7370, train_loss 40.864597,Time used 0.006005s\n",
      "batch 7371, train_loss 32.960667,Time used 0.005000s\n",
      "batch 7372, train_loss 35.368893,Time used 0.004994s\n",
      "batch 7373, train_loss 26.772497,Time used 0.005000s\n",
      "batch 7374, train_loss 35.660179,Time used 0.007000s\n",
      "batch 7375, train_loss 31.872717,Time used 0.005003s\n",
      "batch 7376, train_loss 26.828472,Time used 0.004998s\n",
      "batch 7377, train_loss 30.497711,Time used 0.006038s\n",
      "batch 7378, train_loss 32.474163,Time used 0.005968s\n",
      "batch 7379, train_loss 41.324795,Time used 0.007030s\n",
      "batch 7380, train_loss 34.701462,Time used 0.005967s\n",
      "batch 7381, train_loss 35.797741,Time used 0.006000s\n",
      "batch 7382, train_loss 39.887367,Time used 0.005034s\n",
      "batch 7383, train_loss 27.118122,Time used 0.005999s\n",
      "batch 7384, train_loss 30.590084,Time used 0.005000s\n",
      "batch 7385, train_loss 34.164490,Time used 0.006004s\n",
      "batch 7386, train_loss 31.226105,Time used 0.005996s\n",
      "batch 7387, train_loss 38.043091,Time used 0.006001s\n",
      "batch 7388, train_loss 36.773659,Time used 0.004963s\n",
      "batch 7389, train_loss 26.592825,Time used 0.005000s\n",
      "batch 7390, train_loss 30.982615,Time used 0.004999s\n",
      "batch 7391, train_loss 30.467426,Time used 0.006001s\n",
      "batch 7392, train_loss 30.114496,Time used 0.004999s\n",
      "batch 7393, train_loss 30.406874,Time used 0.004998s\n",
      "batch 7394, train_loss 28.716173,Time used 0.005000s\n",
      "batch 7395, train_loss 31.433119,Time used 0.006001s\n",
      "batch 7396, train_loss 39.274193,Time used 0.008036s\n",
      "batch 7397, train_loss 34.524445,Time used 0.007998s\n",
      "batch 7398, train_loss 31.437313,Time used 0.004967s\n",
      "batch 7399, train_loss 28.891272,Time used 0.005034s\n",
      "batch 7400, train_loss 32.600315,Time used 0.005963s\n",
      "***************************test_batch 7400, test_rmse_loss 7.117907,test_mae_loss 3.180186,test_mape_loss 53.045198,Time used 0.017002s\n",
      "batch 7401, train_loss 34.004845,Time used 0.006002s\n",
      "batch 7402, train_loss 29.531799,Time used 0.006033s\n",
      "batch 7403, train_loss 32.757618,Time used 0.008035s\n",
      "batch 7404, train_loss 29.513041,Time used 0.006963s\n",
      "batch 7405, train_loss 33.230522,Time used 0.004999s\n",
      "batch 7406, train_loss 35.576443,Time used 0.005000s\n",
      "batch 7407, train_loss 34.758045,Time used 0.006000s\n",
      "batch 7408, train_loss 36.076618,Time used 0.007039s\n",
      "batch 7409, train_loss 32.866768,Time used 0.007965s\n",
      "batch 7410, train_loss 39.593304,Time used 0.008998s\n",
      "batch 7411, train_loss 30.389732,Time used 0.008997s\n",
      "batch 7412, train_loss 34.357922,Time used 0.008000s\n",
      "batch 7413, train_loss 31.588633,Time used 0.006004s\n",
      "batch 7414, train_loss 34.181705,Time used 0.008042s\n",
      "batch 7415, train_loss 37.266312,Time used 0.007959s\n",
      "batch 7416, train_loss 31.502108,Time used 0.008997s\n",
      "batch 7417, train_loss 32.073135,Time used 0.006003s\n",
      "batch 7418, train_loss 31.133816,Time used 0.004962s\n",
      "batch 7419, train_loss 32.453056,Time used 0.005001s\n",
      "batch 7420, train_loss 30.645132,Time used 0.006000s\n",
      "batch 7421, train_loss 34.355206,Time used 0.005035s\n",
      "batch 7422, train_loss 32.234436,Time used 0.005002s\n",
      "batch 7423, train_loss 38.443882,Time used 0.004997s\n",
      "batch 7424, train_loss 36.194969,Time used 0.006964s\n",
      "batch 7425, train_loss 31.208349,Time used 0.005002s\n",
      "batch 7426, train_loss 40.179310,Time used 0.006999s\n",
      "batch 7427, train_loss 31.225824,Time used 0.004998s\n",
      "batch 7428, train_loss 38.301342,Time used 0.006001s\n",
      "batch 7429, train_loss 30.128735,Time used 0.006999s\n",
      "batch 7430, train_loss 27.989719,Time used 0.008001s\n",
      "batch 7431, train_loss 29.548481,Time used 0.009001s\n",
      "batch 7432, train_loss 31.208342,Time used 0.007998s\n",
      "batch 7433, train_loss 30.210642,Time used 0.006037s\n",
      "batch 7434, train_loss 38.492222,Time used 0.004999s\n",
      "batch 7435, train_loss 34.806454,Time used 0.004968s\n",
      "batch 7436, train_loss 37.075649,Time used 0.005999s\n",
      "batch 7437, train_loss 33.536190,Time used 0.005000s\n",
      "batch 7438, train_loss 33.242561,Time used 0.005002s\n",
      "batch 7439, train_loss 29.263218,Time used 0.005000s\n",
      "batch 7440, train_loss 29.213415,Time used 0.005033s\n",
      "batch 7441, train_loss 31.870888,Time used 0.005988s\n",
      "batch 7442, train_loss 30.911285,Time used 0.004995s\n",
      "batch 7443, train_loss 40.690048,Time used 0.006001s\n",
      "batch 7444, train_loss 36.511074,Time used 0.004967s\n",
      "batch 7445, train_loss 27.585276,Time used 0.006000s\n",
      "batch 7446, train_loss 40.752033,Time used 0.005032s\n",
      "batch 7447, train_loss 37.279564,Time used 0.004969s\n",
      "batch 7448, train_loss 31.766777,Time used 0.004998s\n",
      "batch 7449, train_loss 29.963427,Time used 0.005000s\n",
      "batch 7450, train_loss 26.760975,Time used 0.007998s\n",
      "batch 7451, train_loss 37.892277,Time used 0.008001s\n",
      "batch 7452, train_loss 31.529453,Time used 0.006035s\n",
      "batch 7453, train_loss 26.444458,Time used 0.005000s\n",
      "batch 7454, train_loss 37.865341,Time used 0.004997s\n",
      "batch 7455, train_loss 31.989439,Time used 0.006964s\n",
      "batch 7456, train_loss 29.795479,Time used 0.006000s\n",
      "batch 7457, train_loss 32.596691,Time used 0.007000s\n",
      "batch 7458, train_loss 35.900829,Time used 0.008000s\n",
      "batch 7459, train_loss 30.658648,Time used 0.008005s\n",
      "batch 7460, train_loss 25.945658,Time used 0.008000s\n",
      "batch 7461, train_loss 32.033974,Time used 0.006001s\n",
      "batch 7462, train_loss 40.974316,Time used 0.005001s\n",
      "batch 7463, train_loss 34.102070,Time used 0.005998s\n",
      "batch 7464, train_loss 29.874723,Time used 0.004997s\n",
      "batch 7465, train_loss 41.078354,Time used 0.007003s\n",
      "batch 7466, train_loss 32.421444,Time used 0.008994s\n",
      "batch 7467, train_loss 35.921993,Time used 0.005003s\n",
      "batch 7468, train_loss 33.959072,Time used 0.004997s\n",
      "batch 7469, train_loss 40.461967,Time used 0.005001s\n",
      "batch 7470, train_loss 30.943363,Time used 0.004999s\n",
      "batch 7471, train_loss 33.113674,Time used 0.005000s\n",
      "batch 7472, train_loss 30.891619,Time used 0.005001s\n",
      "batch 7473, train_loss 31.122362,Time used 0.006000s\n",
      "batch 7474, train_loss 25.237417,Time used 0.005000s\n",
      "batch 7475, train_loss 32.489582,Time used 0.005000s\n",
      "batch 7476, train_loss 32.206398,Time used 0.006998s\n",
      "batch 7477, train_loss 36.411175,Time used 0.008003s\n",
      "batch 7478, train_loss 31.459644,Time used 0.007000s\n",
      "batch 7479, train_loss 27.416697,Time used 0.005998s\n",
      "batch 7480, train_loss 29.522188,Time used 0.005001s\n",
      "batch 7481, train_loss 30.583982,Time used 0.004998s\n",
      "batch 7482, train_loss 30.704643,Time used 0.004999s\n",
      "batch 7483, train_loss 36.913372,Time used 0.006001s\n",
      "batch 7484, train_loss 31.617916,Time used 0.006001s\n",
      "batch 7485, train_loss 32.005955,Time used 0.004998s\n",
      "batch 7486, train_loss 35.416775,Time used 0.006002s\n",
      "batch 7487, train_loss 39.788754,Time used 0.007997s\n",
      "batch 7488, train_loss 28.393930,Time used 0.007003s\n",
      "batch 7489, train_loss 28.993299,Time used 0.006998s\n",
      "batch 7490, train_loss 29.744720,Time used 0.006000s\n",
      "batch 7491, train_loss 34.808689,Time used 0.007001s\n",
      "batch 7492, train_loss 36.291058,Time used 0.009002s\n",
      "batch 7493, train_loss 30.653280,Time used 0.006999s\n",
      "batch 7494, train_loss 33.511787,Time used 0.005001s\n",
      "batch 7495, train_loss 31.052488,Time used 0.005997s\n",
      "batch 7496, train_loss 30.738480,Time used 0.005001s\n",
      "batch 7497, train_loss 31.184145,Time used 0.004999s\n",
      "batch 7498, train_loss 32.675301,Time used 0.005001s\n",
      "batch 7499, train_loss 30.218830,Time used 0.005003s\n",
      "batch 7500, train_loss 36.259220,Time used 0.006001s\n",
      "***************************test_batch 7500, test_rmse_loss 7.104570,test_mae_loss 3.173831,test_mape_loss 52.914801,Time used 0.018001s\n",
      "batch 7501, train_loss 30.365807,Time used 0.005000s\n",
      "batch 7502, train_loss 38.571445,Time used 0.006031s\n",
      "batch 7503, train_loss 43.385284,Time used 0.005002s\n",
      "batch 7504, train_loss 31.364603,Time used 0.005998s\n",
      "batch 7505, train_loss 30.691343,Time used 0.006000s\n",
      "batch 7506, train_loss 34.662693,Time used 0.004965s\n",
      "batch 7507, train_loss 31.330885,Time used 0.005998s\n",
      "batch 7508, train_loss 29.893272,Time used 0.004999s\n",
      "batch 7509, train_loss 27.310463,Time used 0.005000s\n",
      "batch 7510, train_loss 39.940979,Time used 0.005004s\n",
      "batch 7511, train_loss 32.729099,Time used 0.005996s\n",
      "batch 7512, train_loss 33.318710,Time used 0.005002s\n",
      "batch 7513, train_loss 33.871506,Time used 0.005967s\n",
      "batch 7514, train_loss 30.575294,Time used 0.005994s\n",
      "batch 7515, train_loss 35.181152,Time used 0.007001s\n",
      "batch 7516, train_loss 35.681690,Time used 0.006001s\n",
      "batch 7517, train_loss 28.628166,Time used 0.005001s\n",
      "batch 7518, train_loss 33.647430,Time used 0.005000s\n",
      "batch 7519, train_loss 32.542419,Time used 0.005999s\n",
      "batch 7520, train_loss 29.038206,Time used 0.005000s\n",
      "batch 7521, train_loss 36.805481,Time used 0.005001s\n",
      "batch 7522, train_loss 32.057419,Time used 0.006000s\n",
      "batch 7523, train_loss 31.986006,Time used 0.005000s\n",
      "batch 7524, train_loss 32.895264,Time used 0.005000s\n",
      "batch 7525, train_loss 27.439152,Time used 0.005002s\n",
      "batch 7526, train_loss 30.194126,Time used 0.006000s\n",
      "batch 7527, train_loss 31.696054,Time used 0.005000s\n",
      "batch 7528, train_loss 37.604679,Time used 0.004999s\n",
      "batch 7529, train_loss 34.017601,Time used 0.006002s\n",
      "batch 7530, train_loss 34.939007,Time used 0.004998s\n",
      "batch 7531, train_loss 39.705673,Time used 0.006001s\n",
      "batch 7532, train_loss 41.217541,Time used 0.007000s\n",
      "batch 7533, train_loss 33.616684,Time used 0.007002s\n",
      "batch 7534, train_loss 29.403042,Time used 0.005998s\n",
      "batch 7535, train_loss 25.474403,Time used 0.005000s\n",
      "batch 7536, train_loss 30.816395,Time used 0.006002s\n",
      "batch 7537, train_loss 29.903502,Time used 0.004998s\n",
      "batch 7538, train_loss 28.432659,Time used 0.005003s\n",
      "batch 7539, train_loss 31.896742,Time used 0.004996s\n",
      "batch 7540, train_loss 33.593899,Time used 0.005000s\n",
      "batch 7541, train_loss 35.325928,Time used 0.007003s\n",
      "batch 7542, train_loss 34.868984,Time used 0.007997s\n",
      "batch 7543, train_loss 38.299488,Time used 0.006001s\n",
      "batch 7544, train_loss 33.732208,Time used 0.005003s\n",
      "batch 7545, train_loss 36.962128,Time used 0.004000s\n",
      "batch 7546, train_loss 27.821991,Time used 0.005001s\n",
      "batch 7547, train_loss 38.918255,Time used 0.004999s\n",
      "batch 7548, train_loss 26.244743,Time used 0.005002s\n",
      "batch 7549, train_loss 29.865305,Time used 0.005999s\n",
      "batch 7550, train_loss 38.332039,Time used 0.005002s\n",
      "batch 7551, train_loss 34.796467,Time used 0.008999s\n",
      "batch 7552, train_loss 26.138832,Time used 0.006000s\n",
      "batch 7553, train_loss 25.771301,Time used 0.004998s\n",
      "batch 7554, train_loss 40.749466,Time used 0.005999s\n",
      "batch 7555, train_loss 33.969101,Time used 0.005001s\n",
      "batch 7556, train_loss 30.230049,Time used 0.005000s\n",
      "batch 7557, train_loss 31.901001,Time used 0.006001s\n",
      "batch 7558, train_loss 35.547630,Time used 0.005003s\n",
      "batch 7559, train_loss 34.252884,Time used 0.004997s\n",
      "batch 7560, train_loss 29.701822,Time used 0.003999s\n",
      "batch 7561, train_loss 40.545334,Time used 0.006003s\n",
      "batch 7562, train_loss 33.617832,Time used 0.004999s\n",
      "batch 7563, train_loss 30.370058,Time used 0.006000s\n",
      "batch 7564, train_loss 35.895046,Time used 0.006998s\n",
      "batch 7565, train_loss 29.535072,Time used 0.008003s\n",
      "batch 7566, train_loss 31.462336,Time used 0.005994s\n",
      "batch 7567, train_loss 30.275249,Time used 0.006000s\n",
      "batch 7568, train_loss 27.301743,Time used 0.006002s\n",
      "batch 7569, train_loss 35.063736,Time used 0.005035s\n",
      "batch 7570, train_loss 37.077847,Time used 0.005000s\n",
      "batch 7571, train_loss 33.927193,Time used 0.006002s\n",
      "batch 7572, train_loss 28.796560,Time used 0.004961s\n",
      "batch 7573, train_loss 35.935764,Time used 0.004999s\n",
      "batch 7574, train_loss 35.782448,Time used 0.005000s\n",
      "batch 7575, train_loss 28.949379,Time used 0.008000s\n",
      "batch 7576, train_loss 30.778461,Time used 0.005001s\n",
      "batch 7577, train_loss 30.411926,Time used 0.006000s\n",
      "batch 7578, train_loss 33.072559,Time used 0.005001s\n",
      "batch 7579, train_loss 30.972450,Time used 0.005999s\n",
      "batch 7580, train_loss 39.121746,Time used 0.006001s\n",
      "batch 7581, train_loss 27.248180,Time used 0.006999s\n",
      "batch 7582, train_loss 30.002718,Time used 0.007001s\n",
      "batch 7583, train_loss 35.098724,Time used 0.009001s\n",
      "batch 7584, train_loss 35.153687,Time used 0.007000s\n",
      "batch 7585, train_loss 39.330791,Time used 0.006002s\n",
      "batch 7586, train_loss 34.785332,Time used 0.005000s\n",
      "batch 7587, train_loss 28.898930,Time used 0.004000s\n",
      "batch 7588, train_loss 34.063454,Time used 0.005999s\n",
      "batch 7589, train_loss 35.890625,Time used 0.004999s\n",
      "batch 7590, train_loss 41.080647,Time used 0.004998s\n",
      "batch 7591, train_loss 32.452656,Time used 0.004997s\n",
      "batch 7592, train_loss 32.765682,Time used 0.005001s\n",
      "batch 7593, train_loss 30.209394,Time used 0.005999s\n",
      "batch 7594, train_loss 30.145292,Time used 0.005001s\n",
      "batch 7595, train_loss 33.553856,Time used 0.005998s\n",
      "batch 7596, train_loss 30.342270,Time used 0.006001s\n",
      "batch 7597, train_loss 32.492226,Time used 0.004999s\n",
      "batch 7598, train_loss 32.279060,Time used 0.005001s\n",
      "batch 7599, train_loss 34.981297,Time used 0.005999s\n",
      "batch 7600, train_loss 22.964334,Time used 0.004999s\n",
      "***************************test_batch 7600, test_rmse_loss 7.082819,test_mae_loss 3.168047,test_mape_loss 52.897033,Time used 0.018002s\n",
      "batch 7601, train_loss 34.859486,Time used 0.006032s\n",
      "batch 7602, train_loss 34.678043,Time used 0.006004s\n",
      "batch 7603, train_loss 28.393795,Time used 0.005009s\n",
      "batch 7604, train_loss 33.738728,Time used 0.005959s\n",
      "batch 7605, train_loss 33.881191,Time used 0.004997s\n",
      "batch 7606, train_loss 27.911249,Time used 0.006006s\n",
      "batch 7607, train_loss 29.294035,Time used 0.005998s\n",
      "batch 7608, train_loss 35.853092,Time used 0.004999s\n",
      "batch 7609, train_loss 27.613140,Time used 0.004984s\n",
      "batch 7610, train_loss 27.422308,Time used 0.005967s\n",
      "batch 7611, train_loss 34.791039,Time used 0.005001s\n",
      "batch 7612, train_loss 29.812359,Time used 0.008029s\n",
      "batch 7613, train_loss 34.084171,Time used 0.006970s\n",
      "batch 7614, train_loss 31.696787,Time used 0.005033s\n",
      "batch 7615, train_loss 37.424023,Time used 0.005005s\n",
      "batch 7616, train_loss 29.597321,Time used 0.005995s\n",
      "batch 7617, train_loss 32.055698,Time used 0.005000s\n",
      "batch 7618, train_loss 35.516781,Time used 0.005002s\n",
      "batch 7619, train_loss 31.603359,Time used 0.005000s\n",
      "batch 7620, train_loss 33.027546,Time used 0.004999s\n",
      "batch 7621, train_loss 36.976501,Time used 0.004999s\n",
      "batch 7622, train_loss 36.102062,Time used 0.005966s\n",
      "batch 7623, train_loss 33.597744,Time used 0.006999s\n",
      "batch 7624, train_loss 30.204897,Time used 0.006001s\n",
      "batch 7625, train_loss 34.599243,Time used 0.005030s\n",
      "batch 7626, train_loss 36.523357,Time used 0.005000s\n",
      "batch 7627, train_loss 35.923351,Time used 0.005002s\n",
      "batch 7628, train_loss 31.722389,Time used 0.007998s\n",
      "batch 7629, train_loss 35.390957,Time used 0.008002s\n",
      "batch 7630, train_loss 31.328392,Time used 0.005967s\n",
      "batch 7631, train_loss 30.135952,Time used 0.005998s\n",
      "batch 7632, train_loss 26.538382,Time used 0.006964s\n",
      "batch 7633, train_loss 35.474674,Time used 0.006000s\n",
      "batch 7634, train_loss 31.612898,Time used 0.005003s\n",
      "batch 7635, train_loss 36.012875,Time used 0.005001s\n",
      "batch 7636, train_loss 33.376938,Time used 0.005994s\n",
      "batch 7637, train_loss 32.237488,Time used 0.005001s\n",
      "batch 7638, train_loss 29.311447,Time used 0.007000s\n",
      "batch 7639, train_loss 29.979803,Time used 0.006002s\n",
      "batch 7640, train_loss 29.110838,Time used 0.005998s\n",
      "batch 7641, train_loss 31.277046,Time used 0.006005s\n",
      "batch 7642, train_loss 35.400436,Time used 0.007998s\n",
      "batch 7643, train_loss 33.316647,Time used 0.006034s\n",
      "batch 7644, train_loss 28.471172,Time used 0.005000s\n",
      "batch 7645, train_loss 33.084385,Time used 0.005999s\n",
      "batch 7646, train_loss 39.156662,Time used 0.004970s\n",
      "batch 7647, train_loss 33.844742,Time used 0.005999s\n",
      "batch 7648, train_loss 32.372524,Time used 0.005998s\n",
      "batch 7649, train_loss 36.262321,Time used 0.004998s\n",
      "batch 7650, train_loss 30.426498,Time used 0.005000s\n",
      "batch 7651, train_loss 32.406265,Time used 0.006000s\n",
      "batch 7652, train_loss 28.872549,Time used 0.005000s\n",
      "batch 7653, train_loss 35.791107,Time used 0.006001s\n",
      "batch 7654, train_loss 31.727022,Time used 0.006036s\n",
      "batch 7655, train_loss 31.303425,Time used 0.005000s\n",
      "batch 7656, train_loss 31.905880,Time used 0.004968s\n",
      "batch 7657, train_loss 34.636932,Time used 0.008000s\n",
      "batch 7658, train_loss 37.226761,Time used 0.006002s\n",
      "batch 7659, train_loss 30.337729,Time used 0.007034s\n",
      "batch 7660, train_loss 33.154510,Time used 0.006964s\n",
      "batch 7661, train_loss 31.430944,Time used 0.007998s\n",
      "batch 7662, train_loss 31.583916,Time used 0.009002s\n",
      "batch 7663, train_loss 37.124729,Time used 0.006003s\n",
      "batch 7664, train_loss 26.763048,Time used 0.008002s\n",
      "batch 7665, train_loss 28.451948,Time used 0.007997s\n",
      "batch 7666, train_loss 32.420883,Time used 0.006001s\n",
      "batch 7667, train_loss 34.917747,Time used 0.008033s\n",
      "batch 7668, train_loss 33.963451,Time used 0.005000s\n",
      "batch 7669, train_loss 34.478203,Time used 0.004968s\n",
      "batch 7670, train_loss 34.325306,Time used 0.005033s\n",
      "batch 7671, train_loss 32.391178,Time used 0.005968s\n",
      "batch 7672, train_loss 29.679552,Time used 0.005035s\n",
      "batch 7673, train_loss 26.517324,Time used 0.007995s\n",
      "batch 7674, train_loss 28.822977,Time used 0.005000s\n",
      "batch 7675, train_loss 31.494474,Time used 0.006001s\n",
      "batch 7676, train_loss 37.878769,Time used 0.005000s\n",
      "batch 7677, train_loss 33.844997,Time used 0.005000s\n",
      "batch 7678, train_loss 37.227444,Time used 0.005002s\n",
      "batch 7679, train_loss 26.826990,Time used 0.006964s\n",
      "batch 7680, train_loss 35.795322,Time used 0.007042s\n",
      "batch 7681, train_loss 28.247555,Time used 0.005032s\n",
      "batch 7682, train_loss 32.135780,Time used 0.005004s\n",
      "batch 7683, train_loss 36.463535,Time used 0.004998s\n",
      "batch 7684, train_loss 34.867767,Time used 0.004999s\n",
      "batch 7685, train_loss 32.796391,Time used 0.005000s\n",
      "batch 7686, train_loss 27.535343,Time used 0.005001s\n",
      "batch 7687, train_loss 32.226704,Time used 0.004999s\n",
      "batch 7688, train_loss 31.912302,Time used 0.005002s\n",
      "batch 7689, train_loss 28.682394,Time used 0.005000s\n",
      "batch 7690, train_loss 37.419075,Time used 0.004999s\n",
      "batch 7691, train_loss 29.869160,Time used 0.004963s\n",
      "batch 7692, train_loss 36.696468,Time used 0.006038s\n",
      "batch 7693, train_loss 28.227892,Time used 0.008000s\n",
      "batch 7694, train_loss 33.874382,Time used 0.007966s\n",
      "batch 7695, train_loss 30.647453,Time used 0.007003s\n",
      "batch 7696, train_loss 36.493401,Time used 0.004999s\n",
      "batch 7697, train_loss 30.103872,Time used 0.007998s\n",
      "batch 7698, train_loss 35.716221,Time used 0.006000s\n",
      "batch 7699, train_loss 30.830622,Time used 0.004999s\n",
      "batch 7700, train_loss 33.352249,Time used 0.006003s\n",
      "***************************test_batch 7700, test_rmse_loss 7.027675,test_mae_loss 3.150359,test_mape_loss 53.199908,Time used 0.019032s\n",
      "batch 7701, train_loss 34.471340,Time used 0.005000s\n",
      "batch 7702, train_loss 32.117371,Time used 0.005964s\n",
      "batch 7703, train_loss 36.651245,Time used 0.004999s\n",
      "batch 7704, train_loss 29.188881,Time used 0.004000s\n",
      "batch 7705, train_loss 37.267982,Time used 0.005999s\n",
      "batch 7706, train_loss 28.607038,Time used 0.005001s\n",
      "batch 7707, train_loss 28.572081,Time used 0.004999s\n",
      "batch 7708, train_loss 30.628738,Time used 0.008002s\n",
      "batch 7709, train_loss 37.447639,Time used 0.006001s\n",
      "batch 7710, train_loss 33.641121,Time used 0.006001s\n",
      "batch 7711, train_loss 32.922104,Time used 0.005002s\n",
      "batch 7712, train_loss 33.557743,Time used 0.004966s\n",
      "batch 7713, train_loss 28.385540,Time used 0.007031s\n",
      "batch 7714, train_loss 24.919044,Time used 0.007000s\n",
      "batch 7715, train_loss 33.089615,Time used 0.005967s\n",
      "batch 7716, train_loss 28.386356,Time used 0.005000s\n",
      "batch 7717, train_loss 36.785675,Time used 0.005000s\n",
      "batch 7718, train_loss 26.652826,Time used 0.005001s\n",
      "batch 7719, train_loss 37.350220,Time used 0.004999s\n",
      "batch 7720, train_loss 29.945902,Time used 0.012997s\n",
      "batch 7721, train_loss 34.657043,Time used 0.008000s\n",
      "batch 7722, train_loss 34.091972,Time used 0.007008s\n",
      "batch 7723, train_loss 33.341599,Time used 0.004993s\n",
      "batch 7724, train_loss 39.664631,Time used 0.005038s\n",
      "batch 7725, train_loss 30.560152,Time used 0.005964s\n",
      "batch 7726, train_loss 30.168377,Time used 0.005036s\n",
      "batch 7727, train_loss 32.054577,Time used 0.005968s\n",
      "batch 7728, train_loss 36.239555,Time used 0.007035s\n",
      "batch 7729, train_loss 30.887051,Time used 0.005967s\n",
      "batch 7730, train_loss 36.102425,Time used 0.004996s\n",
      "batch 7731, train_loss 33.489594,Time used 0.005002s\n",
      "batch 7732, train_loss 37.576923,Time used 0.006039s\n",
      "batch 7733, train_loss 34.082794,Time used 0.005000s\n",
      "batch 7734, train_loss 37.252110,Time used 0.005958s\n",
      "batch 7735, train_loss 32.784237,Time used 0.006000s\n",
      "batch 7736, train_loss 28.433214,Time used 0.005001s\n",
      "batch 7737, train_loss 35.326294,Time used 0.005999s\n",
      "batch 7738, train_loss 30.254902,Time used 0.005000s\n",
      "batch 7739, train_loss 38.261093,Time used 0.005000s\n",
      "batch 7740, train_loss 36.146351,Time used 0.005036s\n",
      "batch 7741, train_loss 30.249571,Time used 0.005967s\n",
      "batch 7742, train_loss 31.457418,Time used 0.004999s\n",
      "batch 7743, train_loss 29.052811,Time used 0.007034s\n",
      "batch 7744, train_loss 29.514137,Time used 0.007963s\n",
      "batch 7745, train_loss 25.349390,Time used 0.006999s\n",
      "batch 7746, train_loss 32.556534,Time used 0.007001s\n",
      "batch 7747, train_loss 32.519306,Time used 0.007037s\n",
      "batch 7748, train_loss 30.942011,Time used 0.007034s\n",
      "batch 7749, train_loss 28.086515,Time used 0.007962s\n",
      "batch 7750, train_loss 36.055412,Time used 0.006001s\n",
      "batch 7751, train_loss 28.850283,Time used 0.007005s\n",
      "batch 7752, train_loss 32.192944,Time used 0.005998s\n",
      "batch 7753, train_loss 34.604778,Time used 0.004993s\n",
      "batch 7754, train_loss 33.815765,Time used 0.004999s\n",
      "batch 7755, train_loss 34.252197,Time used 0.005996s\n",
      "batch 7756, train_loss 28.146488,Time used 0.004999s\n",
      "batch 7757, train_loss 32.491272,Time used 0.006002s\n",
      "batch 7758, train_loss 34.285957,Time used 0.005033s\n",
      "batch 7759, train_loss 33.483822,Time used 0.005002s\n",
      "batch 7760, train_loss 31.612881,Time used 0.005964s\n",
      "batch 7761, train_loss 26.127865,Time used 0.008036s\n",
      "batch 7762, train_loss 37.105389,Time used 0.007968s\n",
      "batch 7763, train_loss 30.838123,Time used 0.007035s\n",
      "batch 7764, train_loss 34.142204,Time used 0.005008s\n",
      "batch 7765, train_loss 29.363974,Time used 0.008954s\n",
      "batch 7766, train_loss 26.090944,Time used 0.005001s\n",
      "batch 7767, train_loss 36.122017,Time used 0.005038s\n",
      "batch 7768, train_loss 30.326399,Time used 0.005000s\n",
      "batch 7769, train_loss 30.764666,Time used 0.005002s\n",
      "batch 7770, train_loss 35.689167,Time used 0.004963s\n",
      "batch 7771, train_loss 30.092278,Time used 0.005998s\n",
      "batch 7772, train_loss 31.371855,Time used 0.005000s\n",
      "batch 7773, train_loss 33.167507,Time used 0.007001s\n",
      "batch 7774, train_loss 36.451992,Time used 0.008999s\n",
      "batch 7775, train_loss 34.930611,Time used 0.008001s\n",
      "batch 7776, train_loss 31.115206,Time used 0.005998s\n",
      "batch 7777, train_loss 30.096788,Time used 0.008000s\n",
      "batch 7778, train_loss 34.829342,Time used 0.006000s\n",
      "batch 7779, train_loss 33.605442,Time used 0.005002s\n",
      "batch 7780, train_loss 30.363127,Time used 0.005000s\n",
      "batch 7781, train_loss 30.750963,Time used 0.006998s\n",
      "batch 7782, train_loss 30.627989,Time used 0.004998s\n",
      "batch 7783, train_loss 27.729652,Time used 0.007002s\n",
      "batch 7784, train_loss 31.533178,Time used 0.008001s\n",
      "batch 7785, train_loss 32.884846,Time used 0.008036s\n",
      "batch 7786, train_loss 30.499208,Time used 0.004962s\n",
      "batch 7787, train_loss 35.068943,Time used 0.006002s\n",
      "batch 7788, train_loss 28.601368,Time used 0.007999s\n",
      "batch 7789, train_loss 30.893671,Time used 0.005003s\n",
      "batch 7790, train_loss 29.214407,Time used 0.005997s\n",
      "batch 7791, train_loss 27.654074,Time used 0.004999s\n",
      "batch 7792, train_loss 39.650330,Time used 0.005004s\n",
      "batch 7793, train_loss 31.440310,Time used 0.007000s\n",
      "batch 7794, train_loss 32.571358,Time used 0.006003s\n",
      "batch 7795, train_loss 33.828762,Time used 0.006997s\n",
      "batch 7796, train_loss 42.534233,Time used 0.005000s\n",
      "batch 7797, train_loss 32.443665,Time used 0.005000s\n",
      "batch 7798, train_loss 31.265005,Time used 0.006001s\n",
      "batch 7799, train_loss 36.591084,Time used 0.004997s\n",
      "batch 7800, train_loss 31.526936,Time used 0.005000s\n",
      "***************************test_batch 7800, test_rmse_loss 7.062094,test_mae_loss 3.159117,test_mape_loss 52.866474,Time used 0.018001s\n",
      "batch 7801, train_loss 41.356930,Time used 0.006003s\n",
      "batch 7802, train_loss 26.928453,Time used 0.005031s\n",
      "batch 7803, train_loss 32.991699,Time used 0.007001s\n",
      "batch 7804, train_loss 31.215269,Time used 0.005001s\n",
      "batch 7805, train_loss 31.192486,Time used 0.006002s\n",
      "batch 7806, train_loss 34.155342,Time used 0.006034s\n",
      "batch 7807, train_loss 32.475483,Time used 0.007968s\n",
      "batch 7808, train_loss 37.374424,Time used 0.008032s\n",
      "batch 7809, train_loss 27.353914,Time used 0.005003s\n",
      "batch 7810, train_loss 31.393063,Time used 0.005998s\n",
      "batch 7811, train_loss 40.654396,Time used 0.004999s\n",
      "batch 7812, train_loss 34.828609,Time used 0.005004s\n",
      "batch 7813, train_loss 31.853132,Time used 0.005997s\n",
      "batch 7814, train_loss 34.632053,Time used 0.005000s\n",
      "batch 7815, train_loss 35.456520,Time used 0.005002s\n",
      "batch 7816, train_loss 24.577673,Time used 0.005965s\n",
      "batch 7817, train_loss 30.357687,Time used 0.005000s\n",
      "batch 7818, train_loss 31.123621,Time used 0.005000s\n",
      "batch 7819, train_loss 29.589190,Time used 0.006001s\n",
      "batch 7820, train_loss 32.308849,Time used 0.004999s\n",
      "batch 7821, train_loss 29.848251,Time used 0.006998s\n",
      "batch 7822, train_loss 30.441143,Time used 0.005000s\n",
      "batch 7823, train_loss 35.514008,Time used 0.006000s\n",
      "batch 7824, train_loss 26.941074,Time used 0.005999s\n",
      "batch 7825, train_loss 29.565315,Time used 0.004999s\n",
      "batch 7826, train_loss 31.896502,Time used 0.006001s\n",
      "batch 7827, train_loss 25.709387,Time used 0.006998s\n",
      "batch 7828, train_loss 31.342182,Time used 0.006002s\n",
      "batch 7829, train_loss 31.264240,Time used 0.005998s\n",
      "batch 7830, train_loss 26.879824,Time used 0.005000s\n",
      "batch 7831, train_loss 34.735832,Time used 0.008001s\n",
      "batch 7832, train_loss 29.595716,Time used 0.006998s\n",
      "batch 7833, train_loss 34.545403,Time used 0.006999s\n",
      "batch 7834, train_loss 31.756487,Time used 0.008001s\n",
      "batch 7835, train_loss 32.755913,Time used 0.006036s\n",
      "batch 7836, train_loss 30.862696,Time used 0.006964s\n",
      "batch 7837, train_loss 35.243061,Time used 0.006033s\n",
      "batch 7838, train_loss 37.926624,Time used 0.004009s\n",
      "batch 7839, train_loss 35.034424,Time used 0.004963s\n",
      "batch 7840, train_loss 37.590866,Time used 0.008038s\n",
      "batch 7841, train_loss 29.259087,Time used 0.007997s\n",
      "batch 7842, train_loss 31.106028,Time used 0.006025s\n",
      "batch 7843, train_loss 32.316612,Time used 0.004978s\n",
      "batch 7844, train_loss 37.845150,Time used 0.006032s\n",
      "batch 7845, train_loss 30.775236,Time used 0.005000s\n",
      "batch 7846, train_loss 29.463278,Time used 0.005002s\n",
      "batch 7847, train_loss 34.030361,Time used 0.005003s\n",
      "batch 7848, train_loss 31.720957,Time used 0.005961s\n",
      "batch 7849, train_loss 32.461548,Time used 0.005031s\n",
      "batch 7850, train_loss 31.715099,Time used 0.004968s\n",
      "batch 7851, train_loss 34.121609,Time used 0.003996s\n",
      "batch 7852, train_loss 36.419090,Time used 0.007967s\n",
      "batch 7853, train_loss 31.014099,Time used 0.005000s\n",
      "batch 7854, train_loss 37.445629,Time used 0.004999s\n",
      "batch 7855, train_loss 30.557610,Time used 0.004999s\n",
      "batch 7856, train_loss 35.741425,Time used 0.005000s\n",
      "batch 7857, train_loss 27.975901,Time used 0.005001s\n",
      "batch 7858, train_loss 31.534430,Time used 0.005000s\n",
      "batch 7859, train_loss 30.394466,Time used 0.005001s\n",
      "batch 7860, train_loss 27.872644,Time used 0.006001s\n",
      "batch 7861, train_loss 26.063272,Time used 0.006004s\n",
      "batch 7862, train_loss 36.384689,Time used 0.005031s\n",
      "batch 7863, train_loss 34.570480,Time used 0.005969s\n",
      "batch 7864, train_loss 26.662487,Time used 0.005033s\n",
      "batch 7865, train_loss 29.058950,Time used 0.004998s\n",
      "batch 7866, train_loss 32.243061,Time used 0.004969s\n",
      "batch 7867, train_loss 34.645199,Time used 0.004995s\n",
      "batch 7868, train_loss 30.883512,Time used 0.005000s\n",
      "batch 7869, train_loss 33.206554,Time used 0.007001s\n",
      "batch 7870, train_loss 37.847488,Time used 0.005002s\n",
      "batch 7871, train_loss 32.870457,Time used 0.005998s\n",
      "batch 7872, train_loss 30.334114,Time used 0.007966s\n",
      "batch 7873, train_loss 27.990364,Time used 0.004999s\n",
      "batch 7874, train_loss 30.863207,Time used 0.005000s\n",
      "batch 7875, train_loss 32.133305,Time used 0.005002s\n",
      "batch 7876, train_loss 30.111803,Time used 0.005999s\n",
      "batch 7877, train_loss 31.353174,Time used 0.008003s\n",
      "batch 7878, train_loss 32.667980,Time used 0.006999s\n",
      "batch 7879, train_loss 32.748699,Time used 0.005002s\n",
      "batch 7880, train_loss 30.401556,Time used 0.005033s\n",
      "batch 7881, train_loss 30.774302,Time used 0.004999s\n",
      "batch 7882, train_loss 33.658684,Time used 0.005002s\n",
      "batch 7883, train_loss 33.385509,Time used 0.004966s\n",
      "batch 7884, train_loss 35.481464,Time used 0.006032s\n",
      "batch 7885, train_loss 29.631886,Time used 0.005003s\n",
      "batch 7886, train_loss 28.909658,Time used 0.004964s\n",
      "batch 7887, train_loss 30.127483,Time used 0.005035s\n",
      "batch 7888, train_loss 30.816969,Time used 0.006032s\n",
      "batch 7889, train_loss 37.290829,Time used 0.005964s\n",
      "batch 7890, train_loss 37.115070,Time used 0.007000s\n",
      "batch 7891, train_loss 33.876347,Time used 0.007999s\n",
      "batch 7892, train_loss 32.733303,Time used 0.005000s\n",
      "batch 7893, train_loss 32.730095,Time used 0.006002s\n",
      "batch 7894, train_loss 26.931910,Time used 0.006037s\n",
      "batch 7895, train_loss 37.196304,Time used 0.004998s\n",
      "batch 7896, train_loss 32.258640,Time used 0.004967s\n",
      "batch 7897, train_loss 31.264458,Time used 0.004998s\n",
      "batch 7898, train_loss 30.836979,Time used 0.004998s\n",
      "batch 7899, train_loss 34.305344,Time used 0.004968s\n",
      "batch 7900, train_loss 29.587835,Time used 0.005000s\n",
      "***************************test_batch 7900, test_rmse_loss 7.026586,test_mae_loss 3.144654,test_mape_loss 52.889921,Time used 0.019997s\n",
      "batch 7901, train_loss 28.271338,Time used 0.006001s\n",
      "batch 7902, train_loss 32.410530,Time used 0.005000s\n",
      "batch 7903, train_loss 30.939713,Time used 0.005000s\n",
      "batch 7904, train_loss 32.919334,Time used 0.005001s\n",
      "batch 7905, train_loss 32.547192,Time used 0.005031s\n",
      "batch 7906, train_loss 29.138571,Time used 0.005968s\n",
      "batch 7907, train_loss 31.314623,Time used 0.006034s\n",
      "batch 7908, train_loss 35.766529,Time used 0.004999s\n",
      "batch 7909, train_loss 34.560101,Time used 0.004968s\n",
      "batch 7910, train_loss 27.335297,Time used 0.004999s\n",
      "batch 7911, train_loss 27.948275,Time used 0.005000s\n",
      "batch 7912, train_loss 31.547808,Time used 0.005996s\n",
      "batch 7913, train_loss 34.333569,Time used 0.005000s\n",
      "batch 7914, train_loss 29.601044,Time used 0.004997s\n",
      "batch 7915, train_loss 30.913162,Time used 0.006003s\n",
      "batch 7916, train_loss 34.204754,Time used 0.005998s\n",
      "batch 7917, train_loss 33.441254,Time used 0.005000s\n",
      "batch 7918, train_loss 35.890297,Time used 0.005000s\n",
      "batch 7919, train_loss 30.878258,Time used 0.005001s\n",
      "batch 7920, train_loss 40.265751,Time used 0.004998s\n",
      "batch 7921, train_loss 31.991259,Time used 0.008002s\n",
      "batch 7922, train_loss 32.127655,Time used 0.007000s\n",
      "batch 7923, train_loss 32.771027,Time used 0.010000s\n",
      "batch 7924, train_loss 31.970165,Time used 0.009999s\n",
      "batch 7925, train_loss 34.180046,Time used 0.006999s\n",
      "batch 7926, train_loss 32.251324,Time used 0.005000s\n",
      "batch 7927, train_loss 33.558510,Time used 0.006001s\n",
      "batch 7928, train_loss 28.642895,Time used 0.004999s\n",
      "batch 7929, train_loss 31.294836,Time used 0.005004s\n",
      "batch 7930, train_loss 35.181793,Time used 0.004997s\n",
      "batch 7931, train_loss 30.878437,Time used 0.005001s\n",
      "batch 7932, train_loss 31.658804,Time used 0.006001s\n",
      "batch 7933, train_loss 34.443050,Time used 0.005999s\n",
      "batch 7934, train_loss 35.713562,Time used 0.004999s\n",
      "batch 7935, train_loss 27.771879,Time used 0.005001s\n",
      "batch 7936, train_loss 31.741350,Time used 0.005999s\n",
      "batch 7937, train_loss 32.499622,Time used 0.006001s\n",
      "batch 7938, train_loss 34.582714,Time used 0.006001s\n",
      "batch 7939, train_loss 31.966658,Time used 0.008003s\n",
      "batch 7940, train_loss 30.530849,Time used 0.008037s\n",
      "batch 7941, train_loss 31.791803,Time used 0.004996s\n",
      "batch 7942, train_loss 31.338243,Time used 0.005000s\n",
      "batch 7943, train_loss 25.553076,Time used 0.005969s\n",
      "batch 7944, train_loss 35.005543,Time used 0.008032s\n",
      "batch 7945, train_loss 28.771017,Time used 0.005000s\n",
      "batch 7946, train_loss 32.406574,Time used 0.005000s\n",
      "batch 7947, train_loss 32.978077,Time used 0.006002s\n",
      "batch 7948, train_loss 31.952988,Time used 0.005999s\n",
      "batch 7949, train_loss 39.137302,Time used 0.005000s\n",
      "batch 7950, train_loss 30.144190,Time used 0.006001s\n",
      "batch 7951, train_loss 32.345749,Time used 0.008004s\n",
      "batch 7952, train_loss 33.688217,Time used 0.006995s\n",
      "batch 7953, train_loss 32.702393,Time used 0.007998s\n",
      "batch 7954, train_loss 38.575268,Time used 0.004999s\n",
      "batch 7955, train_loss 27.841047,Time used 0.005042s\n",
      "batch 7956, train_loss 29.989977,Time used 0.007998s\n",
      "batch 7957, train_loss 26.217381,Time used 0.005965s\n",
      "batch 7958, train_loss 29.902828,Time used 0.005000s\n",
      "batch 7959, train_loss 30.737013,Time used 0.005000s\n",
      "batch 7960, train_loss 37.024700,Time used 0.005997s\n",
      "batch 7961, train_loss 32.948643,Time used 0.005000s\n",
      "batch 7962, train_loss 36.693821,Time used 0.005002s\n",
      "batch 7963, train_loss 29.649391,Time used 0.006037s\n",
      "batch 7964, train_loss 35.118095,Time used 0.004998s\n",
      "batch 7965, train_loss 29.154961,Time used 0.005001s\n",
      "batch 7966, train_loss 28.877213,Time used 0.005965s\n",
      "batch 7967, train_loss 27.693939,Time used 0.005035s\n",
      "batch 7968, train_loss 33.466320,Time used 0.005000s\n",
      "batch 7969, train_loss 29.620667,Time used 0.005000s\n",
      "batch 7970, train_loss 31.160355,Time used 0.004998s\n",
      "batch 7971, train_loss 27.611923,Time used 0.004962s\n",
      "batch 7972, train_loss 38.331139,Time used 0.004999s\n",
      "batch 7973, train_loss 32.939556,Time used 0.006999s\n",
      "batch 7974, train_loss 32.850426,Time used 0.005001s\n",
      "batch 7975, train_loss 35.450981,Time used 0.004999s\n",
      "batch 7976, train_loss 29.605761,Time used 0.005003s\n",
      "batch 7977, train_loss 30.378645,Time used 0.005000s\n",
      "batch 7978, train_loss 35.600117,Time used 0.005999s\n",
      "batch 7979, train_loss 31.735926,Time used 0.005003s\n",
      "batch 7980, train_loss 31.754396,Time used 0.005033s\n",
      "batch 7981, train_loss 26.147490,Time used 0.005968s\n",
      "batch 7982, train_loss 32.823700,Time used 0.005999s\n",
      "batch 7983, train_loss 35.510551,Time used 0.005001s\n",
      "batch 7984, train_loss 34.436733,Time used 0.004998s\n",
      "batch 7985, train_loss 28.422396,Time used 0.005005s\n",
      "batch 7986, train_loss 30.976242,Time used 0.005031s\n",
      "batch 7987, train_loss 34.670372,Time used 0.005000s\n",
      "batch 7988, train_loss 35.833279,Time used 0.004960s\n",
      "batch 7989, train_loss 29.247719,Time used 0.005000s\n",
      "batch 7990, train_loss 32.518715,Time used 0.005002s\n",
      "batch 7991, train_loss 30.637552,Time used 0.006042s\n",
      "batch 7992, train_loss 28.432581,Time used 0.004961s\n",
      "batch 7993, train_loss 28.479103,Time used 0.004999s\n",
      "batch 7994, train_loss 30.332012,Time used 0.005001s\n",
      "batch 7995, train_loss 31.007559,Time used 0.005000s\n",
      "batch 7996, train_loss 31.436865,Time used 0.004997s\n",
      "batch 7997, train_loss 29.547880,Time used 0.005001s\n",
      "batch 7998, train_loss 27.770872,Time used 0.005000s\n",
      "batch 7999, train_loss 28.289814,Time used 0.005002s\n",
      "batch 8000, train_loss 30.505686,Time used 0.005004s\n",
      "***************************test_batch 8000, test_rmse_loss 7.059424,test_mae_loss 3.153368,test_mape_loss 52.477754,Time used 0.018998s\n",
      "batch 8001, train_loss 38.160473,Time used 0.005998s\n",
      "batch 8002, train_loss 35.242996,Time used 0.005002s\n",
      "batch 8003, train_loss 31.774464,Time used 0.004998s\n",
      "batch 8004, train_loss 41.825817,Time used 0.008003s\n",
      "batch 8005, train_loss 37.152271,Time used 0.008000s\n",
      "batch 8006, train_loss 31.905668,Time used 0.007996s\n",
      "batch 8007, train_loss 33.668350,Time used 0.008000s\n",
      "batch 8008, train_loss 25.877918,Time used 0.006002s\n",
      "batch 8009, train_loss 32.988735,Time used 0.006004s\n",
      "batch 8010, train_loss 30.752140,Time used 0.005998s\n",
      "batch 8011, train_loss 32.419411,Time used 0.005002s\n",
      "batch 8012, train_loss 32.616802,Time used 0.005999s\n",
      "batch 8013, train_loss 30.596434,Time used 0.005000s\n",
      "batch 8014, train_loss 25.410681,Time used 0.005000s\n",
      "batch 8015, train_loss 34.869801,Time used 0.006001s\n",
      "batch 8016, train_loss 33.094841,Time used 0.005996s\n",
      "batch 8017, train_loss 29.754810,Time used 0.004998s\n",
      "batch 8018, train_loss 27.265362,Time used 0.005001s\n",
      "batch 8019, train_loss 30.978729,Time used 0.006000s\n",
      "batch 8020, train_loss 33.878262,Time used 0.005000s\n",
      "batch 8021, train_loss 31.372395,Time used 0.005000s\n",
      "batch 8022, train_loss 29.785606,Time used 0.005002s\n",
      "batch 8023, train_loss 30.422331,Time used 0.005032s\n",
      "batch 8024, train_loss 35.618713,Time used 0.005030s\n",
      "batch 8025, train_loss 33.091194,Time used 0.004967s\n",
      "batch 8026, train_loss 29.754580,Time used 0.005000s\n",
      "batch 8027, train_loss 24.335217,Time used 0.005036s\n",
      "batch 8028, train_loss 32.781231,Time used 0.004997s\n",
      "batch 8029, train_loss 32.033344,Time used 0.004998s\n",
      "batch 8030, train_loss 36.609882,Time used 0.006970s\n",
      "batch 8031, train_loss 33.808109,Time used 0.005999s\n",
      "batch 8032, train_loss 36.694103,Time used 0.004998s\n",
      "batch 8033, train_loss 31.235674,Time used 0.005999s\n",
      "batch 8034, train_loss 28.504171,Time used 0.006003s\n",
      "batch 8035, train_loss 25.962107,Time used 0.004997s\n",
      "batch 8036, train_loss 33.975868,Time used 0.005000s\n",
      "batch 8037, train_loss 33.667480,Time used 0.004999s\n",
      "batch 8038, train_loss 36.866585,Time used 0.007003s\n",
      "batch 8039, train_loss 36.349155,Time used 0.006999s\n",
      "batch 8040, train_loss 29.887060,Time used 0.005001s\n",
      "batch 8041, train_loss 32.297974,Time used 0.007002s\n",
      "batch 8042, train_loss 32.701748,Time used 0.009000s\n",
      "batch 8043, train_loss 38.253178,Time used 0.006999s\n",
      "batch 8044, train_loss 31.212643,Time used 0.005000s\n",
      "batch 8045, train_loss 25.162868,Time used 0.005002s\n",
      "batch 8046, train_loss 30.857904,Time used 0.005000s\n",
      "batch 8047, train_loss 30.119473,Time used 0.005000s\n",
      "batch 8048, train_loss 32.076950,Time used 0.004000s\n",
      "batch 8049, train_loss 32.371403,Time used 0.006002s\n",
      "batch 8050, train_loss 32.445152,Time used 0.004998s\n",
      "batch 8051, train_loss 29.721859,Time used 0.006000s\n",
      "batch 8052, train_loss 26.077126,Time used 0.004998s\n",
      "batch 8053, train_loss 33.504795,Time used 0.004999s\n",
      "batch 8054, train_loss 29.828686,Time used 0.005000s\n",
      "batch 8055, train_loss 35.882473,Time used 0.005000s\n",
      "batch 8056, train_loss 32.898880,Time used 0.005000s\n",
      "batch 8057, train_loss 36.397984,Time used 0.006000s\n",
      "batch 8058, train_loss 31.028290,Time used 0.005005s\n",
      "batch 8059, train_loss 34.091473,Time used 0.008032s\n",
      "batch 8060, train_loss 30.755344,Time used 0.004969s\n",
      "batch 8061, train_loss 30.158865,Time used 0.004999s\n",
      "batch 8062, train_loss 33.693489,Time used 0.006000s\n",
      "batch 8063, train_loss 33.051769,Time used 0.006995s\n",
      "batch 8064, train_loss 29.342867,Time used 0.006000s\n",
      "batch 8065, train_loss 30.374714,Time used 0.005005s\n",
      "batch 8066, train_loss 31.723982,Time used 0.005001s\n",
      "batch 8067, train_loss 27.675821,Time used 0.005999s\n",
      "batch 8068, train_loss 30.674189,Time used 0.006000s\n",
      "batch 8069, train_loss 30.409786,Time used 0.006995s\n",
      "batch 8070, train_loss 29.613441,Time used 0.007009s\n",
      "batch 8071, train_loss 28.082584,Time used 0.004998s\n",
      "batch 8072, train_loss 28.840595,Time used 0.005997s\n",
      "batch 8073, train_loss 34.867867,Time used 0.006999s\n",
      "batch 8074, train_loss 30.909849,Time used 0.006031s\n",
      "batch 8075, train_loss 32.770309,Time used 0.005968s\n",
      "batch 8076, train_loss 31.573408,Time used 0.005033s\n",
      "batch 8077, train_loss 32.298615,Time used 0.004999s\n",
      "batch 8078, train_loss 38.887772,Time used 0.006001s\n",
      "batch 8079, train_loss 31.120409,Time used 0.004966s\n",
      "batch 8080, train_loss 31.517380,Time used 0.006035s\n",
      "batch 8081, train_loss 32.852051,Time used 0.006999s\n",
      "batch 8082, train_loss 37.840115,Time used 0.007967s\n",
      "batch 8083, train_loss 32.879391,Time used 0.004995s\n",
      "batch 8084, train_loss 32.113438,Time used 0.004999s\n",
      "batch 8085, train_loss 39.434887,Time used 0.005000s\n",
      "batch 8086, train_loss 28.956465,Time used 0.009003s\n",
      "batch 8087, train_loss 27.839706,Time used 0.008040s\n",
      "batch 8088, train_loss 29.755667,Time used 0.007001s\n",
      "batch 8089, train_loss 32.139130,Time used 0.006963s\n",
      "batch 8090, train_loss 30.559078,Time used 0.008002s\n",
      "batch 8091, train_loss 31.929249,Time used 0.008039s\n",
      "batch 8092, train_loss 33.988338,Time used 0.006958s\n",
      "batch 8093, train_loss 29.893526,Time used 0.007000s\n",
      "batch 8094, train_loss 33.825535,Time used 0.007998s\n",
      "batch 8095, train_loss 27.498863,Time used 0.007002s\n",
      "batch 8096, train_loss 34.355843,Time used 0.006998s\n",
      "batch 8097, train_loss 34.959023,Time used 0.007006s\n",
      "batch 8098, train_loss 38.481884,Time used 0.007997s\n",
      "batch 8099, train_loss 28.773521,Time used 0.009001s\n",
      "batch 8100, train_loss 29.937038,Time used 0.005000s\n",
      "***************************test_batch 8100, test_rmse_loss 7.036056,test_mae_loss 3.146792,test_mape_loss 52.456353,Time used 0.018032s\n",
      "batch 8101, train_loss 31.155037,Time used 0.004969s\n",
      "batch 8102, train_loss 34.786583,Time used 0.005001s\n",
      "batch 8103, train_loss 30.146791,Time used 0.004999s\n",
      "batch 8104, train_loss 33.058998,Time used 0.005967s\n",
      "batch 8105, train_loss 32.014519,Time used 0.007999s\n",
      "batch 8106, train_loss 29.850582,Time used 0.005004s\n",
      "batch 8107, train_loss 32.994659,Time used 0.004999s\n",
      "batch 8108, train_loss 39.447826,Time used 0.005000s\n",
      "batch 8109, train_loss 26.562300,Time used 0.005000s\n",
      "batch 8110, train_loss 31.012676,Time used 0.007033s\n",
      "batch 8111, train_loss 24.343327,Time used 0.004963s\n",
      "batch 8112, train_loss 30.510403,Time used 0.005001s\n",
      "batch 8113, train_loss 30.065071,Time used 0.004997s\n",
      "batch 8114, train_loss 29.745113,Time used 0.007000s\n",
      "batch 8115, train_loss 32.867989,Time used 0.005000s\n",
      "batch 8116, train_loss 29.113163,Time used 0.005999s\n",
      "batch 8117, train_loss 34.807663,Time used 0.005001s\n",
      "batch 8118, train_loss 30.652620,Time used 0.005034s\n",
      "batch 8119, train_loss 30.899799,Time used 0.008002s\n",
      "batch 8120, train_loss 35.444492,Time used 0.006001s\n",
      "batch 8121, train_loss 30.238100,Time used 0.007960s\n",
      "batch 8122, train_loss 30.794403,Time used 0.008001s\n",
      "batch 8123, train_loss 31.905844,Time used 0.008000s\n",
      "batch 8124, train_loss 30.459223,Time used 0.005001s\n",
      "batch 8125, train_loss 32.892918,Time used 0.006000s\n",
      "batch 8126, train_loss 33.578793,Time used 0.005004s\n",
      "batch 8127, train_loss 29.738157,Time used 0.005000s\n",
      "batch 8128, train_loss 30.991650,Time used 0.005998s\n",
      "batch 8129, train_loss 26.846939,Time used 0.004998s\n",
      "batch 8130, train_loss 32.675720,Time used 0.005040s\n",
      "batch 8131, train_loss 25.144157,Time used 0.005000s\n",
      "batch 8132, train_loss 37.061954,Time used 0.004966s\n",
      "batch 8133, train_loss 34.757629,Time used 0.005000s\n",
      "batch 8134, train_loss 34.827267,Time used 0.005000s\n",
      "batch 8135, train_loss 34.643024,Time used 0.004998s\n",
      "batch 8136, train_loss 30.237438,Time used 0.005002s\n",
      "batch 8137, train_loss 30.588564,Time used 0.005996s\n",
      "batch 8138, train_loss 35.973808,Time used 0.005004s\n",
      "batch 8139, train_loss 30.481337,Time used 0.005000s\n",
      "batch 8140, train_loss 29.454502,Time used 0.005001s\n",
      "batch 8141, train_loss 31.803501,Time used 0.006034s\n",
      "batch 8142, train_loss 29.424137,Time used 0.004999s\n",
      "batch 8143, train_loss 29.912374,Time used 0.004999s\n",
      "batch 8144, train_loss 37.139961,Time used 0.005001s\n",
      "batch 8145, train_loss 30.049164,Time used 0.004999s\n",
      "batch 8146, train_loss 30.459425,Time used 0.005967s\n",
      "batch 8147, train_loss 32.465755,Time used 0.004998s\n",
      "batch 8148, train_loss 26.936546,Time used 0.006000s\n",
      "batch 8149, train_loss 35.388725,Time used 0.005000s\n",
      "batch 8150, train_loss 37.788879,Time used 0.007004s\n",
      "batch 8151, train_loss 33.770287,Time used 0.005999s\n",
      "batch 8152, train_loss 31.519358,Time used 0.004998s\n",
      "batch 8153, train_loss 32.508820,Time used 0.005999s\n",
      "batch 8154, train_loss 33.614208,Time used 0.005001s\n",
      "batch 8155, train_loss 29.771759,Time used 0.008002s\n",
      "batch 8156, train_loss 32.874947,Time used 0.005997s\n",
      "batch 8157, train_loss 25.618011,Time used 0.007001s\n",
      "batch 8158, train_loss 29.368320,Time used 0.004999s\n",
      "batch 8159, train_loss 28.038843,Time used 0.005002s\n",
      "batch 8160, train_loss 34.762192,Time used 0.005036s\n",
      "batch 8161, train_loss 30.354229,Time used 0.005998s\n",
      "batch 8162, train_loss 30.813894,Time used 0.004995s\n",
      "batch 8163, train_loss 30.752068,Time used 0.004996s\n",
      "batch 8164, train_loss 27.050211,Time used 0.008000s\n",
      "batch 8165, train_loss 28.714916,Time used 0.006006s\n",
      "batch 8166, train_loss 39.480820,Time used 0.005032s\n",
      "batch 8167, train_loss 25.573078,Time used 0.004967s\n",
      "batch 8168, train_loss 33.551739,Time used 0.006999s\n",
      "batch 8169, train_loss 25.317574,Time used 0.004966s\n",
      "batch 8170, train_loss 37.687748,Time used 0.004998s\n",
      "batch 8171, train_loss 35.612549,Time used 0.006999s\n",
      "batch 8172, train_loss 32.649136,Time used 0.006047s\n",
      "batch 8173, train_loss 28.869020,Time used 0.007989s\n",
      "batch 8174, train_loss 34.529762,Time used 0.005000s\n",
      "batch 8175, train_loss 32.885849,Time used 0.005963s\n",
      "batch 8176, train_loss 40.378494,Time used 0.005000s\n",
      "batch 8177, train_loss 27.859802,Time used 0.005000s\n",
      "batch 8178, train_loss 32.329433,Time used 0.006005s\n",
      "batch 8179, train_loss 29.750023,Time used 0.007031s\n",
      "batch 8180, train_loss 30.385233,Time used 0.007964s\n",
      "batch 8181, train_loss 29.472290,Time used 0.007001s\n",
      "batch 8182, train_loss 28.373230,Time used 0.006001s\n",
      "batch 8183, train_loss 30.951843,Time used 0.005998s\n",
      "batch 8184, train_loss 35.188107,Time used 0.007006s\n",
      "batch 8185, train_loss 34.853691,Time used 0.007964s\n",
      "batch 8186, train_loss 30.276619,Time used 0.005997s\n",
      "batch 8187, train_loss 31.366219,Time used 0.008006s\n",
      "batch 8188, train_loss 33.776173,Time used 0.005995s\n",
      "batch 8189, train_loss 31.005157,Time used 0.005000s\n",
      "batch 8190, train_loss 31.543995,Time used 0.004999s\n",
      "batch 8191, train_loss 30.132792,Time used 0.005037s\n",
      "batch 8192, train_loss 29.039682,Time used 0.005999s\n",
      "batch 8193, train_loss 31.135946,Time used 0.004969s\n",
      "batch 8194, train_loss 34.724464,Time used 0.004997s\n",
      "batch 8195, train_loss 31.361145,Time used 0.005000s\n",
      "batch 8196, train_loss 31.665251,Time used 0.006000s\n",
      "batch 8197, train_loss 32.952919,Time used 0.004995s\n",
      "batch 8198, train_loss 31.825762,Time used 0.008000s\n",
      "batch 8199, train_loss 33.830578,Time used 0.006000s\n",
      "batch 8200, train_loss 28.808622,Time used 0.004999s\n",
      "***************************test_batch 8200, test_rmse_loss 7.058738,test_mae_loss 3.152971,test_mape_loss 52.213137,Time used 0.017969s\n",
      "batch 8201, train_loss 35.171459,Time used 0.005007s\n",
      "batch 8202, train_loss 33.325668,Time used 0.006025s\n",
      "batch 8203, train_loss 31.619110,Time used 0.006029s\n",
      "batch 8204, train_loss 30.997931,Time used 0.006002s\n",
      "batch 8205, train_loss 27.499352,Time used 0.005001s\n",
      "batch 8206, train_loss 30.050732,Time used 0.005003s\n",
      "batch 8207, train_loss 27.951691,Time used 0.004999s\n",
      "batch 8208, train_loss 32.798931,Time used 0.004998s\n",
      "batch 8209, train_loss 28.800367,Time used 0.006999s\n",
      "batch 8210, train_loss 30.115864,Time used 0.008005s\n",
      "batch 8211, train_loss 31.098364,Time used 0.007998s\n",
      "batch 8212, train_loss 37.185913,Time used 0.007034s\n",
      "batch 8213, train_loss 32.965603,Time used 0.005000s\n",
      "batch 8214, train_loss 30.809240,Time used 0.005000s\n",
      "batch 8215, train_loss 31.276192,Time used 0.004968s\n",
      "batch 8216, train_loss 31.152529,Time used 0.005998s\n",
      "batch 8217, train_loss 29.211777,Time used 0.005002s\n",
      "batch 8218, train_loss 30.570002,Time used 0.005994s\n",
      "batch 8219, train_loss 29.056862,Time used 0.004999s\n",
      "batch 8220, train_loss 33.204315,Time used 0.005000s\n",
      "batch 8221, train_loss 30.927856,Time used 0.005004s\n",
      "batch 8222, train_loss 28.582027,Time used 0.005035s\n",
      "batch 8223, train_loss 32.473354,Time used 0.004000s\n",
      "batch 8224, train_loss 34.577747,Time used 0.004966s\n",
      "batch 8225, train_loss 33.382805,Time used 0.005002s\n",
      "batch 8226, train_loss 27.745813,Time used 0.004000s\n",
      "batch 8227, train_loss 30.583281,Time used 0.008033s\n",
      "batch 8228, train_loss 31.830755,Time used 0.005001s\n",
      "batch 8229, train_loss 29.024401,Time used 0.005005s\n",
      "batch 8230, train_loss 31.816999,Time used 0.005001s\n",
      "batch 8231, train_loss 35.730152,Time used 0.004036s\n",
      "batch 8232, train_loss 34.175110,Time used 0.003993s\n",
      "batch 8233, train_loss 32.279739,Time used 0.004998s\n",
      "batch 8234, train_loss 30.263176,Time used 0.007000s\n",
      "batch 8235, train_loss 35.300301,Time used 0.008997s\n",
      "batch 8236, train_loss 28.346910,Time used 0.009001s\n",
      "batch 8237, train_loss 32.261806,Time used 0.005002s\n",
      "batch 8238, train_loss 30.834759,Time used 0.006001s\n",
      "batch 8239, train_loss 29.479101,Time used 0.005000s\n",
      "batch 8240, train_loss 33.266270,Time used 0.006000s\n",
      "batch 8241, train_loss 27.194481,Time used 0.007998s\n",
      "batch 8242, train_loss 28.202265,Time used 0.005998s\n",
      "batch 8243, train_loss 32.916214,Time used 0.005001s\n",
      "batch 8244, train_loss 28.562449,Time used 0.005999s\n",
      "batch 8245, train_loss 29.901663,Time used 0.008000s\n",
      "batch 8246, train_loss 35.128136,Time used 0.006001s\n",
      "batch 8247, train_loss 28.494308,Time used 0.004999s\n",
      "batch 8248, train_loss 31.509365,Time used 0.005000s\n",
      "batch 8249, train_loss 39.115864,Time used 0.005035s\n",
      "batch 8250, train_loss 33.189724,Time used 0.005965s\n",
      "batch 8251, train_loss 34.975746,Time used 0.005999s\n",
      "batch 8252, train_loss 31.335205,Time used 0.005000s\n",
      "batch 8253, train_loss 31.551620,Time used 0.005001s\n",
      "batch 8254, train_loss 27.463682,Time used 0.007000s\n",
      "batch 8255, train_loss 28.824652,Time used 0.007000s\n",
      "batch 8256, train_loss 35.075630,Time used 0.007001s\n",
      "batch 8257, train_loss 32.834202,Time used 0.007962s\n",
      "batch 8258, train_loss 38.015453,Time used 0.007033s\n",
      "batch 8259, train_loss 27.493904,Time used 0.006966s\n",
      "batch 8260, train_loss 28.684549,Time used 0.005996s\n",
      "batch 8261, train_loss 32.799862,Time used 0.008002s\n",
      "batch 8262, train_loss 31.663860,Time used 0.010000s\n",
      "batch 8263, train_loss 30.795805,Time used 0.007997s\n",
      "batch 8264, train_loss 29.868704,Time used 0.008001s\n",
      "batch 8265, train_loss 28.953497,Time used 0.008001s\n",
      "batch 8266, train_loss 32.225639,Time used 0.009998s\n",
      "batch 8267, train_loss 24.337532,Time used 0.008002s\n",
      "batch 8268, train_loss 29.653101,Time used 0.008000s\n",
      "batch 8269, train_loss 32.568302,Time used 0.007002s\n",
      "batch 8270, train_loss 32.433342,Time used 0.009000s\n",
      "batch 8271, train_loss 33.680969,Time used 0.008000s\n",
      "batch 8272, train_loss 28.096935,Time used 0.008999s\n",
      "batch 8273, train_loss 42.627495,Time used 0.008001s\n",
      "batch 8274, train_loss 32.538673,Time used 0.008003s\n",
      "batch 8275, train_loss 31.113605,Time used 0.007996s\n",
      "batch 8276, train_loss 35.649395,Time used 0.009002s\n",
      "batch 8277, train_loss 27.763937,Time used 0.009998s\n",
      "batch 8278, train_loss 33.009411,Time used 0.008998s\n",
      "batch 8279, train_loss 31.993793,Time used 0.008002s\n",
      "batch 8280, train_loss 24.935999,Time used 0.005000s\n",
      "batch 8281, train_loss 29.843729,Time used 0.007996s\n",
      "batch 8282, train_loss 37.008240,Time used 0.008000s\n",
      "batch 8283, train_loss 31.102215,Time used 0.008002s\n",
      "batch 8284, train_loss 35.552708,Time used 0.007001s\n",
      "batch 8285, train_loss 34.802326,Time used 0.007001s\n",
      "batch 8286, train_loss 24.489033,Time used 0.009000s\n",
      "batch 8287, train_loss 31.796515,Time used 0.008001s\n",
      "batch 8288, train_loss 33.177967,Time used 0.007999s\n",
      "batch 8289, train_loss 30.506544,Time used 0.007000s\n",
      "batch 8290, train_loss 25.589602,Time used 0.008000s\n",
      "batch 8291, train_loss 28.975067,Time used 0.009001s\n",
      "batch 8292, train_loss 27.734337,Time used 0.008999s\n",
      "batch 8293, train_loss 28.170460,Time used 0.009001s\n",
      "batch 8294, train_loss 34.854652,Time used 0.009999s\n",
      "batch 8295, train_loss 28.291010,Time used 0.009001s\n",
      "batch 8296, train_loss 33.412182,Time used 0.012000s\n",
      "batch 8297, train_loss 31.259285,Time used 0.012000s\n",
      "batch 8298, train_loss 27.807720,Time used 0.019001s\n",
      "batch 8299, train_loss 37.524456,Time used 0.008998s\n",
      "batch 8300, train_loss 33.710167,Time used 0.009000s\n",
      "***************************test_batch 8300, test_rmse_loss 6.993646,test_mae_loss 3.129847,test_mape_loss 52.576935,Time used 0.030000s\n",
      "batch 8301, train_loss 32.084221,Time used 0.008000s\n",
      "batch 8302, train_loss 34.187359,Time used 0.009001s\n",
      "batch 8303, train_loss 29.697048,Time used 0.007000s\n",
      "batch 8304, train_loss 31.135715,Time used 0.007000s\n",
      "batch 8305, train_loss 26.905088,Time used 0.009001s\n",
      "batch 8306, train_loss 30.246426,Time used 0.009001s\n",
      "batch 8307, train_loss 30.740318,Time used 0.007001s\n",
      "batch 8308, train_loss 25.366072,Time used 0.008998s\n",
      "batch 8309, train_loss 28.468542,Time used 0.008999s\n",
      "batch 8310, train_loss 33.775253,Time used 0.008000s\n",
      "batch 8311, train_loss 33.270351,Time used 0.009997s\n",
      "batch 8312, train_loss 30.629845,Time used 0.009001s\n",
      "batch 8313, train_loss 33.412537,Time used 0.008000s\n",
      "batch 8314, train_loss 31.912348,Time used 0.006998s\n",
      "batch 8315, train_loss 32.221554,Time used 0.009002s\n",
      "batch 8316, train_loss 34.853741,Time used 0.009009s\n",
      "batch 8317, train_loss 30.202150,Time used 0.005000s\n",
      "batch 8318, train_loss 31.383286,Time used 0.006000s\n",
      "batch 8319, train_loss 29.403906,Time used 0.006000s\n",
      "batch 8320, train_loss 34.147274,Time used 0.005000s\n",
      "batch 8321, train_loss 32.464153,Time used 0.007002s\n",
      "batch 8322, train_loss 34.729275,Time used 0.006998s\n",
      "batch 8323, train_loss 29.145998,Time used 0.011003s\n",
      "batch 8324, train_loss 33.131546,Time used 0.008001s\n",
      "batch 8325, train_loss 30.122124,Time used 0.006999s\n",
      "batch 8326, train_loss 28.010626,Time used 0.007001s\n",
      "batch 8327, train_loss 39.155025,Time used 0.007001s\n",
      "batch 8328, train_loss 28.087355,Time used 0.008999s\n",
      "batch 8329, train_loss 27.770767,Time used 0.007997s\n",
      "batch 8330, train_loss 36.376778,Time used 0.006999s\n",
      "batch 8331, train_loss 27.778036,Time used 0.009001s\n",
      "batch 8332, train_loss 34.601818,Time used 0.008998s\n",
      "batch 8333, train_loss 32.276588,Time used 0.009000s\n",
      "batch 8334, train_loss 31.513557,Time used 0.009000s\n",
      "batch 8335, train_loss 25.967648,Time used 0.009000s\n",
      "batch 8336, train_loss 35.112144,Time used 0.008001s\n",
      "batch 8337, train_loss 28.199312,Time used 0.007997s\n",
      "batch 8338, train_loss 31.698664,Time used 0.006999s\n",
      "batch 8339, train_loss 31.346973,Time used 0.007001s\n",
      "batch 8340, train_loss 28.115356,Time used 0.008000s\n",
      "batch 8341, train_loss 31.705288,Time used 0.009001s\n",
      "batch 8342, train_loss 35.838947,Time used 0.006999s\n",
      "batch 8343, train_loss 29.617794,Time used 0.008001s\n",
      "batch 8344, train_loss 35.578934,Time used 0.008002s\n",
      "batch 8345, train_loss 28.340120,Time used 0.006999s\n",
      "batch 8346, train_loss 32.306232,Time used 0.007002s\n",
      "batch 8347, train_loss 27.197729,Time used 0.006999s\n",
      "batch 8348, train_loss 30.621902,Time used 0.009001s\n",
      "batch 8349, train_loss 31.019068,Time used 0.007997s\n",
      "batch 8350, train_loss 33.634682,Time used 0.008003s\n",
      "batch 8351, train_loss 32.984554,Time used 0.011998s\n",
      "batch 8352, train_loss 31.136671,Time used 0.008998s\n",
      "batch 8353, train_loss 28.644958,Time used 0.008998s\n",
      "batch 8354, train_loss 32.274639,Time used 0.010002s\n",
      "batch 8355, train_loss 41.618088,Time used 0.010001s\n",
      "batch 8356, train_loss 26.828217,Time used 0.010995s\n",
      "batch 8357, train_loss 26.703897,Time used 0.010000s\n",
      "batch 8358, train_loss 30.939804,Time used 0.016999s\n",
      "batch 8359, train_loss 31.878540,Time used 0.009001s\n",
      "batch 8360, train_loss 29.736645,Time used 0.008998s\n",
      "batch 8361, train_loss 31.716576,Time used 0.008003s\n",
      "batch 8362, train_loss 26.860094,Time used 0.008000s\n",
      "batch 8363, train_loss 33.353149,Time used 0.006999s\n",
      "batch 8364, train_loss 32.786873,Time used 0.006001s\n",
      "batch 8365, train_loss 31.713348,Time used 0.006001s\n",
      "batch 8366, train_loss 37.943699,Time used 0.008998s\n",
      "batch 8367, train_loss 33.734146,Time used 0.006998s\n",
      "batch 8368, train_loss 31.465101,Time used 0.008002s\n",
      "batch 8369, train_loss 31.371685,Time used 0.007001s\n",
      "batch 8370, train_loss 32.361309,Time used 0.006001s\n",
      "batch 8371, train_loss 24.640436,Time used 0.007001s\n",
      "batch 8372, train_loss 32.583801,Time used 0.007001s\n",
      "batch 8373, train_loss 30.585735,Time used 0.008000s\n",
      "batch 8374, train_loss 33.348095,Time used 0.008002s\n",
      "batch 8375, train_loss 28.969629,Time used 0.008999s\n",
      "batch 8376, train_loss 27.668961,Time used 0.015000s\n",
      "batch 8377, train_loss 28.993399,Time used 0.016997s\n",
      "batch 8378, train_loss 29.810871,Time used 0.009002s\n",
      "batch 8379, train_loss 31.756527,Time used 0.009004s\n",
      "batch 8380, train_loss 35.186985,Time used 0.009996s\n",
      "batch 8381, train_loss 32.275543,Time used 0.008999s\n",
      "batch 8382, train_loss 30.512129,Time used 0.007001s\n",
      "batch 8383, train_loss 30.742466,Time used 0.008003s\n",
      "batch 8384, train_loss 32.559887,Time used 0.005998s\n",
      "batch 8385, train_loss 32.440815,Time used 0.007000s\n",
      "batch 8386, train_loss 30.155581,Time used 0.006999s\n",
      "batch 8387, train_loss 32.147430,Time used 0.006999s\n",
      "batch 8388, train_loss 28.168240,Time used 0.005001s\n",
      "batch 8389, train_loss 35.402805,Time used 0.005999s\n",
      "batch 8390, train_loss 30.466522,Time used 0.006001s\n",
      "batch 8391, train_loss 29.936504,Time used 0.005000s\n",
      "batch 8392, train_loss 28.491306,Time used 0.006003s\n",
      "batch 8393, train_loss 31.348797,Time used 0.005998s\n",
      "batch 8394, train_loss 31.621096,Time used 0.006001s\n",
      "batch 8395, train_loss 31.426123,Time used 0.006999s\n",
      "batch 8396, train_loss 27.575104,Time used 0.006000s\n",
      "batch 8397, train_loss 30.789492,Time used 0.005001s\n",
      "batch 8398, train_loss 33.302780,Time used 0.006001s\n",
      "batch 8399, train_loss 32.116547,Time used 0.004997s\n",
      "batch 8400, train_loss 31.938484,Time used 0.004999s\n",
      "***************************test_batch 8400, test_rmse_loss 7.012615,test_mae_loss 3.137518,test_mape_loss 52.199698,Time used 0.018003s\n",
      "batch 8401, train_loss 27.282051,Time used 0.005999s\n",
      "batch 8402, train_loss 36.066067,Time used 0.004997s\n",
      "batch 8403, train_loss 31.811865,Time used 0.005001s\n",
      "batch 8404, train_loss 32.567520,Time used 0.004998s\n",
      "batch 8405, train_loss 29.614336,Time used 0.004999s\n",
      "batch 8406, train_loss 34.630566,Time used 0.005003s\n",
      "batch 8407, train_loss 27.156570,Time used 0.005005s\n",
      "batch 8408, train_loss 27.540295,Time used 0.004996s\n",
      "batch 8409, train_loss 31.851128,Time used 0.005000s\n",
      "batch 8410, train_loss 31.007843,Time used 0.005007s\n",
      "batch 8411, train_loss 29.821709,Time used 0.005031s\n",
      "batch 8412, train_loss 34.602997,Time used 0.005962s\n",
      "batch 8413, train_loss 29.451778,Time used 0.006999s\n",
      "batch 8414, train_loss 30.897863,Time used 0.005002s\n",
      "batch 8415, train_loss 32.973183,Time used 0.006000s\n",
      "batch 8416, train_loss 33.522266,Time used 0.006000s\n",
      "batch 8417, train_loss 35.027321,Time used 0.005002s\n",
      "batch 8418, train_loss 28.586414,Time used 0.007999s\n",
      "batch 8419, train_loss 32.925060,Time used 0.005001s\n",
      "batch 8420, train_loss 29.208963,Time used 0.008010s\n",
      "batch 8421, train_loss 27.149763,Time used 0.005998s\n",
      "batch 8422, train_loss 32.211540,Time used 0.005001s\n",
      "batch 8423, train_loss 32.013275,Time used 0.005999s\n",
      "batch 8424, train_loss 29.805353,Time used 0.005000s\n",
      "batch 8425, train_loss 31.158928,Time used 0.005996s\n",
      "batch 8426, train_loss 27.044230,Time used 0.005035s\n",
      "batch 8427, train_loss 34.860611,Time used 0.005000s\n",
      "batch 8428, train_loss 23.833073,Time used 0.006000s\n",
      "batch 8429, train_loss 27.431770,Time used 0.005000s\n",
      "batch 8430, train_loss 33.655434,Time used 0.004966s\n",
      "batch 8431, train_loss 36.193253,Time used 0.005996s\n",
      "batch 8432, train_loss 35.315277,Time used 0.005001s\n",
      "batch 8433, train_loss 30.512793,Time used 0.004998s\n",
      "batch 8434, train_loss 33.772182,Time used 0.006001s\n",
      "batch 8435, train_loss 30.203533,Time used 0.004999s\n",
      "batch 8436, train_loss 29.635847,Time used 0.005001s\n",
      "batch 8437, train_loss 36.877235,Time used 0.007001s\n",
      "batch 8438, train_loss 31.385813,Time used 0.005001s\n",
      "batch 8439, train_loss 27.116653,Time used 0.006004s\n",
      "batch 8440, train_loss 33.644741,Time used 0.007997s\n",
      "batch 8441, train_loss 32.440182,Time used 0.005998s\n",
      "batch 8442, train_loss 31.150887,Time used 0.004999s\n",
      "batch 8443, train_loss 30.710625,Time used 0.004999s\n",
      "batch 8444, train_loss 25.048580,Time used 0.005000s\n",
      "batch 8445, train_loss 36.194153,Time used 0.006002s\n",
      "batch 8446, train_loss 27.116047,Time used 0.006000s\n",
      "batch 8447, train_loss 31.821962,Time used 0.005000s\n",
      "batch 8448, train_loss 29.631748,Time used 0.004999s\n",
      "batch 8449, train_loss 31.834639,Time used 0.005030s\n",
      "batch 8450, train_loss 37.244347,Time used 0.006000s\n",
      "batch 8451, train_loss 31.181799,Time used 0.005000s\n",
      "batch 8452, train_loss 37.061638,Time used 0.006965s\n",
      "batch 8453, train_loss 30.161654,Time used 0.005999s\n",
      "batch 8454, train_loss 35.580688,Time used 0.005002s\n",
      "batch 8455, train_loss 27.116264,Time used 0.004999s\n",
      "batch 8456, train_loss 29.332556,Time used 0.006000s\n",
      "batch 8457, train_loss 38.925751,Time used 0.005001s\n",
      "batch 8458, train_loss 32.021313,Time used 0.004999s\n",
      "batch 8459, train_loss 31.165102,Time used 0.005001s\n",
      "batch 8460, train_loss 27.140917,Time used 0.005003s\n",
      "batch 8461, train_loss 30.427889,Time used 0.004998s\n",
      "batch 8462, train_loss 28.215319,Time used 0.006000s\n",
      "batch 8463, train_loss 29.499132,Time used 0.004999s\n",
      "batch 8464, train_loss 34.785942,Time used 0.005000s\n",
      "batch 8465, train_loss 27.148750,Time used 0.005002s\n",
      "batch 8466, train_loss 25.757444,Time used 0.004999s\n",
      "batch 8467, train_loss 29.545151,Time used 0.005999s\n",
      "batch 8468, train_loss 30.920687,Time used 0.005001s\n",
      "batch 8469, train_loss 30.067987,Time used 0.006998s\n",
      "batch 8470, train_loss 31.835693,Time used 0.005001s\n",
      "batch 8471, train_loss 30.993023,Time used 0.005001s\n",
      "batch 8472, train_loss 27.829622,Time used 0.004998s\n",
      "batch 8473, train_loss 31.204103,Time used 0.005000s\n",
      "batch 8474, train_loss 33.311478,Time used 0.005001s\n",
      "batch 8475, train_loss 25.513533,Time used 0.004999s\n",
      "batch 8476, train_loss 31.804331,Time used 0.006001s\n",
      "batch 8477, train_loss 32.242588,Time used 0.005001s\n",
      "batch 8478, train_loss 25.934156,Time used 0.006000s\n",
      "batch 8479, train_loss 31.002615,Time used 0.005000s\n",
      "batch 8480, train_loss 34.934639,Time used 0.004998s\n",
      "batch 8481, train_loss 29.621357,Time used 0.005000s\n",
      "batch 8482, train_loss 25.362862,Time used 0.005001s\n",
      "batch 8483, train_loss 35.663128,Time used 0.008000s\n",
      "batch 8484, train_loss 26.498396,Time used 0.006999s\n",
      "batch 8485, train_loss 43.205696,Time used 0.005997s\n",
      "batch 8486, train_loss 35.516949,Time used 0.005999s\n",
      "batch 8487, train_loss 30.967735,Time used 0.006001s\n",
      "batch 8488, train_loss 33.987942,Time used 0.009003s\n",
      "batch 8489, train_loss 29.170527,Time used 0.005032s\n",
      "batch 8490, train_loss 32.837746,Time used 0.008966s\n",
      "batch 8491, train_loss 29.611517,Time used 0.005032s\n",
      "batch 8492, train_loss 31.416624,Time used 0.004967s\n",
      "batch 8493, train_loss 31.091587,Time used 0.006001s\n",
      "batch 8494, train_loss 28.541643,Time used 0.005000s\n",
      "batch 8495, train_loss 25.234432,Time used 0.006033s\n",
      "batch 8496, train_loss 29.817305,Time used 0.004999s\n",
      "batch 8497, train_loss 29.379780,Time used 0.005963s\n",
      "batch 8498, train_loss 26.163296,Time used 0.005000s\n",
      "batch 8499, train_loss 33.484932,Time used 0.005034s\n",
      "batch 8500, train_loss 31.428127,Time used 0.004998s\n",
      "***************************test_batch 8500, test_rmse_loss 6.983281,test_mae_loss 3.125798,test_mape_loss 52.388759,Time used 0.021965s\n",
      "batch 8501, train_loss 31.885536,Time used 0.006004s\n",
      "batch 8502, train_loss 31.839506,Time used 0.005030s\n",
      "batch 8503, train_loss 29.057844,Time used 0.005003s\n",
      "batch 8504, train_loss 31.829739,Time used 0.007960s\n",
      "batch 8505, train_loss 33.963001,Time used 0.008000s\n",
      "batch 8506, train_loss 37.067413,Time used 0.006006s\n",
      "batch 8507, train_loss 31.100832,Time used 0.004999s\n",
      "batch 8508, train_loss 29.240053,Time used 0.005000s\n",
      "batch 8509, train_loss 35.368908,Time used 0.005026s\n",
      "batch 8510, train_loss 29.067348,Time used 0.006007s\n",
      "batch 8511, train_loss 26.610840,Time used 0.006001s\n",
      "batch 8512, train_loss 36.636303,Time used 0.004966s\n",
      "batch 8513, train_loss 33.298977,Time used 0.006031s\n",
      "batch 8514, train_loss 25.372009,Time used 0.006000s\n",
      "batch 8515, train_loss 37.979019,Time used 0.005007s\n",
      "batch 8516, train_loss 28.222185,Time used 0.004992s\n",
      "batch 8517, train_loss 33.705345,Time used 0.005967s\n",
      "batch 8518, train_loss 28.090616,Time used 0.006999s\n",
      "batch 8519, train_loss 26.196447,Time used 0.008002s\n",
      "batch 8520, train_loss 26.253010,Time used 0.005000s\n",
      "batch 8521, train_loss 32.109085,Time used 0.006000s\n",
      "batch 8522, train_loss 27.490923,Time used 0.005000s\n",
      "batch 8523, train_loss 28.660212,Time used 0.005000s\n",
      "batch 8524, train_loss 33.176014,Time used 0.005033s\n",
      "batch 8525, train_loss 28.569794,Time used 0.005963s\n",
      "batch 8526, train_loss 35.612137,Time used 0.005999s\n",
      "batch 8527, train_loss 30.335588,Time used 0.005007s\n",
      "batch 8528, train_loss 31.784685,Time used 0.004998s\n",
      "batch 8529, train_loss 26.665182,Time used 0.005998s\n",
      "batch 8530, train_loss 33.676765,Time used 0.005000s\n",
      "batch 8531, train_loss 34.851608,Time used 0.005000s\n",
      "batch 8532, train_loss 26.688171,Time used 0.006000s\n",
      "batch 8533, train_loss 28.883209,Time used 0.005000s\n",
      "batch 8534, train_loss 24.403667,Time used 0.004999s\n",
      "batch 8535, train_loss 30.609339,Time used 0.005002s\n",
      "batch 8536, train_loss 30.549440,Time used 0.005999s\n",
      "batch 8537, train_loss 36.350342,Time used 0.007000s\n",
      "batch 8538, train_loss 26.328772,Time used 0.007002s\n",
      "batch 8539, train_loss 29.745796,Time used 0.006000s\n",
      "batch 8540, train_loss 32.780899,Time used 0.007002s\n",
      "batch 8541, train_loss 38.225838,Time used 0.007996s\n",
      "batch 8542, train_loss 35.842083,Time used 0.007002s\n",
      "batch 8543, train_loss 33.349709,Time used 0.004998s\n",
      "batch 8544, train_loss 25.780313,Time used 0.006001s\n",
      "batch 8545, train_loss 27.838129,Time used 0.005996s\n",
      "batch 8546, train_loss 39.276600,Time used 0.006001s\n",
      "batch 8547, train_loss 33.604023,Time used 0.005001s\n",
      "batch 8548, train_loss 36.526806,Time used 0.005999s\n",
      "batch 8549, train_loss 33.444447,Time used 0.004999s\n",
      "batch 8550, train_loss 29.801226,Time used 0.006000s\n",
      "batch 8551, train_loss 28.489119,Time used 0.006001s\n",
      "batch 8552, train_loss 24.841419,Time used 0.005000s\n",
      "batch 8553, train_loss 26.297218,Time used 0.005001s\n",
      "batch 8554, train_loss 27.910673,Time used 0.006035s\n",
      "batch 8555, train_loss 30.551317,Time used 0.005006s\n",
      "batch 8556, train_loss 27.016108,Time used 0.005995s\n",
      "batch 8557, train_loss 36.325005,Time used 0.005967s\n",
      "batch 8558, train_loss 30.755236,Time used 0.005000s\n",
      "batch 8559, train_loss 30.885284,Time used 0.005999s\n",
      "batch 8560, train_loss 33.543770,Time used 0.006997s\n",
      "batch 8561, train_loss 31.907021,Time used 0.008001s\n",
      "batch 8562, train_loss 31.118855,Time used 0.006000s\n",
      "batch 8563, train_loss 29.773369,Time used 0.005000s\n",
      "batch 8564, train_loss 27.985386,Time used 0.006999s\n",
      "batch 8565, train_loss 29.308050,Time used 0.005000s\n",
      "batch 8566, train_loss 29.150761,Time used 0.005000s\n",
      "batch 8567, train_loss 33.998554,Time used 0.007002s\n",
      "batch 8568, train_loss 31.957291,Time used 0.007998s\n",
      "batch 8569, train_loss 29.727535,Time used 0.004997s\n",
      "batch 8570, train_loss 34.837799,Time used 0.005000s\n",
      "batch 8571, train_loss 33.200893,Time used 0.005000s\n",
      "batch 8572, train_loss 32.620800,Time used 0.005000s\n",
      "batch 8573, train_loss 30.269606,Time used 0.005000s\n",
      "batch 8574, train_loss 33.183697,Time used 0.007003s\n",
      "batch 8575, train_loss 29.778433,Time used 0.007999s\n",
      "batch 8576, train_loss 32.313755,Time used 0.006038s\n",
      "batch 8577, train_loss 31.584061,Time used 0.005996s\n",
      "batch 8578, train_loss 28.271040,Time used 0.004968s\n",
      "batch 8579, train_loss 32.064548,Time used 0.006001s\n",
      "batch 8580, train_loss 27.214771,Time used 0.004998s\n",
      "batch 8581, train_loss 26.918537,Time used 0.005000s\n",
      "batch 8582, train_loss 26.668867,Time used 0.006995s\n",
      "batch 8583, train_loss 29.658770,Time used 0.007000s\n",
      "batch 8584, train_loss 31.760523,Time used 0.006001s\n",
      "batch 8585, train_loss 29.486090,Time used 0.006999s\n",
      "batch 8586, train_loss 35.925362,Time used 0.006000s\n",
      "batch 8587, train_loss 32.388870,Time used 0.005003s\n",
      "batch 8588, train_loss 31.924013,Time used 0.006035s\n",
      "batch 8589, train_loss 28.339167,Time used 0.005000s\n",
      "batch 8590, train_loss 31.965961,Time used 0.004968s\n",
      "batch 8591, train_loss 30.431194,Time used 0.008032s\n",
      "batch 8592, train_loss 30.957682,Time used 0.006000s\n",
      "batch 8593, train_loss 29.271009,Time used 0.004963s\n",
      "batch 8594, train_loss 28.735594,Time used 0.006999s\n",
      "batch 8595, train_loss 28.137625,Time used 0.008002s\n",
      "batch 8596, train_loss 39.268074,Time used 0.006998s\n",
      "batch 8597, train_loss 27.167662,Time used 0.005997s\n",
      "batch 8598, train_loss 32.237816,Time used 0.006004s\n",
      "batch 8599, train_loss 28.959150,Time used 0.006000s\n",
      "batch 8600, train_loss 30.844414,Time used 0.006996s\n",
      "***************************test_batch 8600, test_rmse_loss 7.009138,test_mae_loss 3.133337,test_mape_loss 52.043842,Time used 0.027997s\n",
      "batch 8601, train_loss 35.452278,Time used 0.007005s\n",
      "batch 8602, train_loss 30.374287,Time used 0.005000s\n",
      "batch 8603, train_loss 32.203491,Time used 0.006000s\n",
      "batch 8604, train_loss 31.982569,Time used 0.006036s\n",
      "batch 8605, train_loss 30.749117,Time used 0.004999s\n",
      "batch 8606, train_loss 29.083729,Time used 0.004966s\n",
      "batch 8607, train_loss 31.345924,Time used 0.008001s\n",
      "batch 8608, train_loss 27.510641,Time used 0.005997s\n",
      "batch 8609, train_loss 31.086403,Time used 0.007035s\n",
      "batch 8610, train_loss 31.305367,Time used 0.005967s\n",
      "batch 8611, train_loss 28.453552,Time used 0.005998s\n",
      "batch 8612, train_loss 32.221394,Time used 0.005036s\n",
      "batch 8613, train_loss 29.960135,Time used 0.004964s\n",
      "batch 8614, train_loss 31.823248,Time used 0.006001s\n",
      "batch 8615, train_loss 33.127449,Time used 0.005997s\n",
      "batch 8616, train_loss 28.892473,Time used 0.005000s\n",
      "batch 8617, train_loss 32.623165,Time used 0.006998s\n",
      "batch 8618, train_loss 35.875805,Time used 0.004999s\n",
      "batch 8619, train_loss 29.724972,Time used 0.005000s\n",
      "batch 8620, train_loss 26.545895,Time used 0.005000s\n",
      "batch 8621, train_loss 25.074976,Time used 0.005001s\n",
      "batch 8622, train_loss 23.911007,Time used 0.005999s\n",
      "batch 8623, train_loss 28.302053,Time used 0.006001s\n",
      "batch 8624, train_loss 35.201324,Time used 0.007004s\n",
      "batch 8625, train_loss 36.572628,Time used 0.004998s\n",
      "batch 8626, train_loss 27.105839,Time used 0.005000s\n",
      "batch 8627, train_loss 32.010372,Time used 0.005007s\n",
      "batch 8628, train_loss 35.411934,Time used 0.005030s\n",
      "batch 8629, train_loss 21.678705,Time used 0.004999s\n",
      "batch 8630, train_loss 36.288513,Time used 0.008002s\n",
      "batch 8631, train_loss 35.096889,Time used 0.004998s\n",
      "batch 8632, train_loss 25.642855,Time used 0.005002s\n",
      "batch 8633, train_loss 30.216459,Time used 0.006034s\n",
      "batch 8634, train_loss 30.077225,Time used 0.004998s\n",
      "batch 8635, train_loss 31.621250,Time used 0.004964s\n",
      "batch 8636, train_loss 35.978462,Time used 0.005001s\n",
      "batch 8637, train_loss 24.936171,Time used 0.004999s\n",
      "batch 8638, train_loss 35.073483,Time used 0.005005s\n",
      "batch 8639, train_loss 29.724472,Time used 0.005000s\n",
      "batch 8640, train_loss 34.204800,Time used 0.005000s\n",
      "batch 8641, train_loss 25.351835,Time used 0.008998s\n",
      "batch 8642, train_loss 36.533588,Time used 0.009001s\n",
      "batch 8643, train_loss 29.893776,Time used 0.007999s\n",
      "batch 8644, train_loss 26.020811,Time used 0.007000s\n",
      "batch 8645, train_loss 30.950760,Time used 0.005001s\n",
      "batch 8646, train_loss 40.154396,Time used 0.005999s\n",
      "batch 8647, train_loss 27.524618,Time used 0.005999s\n",
      "batch 8648, train_loss 30.886856,Time used 0.004999s\n",
      "batch 8649, train_loss 29.729370,Time used 0.006000s\n",
      "batch 8650, train_loss 31.454309,Time used 0.005003s\n",
      "batch 8651, train_loss 28.677063,Time used 0.006001s\n",
      "batch 8652, train_loss 28.765415,Time used 0.005996s\n",
      "batch 8653, train_loss 28.824467,Time used 0.005001s\n",
      "batch 8654, train_loss 30.030405,Time used 0.004999s\n",
      "batch 8655, train_loss 37.052200,Time used 0.005002s\n",
      "batch 8656, train_loss 32.003021,Time used 0.005001s\n",
      "batch 8657, train_loss 27.639376,Time used 0.005000s\n",
      "batch 8658, train_loss 39.109417,Time used 0.006999s\n",
      "batch 8659, train_loss 28.955278,Time used 0.005999s\n",
      "batch 8660, train_loss 35.659283,Time used 0.005002s\n",
      "batch 8661, train_loss 30.608673,Time used 0.004998s\n",
      "batch 8662, train_loss 27.433170,Time used 0.005000s\n",
      "batch 8663, train_loss 26.927244,Time used 0.005999s\n",
      "batch 8664, train_loss 27.070400,Time used 0.005001s\n",
      "batch 8665, train_loss 27.910755,Time used 0.007997s\n",
      "batch 8666, train_loss 28.612825,Time used 0.006003s\n",
      "batch 8667, train_loss 32.573906,Time used 0.006000s\n",
      "batch 8668, train_loss 34.113724,Time used 0.005998s\n",
      "batch 8669, train_loss 33.464661,Time used 0.005000s\n",
      "batch 8670, train_loss 31.746202,Time used 0.006003s\n",
      "batch 8671, train_loss 28.481979,Time used 0.005000s\n",
      "batch 8672, train_loss 32.187183,Time used 0.005001s\n",
      "batch 8673, train_loss 34.027515,Time used 0.006997s\n",
      "batch 8674, train_loss 28.221218,Time used 0.005004s\n",
      "batch 8675, train_loss 28.678804,Time used 0.004999s\n",
      "batch 8676, train_loss 27.209780,Time used 0.005996s\n",
      "batch 8677, train_loss 32.925892,Time used 0.004999s\n",
      "batch 8678, train_loss 30.809858,Time used 0.004000s\n",
      "batch 8679, train_loss 27.632593,Time used 0.008002s\n",
      "batch 8680, train_loss 29.845919,Time used 0.004999s\n",
      "batch 8681, train_loss 32.279804,Time used 0.006999s\n",
      "batch 8682, train_loss 28.873709,Time used 0.005000s\n",
      "batch 8683, train_loss 28.264774,Time used 0.007000s\n",
      "batch 8684, train_loss 31.609303,Time used 0.005006s\n",
      "batch 8685, train_loss 32.140709,Time used 0.006999s\n",
      "batch 8686, train_loss 36.528362,Time used 0.006002s\n",
      "batch 8687, train_loss 30.389004,Time used 0.006001s\n",
      "batch 8688, train_loss 28.664698,Time used 0.010035s\n",
      "batch 8689, train_loss 27.631626,Time used 0.005996s\n",
      "batch 8690, train_loss 33.532856,Time used 0.004999s\n",
      "batch 8691, train_loss 32.449986,Time used 0.006006s\n",
      "batch 8692, train_loss 23.196375,Time used 0.006997s\n",
      "batch 8693, train_loss 35.558235,Time used 0.004997s\n",
      "batch 8694, train_loss 34.723755,Time used 0.005001s\n",
      "batch 8695, train_loss 32.278599,Time used 0.004999s\n",
      "batch 8696, train_loss 29.806227,Time used 0.005000s\n",
      "batch 8697, train_loss 31.229479,Time used 0.005001s\n",
      "batch 8698, train_loss 26.647280,Time used 0.005004s\n",
      "batch 8699, train_loss 27.296309,Time used 0.004996s\n",
      "batch 8700, train_loss 30.062847,Time used 0.005999s\n",
      "***************************test_batch 8700, test_rmse_loss 6.937371,test_mae_loss 3.107480,test_mape_loss 52.437638,Time used 0.023001s\n",
      "batch 8701, train_loss 31.971916,Time used 0.006001s\n",
      "batch 8702, train_loss 31.997080,Time used 0.006029s\n",
      "batch 8703, train_loss 26.465574,Time used 0.006001s\n",
      "batch 8704, train_loss 30.869890,Time used 0.004997s\n",
      "batch 8705, train_loss 33.406197,Time used 0.005966s\n",
      "batch 8706, train_loss 26.098928,Time used 0.007000s\n",
      "batch 8707, train_loss 29.610441,Time used 0.008000s\n",
      "batch 8708, train_loss 35.800785,Time used 0.005000s\n",
      "batch 8709, train_loss 31.971006,Time used 0.005001s\n",
      "batch 8710, train_loss 25.106741,Time used 0.004996s\n",
      "batch 8711, train_loss 32.548492,Time used 0.005001s\n",
      "batch 8712, train_loss 35.456707,Time used 0.007001s\n",
      "batch 8713, train_loss 28.025038,Time used 0.007997s\n",
      "batch 8714, train_loss 31.489166,Time used 0.007999s\n",
      "batch 8715, train_loss 30.234039,Time used 0.008003s\n",
      "batch 8716, train_loss 29.170530,Time used 0.007000s\n",
      "batch 8717, train_loss 28.422716,Time used 0.005997s\n",
      "batch 8718, train_loss 36.531799,Time used 0.005998s\n",
      "batch 8719, train_loss 27.590509,Time used 0.008000s\n",
      "batch 8720, train_loss 32.853867,Time used 0.006001s\n",
      "batch 8721, train_loss 32.035980,Time used 0.005001s\n",
      "batch 8722, train_loss 29.887589,Time used 0.005999s\n",
      "batch 8723, train_loss 26.222771,Time used 0.008001s\n",
      "batch 8724, train_loss 30.243820,Time used 0.007994s\n",
      "batch 8725, train_loss 24.761251,Time used 0.008036s\n",
      "batch 8726, train_loss 36.649029,Time used 0.004999s\n",
      "batch 8727, train_loss 36.610603,Time used 0.004966s\n",
      "batch 8728, train_loss 28.060627,Time used 0.004999s\n",
      "batch 8729, train_loss 29.583088,Time used 0.007034s\n",
      "batch 8730, train_loss 26.102121,Time used 0.005000s\n",
      "batch 8731, train_loss 34.717571,Time used 0.005000s\n",
      "batch 8732, train_loss 29.620083,Time used 0.006967s\n",
      "batch 8733, train_loss 31.719936,Time used 0.004997s\n",
      "batch 8734, train_loss 29.559099,Time used 0.007003s\n",
      "batch 8735, train_loss 31.461929,Time used 0.005998s\n",
      "batch 8736, train_loss 33.561802,Time used 0.005001s\n",
      "batch 8737, train_loss 31.671043,Time used 0.004999s\n",
      "batch 8738, train_loss 29.308287,Time used 0.006001s\n",
      "batch 8739, train_loss 34.040329,Time used 0.004997s\n",
      "batch 8740, train_loss 30.509066,Time used 0.010001s\n",
      "batch 8741, train_loss 32.711414,Time used 0.007999s\n",
      "batch 8742, train_loss 31.785055,Time used 0.008000s\n",
      "batch 8743, train_loss 26.905157,Time used 0.008002s\n",
      "batch 8744, train_loss 29.220230,Time used 0.006001s\n",
      "batch 8745, train_loss 33.528358,Time used 0.006999s\n",
      "batch 8746, train_loss 29.947001,Time used 0.005000s\n",
      "batch 8747, train_loss 33.917198,Time used 0.006000s\n",
      "batch 8748, train_loss 30.328289,Time used 0.006001s\n",
      "batch 8749, train_loss 27.378466,Time used 0.004997s\n",
      "batch 8750, train_loss 30.408548,Time used 0.006001s\n",
      "batch 8751, train_loss 28.971378,Time used 0.005000s\n",
      "batch 8752, train_loss 24.906593,Time used 0.004999s\n",
      "batch 8753, train_loss 28.801033,Time used 0.005004s\n",
      "batch 8754, train_loss 35.220104,Time used 0.005999s\n",
      "batch 8755, train_loss 32.068729,Time used 0.005038s\n",
      "batch 8756, train_loss 35.354309,Time used 0.006961s\n",
      "batch 8757, train_loss 30.416330,Time used 0.007001s\n",
      "batch 8758, train_loss 30.537367,Time used 0.005999s\n",
      "batch 8759, train_loss 27.034307,Time used 0.005000s\n",
      "batch 8760, train_loss 28.514141,Time used 0.005000s\n",
      "batch 8761, train_loss 27.438417,Time used 0.004997s\n",
      "batch 8762, train_loss 32.910252,Time used 0.006002s\n",
      "batch 8763, train_loss 21.126959,Time used 0.004999s\n",
      "batch 8764, train_loss 33.831463,Time used 0.005999s\n",
      "batch 8765, train_loss 32.889591,Time used 0.006999s\n",
      "batch 8766, train_loss 29.626923,Time used 0.008000s\n",
      "batch 8767, train_loss 29.294886,Time used 0.006999s\n",
      "batch 8768, train_loss 29.597420,Time used 0.005001s\n",
      "batch 8769, train_loss 26.066805,Time used 0.005000s\n",
      "batch 8770, train_loss 30.224852,Time used 0.005000s\n",
      "batch 8771, train_loss 34.563442,Time used 0.005002s\n",
      "batch 8772, train_loss 30.512602,Time used 0.006001s\n",
      "batch 8773, train_loss 33.272537,Time used 0.005999s\n",
      "batch 8774, train_loss 30.784019,Time used 0.005003s\n",
      "batch 8775, train_loss 25.012932,Time used 0.004997s\n",
      "batch 8776, train_loss 28.962372,Time used 0.006001s\n",
      "batch 8777, train_loss 28.260796,Time used 0.005000s\n",
      "batch 8778, train_loss 33.364281,Time used 0.006000s\n",
      "batch 8779, train_loss 30.413080,Time used 0.005999s\n",
      "batch 8780, train_loss 37.575794,Time used 0.004999s\n",
      "batch 8781, train_loss 35.666855,Time used 0.005008s\n",
      "batch 8782, train_loss 32.891205,Time used 0.005030s\n",
      "batch 8783, train_loss 29.653316,Time used 0.004967s\n",
      "batch 8784, train_loss 27.920641,Time used 0.005997s\n",
      "batch 8785, train_loss 32.646286,Time used 0.004986s\n",
      "batch 8786, train_loss 28.789959,Time used 0.005977s\n",
      "batch 8787, train_loss 29.565819,Time used 0.004999s\n",
      "batch 8788, train_loss 28.021795,Time used 0.004999s\n",
      "batch 8789, train_loss 26.443480,Time used 0.005026s\n",
      "batch 8790, train_loss 32.698936,Time used 0.005011s\n",
      "batch 8791, train_loss 25.246319,Time used 0.004970s\n",
      "batch 8792, train_loss 35.838535,Time used 0.008034s\n",
      "batch 8793, train_loss 29.337831,Time used 0.006988s\n",
      "batch 8794, train_loss 31.170540,Time used 0.007974s\n",
      "batch 8795, train_loss 27.761154,Time used 0.009003s\n",
      "batch 8796, train_loss 34.386459,Time used 0.006000s\n",
      "batch 8797, train_loss 30.151272,Time used 0.005000s\n",
      "batch 8798, train_loss 34.230663,Time used 0.005000s\n",
      "batch 8799, train_loss 29.223751,Time used 0.008042s\n",
      "batch 8800, train_loss 28.614132,Time used 0.004990s\n",
      "***************************test_batch 8800, test_rmse_loss 6.980889,test_mae_loss 3.120629,test_mape_loss 51.980460,Time used 0.022998s\n",
      "batch 8801, train_loss 31.987659,Time used 0.007999s\n",
      "batch 8802, train_loss 36.398979,Time used 0.005004s\n",
      "batch 8803, train_loss 30.535053,Time used 0.005036s\n",
      "batch 8804, train_loss 34.514790,Time used 0.005001s\n",
      "batch 8805, train_loss 28.284903,Time used 0.007961s\n",
      "batch 8806, train_loss 28.971073,Time used 0.007998s\n",
      "batch 8807, train_loss 25.905027,Time used 0.006001s\n",
      "batch 8808, train_loss 30.515865,Time used 0.006000s\n",
      "batch 8809, train_loss 28.942049,Time used 0.005030s\n",
      "batch 8810, train_loss 26.892839,Time used 0.004999s\n",
      "batch 8811, train_loss 30.731897,Time used 0.005965s\n",
      "batch 8812, train_loss 28.022371,Time used 0.005000s\n",
      "batch 8813, train_loss 25.514452,Time used 0.006000s\n",
      "batch 8814, train_loss 35.621719,Time used 0.006002s\n",
      "batch 8815, train_loss 28.113808,Time used 0.008001s\n",
      "batch 8816, train_loss 29.707977,Time used 0.005997s\n",
      "batch 8817, train_loss 31.259132,Time used 0.005000s\n",
      "batch 8818, train_loss 26.607136,Time used 0.005001s\n",
      "batch 8819, train_loss 29.392754,Time used 0.005999s\n",
      "batch 8820, train_loss 28.739853,Time used 0.005001s\n",
      "batch 8821, train_loss 25.888958,Time used 0.005999s\n",
      "batch 8822, train_loss 27.552666,Time used 0.006001s\n",
      "batch 8823, train_loss 34.220772,Time used 0.005001s\n",
      "batch 8824, train_loss 31.536665,Time used 0.006001s\n",
      "batch 8825, train_loss 31.597311,Time used 0.004999s\n",
      "batch 8826, train_loss 40.308601,Time used 0.007002s\n",
      "batch 8827, train_loss 32.663364,Time used 0.006001s\n",
      "batch 8828, train_loss 27.331194,Time used 0.005998s\n",
      "batch 8829, train_loss 30.581579,Time used 0.006000s\n",
      "batch 8830, train_loss 33.968582,Time used 0.004997s\n",
      "batch 8831, train_loss 29.708715,Time used 0.008999s\n",
      "batch 8832, train_loss 35.294022,Time used 0.008001s\n",
      "batch 8833, train_loss 19.841372,Time used 0.004998s\n",
      "batch 8834, train_loss 40.705395,Time used 0.004998s\n",
      "batch 8835, train_loss 31.947615,Time used 0.005002s\n",
      "batch 8836, train_loss 27.854687,Time used 0.006001s\n",
      "batch 8837, train_loss 28.435795,Time used 0.004997s\n",
      "batch 8838, train_loss 30.551220,Time used 0.005000s\n",
      "batch 8839, train_loss 30.799755,Time used 0.006004s\n",
      "batch 8840, train_loss 33.318317,Time used 0.005034s\n",
      "batch 8841, train_loss 33.855549,Time used 0.004968s\n",
      "batch 8842, train_loss 25.499067,Time used 0.006002s\n",
      "batch 8843, train_loss 28.112129,Time used 0.004967s\n",
      "batch 8844, train_loss 32.168900,Time used 0.005040s\n",
      "batch 8845, train_loss 31.971201,Time used 0.006995s\n",
      "batch 8846, train_loss 27.730757,Time used 0.004000s\n",
      "batch 8847, train_loss 32.788986,Time used 0.004000s\n",
      "batch 8848, train_loss 27.972540,Time used 0.008000s\n",
      "batch 8849, train_loss 33.662876,Time used 0.004967s\n",
      "batch 8850, train_loss 24.017611,Time used 0.006995s\n",
      "batch 8851, train_loss 26.991545,Time used 0.007000s\n",
      "batch 8852, train_loss 33.799110,Time used 0.006000s\n",
      "batch 8853, train_loss 35.009048,Time used 0.005994s\n",
      "batch 8854, train_loss 31.219994,Time used 0.008003s\n",
      "batch 8855, train_loss 30.985033,Time used 0.004997s\n",
      "batch 8856, train_loss 30.283909,Time used 0.003999s\n",
      "batch 8857, train_loss 30.498838,Time used 0.006000s\n",
      "batch 8858, train_loss 30.928467,Time used 0.005999s\n",
      "batch 8859, train_loss 32.915939,Time used 0.005035s\n",
      "batch 8860, train_loss 30.130354,Time used 0.004968s\n",
      "batch 8861, train_loss 24.093565,Time used 0.005004s\n",
      "batch 8862, train_loss 26.281199,Time used 0.005998s\n",
      "batch 8863, train_loss 29.599340,Time used 0.004999s\n",
      "batch 8864, train_loss 28.020590,Time used 0.004998s\n",
      "batch 8865, train_loss 33.647385,Time used 0.005968s\n",
      "batch 8866, train_loss 26.743113,Time used 0.005002s\n",
      "batch 8867, train_loss 30.185495,Time used 0.004998s\n",
      "batch 8868, train_loss 31.985893,Time used 0.005034s\n",
      "batch 8869, train_loss 30.820768,Time used 0.005000s\n",
      "batch 8870, train_loss 34.313168,Time used 0.005003s\n",
      "batch 8871, train_loss 26.630735,Time used 0.005965s\n",
      "batch 8872, train_loss 27.946043,Time used 0.005034s\n",
      "batch 8873, train_loss 30.933640,Time used 0.005000s\n",
      "batch 8874, train_loss 29.460430,Time used 0.004966s\n",
      "batch 8875, train_loss 37.078339,Time used 0.005999s\n",
      "batch 8876, train_loss 28.149471,Time used 0.007005s\n",
      "batch 8877, train_loss 34.671345,Time used 0.005004s\n",
      "batch 8878, train_loss 29.357716,Time used 0.005000s\n",
      "batch 8879, train_loss 30.396967,Time used 0.006004s\n",
      "batch 8880, train_loss 33.224926,Time used 0.007003s\n",
      "batch 8881, train_loss 32.312805,Time used 0.007002s\n",
      "batch 8882, train_loss 30.074221,Time used 0.006998s\n",
      "batch 8883, train_loss 34.141994,Time used 0.008004s\n",
      "batch 8884, train_loss 27.296122,Time used 0.006998s\n",
      "batch 8885, train_loss 26.833078,Time used 0.006041s\n",
      "batch 8886, train_loss 32.172993,Time used 0.004997s\n",
      "batch 8887, train_loss 23.916977,Time used 0.006968s\n",
      "batch 8888, train_loss 32.499256,Time used 0.005001s\n",
      "batch 8889, train_loss 28.041931,Time used 0.005997s\n",
      "batch 8890, train_loss 34.861057,Time used 0.006999s\n",
      "batch 8891, train_loss 25.127718,Time used 0.008033s\n",
      "batch 8892, train_loss 30.531879,Time used 0.007967s\n",
      "batch 8893, train_loss 27.542795,Time used 0.005997s\n",
      "batch 8894, train_loss 31.714876,Time used 0.005037s\n",
      "batch 8895, train_loss 30.151768,Time used 0.004999s\n",
      "batch 8896, train_loss 32.460720,Time used 0.007962s\n",
      "batch 8897, train_loss 26.327719,Time used 0.008000s\n",
      "batch 8898, train_loss 35.562485,Time used 0.006004s\n",
      "batch 8899, train_loss 28.850050,Time used 0.005033s\n",
      "batch 8900, train_loss 32.025974,Time used 0.004998s\n",
      "***************************test_batch 8900, test_rmse_loss 6.965940,test_mae_loss 3.112433,test_mape_loss 51.853172,Time used 0.027963s\n",
      "batch 8901, train_loss 32.006081,Time used 0.006007s\n",
      "batch 8902, train_loss 29.824129,Time used 0.005001s\n",
      "batch 8903, train_loss 28.785713,Time used 0.006000s\n",
      "batch 8904, train_loss 33.865681,Time used 0.004995s\n",
      "batch 8905, train_loss 32.091854,Time used 0.006001s\n",
      "batch 8906, train_loss 26.150890,Time used 0.006999s\n",
      "batch 8907, train_loss 33.943005,Time used 0.006001s\n",
      "batch 8908, train_loss 30.686811,Time used 0.008001s\n",
      "batch 8909, train_loss 31.908899,Time used 0.008000s\n",
      "batch 8910, train_loss 22.544205,Time used 0.007999s\n",
      "batch 8911, train_loss 30.440247,Time used 0.007000s\n",
      "batch 8912, train_loss 29.304125,Time used 0.007000s\n",
      "batch 8913, train_loss 34.776810,Time used 0.005000s\n",
      "batch 8914, train_loss 26.197714,Time used 0.005000s\n",
      "batch 8915, train_loss 32.998348,Time used 0.006999s\n",
      "batch 8916, train_loss 32.588528,Time used 0.008000s\n",
      "batch 8917, train_loss 32.045052,Time used 0.005002s\n",
      "batch 8918, train_loss 34.349712,Time used 0.005000s\n",
      "batch 8919, train_loss 28.043978,Time used 0.005001s\n",
      "batch 8920, train_loss 30.885790,Time used 0.006000s\n",
      "batch 8921, train_loss 28.105326,Time used 0.005002s\n",
      "batch 8922, train_loss 35.791065,Time used 0.004997s\n",
      "batch 8923, train_loss 25.192028,Time used 0.005000s\n",
      "batch 8924, train_loss 25.824030,Time used 0.004998s\n",
      "batch 8925, train_loss 30.422066,Time used 0.005001s\n",
      "batch 8926, train_loss 28.667871,Time used 0.005000s\n",
      "batch 8927, train_loss 29.619436,Time used 0.006000s\n",
      "batch 8928, train_loss 33.274464,Time used 0.005000s\n",
      "batch 8929, train_loss 27.593811,Time used 0.004999s\n",
      "batch 8930, train_loss 26.644958,Time used 0.005998s\n",
      "batch 8931, train_loss 31.846909,Time used 0.006034s\n",
      "batch 8932, train_loss 36.382362,Time used 0.005000s\n",
      "batch 8933, train_loss 31.254831,Time used 0.006967s\n",
      "batch 8934, train_loss 28.267246,Time used 0.004998s\n",
      "batch 8935, train_loss 34.816330,Time used 0.005000s\n",
      "batch 8936, train_loss 30.571476,Time used 0.005002s\n",
      "batch 8937, train_loss 28.957771,Time used 0.007000s\n",
      "batch 8938, train_loss 29.199106,Time used 0.006000s\n",
      "batch 8939, train_loss 35.015095,Time used 0.007999s\n",
      "batch 8940, train_loss 31.306446,Time used 0.008003s\n",
      "batch 8941, train_loss 28.106817,Time used 0.010000s\n",
      "batch 8942, train_loss 24.715519,Time used 0.005999s\n",
      "batch 8943, train_loss 31.124046,Time used 0.005000s\n",
      "batch 8944, train_loss 33.277370,Time used 0.006000s\n",
      "batch 8945, train_loss 23.507078,Time used 0.006002s\n",
      "batch 8946, train_loss 28.978689,Time used 0.005002s\n",
      "batch 8947, train_loss 33.820290,Time used 0.005002s\n",
      "batch 8948, train_loss 30.554892,Time used 0.006997s\n",
      "batch 8949, train_loss 30.350685,Time used 0.005001s\n",
      "batch 8950, train_loss 32.212322,Time used 0.005998s\n",
      "batch 8951, train_loss 25.907230,Time used 0.005000s\n",
      "batch 8952, train_loss 30.580145,Time used 0.006000s\n",
      "batch 8953, train_loss 25.288385,Time used 0.008000s\n",
      "batch 8954, train_loss 27.145313,Time used 0.006001s\n",
      "batch 8955, train_loss 27.648638,Time used 0.004997s\n",
      "batch 8956, train_loss 30.908388,Time used 0.005000s\n",
      "batch 8957, train_loss 28.069294,Time used 0.005005s\n",
      "batch 8958, train_loss 28.196196,Time used 0.004996s\n",
      "batch 8959, train_loss 33.509281,Time used 0.005000s\n",
      "batch 8960, train_loss 29.088694,Time used 0.005996s\n",
      "batch 8961, train_loss 36.910145,Time used 0.005001s\n",
      "batch 8962, train_loss 32.039478,Time used 0.006002s\n",
      "batch 8963, train_loss 34.018948,Time used 0.005000s\n",
      "batch 8964, train_loss 30.575066,Time used 0.005001s\n",
      "batch 8965, train_loss 23.725189,Time used 0.004999s\n",
      "batch 8966, train_loss 29.021030,Time used 0.006001s\n",
      "batch 8967, train_loss 28.143074,Time used 0.007999s\n",
      "batch 8968, train_loss 29.323389,Time used 0.006999s\n",
      "batch 8969, train_loss 28.553253,Time used 0.005002s\n",
      "batch 8970, train_loss 32.163883,Time used 0.006000s\n",
      "batch 8971, train_loss 34.172665,Time used 0.006999s\n",
      "batch 8972, train_loss 27.228691,Time used 0.007001s\n",
      "batch 8973, train_loss 34.613876,Time used 0.006000s\n",
      "batch 8974, train_loss 30.772018,Time used 0.005998s\n",
      "batch 8975, train_loss 30.203459,Time used 0.005000s\n",
      "batch 8976, train_loss 32.712170,Time used 0.007002s\n",
      "batch 8977, train_loss 32.803223,Time used 0.007999s\n",
      "batch 8978, train_loss 29.649832,Time used 0.005034s\n",
      "batch 8979, train_loss 31.276793,Time used 0.006000s\n",
      "batch 8980, train_loss 27.035894,Time used 0.005002s\n",
      "batch 8981, train_loss 31.427755,Time used 0.004997s\n",
      "batch 8982, train_loss 28.637775,Time used 0.004996s\n",
      "batch 8983, train_loss 30.420639,Time used 0.005000s\n",
      "batch 8984, train_loss 32.980721,Time used 0.005000s\n",
      "batch 8985, train_loss 31.884996,Time used 0.006051s\n",
      "batch 8986, train_loss 26.685396,Time used 0.004988s\n",
      "batch 8987, train_loss 27.668491,Time used 0.004998s\n",
      "batch 8988, train_loss 26.275398,Time used 0.004962s\n",
      "batch 8989, train_loss 27.646317,Time used 0.005999s\n",
      "batch 8990, train_loss 30.659458,Time used 0.005001s\n",
      "batch 8991, train_loss 21.332684,Time used 0.006043s\n",
      "batch 8992, train_loss 35.332455,Time used 0.004996s\n",
      "batch 8993, train_loss 28.150908,Time used 0.004998s\n",
      "batch 8994, train_loss 39.740639,Time used 0.005963s\n",
      "batch 8995, train_loss 27.569923,Time used 0.005000s\n",
      "batch 8996, train_loss 30.283894,Time used 0.006000s\n",
      "batch 8997, train_loss 31.759476,Time used 0.005036s\n",
      "batch 8998, train_loss 31.306705,Time used 0.007000s\n",
      "batch 8999, train_loss 28.919939,Time used 0.006978s\n",
      "batch 9000, train_loss 33.188984,Time used 0.006999s\n",
      "***************************test_batch 9000, test_rmse_loss 6.924651,test_mae_loss 3.099282,test_mape_loss 52.026146,Time used 0.023004s\n",
      "batch 9001, train_loss 26.621613,Time used 0.004998s\n",
      "batch 9002, train_loss 27.695831,Time used 0.008039s\n",
      "batch 9003, train_loss 30.133432,Time used 0.005998s\n",
      "batch 9004, train_loss 31.646648,Time used 0.004964s\n",
      "batch 9005, train_loss 30.697844,Time used 0.005000s\n",
      "batch 9006, train_loss 28.773071,Time used 0.004997s\n",
      "batch 9007, train_loss 30.813675,Time used 0.006002s\n",
      "batch 9008, train_loss 29.620884,Time used 0.005998s\n",
      "batch 9009, train_loss 28.963646,Time used 0.005000s\n",
      "batch 9010, train_loss 35.575340,Time used 0.006000s\n",
      "batch 9011, train_loss 28.427153,Time used 0.005000s\n",
      "batch 9012, train_loss 35.890472,Time used 0.005000s\n",
      "batch 9013, train_loss 36.642002,Time used 0.006001s\n",
      "batch 9014, train_loss 26.884392,Time used 0.004999s\n",
      "batch 9015, train_loss 30.708080,Time used 0.005000s\n",
      "batch 9016, train_loss 26.774206,Time used 0.006001s\n",
      "batch 9017, train_loss 28.450050,Time used 0.008001s\n",
      "batch 9018, train_loss 35.459545,Time used 0.005999s\n",
      "batch 9019, train_loss 27.901985,Time used 0.005003s\n",
      "batch 9020, train_loss 31.170647,Time used 0.005002s\n",
      "batch 9021, train_loss 27.828627,Time used 0.006996s\n",
      "batch 9022, train_loss 30.460161,Time used 0.006999s\n",
      "batch 9023, train_loss 27.276283,Time used 0.006003s\n",
      "batch 9024, train_loss 26.688576,Time used 0.005998s\n",
      "batch 9025, train_loss 31.106949,Time used 0.004999s\n",
      "batch 9026, train_loss 33.630795,Time used 0.005000s\n",
      "batch 9027, train_loss 26.861670,Time used 0.004999s\n",
      "batch 9028, train_loss 31.567970,Time used 0.005001s\n",
      "batch 9029, train_loss 26.581396,Time used 0.005001s\n",
      "batch 9030, train_loss 32.359962,Time used 0.007000s\n",
      "batch 9031, train_loss 28.800259,Time used 0.004999s\n",
      "batch 9032, train_loss 28.009199,Time used 0.004999s\n",
      "batch 9033, train_loss 30.038559,Time used 0.006000s\n",
      "batch 9034, train_loss 29.533606,Time used 0.004998s\n",
      "batch 9035, train_loss 28.285664,Time used 0.006041s\n",
      "batch 9036, train_loss 27.612202,Time used 0.004995s\n",
      "batch 9037, train_loss 29.772488,Time used 0.005000s\n",
      "batch 9038, train_loss 28.486645,Time used 0.006000s\n",
      "batch 9039, train_loss 34.056667,Time used 0.006001s\n",
      "batch 9040, train_loss 34.530159,Time used 0.005002s\n",
      "batch 9041, train_loss 28.812372,Time used 0.004997s\n",
      "batch 9042, train_loss 28.441040,Time used 0.006969s\n",
      "batch 9043, train_loss 30.188314,Time used 0.004998s\n",
      "batch 9044, train_loss 32.233074,Time used 0.004997s\n",
      "batch 9045, train_loss 36.820614,Time used 0.005003s\n",
      "batch 9046, train_loss 26.570772,Time used 0.003999s\n",
      "batch 9047, train_loss 27.475643,Time used 0.005041s\n",
      "batch 9048, train_loss 28.216135,Time used 0.005963s\n",
      "batch 9049, train_loss 25.447786,Time used 0.006002s\n",
      "batch 9050, train_loss 34.364620,Time used 0.005001s\n",
      "batch 9051, train_loss 28.635895,Time used 0.006994s\n",
      "batch 9052, train_loss 31.505772,Time used 0.005007s\n",
      "batch 9053, train_loss 28.430466,Time used 0.006998s\n",
      "batch 9054, train_loss 30.321695,Time used 0.004997s\n",
      "batch 9055, train_loss 29.553616,Time used 0.006000s\n",
      "batch 9056, train_loss 28.567656,Time used 0.005000s\n",
      "batch 9057, train_loss 32.634338,Time used 0.005000s\n",
      "batch 9058, train_loss 30.051016,Time used 0.006003s\n",
      "batch 9059, train_loss 27.633600,Time used 0.007999s\n",
      "batch 9060, train_loss 28.908997,Time used 0.008004s\n",
      "batch 9061, train_loss 37.073635,Time used 0.008000s\n",
      "batch 9062, train_loss 27.893925,Time used 0.005001s\n",
      "batch 9063, train_loss 27.682579,Time used 0.005998s\n",
      "batch 9064, train_loss 29.756567,Time used 0.007001s\n",
      "batch 9065, train_loss 30.202196,Time used 0.008002s\n",
      "batch 9066, train_loss 29.490780,Time used 0.006001s\n",
      "batch 9067, train_loss 27.735859,Time used 0.004995s\n",
      "batch 9068, train_loss 31.525251,Time used 0.007000s\n",
      "batch 9069, train_loss 25.505232,Time used 0.005003s\n",
      "batch 9070, train_loss 31.120420,Time used 0.006037s\n",
      "batch 9071, train_loss 35.573330,Time used 0.005997s\n",
      "batch 9072, train_loss 29.496140,Time used 0.005000s\n",
      "batch 9073, train_loss 24.002689,Time used 0.008008s\n",
      "batch 9074, train_loss 31.628052,Time used 0.005955s\n",
      "batch 9075, train_loss 34.270458,Time used 0.007037s\n",
      "batch 9076, train_loss 31.946266,Time used 0.006962s\n",
      "batch 9077, train_loss 26.912064,Time used 0.005002s\n",
      "batch 9078, train_loss 29.979439,Time used 0.005000s\n",
      "batch 9079, train_loss 29.178713,Time used 0.005036s\n",
      "batch 9080, train_loss 33.455360,Time used 0.004965s\n",
      "batch 9081, train_loss 30.211483,Time used 0.005001s\n",
      "batch 9082, train_loss 32.991917,Time used 0.006996s\n",
      "batch 9083, train_loss 30.116894,Time used 0.008000s\n",
      "batch 9084, train_loss 29.240797,Time used 0.008040s\n",
      "batch 9085, train_loss 27.971762,Time used 0.007996s\n",
      "batch 9086, train_loss 30.840179,Time used 0.008000s\n",
      "batch 9087, train_loss 29.788031,Time used 0.005002s\n",
      "batch 9088, train_loss 32.069859,Time used 0.004964s\n",
      "batch 9089, train_loss 27.229704,Time used 0.004998s\n",
      "batch 9090, train_loss 27.099678,Time used 0.006002s\n",
      "batch 9091, train_loss 33.530396,Time used 0.006000s\n",
      "batch 9092, train_loss 29.264009,Time used 0.005000s\n",
      "batch 9093, train_loss 24.476688,Time used 0.006000s\n",
      "batch 9094, train_loss 30.466764,Time used 0.005998s\n",
      "batch 9095, train_loss 33.708908,Time used 0.008996s\n",
      "batch 9096, train_loss 27.721762,Time used 0.007039s\n",
      "batch 9097, train_loss 32.579418,Time used 0.006036s\n",
      "batch 9098, train_loss 28.493000,Time used 0.005004s\n",
      "batch 9099, train_loss 28.788837,Time used 0.004993s\n",
      "batch 9100, train_loss 26.345369,Time used 0.004963s\n",
      "***************************test_batch 9100, test_rmse_loss 6.937912,test_mae_loss 3.103010,test_mape_loss 51.852131,Time used 0.016040s\n",
      "batch 9101, train_loss 25.420689,Time used 0.006004s\n",
      "batch 9102, train_loss 27.281149,Time used 0.004961s\n",
      "batch 9103, train_loss 32.367687,Time used 0.005996s\n",
      "batch 9104, train_loss 31.345942,Time used 0.005004s\n",
      "batch 9105, train_loss 26.960352,Time used 0.005035s\n",
      "batch 9106, train_loss 31.680216,Time used 0.005964s\n",
      "batch 9107, train_loss 29.509277,Time used 0.004999s\n",
      "batch 9108, train_loss 25.077198,Time used 0.005001s\n",
      "batch 9109, train_loss 31.221100,Time used 0.006000s\n",
      "batch 9110, train_loss 29.458965,Time used 0.004999s\n",
      "batch 9111, train_loss 30.570433,Time used 0.004999s\n",
      "batch 9112, train_loss 32.927032,Time used 0.004997s\n",
      "batch 9113, train_loss 29.634474,Time used 0.004999s\n",
      "batch 9114, train_loss 33.696201,Time used 0.005997s\n",
      "batch 9115, train_loss 31.678064,Time used 0.007998s\n",
      "batch 9116, train_loss 29.518797,Time used 0.008007s\n",
      "batch 9117, train_loss 34.326374,Time used 0.005000s\n",
      "batch 9118, train_loss 31.575754,Time used 0.006032s\n",
      "batch 9119, train_loss 27.498253,Time used 0.004967s\n",
      "batch 9120, train_loss 28.614557,Time used 0.004998s\n",
      "batch 9121, train_loss 29.669201,Time used 0.006002s\n",
      "batch 9122, train_loss 29.080448,Time used 0.004996s\n",
      "batch 9123, train_loss 23.708103,Time used 0.005002s\n",
      "batch 9124, train_loss 41.137352,Time used 0.005996s\n",
      "batch 9125, train_loss 32.134140,Time used 0.005002s\n",
      "batch 9126, train_loss 30.117529,Time used 0.005999s\n",
      "batch 9127, train_loss 27.632967,Time used 0.006006s\n",
      "batch 9128, train_loss 23.504581,Time used 0.004995s\n",
      "batch 9129, train_loss 32.263653,Time used 0.006006s\n",
      "batch 9130, train_loss 35.532341,Time used 0.007002s\n",
      "batch 9131, train_loss 29.034355,Time used 0.009001s\n",
      "batch 9132, train_loss 30.013353,Time used 0.007997s\n",
      "batch 9133, train_loss 24.868923,Time used 0.005997s\n",
      "batch 9134, train_loss 27.238157,Time used 0.005000s\n",
      "batch 9135, train_loss 21.728432,Time used 0.005001s\n",
      "batch 9136, train_loss 33.745327,Time used 0.006004s\n",
      "batch 9137, train_loss 31.521250,Time used 0.004997s\n",
      "batch 9138, train_loss 32.475101,Time used 0.005998s\n",
      "batch 9139, train_loss 29.683908,Time used 0.006004s\n",
      "batch 9140, train_loss 23.026363,Time used 0.005000s\n",
      "batch 9141, train_loss 34.382076,Time used 0.005002s\n",
      "batch 9142, train_loss 29.178867,Time used 0.006994s\n",
      "batch 9143, train_loss 33.360989,Time used 0.006000s\n",
      "batch 9144, train_loss 31.019413,Time used 0.005000s\n",
      "batch 9145, train_loss 31.115337,Time used 0.006001s\n",
      "batch 9146, train_loss 37.187191,Time used 0.005003s\n",
      "batch 9147, train_loss 29.575438,Time used 0.004999s\n",
      "batch 9148, train_loss 27.515968,Time used 0.005999s\n",
      "batch 9149, train_loss 38.692917,Time used 0.005996s\n",
      "batch 9150, train_loss 30.179199,Time used 0.007000s\n",
      "batch 9151, train_loss 23.111296,Time used 0.008000s\n",
      "batch 9152, train_loss 29.139221,Time used 0.005002s\n",
      "batch 9153, train_loss 26.276621,Time used 0.004999s\n",
      "batch 9154, train_loss 30.905422,Time used 0.006003s\n",
      "batch 9155, train_loss 31.975706,Time used 0.004998s\n",
      "batch 9156, train_loss 28.495405,Time used 0.006002s\n",
      "batch 9157, train_loss 31.942896,Time used 0.007999s\n",
      "batch 9158, train_loss 26.000055,Time used 0.007001s\n",
      "batch 9159, train_loss 24.399525,Time used 0.005998s\n",
      "batch 9160, train_loss 24.612328,Time used 0.004999s\n",
      "batch 9161, train_loss 31.926409,Time used 0.005000s\n",
      "batch 9162, train_loss 28.657148,Time used 0.005991s\n",
      "batch 9163, train_loss 29.763790,Time used 0.005999s\n",
      "batch 9164, train_loss 33.698486,Time used 0.005006s\n",
      "batch 9165, train_loss 28.139658,Time used 0.004998s\n",
      "batch 9166, train_loss 32.140781,Time used 0.005002s\n",
      "batch 9167, train_loss 31.594023,Time used 0.006003s\n",
      "batch 9168, train_loss 27.312778,Time used 0.006999s\n",
      "batch 9169, train_loss 29.229576,Time used 0.007998s\n",
      "batch 9170, train_loss 24.964231,Time used 0.006002s\n",
      "batch 9171, train_loss 34.907722,Time used 0.005000s\n",
      "batch 9172, train_loss 29.024492,Time used 0.005002s\n",
      "batch 9173, train_loss 30.102057,Time used 0.005995s\n",
      "batch 9174, train_loss 31.003380,Time used 0.005001s\n",
      "batch 9175, train_loss 29.461164,Time used 0.005999s\n",
      "batch 9176, train_loss 33.787605,Time used 0.005002s\n",
      "batch 9177, train_loss 27.470753,Time used 0.005001s\n",
      "batch 9178, train_loss 28.688400,Time used 0.004999s\n",
      "batch 9179, train_loss 31.555996,Time used 0.005000s\n",
      "batch 9180, train_loss 28.184338,Time used 0.004998s\n",
      "batch 9181, train_loss 29.061298,Time used 0.005999s\n",
      "batch 9182, train_loss 28.289934,Time used 0.005000s\n",
      "batch 9183, train_loss 32.065182,Time used 0.005001s\n",
      "batch 9184, train_loss 24.659925,Time used 0.005000s\n",
      "batch 9185, train_loss 28.620840,Time used 0.005003s\n",
      "batch 9186, train_loss 36.413525,Time used 0.005000s\n",
      "batch 9187, train_loss 30.674572,Time used 0.004999s\n",
      "batch 9188, train_loss 21.842144,Time used 0.005000s\n",
      "batch 9189, train_loss 30.630453,Time used 0.006002s\n",
      "batch 9190, train_loss 31.510283,Time used 0.004999s\n",
      "batch 9191, train_loss 28.914253,Time used 0.004996s\n",
      "batch 9192, train_loss 32.936539,Time used 0.004001s\n",
      "batch 9193, train_loss 33.298252,Time used 0.004999s\n",
      "batch 9194, train_loss 29.781334,Time used 0.005000s\n",
      "batch 9195, train_loss 28.519356,Time used 0.005000s\n",
      "batch 9196, train_loss 27.887840,Time used 0.005038s\n",
      "batch 9197, train_loss 31.005716,Time used 0.003967s\n",
      "batch 9198, train_loss 31.427370,Time used 0.005032s\n",
      "batch 9199, train_loss 30.782768,Time used 0.006968s\n",
      "batch 9200, train_loss 26.713026,Time used 0.008000s\n",
      "***************************test_batch 9200, test_rmse_loss 6.853831,test_mae_loss 3.076721,test_mape_loss 52.236431,Time used 0.019002s\n",
      "batch 9201, train_loss 30.632528,Time used 0.004999s\n",
      "batch 9202, train_loss 28.194221,Time used 0.006000s\n",
      "batch 9203, train_loss 33.557709,Time used 0.004999s\n",
      "batch 9204, train_loss 30.083662,Time used 0.004997s\n",
      "batch 9205, train_loss 24.723068,Time used 0.006002s\n",
      "batch 9206, train_loss 29.927336,Time used 0.006000s\n",
      "batch 9207, train_loss 28.805513,Time used 0.005001s\n",
      "batch 9208, train_loss 29.979193,Time used 0.005000s\n",
      "batch 9209, train_loss 28.961447,Time used 0.004994s\n",
      "batch 9210, train_loss 29.206877,Time used 0.006001s\n",
      "batch 9211, train_loss 34.200191,Time used 0.006003s\n",
      "batch 9212, train_loss 29.985041,Time used 0.004999s\n",
      "batch 9213, train_loss 30.620165,Time used 0.005000s\n",
      "batch 9214, train_loss 27.259056,Time used 0.005033s\n",
      "batch 9215, train_loss 26.705332,Time used 0.004998s\n",
      "batch 9216, train_loss 30.048222,Time used 0.004999s\n",
      "batch 9217, train_loss 27.657032,Time used 0.008002s\n",
      "batch 9218, train_loss 26.604963,Time used 0.005967s\n",
      "batch 9219, train_loss 24.098694,Time used 0.005031s\n",
      "batch 9220, train_loss 30.028933,Time used 0.006968s\n",
      "batch 9221, train_loss 28.775629,Time used 0.005034s\n",
      "batch 9222, train_loss 27.800613,Time used 0.005998s\n",
      "batch 9223, train_loss 29.829744,Time used 0.005968s\n",
      "batch 9224, train_loss 28.388866,Time used 0.004999s\n",
      "batch 9225, train_loss 35.761456,Time used 0.005997s\n",
      "batch 9226, train_loss 29.297781,Time used 0.006999s\n",
      "batch 9227, train_loss 31.775890,Time used 0.007999s\n",
      "batch 9228, train_loss 35.118481,Time used 0.006000s\n",
      "batch 9229, train_loss 25.325289,Time used 0.005004s\n",
      "batch 9230, train_loss 29.756247,Time used 0.007000s\n",
      "batch 9231, train_loss 27.940691,Time used 0.008000s\n",
      "batch 9232, train_loss 31.416658,Time used 0.007000s\n",
      "batch 9233, train_loss 35.546150,Time used 0.005995s\n",
      "batch 9234, train_loss 28.052992,Time used 0.006003s\n",
      "batch 9235, train_loss 30.283516,Time used 0.004999s\n",
      "batch 9236, train_loss 28.960045,Time used 0.005000s\n",
      "batch 9237, train_loss 35.183956,Time used 0.006001s\n",
      "batch 9238, train_loss 33.171616,Time used 0.006000s\n",
      "batch 9239, train_loss 23.732382,Time used 0.007000s\n",
      "batch 9240, train_loss 26.559916,Time used 0.004998s\n",
      "batch 9241, train_loss 31.781721,Time used 0.005000s\n",
      "batch 9242, train_loss 33.373863,Time used 0.005998s\n",
      "batch 9243, train_loss 25.257017,Time used 0.005002s\n",
      "batch 9244, train_loss 30.354998,Time used 0.008033s\n",
      "batch 9245, train_loss 27.286558,Time used 0.006000s\n",
      "batch 9246, train_loss 28.701365,Time used 0.005000s\n",
      "batch 9247, train_loss 26.057421,Time used 0.004999s\n",
      "batch 9248, train_loss 31.583399,Time used 0.005000s\n",
      "batch 9249, train_loss 28.166203,Time used 0.006001s\n",
      "batch 9250, train_loss 33.098869,Time used 0.004966s\n",
      "batch 9251, train_loss 25.336226,Time used 0.009001s\n",
      "batch 9252, train_loss 26.255192,Time used 0.004995s\n",
      "batch 9253, train_loss 32.961449,Time used 0.008035s\n",
      "batch 9254, train_loss 27.487091,Time used 0.008003s\n",
      "batch 9255, train_loss 29.666553,Time used 0.007960s\n",
      "batch 9256, train_loss 26.296530,Time used 0.007000s\n",
      "batch 9257, train_loss 31.049513,Time used 0.006001s\n",
      "batch 9258, train_loss 33.372917,Time used 0.005004s\n",
      "batch 9259, train_loss 30.168745,Time used 0.005031s\n",
      "batch 9260, train_loss 28.510048,Time used 0.007964s\n",
      "batch 9261, train_loss 30.948067,Time used 0.007000s\n",
      "batch 9262, train_loss 33.985100,Time used 0.008041s\n",
      "batch 9263, train_loss 27.080187,Time used 0.004995s\n",
      "batch 9264, train_loss 31.212563,Time used 0.005966s\n",
      "batch 9265, train_loss 33.678547,Time used 0.004999s\n",
      "batch 9266, train_loss 24.182592,Time used 0.006001s\n",
      "batch 9267, train_loss 29.514973,Time used 0.003998s\n",
      "batch 9268, train_loss 33.913231,Time used 0.005000s\n",
      "batch 9269, train_loss 30.629366,Time used 0.008002s\n",
      "batch 9270, train_loss 35.979134,Time used 0.005000s\n",
      "batch 9271, train_loss 25.448273,Time used 0.005999s\n",
      "batch 9272, train_loss 30.582012,Time used 0.005000s\n",
      "batch 9273, train_loss 30.135586,Time used 0.005002s\n",
      "batch 9274, train_loss 30.656563,Time used 0.005001s\n",
      "batch 9275, train_loss 26.479771,Time used 0.005003s\n",
      "batch 9276, train_loss 32.807255,Time used 0.004997s\n",
      "batch 9277, train_loss 26.393620,Time used 0.005996s\n",
      "batch 9278, train_loss 31.457701,Time used 0.006000s\n",
      "batch 9279, train_loss 29.743212,Time used 0.005000s\n",
      "batch 9280, train_loss 27.503580,Time used 0.005040s\n",
      "batch 9281, train_loss 29.583359,Time used 0.003999s\n",
      "batch 9282, train_loss 28.326719,Time used 0.003998s\n",
      "batch 9283, train_loss 22.084328,Time used 0.005000s\n",
      "batch 9284, train_loss 32.512402,Time used 0.004966s\n",
      "batch 9285, train_loss 30.990385,Time used 0.005031s\n",
      "batch 9286, train_loss 27.930140,Time used 0.006967s\n",
      "batch 9287, train_loss 27.865204,Time used 0.005001s\n",
      "batch 9288, train_loss 30.426144,Time used 0.004999s\n",
      "batch 9289, train_loss 31.933044,Time used 0.007963s\n",
      "batch 9290, train_loss 30.368683,Time used 0.007999s\n",
      "batch 9291, train_loss 31.464844,Time used 0.008002s\n",
      "batch 9292, train_loss 36.656689,Time used 0.007000s\n",
      "batch 9293, train_loss 32.336288,Time used 0.008002s\n",
      "batch 9294, train_loss 27.947519,Time used 0.006000s\n",
      "batch 9295, train_loss 23.796614,Time used 0.005997s\n",
      "batch 9296, train_loss 33.870270,Time used 0.007035s\n",
      "batch 9297, train_loss 30.538780,Time used 0.004997s\n",
      "batch 9298, train_loss 25.818703,Time used 0.005001s\n",
      "batch 9299, train_loss 32.952038,Time used 0.004970s\n",
      "batch 9300, train_loss 31.891609,Time used 0.005029s\n",
      "***************************test_batch 9300, test_rmse_loss 6.887135,test_mae_loss 3.085545,test_mape_loss 51.982153,Time used 0.017001s\n",
      "batch 9301, train_loss 30.720097,Time used 0.006006s\n",
      "batch 9302, train_loss 24.360659,Time used 0.004994s\n",
      "batch 9303, train_loss 30.559481,Time used 0.004966s\n",
      "batch 9304, train_loss 31.995686,Time used 0.005034s\n",
      "batch 9305, train_loss 25.492828,Time used 0.007967s\n",
      "batch 9306, train_loss 26.790064,Time used 0.005033s\n",
      "batch 9307, train_loss 30.106533,Time used 0.005967s\n",
      "batch 9308, train_loss 22.561062,Time used 0.004995s\n",
      "batch 9309, train_loss 31.337633,Time used 0.005038s\n",
      "batch 9310, train_loss 26.900127,Time used 0.005966s\n",
      "batch 9311, train_loss 30.217794,Time used 0.005000s\n",
      "batch 9312, train_loss 27.051609,Time used 0.005000s\n",
      "batch 9313, train_loss 28.956457,Time used 0.004998s\n",
      "batch 9314, train_loss 30.356018,Time used 0.005004s\n",
      "batch 9315, train_loss 27.816442,Time used 0.006000s\n",
      "batch 9316, train_loss 31.950546,Time used 0.007001s\n",
      "batch 9317, train_loss 31.230152,Time used 0.007998s\n",
      "batch 9318, train_loss 29.868044,Time used 0.005040s\n",
      "batch 9319, train_loss 25.868536,Time used 0.004961s\n",
      "batch 9320, train_loss 33.411163,Time used 0.009004s\n",
      "batch 9321, train_loss 34.296772,Time used 0.006999s\n",
      "batch 9322, train_loss 31.684650,Time used 0.007996s\n",
      "batch 9323, train_loss 27.671265,Time used 0.007005s\n",
      "batch 9324, train_loss 30.879511,Time used 0.006994s\n",
      "batch 9325, train_loss 26.529594,Time used 0.007998s\n",
      "batch 9326, train_loss 31.915392,Time used 0.005001s\n",
      "batch 9327, train_loss 29.683754,Time used 0.006000s\n",
      "batch 9328, train_loss 27.458597,Time used 0.006000s\n",
      "batch 9329, train_loss 25.872137,Time used 0.005000s\n",
      "batch 9330, train_loss 29.662870,Time used 0.005001s\n",
      "batch 9331, train_loss 37.504868,Time used 0.005000s\n",
      "batch 9332, train_loss 28.914770,Time used 0.004999s\n",
      "batch 9333, train_loss 27.146481,Time used 0.005000s\n",
      "batch 9334, train_loss 25.828602,Time used 0.005000s\n",
      "batch 9335, train_loss 22.540995,Time used 0.007000s\n",
      "batch 9336, train_loss 30.111055,Time used 0.004999s\n",
      "batch 9337, train_loss 30.072065,Time used 0.004998s\n",
      "batch 9338, train_loss 26.874197,Time used 0.006000s\n",
      "batch 9339, train_loss 29.056778,Time used 0.006998s\n",
      "batch 9340, train_loss 32.281990,Time used 0.007000s\n",
      "batch 9341, train_loss 29.195675,Time used 0.007999s\n",
      "batch 9342, train_loss 37.445328,Time used 0.008000s\n",
      "batch 9343, train_loss 32.328354,Time used 0.008000s\n",
      "batch 9344, train_loss 25.357010,Time used 0.004999s\n",
      "batch 9345, train_loss 30.084614,Time used 0.005000s\n",
      "batch 9346, train_loss 33.613369,Time used 0.006000s\n",
      "batch 9347, train_loss 29.879297,Time used 0.005000s\n",
      "batch 9348, train_loss 28.088320,Time used 0.007001s\n",
      "batch 9349, train_loss 27.944866,Time used 0.005999s\n",
      "batch 9350, train_loss 30.804914,Time used 0.004999s\n",
      "batch 9351, train_loss 30.384228,Time used 0.008002s\n",
      "batch 9352, train_loss 29.583324,Time used 0.004998s\n",
      "batch 9353, train_loss 30.675364,Time used 0.006002s\n",
      "batch 9354, train_loss 27.468887,Time used 0.004998s\n",
      "batch 9355, train_loss 25.346870,Time used 0.005000s\n",
      "batch 9356, train_loss 27.599241,Time used 0.006004s\n",
      "batch 9357, train_loss 31.503563,Time used 0.007997s\n",
      "batch 9358, train_loss 28.966324,Time used 0.005000s\n",
      "batch 9359, train_loss 24.716328,Time used 0.007999s\n",
      "batch 9360, train_loss 26.454998,Time used 0.005000s\n",
      "batch 9361, train_loss 30.603937,Time used 0.007001s\n",
      "batch 9362, train_loss 24.246613,Time used 0.006000s\n",
      "batch 9363, train_loss 30.140808,Time used 0.007999s\n",
      "batch 9364, train_loss 36.543674,Time used 0.005038s\n",
      "batch 9365, train_loss 24.696705,Time used 0.004970s\n",
      "batch 9366, train_loss 25.562567,Time used 0.004995s\n",
      "batch 9367, train_loss 32.693008,Time used 0.005000s\n",
      "batch 9368, train_loss 29.232664,Time used 0.007997s\n",
      "batch 9369, train_loss 28.505846,Time used 0.007999s\n",
      "batch 9370, train_loss 26.019283,Time used 0.008000s\n",
      "batch 9371, train_loss 31.600826,Time used 0.005001s\n",
      "batch 9372, train_loss 32.288071,Time used 0.006998s\n",
      "batch 9373, train_loss 30.087830,Time used 0.005000s\n",
      "batch 9374, train_loss 26.540941,Time used 0.005000s\n",
      "batch 9375, train_loss 29.380821,Time used 0.006000s\n",
      "batch 9376, train_loss 32.142464,Time used 0.005999s\n",
      "batch 9377, train_loss 30.569546,Time used 0.005003s\n",
      "batch 9378, train_loss 31.203749,Time used 0.004998s\n",
      "batch 9379, train_loss 30.127695,Time used 0.006001s\n",
      "batch 9380, train_loss 32.764652,Time used 0.005002s\n",
      "batch 9381, train_loss 21.648798,Time used 0.004995s\n",
      "batch 9382, train_loss 28.921326,Time used 0.005002s\n",
      "batch 9383, train_loss 28.546860,Time used 0.005999s\n",
      "batch 9384, train_loss 30.516911,Time used 0.005001s\n",
      "batch 9385, train_loss 29.430214,Time used 0.005035s\n",
      "batch 9386, train_loss 29.706884,Time used 0.005003s\n",
      "batch 9387, train_loss 31.820637,Time used 0.007039s\n",
      "batch 9388, train_loss 27.735352,Time used 0.004997s\n",
      "batch 9389, train_loss 30.873701,Time used 0.005964s\n",
      "batch 9390, train_loss 31.087879,Time used 0.007000s\n",
      "batch 9391, train_loss 31.255697,Time used 0.006000s\n",
      "batch 9392, train_loss 28.938227,Time used 0.007999s\n",
      "batch 9393, train_loss 31.956928,Time used 0.005001s\n",
      "batch 9394, train_loss 26.877180,Time used 0.004999s\n",
      "batch 9395, train_loss 30.384016,Time used 0.008002s\n",
      "batch 9396, train_loss 30.202007,Time used 0.007999s\n",
      "batch 9397, train_loss 34.185787,Time used 0.007001s\n",
      "batch 9398, train_loss 29.077389,Time used 0.005000s\n",
      "batch 9399, train_loss 26.642506,Time used 0.008001s\n",
      "batch 9400, train_loss 29.922960,Time used 0.005999s\n",
      "***************************test_batch 9400, test_rmse_loss 6.901144,test_mae_loss 3.089452,test_mape_loss 51.612346,Time used 0.025000s\n",
      "batch 9401, train_loss 27.741766,Time used 0.006001s\n",
      "batch 9402, train_loss 28.260094,Time used 0.004999s\n",
      "batch 9403, train_loss 24.249714,Time used 0.006001s\n",
      "batch 9404, train_loss 34.540878,Time used 0.004997s\n",
      "batch 9405, train_loss 27.118366,Time used 0.006002s\n",
      "batch 9406, train_loss 27.779018,Time used 0.008000s\n",
      "batch 9407, train_loss 29.904928,Time used 0.005999s\n",
      "batch 9408, train_loss 23.682920,Time used 0.006999s\n",
      "batch 9409, train_loss 25.971416,Time used 0.008002s\n",
      "batch 9410, train_loss 27.337164,Time used 0.005035s\n",
      "batch 9411, train_loss 26.166382,Time used 0.006000s\n",
      "batch 9412, train_loss 32.691509,Time used 0.005002s\n",
      "batch 9413, train_loss 39.208248,Time used 0.004964s\n",
      "batch 9414, train_loss 31.688334,Time used 0.005999s\n",
      "batch 9415, train_loss 28.551502,Time used 0.005000s\n",
      "batch 9416, train_loss 29.972797,Time used 0.006000s\n",
      "batch 9417, train_loss 29.489740,Time used 0.005034s\n",
      "batch 9418, train_loss 29.232582,Time used 0.004967s\n",
      "batch 9419, train_loss 26.657780,Time used 0.004999s\n",
      "batch 9420, train_loss 31.717144,Time used 0.007000s\n",
      "batch 9421, train_loss 27.880589,Time used 0.007039s\n",
      "batch 9422, train_loss 33.493294,Time used 0.007994s\n",
      "batch 9423, train_loss 28.410889,Time used 0.007001s\n",
      "batch 9424, train_loss 28.215876,Time used 0.005969s\n",
      "batch 9425, train_loss 28.487881,Time used 0.006001s\n",
      "batch 9426, train_loss 28.976278,Time used 0.007000s\n",
      "batch 9427, train_loss 34.296833,Time used 0.007000s\n",
      "batch 9428, train_loss 28.094597,Time used 0.008000s\n",
      "batch 9429, train_loss 19.594313,Time used 0.005001s\n",
      "batch 9430, train_loss 26.039085,Time used 0.004999s\n",
      "batch 9431, train_loss 30.655426,Time used 0.007002s\n",
      "batch 9432, train_loss 29.779814,Time used 0.007994s\n",
      "batch 9433, train_loss 32.081612,Time used 0.005001s\n",
      "batch 9434, train_loss 26.744421,Time used 0.005000s\n",
      "batch 9435, train_loss 33.702988,Time used 0.006002s\n",
      "batch 9436, train_loss 23.675541,Time used 0.006001s\n",
      "batch 9437, train_loss 26.081718,Time used 0.005996s\n",
      "batch 9438, train_loss 23.189980,Time used 0.007004s\n",
      "batch 9439, train_loss 34.108372,Time used 0.007001s\n",
      "batch 9440, train_loss 29.546455,Time used 0.006001s\n",
      "batch 9441, train_loss 26.328579,Time used 0.004997s\n",
      "batch 9442, train_loss 30.457451,Time used 0.004999s\n",
      "batch 9443, train_loss 28.690437,Time used 0.007001s\n",
      "batch 9444, train_loss 28.106966,Time used 0.005000s\n",
      "batch 9445, train_loss 28.384220,Time used 0.006004s\n",
      "batch 9446, train_loss 37.162113,Time used 0.005000s\n",
      "batch 9447, train_loss 33.441902,Time used 0.004000s\n",
      "batch 9448, train_loss 35.045063,Time used 0.005999s\n",
      "batch 9449, train_loss 33.244408,Time used 0.005002s\n",
      "batch 9450, train_loss 25.807325,Time used 0.005000s\n",
      "batch 9451, train_loss 30.758114,Time used 0.005997s\n",
      "batch 9452, train_loss 26.803715,Time used 0.007036s\n",
      "batch 9453, train_loss 26.763247,Time used 0.004965s\n",
      "batch 9454, train_loss 29.601715,Time used 0.006036s\n",
      "batch 9455, train_loss 26.598671,Time used 0.006999s\n",
      "batch 9456, train_loss 24.666637,Time used 0.006967s\n",
      "batch 9457, train_loss 29.269913,Time used 0.004997s\n",
      "batch 9458, train_loss 31.591759,Time used 0.007033s\n",
      "batch 9459, train_loss 31.868204,Time used 0.006961s\n",
      "batch 9460, train_loss 23.542036,Time used 0.005040s\n",
      "batch 9461, train_loss 28.623978,Time used 0.004996s\n",
      "batch 9462, train_loss 28.487858,Time used 0.007004s\n",
      "batch 9463, train_loss 27.645790,Time used 0.005966s\n",
      "batch 9464, train_loss 25.693155,Time used 0.005032s\n",
      "batch 9465, train_loss 32.201649,Time used 0.006000s\n",
      "batch 9466, train_loss 36.882828,Time used 0.005008s\n",
      "batch 9467, train_loss 28.890823,Time used 0.004966s\n",
      "batch 9468, train_loss 21.841892,Time used 0.005961s\n",
      "batch 9469, train_loss 23.820385,Time used 0.005033s\n",
      "batch 9470, train_loss 32.656387,Time used 0.005002s\n",
      "batch 9471, train_loss 29.412161,Time used 0.006960s\n",
      "batch 9472, train_loss 32.170887,Time used 0.005000s\n",
      "batch 9473, train_loss 32.871239,Time used 0.005000s\n",
      "batch 9474, train_loss 29.686600,Time used 0.005037s\n",
      "batch 9475, train_loss 33.983669,Time used 0.004999s\n",
      "batch 9476, train_loss 28.334959,Time used 0.005965s\n",
      "batch 9477, train_loss 24.981762,Time used 0.004998s\n",
      "batch 9478, train_loss 30.249649,Time used 0.005000s\n",
      "batch 9479, train_loss 23.930889,Time used 0.006001s\n",
      "batch 9480, train_loss 32.311478,Time used 0.005000s\n",
      "batch 9481, train_loss 29.559240,Time used 0.006001s\n",
      "batch 9482, train_loss 29.329630,Time used 0.004999s\n",
      "batch 9483, train_loss 29.496611,Time used 0.005000s\n",
      "batch 9484, train_loss 28.566385,Time used 0.005000s\n",
      "batch 9485, train_loss 34.053303,Time used 0.006000s\n",
      "batch 9486, train_loss 25.116602,Time used 0.005000s\n",
      "batch 9487, train_loss 31.640839,Time used 0.008000s\n",
      "batch 9488, train_loss 27.772270,Time used 0.008001s\n",
      "batch 9489, train_loss 27.624104,Time used 0.005034s\n",
      "batch 9490, train_loss 26.360754,Time used 0.006003s\n",
      "batch 9491, train_loss 28.518574,Time used 0.004999s\n",
      "batch 9492, train_loss 30.074366,Time used 0.005964s\n",
      "batch 9493, train_loss 27.794102,Time used 0.004998s\n",
      "batch 9494, train_loss 29.842775,Time used 0.005007s\n",
      "batch 9495, train_loss 30.832470,Time used 0.007998s\n",
      "batch 9496, train_loss 25.452919,Time used 0.005032s\n",
      "batch 9497, train_loss 31.396481,Time used 0.005964s\n",
      "batch 9498, train_loss 27.253595,Time used 0.004999s\n",
      "batch 9499, train_loss 34.401897,Time used 0.006001s\n",
      "batch 9500, train_loss 25.387280,Time used 0.005000s\n",
      "***************************test_batch 9500, test_rmse_loss 6.873507,test_mae_loss 3.079319,test_mape_loss 51.689737,Time used 0.021004s\n",
      "batch 9501, train_loss 32.759907,Time used 0.004999s\n",
      "batch 9502, train_loss 27.421144,Time used 0.005002s\n",
      "batch 9503, train_loss 26.567238,Time used 0.005998s\n",
      "batch 9504, train_loss 32.250229,Time used 0.005002s\n",
      "batch 9505, train_loss 31.698959,Time used 0.004994s\n",
      "batch 9506, train_loss 32.881470,Time used 0.005001s\n",
      "batch 9507, train_loss 29.022930,Time used 0.005000s\n",
      "batch 9508, train_loss 28.629530,Time used 0.005001s\n",
      "batch 9509, train_loss 29.695230,Time used 0.006960s\n",
      "batch 9510, train_loss 26.166336,Time used 0.007999s\n",
      "batch 9511, train_loss 30.627913,Time used 0.007001s\n",
      "batch 9512, train_loss 25.689253,Time used 0.007999s\n",
      "batch 9513, train_loss 32.039356,Time used 0.007000s\n",
      "batch 9514, train_loss 29.637140,Time used 0.008003s\n",
      "batch 9515, train_loss 25.836954,Time used 0.007999s\n",
      "batch 9516, train_loss 28.082806,Time used 0.006999s\n",
      "batch 9517, train_loss 31.672987,Time used 0.007001s\n",
      "batch 9518, train_loss 29.455448,Time used 0.007998s\n",
      "batch 9519, train_loss 24.532478,Time used 0.007001s\n",
      "batch 9520, train_loss 29.358423,Time used 0.008998s\n",
      "batch 9521, train_loss 26.111937,Time used 0.007005s\n",
      "batch 9522, train_loss 27.748512,Time used 0.005030s\n",
      "batch 9523, train_loss 31.081137,Time used 0.005968s\n",
      "batch 9524, train_loss 26.387468,Time used 0.005003s\n",
      "batch 9525, train_loss 30.617622,Time used 0.005000s\n",
      "batch 9526, train_loss 32.285789,Time used 0.005000s\n",
      "batch 9527, train_loss 30.125015,Time used 0.005000s\n",
      "batch 9528, train_loss 28.345991,Time used 0.004004s\n",
      "batch 9529, train_loss 27.878326,Time used 0.008031s\n",
      "batch 9530, train_loss 27.196972,Time used 0.006002s\n",
      "batch 9531, train_loss 27.637800,Time used 0.005001s\n",
      "batch 9532, train_loss 27.258926,Time used 0.005008s\n",
      "batch 9533, train_loss 27.396708,Time used 0.005959s\n",
      "batch 9534, train_loss 37.828369,Time used 0.004997s\n",
      "batch 9535, train_loss 32.120926,Time used 0.006000s\n",
      "batch 9536, train_loss 28.068310,Time used 0.006000s\n",
      "batch 9537, train_loss 28.488871,Time used 0.007998s\n",
      "batch 9538, train_loss 32.968014,Time used 0.005000s\n",
      "batch 9539, train_loss 26.811131,Time used 0.005000s\n",
      "batch 9540, train_loss 32.748749,Time used 0.005001s\n",
      "batch 9541, train_loss 27.168449,Time used 0.006000s\n",
      "batch 9542, train_loss 28.961761,Time used 0.005000s\n",
      "batch 9543, train_loss 28.844704,Time used 0.008039s\n",
      "batch 9544, train_loss 30.757345,Time used 0.007965s\n",
      "batch 9545, train_loss 27.242054,Time used 0.006000s\n",
      "batch 9546, train_loss 28.073120,Time used 0.005999s\n",
      "batch 9547, train_loss 32.255169,Time used 0.005035s\n",
      "batch 9548, train_loss 23.342436,Time used 0.005001s\n",
      "batch 9549, train_loss 27.047977,Time used 0.005964s\n",
      "batch 9550, train_loss 26.969664,Time used 0.009000s\n",
      "batch 9551, train_loss 30.633553,Time used 0.008003s\n",
      "batch 9552, train_loss 29.117340,Time used 0.005032s\n",
      "batch 9553, train_loss 32.994228,Time used 0.005031s\n",
      "batch 9554, train_loss 31.672750,Time used 0.005003s\n",
      "batch 9555, train_loss 30.921671,Time used 0.005998s\n",
      "batch 9556, train_loss 26.091892,Time used 0.004963s\n",
      "batch 9557, train_loss 27.794647,Time used 0.005999s\n",
      "batch 9558, train_loss 24.849148,Time used 0.005000s\n",
      "batch 9559, train_loss 26.175064,Time used 0.008045s\n",
      "batch 9560, train_loss 22.856699,Time used 0.007953s\n",
      "batch 9561, train_loss 30.255699,Time used 0.005003s\n",
      "batch 9562, train_loss 32.496170,Time used 0.005001s\n",
      "batch 9563, train_loss 35.992420,Time used 0.005999s\n",
      "batch 9564, train_loss 30.881418,Time used 0.006997s\n",
      "batch 9565, train_loss 27.364134,Time used 0.008000s\n",
      "batch 9566, train_loss 31.268391,Time used 0.005035s\n",
      "batch 9567, train_loss 32.249069,Time used 0.004965s\n",
      "batch 9568, train_loss 29.621346,Time used 0.006996s\n",
      "batch 9569, train_loss 29.063725,Time used 0.005000s\n",
      "batch 9570, train_loss 26.647486,Time used 0.006000s\n",
      "batch 9571, train_loss 29.605715,Time used 0.008004s\n",
      "batch 9572, train_loss 22.085115,Time used 0.006000s\n",
      "batch 9573, train_loss 23.079140,Time used 0.007033s\n",
      "batch 9574, train_loss 26.833139,Time used 0.006963s\n",
      "batch 9575, train_loss 32.784267,Time used 0.008006s\n",
      "batch 9576, train_loss 32.271584,Time used 0.006994s\n",
      "batch 9577, train_loss 31.171585,Time used 0.005998s\n",
      "batch 9578, train_loss 28.562054,Time used 0.005000s\n",
      "batch 9579, train_loss 29.362223,Time used 0.005000s\n",
      "batch 9580, train_loss 29.006773,Time used 0.005001s\n",
      "batch 9581, train_loss 27.981745,Time used 0.004999s\n",
      "batch 9582, train_loss 28.164995,Time used 0.005038s\n",
      "batch 9583, train_loss 32.295658,Time used 0.005006s\n",
      "batch 9584, train_loss 26.665667,Time used 0.005958s\n",
      "batch 9585, train_loss 27.158712,Time used 0.005036s\n",
      "batch 9586, train_loss 25.571823,Time used 0.005967s\n",
      "batch 9587, train_loss 26.653437,Time used 0.005031s\n",
      "batch 9588, train_loss 27.969234,Time used 0.005967s\n",
      "batch 9589, train_loss 24.864321,Time used 0.005997s\n",
      "batch 9590, train_loss 34.076923,Time used 0.005001s\n",
      "batch 9591, train_loss 28.099829,Time used 0.007004s\n",
      "batch 9592, train_loss 27.544964,Time used 0.005037s\n",
      "batch 9593, train_loss 29.012903,Time used 0.004997s\n",
      "batch 9594, train_loss 31.947544,Time used 0.005997s\n",
      "batch 9595, train_loss 27.606215,Time used 0.007999s\n",
      "batch 9596, train_loss 31.784327,Time used 0.005000s\n",
      "batch 9597, train_loss 27.823769,Time used 0.005001s\n",
      "batch 9598, train_loss 32.073273,Time used 0.006000s\n",
      "batch 9599, train_loss 27.416603,Time used 0.005002s\n",
      "batch 9600, train_loss 31.451080,Time used 0.005999s\n",
      "***************************test_batch 9600, test_rmse_loss 6.863748,test_mae_loss 3.073494,test_mape_loss 51.654167,Time used 0.018003s\n",
      "batch 9601, train_loss 29.270832,Time used 0.007999s\n",
      "batch 9602, train_loss 29.846226,Time used 0.005000s\n",
      "batch 9603, train_loss 27.100716,Time used 0.005000s\n",
      "batch 9604, train_loss 27.068674,Time used 0.008002s\n",
      "batch 9605, train_loss 26.323627,Time used 0.004999s\n",
      "batch 9606, train_loss 30.394135,Time used 0.005000s\n",
      "batch 9607, train_loss 29.769203,Time used 0.006001s\n",
      "batch 9608, train_loss 31.860899,Time used 0.004998s\n",
      "batch 9609, train_loss 26.736849,Time used 0.005000s\n",
      "batch 9610, train_loss 25.934359,Time used 0.005001s\n",
      "batch 9611, train_loss 28.027010,Time used 0.004999s\n",
      "batch 9612, train_loss 26.765951,Time used 0.004999s\n",
      "batch 9613, train_loss 33.330326,Time used 0.005001s\n",
      "batch 9614, train_loss 23.788630,Time used 0.003999s\n",
      "batch 9615, train_loss 27.396875,Time used 0.004039s\n",
      "batch 9616, train_loss 27.133575,Time used 0.006000s\n",
      "batch 9617, train_loss 32.140285,Time used 0.004998s\n",
      "batch 9618, train_loss 35.259205,Time used 0.005002s\n",
      "batch 9619, train_loss 33.332596,Time used 0.005965s\n",
      "batch 9620, train_loss 27.399563,Time used 0.005033s\n",
      "batch 9621, train_loss 29.773504,Time used 0.007002s\n",
      "batch 9622, train_loss 24.834387,Time used 0.005967s\n",
      "batch 9623, train_loss 28.768269,Time used 0.005995s\n",
      "batch 9624, train_loss 30.899006,Time used 0.006003s\n",
      "batch 9625, train_loss 27.984009,Time used 0.005996s\n",
      "batch 9626, train_loss 33.111996,Time used 0.007003s\n",
      "batch 9627, train_loss 27.042435,Time used 0.004998s\n",
      "batch 9628, train_loss 33.508064,Time used 0.006001s\n",
      "batch 9629, train_loss 28.746475,Time used 0.004997s\n",
      "batch 9630, train_loss 26.390987,Time used 0.005004s\n",
      "batch 9631, train_loss 30.200342,Time used 0.005997s\n",
      "batch 9632, train_loss 25.823395,Time used 0.005038s\n",
      "batch 9633, train_loss 27.495586,Time used 0.004998s\n",
      "batch 9634, train_loss 31.751558,Time used 0.004968s\n",
      "batch 9635, train_loss 25.422565,Time used 0.006000s\n",
      "batch 9636, train_loss 27.859026,Time used 0.004999s\n",
      "batch 9637, train_loss 31.034481,Time used 0.007001s\n",
      "batch 9638, train_loss 29.932564,Time used 0.007996s\n",
      "batch 9639, train_loss 28.681963,Time used 0.005001s\n",
      "batch 9640, train_loss 23.887840,Time used 0.005000s\n",
      "batch 9641, train_loss 24.817280,Time used 0.005000s\n",
      "batch 9642, train_loss 33.542046,Time used 0.006002s\n",
      "batch 9643, train_loss 28.226107,Time used 0.004997s\n",
      "batch 9644, train_loss 29.996283,Time used 0.004999s\n",
      "batch 9645, train_loss 34.296249,Time used 0.005000s\n",
      "batch 9646, train_loss 29.345863,Time used 0.004999s\n",
      "batch 9647, train_loss 25.552135,Time used 0.005001s\n",
      "batch 9648, train_loss 27.383841,Time used 0.006002s\n",
      "batch 9649, train_loss 24.912527,Time used 0.005001s\n",
      "batch 9650, train_loss 29.899162,Time used 0.005997s\n",
      "batch 9651, train_loss 25.298798,Time used 0.008004s\n",
      "batch 9652, train_loss 28.570339,Time used 0.007000s\n",
      "batch 9653, train_loss 30.111664,Time used 0.004999s\n",
      "batch 9654, train_loss 29.146652,Time used 0.006005s\n",
      "batch 9655, train_loss 29.223467,Time used 0.005990s\n",
      "batch 9656, train_loss 30.611263,Time used 0.005000s\n",
      "batch 9657, train_loss 25.728268,Time used 0.005000s\n",
      "batch 9658, train_loss 26.395304,Time used 0.007002s\n",
      "batch 9659, train_loss 30.953924,Time used 0.004997s\n",
      "batch 9660, train_loss 24.118288,Time used 0.005998s\n",
      "batch 9661, train_loss 27.341885,Time used 0.005001s\n",
      "batch 9662, train_loss 30.393301,Time used 0.006001s\n",
      "batch 9663, train_loss 34.418152,Time used 0.009003s\n",
      "batch 9664, train_loss 26.694698,Time used 0.006001s\n",
      "batch 9665, train_loss 29.348782,Time used 0.006034s\n",
      "batch 9666, train_loss 26.222923,Time used 0.004964s\n",
      "batch 9667, train_loss 31.626873,Time used 0.005037s\n",
      "batch 9668, train_loss 34.059910,Time used 0.005998s\n",
      "batch 9669, train_loss 28.122793,Time used 0.005002s\n",
      "batch 9670, train_loss 27.835613,Time used 0.005000s\n",
      "batch 9671, train_loss 29.163584,Time used 0.007962s\n",
      "batch 9672, train_loss 30.787567,Time used 0.005998s\n",
      "batch 9673, train_loss 34.822742,Time used 0.007032s\n",
      "batch 9674, train_loss 20.790974,Time used 0.007963s\n",
      "batch 9675, train_loss 28.857182,Time used 0.006002s\n",
      "batch 9676, train_loss 27.705465,Time used 0.005000s\n",
      "batch 9677, train_loss 27.181692,Time used 0.005035s\n",
      "batch 9678, train_loss 23.071644,Time used 0.004999s\n",
      "batch 9679, train_loss 23.458096,Time used 0.005001s\n",
      "batch 9680, train_loss 30.014460,Time used 0.004998s\n",
      "batch 9681, train_loss 29.755077,Time used 0.004969s\n",
      "batch 9682, train_loss 28.892208,Time used 0.005030s\n",
      "batch 9683, train_loss 31.979328,Time used 0.004997s\n",
      "batch 9684, train_loss 32.583069,Time used 0.005003s\n",
      "batch 9685, train_loss 31.471748,Time used 0.004961s\n",
      "batch 9686, train_loss 29.212095,Time used 0.005000s\n",
      "batch 9687, train_loss 31.201210,Time used 0.005999s\n",
      "batch 9688, train_loss 24.187368,Time used 0.007003s\n",
      "batch 9689, train_loss 35.068367,Time used 0.007997s\n",
      "batch 9690, train_loss 30.561049,Time used 0.006005s\n",
      "batch 9691, train_loss 29.525410,Time used 0.006000s\n",
      "batch 9692, train_loss 29.197107,Time used 0.005033s\n",
      "batch 9693, train_loss 26.895191,Time used 0.006006s\n",
      "batch 9694, train_loss 28.651960,Time used 0.004992s\n",
      "batch 9695, train_loss 29.491686,Time used 0.005000s\n",
      "batch 9696, train_loss 24.878729,Time used 0.006002s\n",
      "batch 9697, train_loss 25.375881,Time used 0.006039s\n",
      "batch 9698, train_loss 26.609377,Time used 0.004996s\n",
      "batch 9699, train_loss 31.505892,Time used 0.005002s\n",
      "batch 9700, train_loss 22.256155,Time used 0.005997s\n",
      "***************************test_batch 9700, test_rmse_loss 6.818083,test_mae_loss 3.061016,test_mape_loss 51.791239,Time used 0.017960s\n",
      "batch 9701, train_loss 24.990894,Time used 0.008000s\n",
      "batch 9702, train_loss 27.175608,Time used 0.005997s\n",
      "batch 9703, train_loss 26.195745,Time used 0.006003s\n",
      "batch 9704, train_loss 32.203720,Time used 0.004000s\n",
      "batch 9705, train_loss 24.499735,Time used 0.007997s\n",
      "batch 9706, train_loss 29.566837,Time used 0.009035s\n",
      "batch 9707, train_loss 28.527639,Time used 0.007967s\n",
      "batch 9708, train_loss 30.230968,Time used 0.004999s\n",
      "batch 9709, train_loss 31.032932,Time used 0.006001s\n",
      "batch 9710, train_loss 31.391359,Time used 0.005000s\n",
      "batch 9711, train_loss 37.154354,Time used 0.005000s\n",
      "batch 9712, train_loss 26.959288,Time used 0.005001s\n",
      "batch 9713, train_loss 26.780699,Time used 0.006000s\n",
      "batch 9714, train_loss 25.574621,Time used 0.006999s\n",
      "batch 9715, train_loss 30.983524,Time used 0.004998s\n",
      "batch 9716, train_loss 36.202530,Time used 0.006006s\n",
      "batch 9717, train_loss 29.301197,Time used 0.005997s\n",
      "batch 9718, train_loss 30.894665,Time used 0.005997s\n",
      "batch 9719, train_loss 23.737217,Time used 0.006000s\n",
      "batch 9720, train_loss 29.098913,Time used 0.005042s\n",
      "batch 9721, train_loss 26.148130,Time used 0.006948s\n",
      "batch 9722, train_loss 30.806086,Time used 0.008001s\n",
      "batch 9723, train_loss 25.341875,Time used 0.007997s\n",
      "batch 9724, train_loss 22.850515,Time used 0.007999s\n",
      "batch 9725, train_loss 30.896759,Time used 0.005001s\n",
      "batch 9726, train_loss 30.578320,Time used 0.006040s\n",
      "batch 9727, train_loss 34.020027,Time used 0.005001s\n",
      "batch 9728, train_loss 31.179367,Time used 0.005961s\n",
      "batch 9729, train_loss 23.898535,Time used 0.005998s\n",
      "batch 9730, train_loss 28.571312,Time used 0.005000s\n",
      "batch 9731, train_loss 31.508224,Time used 0.007001s\n",
      "batch 9732, train_loss 30.193264,Time used 0.007041s\n",
      "batch 9733, train_loss 29.640005,Time used 0.006963s\n",
      "batch 9734, train_loss 24.165073,Time used 0.004999s\n",
      "batch 9735, train_loss 30.528093,Time used 0.004999s\n",
      "batch 9736, train_loss 24.301739,Time used 0.007996s\n",
      "batch 9737, train_loss 29.161200,Time used 0.005002s\n",
      "batch 9738, train_loss 27.813894,Time used 0.006998s\n",
      "batch 9739, train_loss 29.469810,Time used 0.005000s\n",
      "batch 9740, train_loss 27.904957,Time used 0.006000s\n",
      "batch 9741, train_loss 29.060816,Time used 0.007001s\n",
      "batch 9742, train_loss 26.276066,Time used 0.008000s\n",
      "batch 9743, train_loss 27.723537,Time used 0.006003s\n",
      "batch 9744, train_loss 35.395988,Time used 0.005999s\n",
      "batch 9745, train_loss 30.874352,Time used 0.005998s\n",
      "batch 9746, train_loss 27.186930,Time used 0.007001s\n",
      "batch 9747, train_loss 28.826101,Time used 0.008000s\n",
      "batch 9748, train_loss 28.859301,Time used 0.005000s\n",
      "batch 9749, train_loss 28.338835,Time used 0.006000s\n",
      "batch 9750, train_loss 28.619801,Time used 0.006001s\n",
      "batch 9751, train_loss 26.855169,Time used 0.008003s\n",
      "batch 9752, train_loss 32.324936,Time used 0.006000s\n",
      "batch 9753, train_loss 26.091450,Time used 0.004999s\n",
      "batch 9754, train_loss 27.499697,Time used 0.005032s\n",
      "batch 9755, train_loss 31.454931,Time used 0.007968s\n",
      "batch 9756, train_loss 32.850197,Time used 0.005000s\n",
      "batch 9757, train_loss 27.534309,Time used 0.006038s\n",
      "batch 9758, train_loss 30.695240,Time used 0.005001s\n",
      "batch 9759, train_loss 25.543255,Time used 0.005962s\n",
      "batch 9760, train_loss 22.992519,Time used 0.006000s\n",
      "batch 9761, train_loss 23.798323,Time used 0.006035s\n",
      "batch 9762, train_loss 29.099188,Time used 0.005000s\n",
      "batch 9763, train_loss 27.462267,Time used 0.005965s\n",
      "batch 9764, train_loss 29.139442,Time used 0.005000s\n",
      "batch 9765, train_loss 30.064619,Time used 0.005001s\n",
      "batch 9766, train_loss 33.545017,Time used 0.007996s\n",
      "batch 9767, train_loss 29.299210,Time used 0.007000s\n",
      "batch 9768, train_loss 27.653193,Time used 0.006996s\n",
      "batch 9769, train_loss 33.439709,Time used 0.008000s\n",
      "batch 9770, train_loss 29.914831,Time used 0.006999s\n",
      "batch 9771, train_loss 28.643263,Time used 0.006001s\n",
      "batch 9772, train_loss 35.415443,Time used 0.005003s\n",
      "batch 9773, train_loss 36.484436,Time used 0.006000s\n",
      "batch 9774, train_loss 29.660326,Time used 0.006997s\n",
      "batch 9775, train_loss 28.797829,Time used 0.007997s\n",
      "batch 9776, train_loss 29.035305,Time used 0.005038s\n",
      "batch 9777, train_loss 31.077513,Time used 0.006005s\n",
      "batch 9778, train_loss 28.159166,Time used 0.004999s\n",
      "batch 9779, train_loss 26.630857,Time used 0.004964s\n",
      "batch 9780, train_loss 27.017403,Time used 0.006035s\n",
      "batch 9781, train_loss 28.792274,Time used 0.004999s\n",
      "batch 9782, train_loss 29.206770,Time used 0.005001s\n",
      "batch 9783, train_loss 26.590816,Time used 0.006004s\n",
      "batch 9784, train_loss 30.352346,Time used 0.004997s\n",
      "batch 9785, train_loss 29.704889,Time used 0.005960s\n",
      "batch 9786, train_loss 24.209410,Time used 0.005001s\n",
      "batch 9787, train_loss 26.591928,Time used 0.005000s\n",
      "batch 9788, train_loss 25.250669,Time used 0.008001s\n",
      "batch 9789, train_loss 22.748625,Time used 0.006037s\n",
      "batch 9790, train_loss 24.607195,Time used 0.006965s\n",
      "batch 9791, train_loss 28.414194,Time used 0.005002s\n",
      "batch 9792, train_loss 24.104950,Time used 0.005000s\n",
      "batch 9793, train_loss 29.755600,Time used 0.005002s\n",
      "batch 9794, train_loss 25.407730,Time used 0.004999s\n",
      "batch 9795, train_loss 25.565016,Time used 0.006997s\n",
      "batch 9796, train_loss 27.003017,Time used 0.007037s\n",
      "batch 9797, train_loss 31.252892,Time used 0.006960s\n",
      "batch 9798, train_loss 25.082857,Time used 0.006001s\n",
      "batch 9799, train_loss 28.937187,Time used 0.006004s\n",
      "batch 9800, train_loss 27.013809,Time used 0.004999s\n",
      "***************************test_batch 9800, test_rmse_loss 6.823063,test_mae_loss 3.058192,test_mape_loss 51.760659,Time used 0.024034s\n",
      "batch 9801, train_loss 25.923695,Time used 0.004966s\n",
      "batch 9802, train_loss 23.261858,Time used 0.006001s\n",
      "batch 9803, train_loss 29.219696,Time used 0.005999s\n",
      "batch 9804, train_loss 32.981514,Time used 0.005039s\n",
      "batch 9805, train_loss 27.166931,Time used 0.005970s\n",
      "batch 9806, train_loss 30.597622,Time used 0.008025s\n",
      "batch 9807, train_loss 29.701885,Time used 0.005001s\n",
      "batch 9808, train_loss 29.506445,Time used 0.004962s\n",
      "batch 9809, train_loss 34.988338,Time used 0.005000s\n",
      "batch 9810, train_loss 31.231964,Time used 0.005001s\n",
      "batch 9811, train_loss 29.709373,Time used 0.005005s\n",
      "batch 9812, train_loss 31.039923,Time used 0.007033s\n",
      "batch 9813, train_loss 24.896597,Time used 0.007961s\n",
      "batch 9814, train_loss 26.090906,Time used 0.004999s\n",
      "batch 9815, train_loss 26.284851,Time used 0.005001s\n",
      "batch 9816, train_loss 30.803982,Time used 0.005005s\n",
      "batch 9817, train_loss 25.555212,Time used 0.004998s\n",
      "batch 9818, train_loss 25.204760,Time used 0.007001s\n",
      "batch 9819, train_loss 34.738106,Time used 0.005998s\n",
      "batch 9820, train_loss 29.552156,Time used 0.004997s\n",
      "batch 9821, train_loss 28.493082,Time used 0.005999s\n",
      "batch 9822, train_loss 28.535435,Time used 0.005000s\n",
      "batch 9823, train_loss 25.541136,Time used 0.006000s\n",
      "batch 9824, train_loss 24.029209,Time used 0.008000s\n",
      "batch 9825, train_loss 28.531061,Time used 0.008005s\n",
      "batch 9826, train_loss 32.398090,Time used 0.005998s\n",
      "batch 9827, train_loss 30.217422,Time used 0.005036s\n",
      "batch 9828, train_loss 31.836193,Time used 0.005998s\n",
      "batch 9829, train_loss 28.215626,Time used 0.005969s\n",
      "batch 9830, train_loss 26.592121,Time used 0.006999s\n",
      "batch 9831, train_loss 23.478415,Time used 0.006000s\n",
      "batch 9832, train_loss 29.834711,Time used 0.005034s\n",
      "batch 9833, train_loss 24.001308,Time used 0.004999s\n",
      "batch 9834, train_loss 31.118811,Time used 0.004996s\n",
      "batch 9835, train_loss 24.478428,Time used 0.005004s\n",
      "batch 9836, train_loss 32.424061,Time used 0.005000s\n",
      "batch 9837, train_loss 25.986601,Time used 0.006966s\n",
      "batch 9838, train_loss 27.282269,Time used 0.005032s\n",
      "batch 9839, train_loss 33.785931,Time used 0.005968s\n",
      "batch 9840, train_loss 30.531973,Time used 0.005000s\n",
      "batch 9841, train_loss 26.354349,Time used 0.004998s\n",
      "batch 9842, train_loss 31.294384,Time used 0.004969s\n",
      "batch 9843, train_loss 30.575933,Time used 0.004998s\n",
      "batch 9844, train_loss 22.036903,Time used 0.005001s\n",
      "batch 9845, train_loss 26.415693,Time used 0.006002s\n",
      "batch 9846, train_loss 26.438704,Time used 0.007037s\n",
      "batch 9847, train_loss 27.927507,Time used 0.004966s\n",
      "batch 9848, train_loss 34.161327,Time used 0.005001s\n",
      "batch 9849, train_loss 34.001915,Time used 0.005999s\n",
      "batch 9850, train_loss 28.991461,Time used 0.005002s\n",
      "batch 9851, train_loss 29.386621,Time used 0.004999s\n",
      "batch 9852, train_loss 25.043974,Time used 0.008001s\n",
      "batch 9853, train_loss 25.781807,Time used 0.006000s\n",
      "batch 9854, train_loss 28.290823,Time used 0.004997s\n",
      "batch 9855, train_loss 27.941803,Time used 0.005001s\n",
      "batch 9856, train_loss 24.833227,Time used 0.006999s\n",
      "batch 9857, train_loss 30.643324,Time used 0.010004s\n",
      "batch 9858, train_loss 30.513214,Time used 0.007998s\n",
      "batch 9859, train_loss 25.725626,Time used 0.006035s\n",
      "batch 9860, train_loss 28.907084,Time used 0.007966s\n",
      "batch 9861, train_loss 32.581520,Time used 0.005998s\n",
      "batch 9862, train_loss 28.122065,Time used 0.008039s\n",
      "batch 9863, train_loss 30.319502,Time used 0.005963s\n",
      "batch 9864, train_loss 24.578205,Time used 0.004966s\n",
      "batch 9865, train_loss 29.689005,Time used 0.006000s\n",
      "batch 9866, train_loss 29.725954,Time used 0.008001s\n",
      "batch 9867, train_loss 26.192806,Time used 0.007001s\n",
      "batch 9868, train_loss 24.649143,Time used 0.004998s\n",
      "batch 9869, train_loss 24.815506,Time used 0.005002s\n",
      "batch 9870, train_loss 28.430862,Time used 0.005033s\n",
      "batch 9871, train_loss 29.029404,Time used 0.005033s\n",
      "batch 9872, train_loss 24.481205,Time used 0.005963s\n",
      "batch 9873, train_loss 26.258194,Time used 0.007999s\n",
      "batch 9874, train_loss 24.696316,Time used 0.005001s\n",
      "batch 9875, train_loss 28.690205,Time used 0.006007s\n",
      "batch 9876, train_loss 26.953213,Time used 0.008034s\n",
      "batch 9877, train_loss 30.844946,Time used 0.006963s\n",
      "batch 9878, train_loss 26.825050,Time used 0.007001s\n",
      "batch 9879, train_loss 24.959673,Time used 0.008000s\n",
      "batch 9880, train_loss 30.281210,Time used 0.008000s\n",
      "batch 9881, train_loss 28.279228,Time used 0.005998s\n",
      "batch 9882, train_loss 26.463724,Time used 0.005004s\n",
      "batch 9883, train_loss 36.087856,Time used 0.006033s\n",
      "batch 9884, train_loss 34.055508,Time used 0.005962s\n",
      "batch 9885, train_loss 27.191971,Time used 0.006006s\n",
      "batch 9886, train_loss 35.228710,Time used 0.006995s\n",
      "batch 9887, train_loss 29.335958,Time used 0.006001s\n",
      "batch 9888, train_loss 26.541006,Time used 0.005000s\n",
      "batch 9889, train_loss 25.337912,Time used 0.006999s\n",
      "batch 9890, train_loss 29.654770,Time used 0.006000s\n",
      "batch 9891, train_loss 26.596657,Time used 0.006001s\n",
      "batch 9892, train_loss 26.677828,Time used 0.006003s\n",
      "batch 9893, train_loss 23.205908,Time used 0.004997s\n",
      "batch 9894, train_loss 29.041925,Time used 0.005000s\n",
      "batch 9895, train_loss 27.952934,Time used 0.006000s\n",
      "batch 9896, train_loss 31.785049,Time used 0.005997s\n",
      "batch 9897, train_loss 28.125084,Time used 0.005000s\n",
      "batch 9898, train_loss 28.870996,Time used 0.007003s\n",
      "batch 9899, train_loss 31.148310,Time used 0.008001s\n",
      "batch 9900, train_loss 24.685637,Time used 0.007997s\n",
      "***************************test_batch 9900, test_rmse_loss 6.797695,test_mae_loss 3.050801,test_mape_loss 51.643869,Time used 0.020997s\n",
      "batch 9901, train_loss 29.846506,Time used 0.006002s\n",
      "batch 9902, train_loss 30.902281,Time used 0.006997s\n",
      "batch 9903, train_loss 31.411058,Time used 0.005001s\n",
      "batch 9904, train_loss 30.213247,Time used 0.007000s\n",
      "batch 9905, train_loss 28.754078,Time used 0.006001s\n",
      "batch 9906, train_loss 32.730087,Time used 0.004999s\n",
      "batch 9907, train_loss 23.068714,Time used 0.004999s\n",
      "batch 9908, train_loss 30.334894,Time used 0.006000s\n",
      "batch 9909, train_loss 23.740986,Time used 0.006003s\n",
      "batch 9910, train_loss 29.930634,Time used 0.005001s\n",
      "batch 9911, train_loss 28.423716,Time used 0.004998s\n",
      "batch 9912, train_loss 25.569399,Time used 0.006003s\n",
      "batch 9913, train_loss 32.412590,Time used 0.007000s\n",
      "batch 9914, train_loss 28.777456,Time used 0.006000s\n",
      "batch 9915, train_loss 31.814711,Time used 0.005000s\n",
      "batch 9916, train_loss 29.130796,Time used 0.005001s\n",
      "batch 9917, train_loss 26.472702,Time used 0.006001s\n",
      "batch 9918, train_loss 31.574934,Time used 0.004999s\n",
      "batch 9919, train_loss 28.636299,Time used 0.005000s\n",
      "batch 9920, train_loss 26.128895,Time used 0.005000s\n",
      "batch 9921, train_loss 26.305408,Time used 0.005001s\n",
      "batch 9922, train_loss 28.615902,Time used 0.004999s\n",
      "batch 9923, train_loss 26.361641,Time used 0.005001s\n",
      "batch 9924, train_loss 27.278099,Time used 0.005000s\n",
      "batch 9925, train_loss 24.390574,Time used 0.005000s\n",
      "batch 9926, train_loss 29.660574,Time used 0.005002s\n",
      "batch 9927, train_loss 25.613909,Time used 0.006002s\n",
      "batch 9928, train_loss 25.000265,Time used 0.005003s\n",
      "batch 9929, train_loss 27.501019,Time used 0.005999s\n",
      "batch 9930, train_loss 30.715389,Time used 0.006001s\n",
      "batch 9931, train_loss 28.847042,Time used 0.005999s\n",
      "batch 9932, train_loss 30.700523,Time used 0.006037s\n",
      "batch 9933, train_loss 27.823988,Time used 0.004999s\n",
      "batch 9934, train_loss 31.046610,Time used 0.005001s\n",
      "batch 9935, train_loss 25.739878,Time used 0.004964s\n",
      "batch 9936, train_loss 26.101105,Time used 0.007033s\n",
      "batch 9937, train_loss 29.202269,Time used 0.005001s\n",
      "batch 9938, train_loss 27.740595,Time used 0.005038s\n",
      "batch 9939, train_loss 28.562716,Time used 0.006994s\n",
      "batch 9940, train_loss 29.731318,Time used 0.005000s\n",
      "batch 9941, train_loss 25.356628,Time used 0.004992s\n",
      "batch 9942, train_loss 29.960159,Time used 0.005000s\n",
      "batch 9943, train_loss 29.683540,Time used 0.005000s\n",
      "batch 9944, train_loss 30.176970,Time used 0.004964s\n",
      "batch 9945, train_loss 28.019341,Time used 0.008000s\n",
      "batch 9946, train_loss 28.411434,Time used 0.007035s\n",
      "batch 9947, train_loss 33.749592,Time used 0.006993s\n",
      "batch 9948, train_loss 29.279335,Time used 0.008038s\n",
      "batch 9949, train_loss 24.835083,Time used 0.007001s\n",
      "batch 9950, train_loss 26.139643,Time used 0.006002s\n",
      "batch 9951, train_loss 25.360611,Time used 0.004996s\n",
      "batch 9952, train_loss 28.372280,Time used 0.009003s\n",
      "batch 9953, train_loss 27.478649,Time used 0.004998s\n",
      "batch 9954, train_loss 30.787689,Time used 0.005964s\n",
      "batch 9955, train_loss 32.847031,Time used 0.007003s\n",
      "batch 9956, train_loss 25.010725,Time used 0.006997s\n",
      "batch 9957, train_loss 31.288973,Time used 0.005004s\n",
      "batch 9958, train_loss 25.905704,Time used 0.005000s\n",
      "batch 9959, train_loss 22.562193,Time used 0.005996s\n",
      "batch 9960, train_loss 25.078259,Time used 0.006035s\n",
      "batch 9961, train_loss 31.349180,Time used 0.005962s\n",
      "batch 9962, train_loss 27.812628,Time used 0.007003s\n",
      "batch 9963, train_loss 28.501568,Time used 0.005997s\n",
      "batch 9964, train_loss 29.097179,Time used 0.005999s\n",
      "batch 9965, train_loss 26.034096,Time used 0.006999s\n",
      "batch 9966, train_loss 28.399408,Time used 0.008039s\n",
      "batch 9967, train_loss 24.140869,Time used 0.005034s\n",
      "batch 9968, train_loss 25.787954,Time used 0.006963s\n",
      "batch 9969, train_loss 29.886866,Time used 0.005000s\n",
      "batch 9970, train_loss 27.754528,Time used 0.006001s\n",
      "batch 9971, train_loss 31.592020,Time used 0.009038s\n",
      "batch 9972, train_loss 29.592882,Time used 0.007965s\n",
      "batch 9973, train_loss 24.999483,Time used 0.005031s\n",
      "batch 9974, train_loss 29.417336,Time used 0.005003s\n",
      "batch 9975, train_loss 25.220592,Time used 0.007960s\n",
      "batch 9976, train_loss 29.363838,Time used 0.006006s\n",
      "batch 9977, train_loss 28.183104,Time used 0.005997s\n",
      "batch 9978, train_loss 25.658384,Time used 0.004997s\n",
      "batch 9979, train_loss 34.835979,Time used 0.006010s\n",
      "batch 9980, train_loss 28.369177,Time used 0.006990s\n",
      "batch 9981, train_loss 23.327211,Time used 0.005999s\n",
      "batch 9982, train_loss 28.792652,Time used 0.004999s\n",
      "batch 9983, train_loss 31.374866,Time used 0.005042s\n",
      "batch 9984, train_loss 24.687412,Time used 0.004995s\n",
      "batch 9985, train_loss 28.821619,Time used 0.004967s\n",
      "batch 9986, train_loss 27.070904,Time used 0.006031s\n",
      "batch 9987, train_loss 28.234282,Time used 0.005966s\n",
      "batch 9988, train_loss 35.076050,Time used 0.005002s\n",
      "batch 9989, train_loss 27.252829,Time used 0.005000s\n",
      "batch 9990, train_loss 27.289202,Time used 0.005000s\n",
      "batch 9991, train_loss 25.622221,Time used 0.005041s\n",
      "batch 9992, train_loss 24.981216,Time used 0.003999s\n",
      "batch 9993, train_loss 26.330412,Time used 0.005965s\n",
      "batch 9994, train_loss 25.876104,Time used 0.005002s\n",
      "batch 9995, train_loss 29.499750,Time used 0.006998s\n",
      "batch 9996, train_loss 26.949173,Time used 0.005000s\n",
      "batch 9997, train_loss 23.759182,Time used 0.004999s\n",
      "batch 9998, train_loss 29.245077,Time used 0.006001s\n",
      "batch 9999, train_loss 27.055788,Time used 0.004998s\n",
      "batch 10000, train_loss 26.385746,Time used 0.006003s\n",
      "***************************test_batch 10000, test_rmse_loss 6.786324,test_mae_loss 3.044878,test_mape_loss 51.549574,Time used 0.021001s\n",
      "batch 10001, train_loss 28.537365,Time used 0.006034s\n",
      "batch 10002, train_loss 23.994217,Time used 0.004969s\n",
      "batch 10003, train_loss 28.748718,Time used 0.007995s\n",
      "batch 10004, train_loss 35.433441,Time used 0.007003s\n",
      "batch 10005, train_loss 33.335228,Time used 0.005999s\n",
      "batch 10006, train_loss 30.034695,Time used 0.005037s\n",
      "batch 10007, train_loss 25.493189,Time used 0.005999s\n",
      "batch 10008, train_loss 28.209902,Time used 0.004959s\n",
      "batch 10009, train_loss 30.567137,Time used 0.005998s\n",
      "batch 10010, train_loss 34.598949,Time used 0.005038s\n",
      "batch 10011, train_loss 30.419161,Time used 0.006002s\n",
      "batch 10012, train_loss 27.996941,Time used 0.004998s\n",
      "batch 10013, train_loss 28.382446,Time used 0.004968s\n",
      "batch 10014, train_loss 29.262085,Time used 0.006000s\n",
      "batch 10015, train_loss 23.479456,Time used 0.006000s\n",
      "batch 10016, train_loss 28.873295,Time used 0.005034s\n",
      "batch 10017, train_loss 24.612341,Time used 0.004965s\n",
      "batch 10018, train_loss 23.238132,Time used 0.004965s\n",
      "batch 10019, train_loss 34.283878,Time used 0.005000s\n",
      "batch 10020, train_loss 25.557013,Time used 0.005001s\n",
      "batch 10021, train_loss 27.368423,Time used 0.004999s\n",
      "batch 10022, train_loss 26.427050,Time used 0.007033s\n",
      "batch 10023, train_loss 27.058834,Time used 0.007002s\n",
      "batch 10024, train_loss 27.318514,Time used 0.005967s\n",
      "batch 10025, train_loss 27.821375,Time used 0.004998s\n",
      "batch 10026, train_loss 28.791767,Time used 0.005001s\n",
      "batch 10027, train_loss 29.317608,Time used 0.005001s\n",
      "batch 10028, train_loss 25.242287,Time used 0.006003s\n",
      "batch 10029, train_loss 30.405863,Time used 0.005999s\n",
      "batch 10030, train_loss 29.812031,Time used 0.006033s\n",
      "batch 10031, train_loss 24.075756,Time used 0.005001s\n",
      "batch 10032, train_loss 27.046154,Time used 0.005965s\n",
      "batch 10033, train_loss 30.650070,Time used 0.005998s\n",
      "batch 10034, train_loss 25.207548,Time used 0.005003s\n",
      "batch 10035, train_loss 29.026573,Time used 0.007999s\n",
      "batch 10036, train_loss 32.642094,Time used 0.006037s\n",
      "batch 10037, train_loss 25.726513,Time used 0.004995s\n",
      "batch 10038, train_loss 26.224493,Time used 0.005000s\n",
      "batch 10039, train_loss 34.572479,Time used 0.005001s\n",
      "batch 10040, train_loss 26.859457,Time used 0.006000s\n",
      "batch 10041, train_loss 26.370668,Time used 0.005000s\n",
      "batch 10042, train_loss 29.895294,Time used 0.005000s\n",
      "batch 10043, train_loss 34.173832,Time used 0.005003s\n",
      "batch 10044, train_loss 29.843168,Time used 0.004998s\n",
      "batch 10045, train_loss 26.392673,Time used 0.004992s\n",
      "batch 10046, train_loss 30.453850,Time used 0.005008s\n",
      "batch 10047, train_loss 27.029428,Time used 0.007000s\n",
      "batch 10048, train_loss 27.787823,Time used 0.005000s\n",
      "batch 10049, train_loss 26.695673,Time used 0.005002s\n",
      "batch 10050, train_loss 28.153191,Time used 0.004998s\n",
      "batch 10051, train_loss 22.692156,Time used 0.005964s\n",
      "batch 10052, train_loss 26.142633,Time used 0.004999s\n",
      "batch 10053, train_loss 30.808300,Time used 0.005001s\n",
      "batch 10054, train_loss 23.797216,Time used 0.006995s\n",
      "batch 10055, train_loss 25.846079,Time used 0.006001s\n",
      "batch 10056, train_loss 23.484909,Time used 0.005996s\n",
      "batch 10057, train_loss 26.000395,Time used 0.008001s\n",
      "batch 10058, train_loss 31.521807,Time used 0.007005s\n",
      "batch 10059, train_loss 32.646194,Time used 0.006998s\n",
      "batch 10060, train_loss 30.000410,Time used 0.007003s\n",
      "batch 10061, train_loss 33.491634,Time used 0.008030s\n",
      "batch 10062, train_loss 31.152897,Time used 0.006965s\n",
      "batch 10063, train_loss 24.166183,Time used 0.007001s\n",
      "batch 10064, train_loss 24.585802,Time used 0.008000s\n",
      "batch 10065, train_loss 24.878040,Time used 0.008000s\n",
      "batch 10066, train_loss 21.392532,Time used 0.008003s\n",
      "batch 10067, train_loss 29.757050,Time used 0.006994s\n",
      "batch 10068, train_loss 25.539354,Time used 0.005999s\n",
      "batch 10069, train_loss 29.663549,Time used 0.005002s\n",
      "batch 10070, train_loss 24.240242,Time used 0.004998s\n",
      "batch 10071, train_loss 28.134890,Time used 0.005999s\n",
      "batch 10072, train_loss 30.696840,Time used 0.006002s\n",
      "batch 10073, train_loss 30.960779,Time used 0.005001s\n",
      "batch 10074, train_loss 26.604357,Time used 0.004997s\n",
      "batch 10075, train_loss 27.983288,Time used 0.006000s\n",
      "batch 10076, train_loss 22.536312,Time used 0.006000s\n",
      "batch 10077, train_loss 27.452131,Time used 0.004999s\n",
      "batch 10078, train_loss 32.620358,Time used 0.005002s\n",
      "batch 10079, train_loss 26.897575,Time used 0.004999s\n",
      "batch 10080, train_loss 26.651701,Time used 0.005000s\n",
      "batch 10081, train_loss 29.097967,Time used 0.004998s\n",
      "batch 10082, train_loss 26.144655,Time used 0.005001s\n",
      "batch 10083, train_loss 31.284967,Time used 0.005999s\n",
      "batch 10084, train_loss 32.668446,Time used 0.006002s\n",
      "batch 10085, train_loss 27.769203,Time used 0.007001s\n",
      "batch 10086, train_loss 24.730213,Time used 0.004998s\n",
      "batch 10087, train_loss 26.945965,Time used 0.004999s\n",
      "batch 10088, train_loss 30.841782,Time used 0.005002s\n",
      "batch 10089, train_loss 31.836050,Time used 0.005002s\n",
      "batch 10090, train_loss 26.207277,Time used 0.005997s\n",
      "batch 10091, train_loss 27.235817,Time used 0.006003s\n",
      "batch 10092, train_loss 25.626427,Time used 0.005999s\n",
      "batch 10093, train_loss 30.375441,Time used 0.004997s\n",
      "batch 10094, train_loss 21.714542,Time used 0.006001s\n",
      "batch 10095, train_loss 24.329229,Time used 0.004999s\n",
      "batch 10096, train_loss 26.184908,Time used 0.005000s\n",
      "batch 10097, train_loss 24.679075,Time used 0.005003s\n",
      "batch 10098, train_loss 27.832981,Time used 0.008036s\n",
      "batch 10099, train_loss 29.502621,Time used 0.006005s\n",
      "batch 10100, train_loss 30.146088,Time used 0.005000s\n",
      "***************************test_batch 10100, test_rmse_loss 6.758629,test_mae_loss 3.036513,test_mape_loss 51.552074,Time used 0.017963s\n",
      "batch 10101, train_loss 24.652906,Time used 0.008002s\n",
      "batch 10102, train_loss 25.455202,Time used 0.005035s\n",
      "batch 10103, train_loss 33.121941,Time used 0.004961s\n",
      "batch 10104, train_loss 29.431076,Time used 0.005004s\n",
      "batch 10105, train_loss 25.640606,Time used 0.004998s\n",
      "batch 10106, train_loss 25.726330,Time used 0.006996s\n",
      "batch 10107, train_loss 28.422752,Time used 0.006000s\n",
      "batch 10108, train_loss 29.417576,Time used 0.006001s\n",
      "batch 10109, train_loss 25.695068,Time used 0.006000s\n",
      "batch 10110, train_loss 29.056532,Time used 0.005004s\n",
      "batch 10111, train_loss 25.312761,Time used 0.005996s\n",
      "batch 10112, train_loss 35.318607,Time used 0.005000s\n",
      "batch 10113, train_loss 25.890368,Time used 0.006000s\n",
      "batch 10114, train_loss 31.599079,Time used 0.006002s\n",
      "batch 10115, train_loss 29.132811,Time used 0.005001s\n",
      "batch 10116, train_loss 25.824074,Time used 0.007000s\n",
      "batch 10117, train_loss 27.798040,Time used 0.004999s\n",
      "batch 10118, train_loss 24.250423,Time used 0.005999s\n",
      "batch 10119, train_loss 31.731606,Time used 0.008003s\n",
      "batch 10120, train_loss 23.264544,Time used 0.005998s\n",
      "batch 10121, train_loss 31.821558,Time used 0.006004s\n",
      "batch 10122, train_loss 24.614037,Time used 0.005000s\n",
      "batch 10123, train_loss 31.368341,Time used 0.005000s\n",
      "batch 10124, train_loss 19.849146,Time used 0.006000s\n",
      "batch 10125, train_loss 27.961029,Time used 0.004999s\n",
      "batch 10126, train_loss 30.547455,Time used 0.005000s\n",
      "batch 10127, train_loss 25.987295,Time used 0.005002s\n",
      "batch 10128, train_loss 30.321119,Time used 0.004999s\n",
      "batch 10129, train_loss 25.765776,Time used 0.004998s\n",
      "batch 10130, train_loss 25.130201,Time used 0.006008s\n",
      "batch 10131, train_loss 28.931873,Time used 0.005989s\n",
      "batch 10132, train_loss 27.730484,Time used 0.006001s\n",
      "batch 10133, train_loss 24.248875,Time used 0.008001s\n",
      "batch 10134, train_loss 26.156733,Time used 0.007000s\n",
      "batch 10135, train_loss 27.805891,Time used 0.005002s\n",
      "batch 10136, train_loss 29.509365,Time used 0.004998s\n",
      "batch 10137, train_loss 34.627144,Time used 0.008003s\n",
      "batch 10138, train_loss 30.644260,Time used 0.008999s\n",
      "batch 10139, train_loss 26.595652,Time used 0.006002s\n",
      "batch 10140, train_loss 25.920933,Time used 0.007000s\n",
      "batch 10141, train_loss 28.078773,Time used 0.007000s\n",
      "batch 10142, train_loss 25.146244,Time used 0.008000s\n",
      "batch 10143, train_loss 30.022434,Time used 0.007000s\n",
      "batch 10144, train_loss 30.197828,Time used 0.008000s\n",
      "batch 10145, train_loss 28.909616,Time used 0.006997s\n",
      "batch 10146, train_loss 24.644922,Time used 0.007002s\n",
      "batch 10147, train_loss 31.483536,Time used 0.008002s\n",
      "batch 10148, train_loss 26.629906,Time used 0.006998s\n",
      "batch 10149, train_loss 27.292191,Time used 0.009001s\n",
      "batch 10150, train_loss 25.858570,Time used 0.009001s\n",
      "batch 10151, train_loss 25.756420,Time used 0.007999s\n",
      "batch 10152, train_loss 28.456720,Time used 0.007997s\n",
      "batch 10153, train_loss 29.837759,Time used 0.008999s\n",
      "batch 10154, train_loss 26.634602,Time used 0.010003s\n",
      "batch 10155, train_loss 29.877560,Time used 0.008000s\n",
      "batch 10156, train_loss 27.271324,Time used 0.008000s\n",
      "batch 10157, train_loss 30.162712,Time used 0.007998s\n",
      "batch 10158, train_loss 24.507536,Time used 0.010000s\n",
      "batch 10159, train_loss 27.225231,Time used 0.008001s\n",
      "batch 10160, train_loss 26.406458,Time used 0.008000s\n",
      "batch 10161, train_loss 29.456751,Time used 0.008000s\n",
      "batch 10162, train_loss 25.418177,Time used 0.008000s\n",
      "batch 10163, train_loss 26.439459,Time used 0.008000s\n",
      "batch 10164, train_loss 34.594952,Time used 0.006999s\n",
      "batch 10165, train_loss 28.036585,Time used 0.007998s\n",
      "batch 10166, train_loss 23.924026,Time used 0.008001s\n",
      "batch 10167, train_loss 24.705603,Time used 0.008003s\n",
      "batch 10168, train_loss 27.954268,Time used 0.008998s\n",
      "batch 10169, train_loss 29.622747,Time used 0.010001s\n",
      "batch 10170, train_loss 26.015966,Time used 0.007998s\n",
      "batch 10171, train_loss 28.763121,Time used 0.010002s\n",
      "batch 10172, train_loss 28.241583,Time used 0.010999s\n",
      "batch 10173, train_loss 29.202232,Time used 0.010002s\n",
      "batch 10174, train_loss 24.912670,Time used 0.010001s\n",
      "batch 10175, train_loss 26.831831,Time used 0.009000s\n",
      "batch 10176, train_loss 27.974197,Time used 0.013000s\n",
      "batch 10177, train_loss 25.827034,Time used 0.011000s\n",
      "batch 10178, train_loss 28.566618,Time used 0.011000s\n",
      "batch 10179, train_loss 25.306217,Time used 0.010000s\n",
      "batch 10180, train_loss 26.478945,Time used 0.009001s\n",
      "batch 10181, train_loss 27.038378,Time used 0.007999s\n",
      "batch 10182, train_loss 22.701208,Time used 0.008000s\n",
      "batch 10183, train_loss 27.630840,Time used 0.007004s\n",
      "batch 10184, train_loss 28.281681,Time used 0.008996s\n",
      "batch 10185, train_loss 27.132715,Time used 0.007999s\n",
      "batch 10186, train_loss 29.174412,Time used 0.009002s\n",
      "batch 10187, train_loss 28.567751,Time used 0.008999s\n",
      "batch 10188, train_loss 30.631449,Time used 0.007000s\n",
      "batch 10189, train_loss 28.058651,Time used 0.008000s\n",
      "batch 10190, train_loss 26.347189,Time used 0.009000s\n",
      "batch 10191, train_loss 24.545664,Time used 0.009001s\n",
      "batch 10192, train_loss 30.461313,Time used 0.008001s\n",
      "batch 10193, train_loss 29.914591,Time used 0.007999s\n",
      "batch 10194, train_loss 23.014538,Time used 0.008000s\n",
      "batch 10195, train_loss 26.957420,Time used 0.009000s\n",
      "batch 10196, train_loss 29.094637,Time used 0.007999s\n",
      "batch 10197, train_loss 26.602160,Time used 0.007999s\n",
      "batch 10198, train_loss 30.708172,Time used 0.006000s\n",
      "batch 10199, train_loss 31.095530,Time used 0.008999s\n",
      "batch 10200, train_loss 28.978172,Time used 0.007009s\n",
      "***************************test_batch 10200, test_rmse_loss 6.788562,test_mae_loss 3.043126,test_mape_loss 51.217480,Time used 0.024991s\n",
      "batch 10201, train_loss 30.769266,Time used 0.007998s\n",
      "batch 10202, train_loss 27.566172,Time used 0.007000s\n",
      "batch 10203, train_loss 29.971998,Time used 0.006994s\n",
      "batch 10204, train_loss 29.155663,Time used 0.006995s\n",
      "batch 10205, train_loss 25.963627,Time used 0.007002s\n",
      "batch 10206, train_loss 27.587660,Time used 0.006999s\n",
      "batch 10207, train_loss 22.174992,Time used 0.008002s\n",
      "batch 10208, train_loss 29.912933,Time used 0.005999s\n",
      "batch 10209, train_loss 23.664127,Time used 0.005999s\n",
      "batch 10210, train_loss 27.861513,Time used 0.005001s\n",
      "batch 10211, train_loss 30.119730,Time used 0.006001s\n",
      "batch 10212, train_loss 26.766439,Time used 0.006000s\n",
      "batch 10213, train_loss 29.401745,Time used 0.008001s\n",
      "batch 10214, train_loss 24.304014,Time used 0.008001s\n",
      "batch 10215, train_loss 24.709217,Time used 0.007998s\n",
      "batch 10216, train_loss 28.839264,Time used 0.006000s\n",
      "batch 10217, train_loss 28.876287,Time used 0.005001s\n",
      "batch 10218, train_loss 23.828974,Time used 0.007001s\n",
      "batch 10219, train_loss 28.262665,Time used 0.005998s\n",
      "batch 10220, train_loss 34.378040,Time used 0.005998s\n",
      "batch 10221, train_loss 24.746737,Time used 0.005000s\n",
      "batch 10222, train_loss 25.375420,Time used 0.005001s\n",
      "batch 10223, train_loss 29.623550,Time used 0.004999s\n",
      "batch 10224, train_loss 27.963928,Time used 0.006003s\n",
      "batch 10225, train_loss 36.598557,Time used 0.005994s\n",
      "batch 10226, train_loss 28.995770,Time used 0.004998s\n",
      "batch 10227, train_loss 26.580585,Time used 0.005001s\n",
      "batch 10228, train_loss 22.541000,Time used 0.005001s\n",
      "batch 10229, train_loss 28.990969,Time used 0.005001s\n",
      "batch 10230, train_loss 25.572336,Time used 0.006000s\n",
      "batch 10231, train_loss 29.890491,Time used 0.004996s\n",
      "batch 10232, train_loss 26.245110,Time used 0.006002s\n",
      "batch 10233, train_loss 24.752813,Time used 0.006001s\n",
      "batch 10234, train_loss 25.164627,Time used 0.006997s\n",
      "batch 10235, train_loss 25.206284,Time used 0.006003s\n",
      "batch 10236, train_loss 28.435968,Time used 0.006996s\n",
      "batch 10237, train_loss 28.078468,Time used 0.005002s\n",
      "batch 10238, train_loss 24.338081,Time used 0.004999s\n",
      "batch 10239, train_loss 33.139637,Time used 0.007001s\n",
      "batch 10240, train_loss 29.274757,Time used 0.004999s\n",
      "batch 10241, train_loss 24.795528,Time used 0.005000s\n",
      "batch 10242, train_loss 26.850496,Time used 0.007998s\n",
      "batch 10243, train_loss 25.349941,Time used 0.007000s\n",
      "batch 10244, train_loss 24.016289,Time used 0.008001s\n",
      "batch 10245, train_loss 32.901768,Time used 0.005002s\n",
      "batch 10246, train_loss 29.044340,Time used 0.004998s\n",
      "batch 10247, train_loss 32.933788,Time used 0.004999s\n",
      "batch 10248, train_loss 20.734734,Time used 0.006037s\n",
      "batch 10249, train_loss 24.705214,Time used 0.005959s\n",
      "batch 10250, train_loss 27.692980,Time used 0.005004s\n",
      "batch 10251, train_loss 29.047239,Time used 0.007997s\n",
      "batch 10252, train_loss 21.372196,Time used 0.004999s\n",
      "batch 10253, train_loss 28.719278,Time used 0.006001s\n",
      "batch 10254, train_loss 29.102961,Time used 0.005000s\n",
      "batch 10255, train_loss 28.768261,Time used 0.004998s\n",
      "batch 10256, train_loss 30.841475,Time used 0.005000s\n",
      "batch 10257, train_loss 28.459030,Time used 0.005001s\n",
      "batch 10258, train_loss 28.156412,Time used 0.004999s\n",
      "batch 10259, train_loss 22.376987,Time used 0.005001s\n",
      "batch 10260, train_loss 25.782673,Time used 0.005999s\n",
      "batch 10261, train_loss 29.406321,Time used 0.005000s\n",
      "batch 10262, train_loss 27.629379,Time used 0.006002s\n",
      "batch 10263, train_loss 25.003174,Time used 0.008002s\n",
      "batch 10264, train_loss 24.606894,Time used 0.005997s\n",
      "batch 10265, train_loss 28.756058,Time used 0.006002s\n",
      "batch 10266, train_loss 33.850349,Time used 0.005996s\n",
      "batch 10267, train_loss 27.984612,Time used 0.005001s\n",
      "batch 10268, train_loss 31.727049,Time used 0.004999s\n",
      "batch 10269, train_loss 25.517117,Time used 0.004999s\n",
      "batch 10270, train_loss 25.035135,Time used 0.005001s\n",
      "batch 10271, train_loss 26.669827,Time used 0.005001s\n",
      "batch 10272, train_loss 27.882435,Time used 0.004997s\n",
      "batch 10273, train_loss 30.959778,Time used 0.005000s\n",
      "batch 10274, train_loss 26.062653,Time used 0.006001s\n",
      "batch 10275, train_loss 29.480160,Time used 0.004998s\n",
      "batch 10276, train_loss 26.540422,Time used 0.005000s\n",
      "batch 10277, train_loss 24.336597,Time used 0.006001s\n",
      "batch 10278, train_loss 27.275616,Time used 0.004998s\n",
      "batch 10279, train_loss 23.070656,Time used 0.006037s\n",
      "batch 10280, train_loss 27.925446,Time used 0.004967s\n",
      "batch 10281, train_loss 28.928919,Time used 0.005035s\n",
      "batch 10282, train_loss 25.568539,Time used 0.004999s\n",
      "batch 10283, train_loss 28.132412,Time used 0.005000s\n",
      "batch 10284, train_loss 23.252602,Time used 0.005997s\n",
      "batch 10285, train_loss 28.411255,Time used 0.005000s\n",
      "batch 10286, train_loss 21.432232,Time used 0.007965s\n",
      "batch 10287, train_loss 32.847290,Time used 0.010002s\n",
      "batch 10288, train_loss 32.593143,Time used 0.005000s\n",
      "batch 10289, train_loss 32.597607,Time used 0.005000s\n",
      "batch 10290, train_loss 26.193645,Time used 0.006001s\n",
      "batch 10291, train_loss 30.140871,Time used 0.004996s\n",
      "batch 10292, train_loss 26.696577,Time used 0.005000s\n",
      "batch 10293, train_loss 23.655474,Time used 0.006000s\n",
      "batch 10294, train_loss 25.485477,Time used 0.005999s\n",
      "batch 10295, train_loss 28.182541,Time used 0.005000s\n",
      "batch 10296, train_loss 28.142395,Time used 0.005003s\n",
      "batch 10297, train_loss 27.907059,Time used 0.004999s\n",
      "batch 10298, train_loss 23.094994,Time used 0.004967s\n",
      "batch 10299, train_loss 31.820398,Time used 0.004998s\n",
      "batch 10300, train_loss 29.879120,Time used 0.005000s\n",
      "***************************test_batch 10300, test_rmse_loss 6.735236,test_mae_loss 3.026394,test_mape_loss 51.337945,Time used 0.018033s\n",
      "batch 10301, train_loss 25.767324,Time used 0.005969s\n",
      "batch 10302, train_loss 19.056177,Time used 0.008000s\n",
      "batch 10303, train_loss 34.220825,Time used 0.007034s\n",
      "batch 10304, train_loss 29.921425,Time used 0.005002s\n",
      "batch 10305, train_loss 20.877739,Time used 0.005002s\n",
      "batch 10306, train_loss 27.503336,Time used 0.004998s\n",
      "batch 10307, train_loss 26.809757,Time used 0.007991s\n",
      "batch 10308, train_loss 28.386002,Time used 0.004994s\n",
      "batch 10309, train_loss 26.678196,Time used 0.006038s\n",
      "batch 10310, train_loss 31.389910,Time used 0.004999s\n",
      "batch 10311, train_loss 24.071609,Time used 0.005001s\n",
      "batch 10312, train_loss 27.972397,Time used 0.005964s\n",
      "batch 10313, train_loss 27.087704,Time used 0.005000s\n",
      "batch 10314, train_loss 32.147171,Time used 0.004999s\n",
      "batch 10315, train_loss 24.966227,Time used 0.007003s\n",
      "batch 10316, train_loss 28.318705,Time used 0.006000s\n",
      "batch 10317, train_loss 28.512518,Time used 0.005997s\n",
      "batch 10318, train_loss 26.981512,Time used 0.006000s\n",
      "batch 10319, train_loss 28.784010,Time used 0.004999s\n",
      "batch 10320, train_loss 24.377876,Time used 0.005001s\n",
      "batch 10321, train_loss 24.445601,Time used 0.006999s\n",
      "batch 10322, train_loss 25.532911,Time used 0.008000s\n",
      "batch 10323, train_loss 24.658583,Time used 0.006001s\n",
      "batch 10324, train_loss 26.952684,Time used 0.004999s\n",
      "batch 10325, train_loss 30.843920,Time used 0.006000s\n",
      "batch 10326, train_loss 30.959896,Time used 0.008001s\n",
      "batch 10327, train_loss 28.508530,Time used 0.005998s\n",
      "batch 10328, train_loss 29.362562,Time used 0.005037s\n",
      "batch 10329, train_loss 27.887341,Time used 0.004998s\n",
      "batch 10330, train_loss 31.396996,Time used 0.004965s\n",
      "batch 10331, train_loss 25.762384,Time used 0.006000s\n",
      "batch 10332, train_loss 24.079845,Time used 0.006999s\n",
      "batch 10333, train_loss 24.357159,Time used 0.006000s\n",
      "batch 10334, train_loss 29.417788,Time used 0.006011s\n",
      "batch 10335, train_loss 32.376163,Time used 0.007001s\n",
      "batch 10336, train_loss 20.040009,Time used 0.007998s\n",
      "batch 10337, train_loss 29.287262,Time used 0.005001s\n",
      "batch 10338, train_loss 27.556723,Time used 0.005000s\n",
      "batch 10339, train_loss 25.181547,Time used 0.004999s\n",
      "batch 10340, train_loss 27.048496,Time used 0.004999s\n",
      "batch 10341, train_loss 30.570234,Time used 0.005002s\n",
      "batch 10342, train_loss 27.763990,Time used 0.005998s\n",
      "batch 10343, train_loss 22.697474,Time used 0.005000s\n",
      "batch 10344, train_loss 28.407797,Time used 0.006002s\n",
      "batch 10345, train_loss 28.784096,Time used 0.005000s\n",
      "batch 10346, train_loss 27.119898,Time used 0.006999s\n",
      "batch 10347, train_loss 25.428505,Time used 0.005000s\n",
      "batch 10348, train_loss 31.907688,Time used 0.005001s\n",
      "batch 10349, train_loss 30.154087,Time used 0.005999s\n",
      "batch 10350, train_loss 23.696966,Time used 0.005000s\n",
      "batch 10351, train_loss 29.233215,Time used 0.006003s\n",
      "batch 10352, train_loss 25.789249,Time used 0.004998s\n",
      "batch 10353, train_loss 28.044907,Time used 0.003999s\n",
      "batch 10354, train_loss 30.648230,Time used 0.006003s\n",
      "batch 10355, train_loss 28.669733,Time used 0.008997s\n",
      "batch 10356, train_loss 23.781982,Time used 0.004999s\n",
      "batch 10357, train_loss 24.413006,Time used 0.004999s\n",
      "batch 10358, train_loss 26.299486,Time used 0.006000s\n",
      "batch 10359, train_loss 25.816280,Time used 0.005002s\n",
      "batch 10360, train_loss 28.898209,Time used 0.004997s\n",
      "batch 10361, train_loss 29.515747,Time used 0.004999s\n",
      "batch 10362, train_loss 28.567062,Time used 0.005003s\n",
      "batch 10363, train_loss 29.189816,Time used 0.005997s\n",
      "batch 10364, train_loss 21.480770,Time used 0.004999s\n",
      "batch 10365, train_loss 23.347317,Time used 0.007000s\n",
      "batch 10366, train_loss 26.089676,Time used 0.005000s\n",
      "batch 10367, train_loss 28.464823,Time used 0.005000s\n",
      "batch 10368, train_loss 28.478014,Time used 0.008004s\n",
      "batch 10369, train_loss 26.012360,Time used 0.007994s\n",
      "batch 10370, train_loss 28.535849,Time used 0.005001s\n",
      "batch 10371, train_loss 25.453501,Time used 0.006002s\n",
      "batch 10372, train_loss 28.061859,Time used 0.009001s\n",
      "batch 10373, train_loss 18.812263,Time used 0.008999s\n",
      "batch 10374, train_loss 29.453991,Time used 0.008000s\n",
      "batch 10375, train_loss 23.879751,Time used 0.008000s\n",
      "batch 10376, train_loss 25.961462,Time used 0.007998s\n",
      "batch 10377, train_loss 27.643393,Time used 0.008002s\n",
      "batch 10378, train_loss 36.806366,Time used 0.005034s\n",
      "batch 10379, train_loss 29.564890,Time used 0.005968s\n",
      "batch 10380, train_loss 23.827627,Time used 0.005999s\n",
      "batch 10381, train_loss 26.257042,Time used 0.007999s\n",
      "batch 10382, train_loss 26.733513,Time used 0.007007s\n",
      "batch 10383, train_loss 27.693565,Time used 0.005034s\n",
      "batch 10384, train_loss 26.793865,Time used 0.005961s\n",
      "batch 10385, train_loss 27.517740,Time used 0.004998s\n",
      "batch 10386, train_loss 27.501888,Time used 0.005000s\n",
      "batch 10387, train_loss 24.893328,Time used 0.005040s\n",
      "batch 10388, train_loss 31.113279,Time used 0.004998s\n",
      "batch 10389, train_loss 26.067354,Time used 0.005002s\n",
      "batch 10390, train_loss 25.683762,Time used 0.005965s\n",
      "batch 10391, train_loss 31.056784,Time used 0.005000s\n",
      "batch 10392, train_loss 26.787254,Time used 0.004997s\n",
      "batch 10393, train_loss 28.608912,Time used 0.004998s\n",
      "batch 10394, train_loss 23.242849,Time used 0.007006s\n",
      "batch 10395, train_loss 25.000753,Time used 0.004998s\n",
      "batch 10396, train_loss 33.829597,Time used 0.004999s\n",
      "batch 10397, train_loss 23.384218,Time used 0.004999s\n",
      "batch 10398, train_loss 27.970779,Time used 0.005000s\n",
      "batch 10399, train_loss 22.721069,Time used 0.004997s\n",
      "batch 10400, train_loss 25.695213,Time used 0.005001s\n",
      "***************************test_batch 10400, test_rmse_loss 6.734616,test_mae_loss 3.025408,test_mape_loss 51.409026,Time used 0.018998s\n",
      "batch 10401, train_loss 29.997242,Time used 0.006999s\n",
      "batch 10402, train_loss 25.795305,Time used 0.006002s\n",
      "batch 10403, train_loss 26.057018,Time used 0.005999s\n",
      "batch 10404, train_loss 25.191469,Time used 0.005000s\n",
      "batch 10405, train_loss 28.066442,Time used 0.005003s\n",
      "batch 10406, train_loss 25.675596,Time used 0.007000s\n",
      "batch 10407, train_loss 28.207695,Time used 0.005999s\n",
      "batch 10408, train_loss 23.912321,Time used 0.005000s\n",
      "batch 10409, train_loss 29.629915,Time used 0.006001s\n",
      "batch 10410, train_loss 26.322411,Time used 0.006002s\n",
      "batch 10411, train_loss 32.354866,Time used 0.005999s\n",
      "batch 10412, train_loss 31.362545,Time used 0.008001s\n",
      "batch 10413, train_loss 25.340446,Time used 0.008000s\n",
      "batch 10414, train_loss 25.830385,Time used 0.004999s\n",
      "batch 10415, train_loss 25.730452,Time used 0.005034s\n",
      "batch 10416, train_loss 31.363958,Time used 0.006002s\n",
      "batch 10417, train_loss 27.135078,Time used 0.007965s\n",
      "batch 10418, train_loss 28.632710,Time used 0.005999s\n",
      "batch 10419, train_loss 28.707209,Time used 0.006037s\n",
      "batch 10420, train_loss 23.211617,Time used 0.004968s\n",
      "batch 10421, train_loss 23.337456,Time used 0.006031s\n",
      "batch 10422, train_loss 27.127836,Time used 0.005000s\n",
      "batch 10423, train_loss 32.509220,Time used 0.005001s\n",
      "batch 10424, train_loss 24.729900,Time used 0.005002s\n",
      "batch 10425, train_loss 25.971148,Time used 0.004997s\n",
      "batch 10426, train_loss 23.995323,Time used 0.006003s\n",
      "batch 10427, train_loss 28.985922,Time used 0.004999s\n",
      "batch 10428, train_loss 29.738703,Time used 0.004965s\n",
      "batch 10429, train_loss 25.494005,Time used 0.007965s\n",
      "batch 10430, train_loss 25.510008,Time used 0.008003s\n",
      "batch 10431, train_loss 26.709681,Time used 0.008000s\n",
      "batch 10432, train_loss 26.079977,Time used 0.004996s\n",
      "batch 10433, train_loss 27.941031,Time used 0.007002s\n",
      "batch 10434, train_loss 26.885775,Time used 0.008041s\n",
      "batch 10435, train_loss 22.594479,Time used 0.004997s\n",
      "batch 10436, train_loss 26.511318,Time used 0.005008s\n",
      "batch 10437, train_loss 31.392515,Time used 0.006957s\n",
      "batch 10438, train_loss 27.121033,Time used 0.007036s\n",
      "batch 10439, train_loss 26.992277,Time used 0.006999s\n",
      "batch 10440, train_loss 32.657288,Time used 0.004015s\n",
      "batch 10441, train_loss 27.889498,Time used 0.004993s\n",
      "batch 10442, train_loss 26.263647,Time used 0.005000s\n",
      "batch 10443, train_loss 26.637230,Time used 0.005967s\n",
      "batch 10444, train_loss 26.951044,Time used 0.004997s\n",
      "batch 10445, train_loss 22.173395,Time used 0.004998s\n",
      "batch 10446, train_loss 31.590839,Time used 0.006003s\n",
      "batch 10447, train_loss 26.387470,Time used 0.004997s\n",
      "batch 10448, train_loss 23.521900,Time used 0.005000s\n",
      "batch 10449, train_loss 28.314205,Time used 0.005002s\n",
      "batch 10450, train_loss 35.375202,Time used 0.008037s\n",
      "batch 10451, train_loss 25.336800,Time used 0.004969s\n",
      "batch 10452, train_loss 28.526335,Time used 0.004997s\n",
      "batch 10453, train_loss 27.639153,Time used 0.004998s\n",
      "batch 10454, train_loss 27.874283,Time used 0.005001s\n",
      "batch 10455, train_loss 24.119457,Time used 0.004999s\n",
      "batch 10456, train_loss 28.014305,Time used 0.005000s\n",
      "batch 10457, train_loss 28.838381,Time used 0.005000s\n",
      "batch 10458, train_loss 27.696419,Time used 0.006001s\n",
      "batch 10459, train_loss 24.472555,Time used 0.004999s\n",
      "batch 10460, train_loss 27.457628,Time used 0.005000s\n",
      "batch 10461, train_loss 25.282793,Time used 0.006001s\n",
      "batch 10462, train_loss 25.216845,Time used 0.006999s\n",
      "batch 10463, train_loss 24.147572,Time used 0.005000s\n",
      "batch 10464, train_loss 28.761761,Time used 0.006001s\n",
      "batch 10465, train_loss 25.147560,Time used 0.007000s\n",
      "batch 10466, train_loss 30.665636,Time used 0.008000s\n",
      "batch 10467, train_loss 25.357079,Time used 0.005002s\n",
      "batch 10468, train_loss 26.545219,Time used 0.005001s\n",
      "batch 10469, train_loss 27.614944,Time used 0.006998s\n",
      "batch 10470, train_loss 24.772779,Time used 0.006000s\n",
      "batch 10471, train_loss 26.702297,Time used 0.007002s\n",
      "batch 10472, train_loss 23.558710,Time used 0.005002s\n",
      "batch 10473, train_loss 30.362986,Time used 0.005000s\n",
      "batch 10474, train_loss 29.517294,Time used 0.005002s\n",
      "batch 10475, train_loss 26.366772,Time used 0.005000s\n",
      "batch 10476, train_loss 22.161154,Time used 0.005998s\n",
      "batch 10477, train_loss 30.702339,Time used 0.005998s\n",
      "batch 10478, train_loss 26.272400,Time used 0.005000s\n",
      "batch 10479, train_loss 28.123264,Time used 0.004999s\n",
      "batch 10480, train_loss 25.080265,Time used 0.005000s\n",
      "batch 10481, train_loss 29.145794,Time used 0.006001s\n",
      "batch 10482, train_loss 30.627647,Time used 0.004999s\n",
      "batch 10483, train_loss 29.445963,Time used 0.005000s\n",
      "batch 10484, train_loss 23.327055,Time used 0.006001s\n",
      "batch 10485, train_loss 31.004093,Time used 0.004000s\n",
      "batch 10486, train_loss 24.603823,Time used 0.006001s\n",
      "batch 10487, train_loss 25.795008,Time used 0.005000s\n",
      "batch 10488, train_loss 24.120474,Time used 0.005000s\n",
      "batch 10489, train_loss 25.923546,Time used 0.005998s\n",
      "batch 10490, train_loss 28.088255,Time used 0.006001s\n",
      "batch 10491, train_loss 28.003479,Time used 0.004999s\n",
      "batch 10492, train_loss 26.771988,Time used 0.005001s\n",
      "batch 10493, train_loss 26.334551,Time used 0.006001s\n",
      "batch 10494, train_loss 26.614756,Time used 0.004999s\n",
      "batch 10495, train_loss 24.854834,Time used 0.006002s\n",
      "batch 10496, train_loss 25.743746,Time used 0.004999s\n",
      "batch 10497, train_loss 29.129980,Time used 0.004998s\n",
      "batch 10498, train_loss 24.076878,Time used 0.006001s\n",
      "batch 10499, train_loss 24.962759,Time used 0.005000s\n",
      "batch 10500, train_loss 24.797987,Time used 0.005999s\n",
      "***************************test_batch 10500, test_rmse_loss 6.719511,test_mae_loss 3.017981,test_mape_loss 51.139294,Time used 0.026000s\n",
      "batch 10501, train_loss 27.588062,Time used 0.007001s\n",
      "batch 10502, train_loss 30.437532,Time used 0.008000s\n",
      "batch 10503, train_loss 25.527756,Time used 0.006001s\n",
      "batch 10504, train_loss 22.710991,Time used 0.005000s\n",
      "batch 10505, train_loss 26.831644,Time used 0.005999s\n",
      "batch 10506, train_loss 25.424614,Time used 0.006001s\n",
      "batch 10507, train_loss 33.288692,Time used 0.004999s\n",
      "batch 10508, train_loss 28.683760,Time used 0.005001s\n",
      "batch 10509, train_loss 27.882738,Time used 0.005999s\n",
      "batch 10510, train_loss 28.993023,Time used 0.005000s\n",
      "batch 10511, train_loss 25.517550,Time used 0.005002s\n",
      "batch 10512, train_loss 27.799696,Time used 0.005001s\n",
      "batch 10513, train_loss 23.768854,Time used 0.004997s\n",
      "batch 10514, train_loss 29.838810,Time used 0.004999s\n",
      "batch 10515, train_loss 34.179089,Time used 0.006000s\n",
      "batch 10516, train_loss 26.434788,Time used 0.005000s\n",
      "batch 10517, train_loss 26.405272,Time used 0.005000s\n",
      "batch 10518, train_loss 24.345150,Time used 0.005009s\n",
      "batch 10519, train_loss 26.447336,Time used 0.005992s\n",
      "batch 10520, train_loss 26.515587,Time used 0.005000s\n",
      "batch 10521, train_loss 22.337492,Time used 0.007000s\n",
      "batch 10522, train_loss 27.580599,Time used 0.008000s\n",
      "batch 10523, train_loss 28.053679,Time used 0.007000s\n",
      "batch 10524, train_loss 33.984707,Time used 0.004995s\n",
      "batch 10525, train_loss 24.775089,Time used 0.008999s\n",
      "batch 10526, train_loss 25.441677,Time used 0.007001s\n",
      "batch 10527, train_loss 29.863573,Time used 0.006001s\n",
      "batch 10528, train_loss 24.861971,Time used 0.005999s\n",
      "batch 10529, train_loss 23.363436,Time used 0.005000s\n",
      "batch 10530, train_loss 24.371174,Time used 0.005999s\n",
      "batch 10531, train_loss 25.246897,Time used 0.005000s\n",
      "batch 10532, train_loss 29.705605,Time used 0.005002s\n",
      "batch 10533, train_loss 29.146694,Time used 0.006000s\n",
      "batch 10534, train_loss 25.309631,Time used 0.005000s\n",
      "batch 10535, train_loss 22.060186,Time used 0.005001s\n",
      "batch 10536, train_loss 30.481760,Time used 0.006000s\n",
      "batch 10537, train_loss 23.903402,Time used 0.005998s\n",
      "batch 10538, train_loss 28.955923,Time used 0.008001s\n",
      "batch 10539, train_loss 27.479422,Time used 0.005004s\n",
      "batch 10540, train_loss 21.947956,Time used 0.005001s\n",
      "batch 10541, train_loss 25.815996,Time used 0.005035s\n",
      "batch 10542, train_loss 26.719236,Time used 0.009000s\n",
      "batch 10543, train_loss 28.507135,Time used 0.004966s\n",
      "batch 10544, train_loss 24.901562,Time used 0.006996s\n",
      "batch 10545, train_loss 28.624723,Time used 0.007998s\n",
      "batch 10546, train_loss 28.171816,Time used 0.007000s\n",
      "batch 10547, train_loss 29.463379,Time used 0.006007s\n",
      "batch 10548, train_loss 29.717110,Time used 0.005032s\n",
      "batch 10549, train_loss 26.752447,Time used 0.006003s\n",
      "batch 10550, train_loss 24.121918,Time used 0.005960s\n",
      "batch 10551, train_loss 27.608351,Time used 0.005998s\n",
      "batch 10552, train_loss 32.759140,Time used 0.007000s\n",
      "batch 10553, train_loss 25.468536,Time used 0.012000s\n",
      "batch 10554, train_loss 26.350464,Time used 0.005000s\n",
      "batch 10555, train_loss 27.753721,Time used 0.006999s\n",
      "batch 10556, train_loss 26.880611,Time used 0.008038s\n",
      "batch 10557, train_loss 23.591427,Time used 0.006965s\n",
      "batch 10558, train_loss 28.810072,Time used 0.008000s\n",
      "batch 10559, train_loss 21.002048,Time used 0.006000s\n",
      "batch 10560, train_loss 27.534679,Time used 0.005034s\n",
      "batch 10561, train_loss 25.410553,Time used 0.005001s\n",
      "batch 10562, train_loss 25.737638,Time used 0.005962s\n",
      "batch 10563, train_loss 22.935127,Time used 0.005001s\n",
      "batch 10564, train_loss 25.736998,Time used 0.005001s\n",
      "batch 10565, train_loss 26.306509,Time used 0.006999s\n",
      "batch 10566, train_loss 24.393003,Time used 0.005000s\n",
      "batch 10567, train_loss 28.864691,Time used 0.005005s\n",
      "batch 10568, train_loss 31.279211,Time used 0.005032s\n",
      "batch 10569, train_loss 24.629011,Time used 0.005998s\n",
      "batch 10570, train_loss 20.450430,Time used 0.004969s\n",
      "batch 10571, train_loss 30.423824,Time used 0.004000s\n",
      "batch 10572, train_loss 24.166033,Time used 0.005000s\n",
      "batch 10573, train_loss 33.009701,Time used 0.005041s\n",
      "batch 10574, train_loss 27.075592,Time used 0.006993s\n",
      "batch 10575, train_loss 23.999647,Time used 0.007998s\n",
      "batch 10576, train_loss 24.775019,Time used 0.006964s\n",
      "batch 10577, train_loss 31.898537,Time used 0.005000s\n",
      "batch 10578, train_loss 25.391956,Time used 0.007037s\n",
      "batch 10579, train_loss 25.170633,Time used 0.006998s\n",
      "batch 10580, train_loss 31.321871,Time used 0.008000s\n",
      "batch 10581, train_loss 25.152384,Time used 0.005968s\n",
      "batch 10582, train_loss 22.761578,Time used 0.005031s\n",
      "batch 10583, train_loss 31.762947,Time used 0.007963s\n",
      "batch 10584, train_loss 29.053360,Time used 0.005037s\n",
      "batch 10585, train_loss 25.744316,Time used 0.004997s\n",
      "batch 10586, train_loss 25.092806,Time used 0.005001s\n",
      "batch 10587, train_loss 27.386366,Time used 0.007039s\n",
      "batch 10588, train_loss 26.915483,Time used 0.004998s\n",
      "batch 10589, train_loss 27.107533,Time used 0.004963s\n",
      "batch 10590, train_loss 25.382656,Time used 0.008002s\n",
      "batch 10591, train_loss 25.327528,Time used 0.008000s\n",
      "batch 10592, train_loss 25.457584,Time used 0.005000s\n",
      "batch 10593, train_loss 25.141985,Time used 0.007033s\n",
      "batch 10594, train_loss 25.322969,Time used 0.006964s\n",
      "batch 10595, train_loss 31.782267,Time used 0.005038s\n",
      "batch 10596, train_loss 23.238398,Time used 0.004998s\n",
      "batch 10597, train_loss 26.972248,Time used 0.004968s\n",
      "batch 10598, train_loss 27.186594,Time used 0.004999s\n",
      "batch 10599, train_loss 26.351938,Time used 0.005000s\n",
      "batch 10600, train_loss 26.060947,Time used 0.005039s\n",
      "***************************test_batch 10600, test_rmse_loss 6.685212,test_mae_loss 3.006697,test_mape_loss 51.132507,Time used 0.016965s\n",
      "batch 10601, train_loss 21.422201,Time used 0.004999s\n",
      "batch 10602, train_loss 25.856771,Time used 0.005000s\n",
      "batch 10603, train_loss 25.990211,Time used 0.006004s\n",
      "batch 10604, train_loss 29.114239,Time used 0.004999s\n",
      "batch 10605, train_loss 31.736067,Time used 0.005000s\n",
      "batch 10606, train_loss 30.846212,Time used 0.005002s\n",
      "batch 10607, train_loss 28.935858,Time used 0.005003s\n",
      "batch 10608, train_loss 25.791748,Time used 0.005999s\n",
      "batch 10609, train_loss 25.311987,Time used 0.005972s\n",
      "batch 10610, train_loss 25.761887,Time used 0.008033s\n",
      "batch 10611, train_loss 25.648088,Time used 0.005963s\n",
      "batch 10612, train_loss 27.407055,Time used 0.005002s\n",
      "batch 10613, train_loss 25.883858,Time used 0.005036s\n",
      "batch 10614, train_loss 22.816256,Time used 0.004997s\n",
      "batch 10615, train_loss 24.141582,Time used 0.004968s\n",
      "batch 10616, train_loss 21.350090,Time used 0.006000s\n",
      "batch 10617, train_loss 29.823479,Time used 0.005000s\n",
      "batch 10618, train_loss 27.293200,Time used 0.007001s\n",
      "batch 10619, train_loss 25.437246,Time used 0.004998s\n",
      "batch 10620, train_loss 25.965557,Time used 0.004999s\n",
      "batch 10621, train_loss 27.928905,Time used 0.006033s\n",
      "batch 10622, train_loss 27.618006,Time used 0.004968s\n",
      "batch 10623, train_loss 22.538858,Time used 0.005032s\n",
      "batch 10624, train_loss 32.313801,Time used 0.005965s\n",
      "batch 10625, train_loss 26.473690,Time used 0.005036s\n",
      "batch 10626, train_loss 25.148811,Time used 0.004989s\n",
      "batch 10627, train_loss 29.961664,Time used 0.005013s\n",
      "batch 10628, train_loss 27.300877,Time used 0.004966s\n",
      "batch 10629, train_loss 26.684221,Time used 0.005000s\n",
      "batch 10630, train_loss 24.959578,Time used 0.007999s\n",
      "batch 10631, train_loss 37.596306,Time used 0.006000s\n",
      "batch 10632, train_loss 23.746326,Time used 0.005000s\n",
      "batch 10633, train_loss 27.052982,Time used 0.004983s\n",
      "batch 10634, train_loss 26.115046,Time used 0.006002s\n",
      "batch 10635, train_loss 29.597139,Time used 0.004999s\n",
      "batch 10636, train_loss 26.788536,Time used 0.004998s\n",
      "batch 10637, train_loss 29.102898,Time used 0.005965s\n",
      "batch 10638, train_loss 28.168049,Time used 0.008001s\n",
      "batch 10639, train_loss 27.277149,Time used 0.007997s\n",
      "batch 10640, train_loss 23.368111,Time used 0.006038s\n",
      "batch 10641, train_loss 27.781204,Time used 0.007965s\n",
      "batch 10642, train_loss 20.203911,Time used 0.006034s\n",
      "batch 10643, train_loss 28.132912,Time used 0.005005s\n",
      "batch 10644, train_loss 28.420734,Time used 0.006962s\n",
      "batch 10645, train_loss 29.108818,Time used 0.006997s\n",
      "batch 10646, train_loss 23.618885,Time used 0.008004s\n",
      "batch 10647, train_loss 27.576624,Time used 0.008035s\n",
      "batch 10648, train_loss 25.799608,Time used 0.004967s\n",
      "batch 10649, train_loss 29.376900,Time used 0.006034s\n",
      "batch 10650, train_loss 27.875338,Time used 0.005009s\n",
      "batch 10651, train_loss 28.047832,Time used 0.004955s\n",
      "batch 10652, train_loss 28.796850,Time used 0.006004s\n",
      "batch 10653, train_loss 24.264313,Time used 0.006032s\n",
      "batch 10654, train_loss 24.521971,Time used 0.005003s\n",
      "batch 10655, train_loss 24.096561,Time used 0.005000s\n",
      "batch 10656, train_loss 22.704754,Time used 0.004969s\n",
      "batch 10657, train_loss 25.491873,Time used 0.004995s\n",
      "batch 10658, train_loss 27.423466,Time used 0.006003s\n",
      "batch 10659, train_loss 26.309963,Time used 0.008000s\n",
      "batch 10660, train_loss 26.052402,Time used 0.008000s\n",
      "batch 10661, train_loss 29.001331,Time used 0.004997s\n",
      "batch 10662, train_loss 31.273489,Time used 0.006000s\n",
      "batch 10663, train_loss 32.857677,Time used 0.005001s\n",
      "batch 10664, train_loss 23.112181,Time used 0.006002s\n",
      "batch 10665, train_loss 27.591011,Time used 0.005035s\n",
      "batch 10666, train_loss 28.619486,Time used 0.004998s\n",
      "batch 10667, train_loss 26.764568,Time used 0.005970s\n",
      "batch 10668, train_loss 23.273220,Time used 0.006032s\n",
      "batch 10669, train_loss 24.594275,Time used 0.004966s\n",
      "batch 10670, train_loss 25.259951,Time used 0.004998s\n",
      "batch 10671, train_loss 24.684772,Time used 0.005003s\n",
      "batch 10672, train_loss 25.051548,Time used 0.005000s\n",
      "batch 10673, train_loss 27.348679,Time used 0.004995s\n",
      "batch 10674, train_loss 28.736088,Time used 0.006004s\n",
      "batch 10675, train_loss 25.285378,Time used 0.008003s\n",
      "batch 10676, train_loss 27.977472,Time used 0.004997s\n",
      "batch 10677, train_loss 24.210848,Time used 0.005000s\n",
      "batch 10678, train_loss 28.514158,Time used 0.008998s\n",
      "batch 10679, train_loss 21.998085,Time used 0.006001s\n",
      "batch 10680, train_loss 24.873465,Time used 0.006001s\n",
      "batch 10681, train_loss 22.442793,Time used 0.005031s\n",
      "batch 10682, train_loss 24.732367,Time used 0.006000s\n",
      "batch 10683, train_loss 25.663631,Time used 0.005001s\n",
      "batch 10684, train_loss 27.934053,Time used 0.004996s\n",
      "batch 10685, train_loss 23.838263,Time used 0.004001s\n",
      "batch 10686, train_loss 24.650522,Time used 0.005002s\n",
      "batch 10687, train_loss 22.709238,Time used 0.005002s\n",
      "batch 10688, train_loss 26.176262,Time used 0.004003s\n",
      "batch 10689, train_loss 25.791553,Time used 0.004999s\n",
      "batch 10690, train_loss 26.900936,Time used 0.006000s\n",
      "batch 10691, train_loss 27.315451,Time used 0.006997s\n",
      "batch 10692, train_loss 25.618715,Time used 0.006000s\n",
      "batch 10693, train_loss 31.022230,Time used 0.008003s\n",
      "batch 10694, train_loss 29.393438,Time used 0.008003s\n",
      "batch 10695, train_loss 26.335108,Time used 0.006999s\n",
      "batch 10696, train_loss 32.472908,Time used 0.005996s\n",
      "batch 10697, train_loss 26.183706,Time used 0.005002s\n",
      "batch 10698, train_loss 25.754780,Time used 0.006001s\n",
      "batch 10699, train_loss 25.762295,Time used 0.005002s\n",
      "batch 10700, train_loss 25.064121,Time used 0.004998s\n",
      "***************************test_batch 10700, test_rmse_loss 6.650447,test_mae_loss 2.996168,test_mape_loss 51.326545,Time used 0.018005s\n",
      "batch 10701, train_loss 29.380985,Time used 0.005995s\n",
      "batch 10702, train_loss 27.154573,Time used 0.006999s\n",
      "batch 10703, train_loss 26.082525,Time used 0.006000s\n",
      "batch 10704, train_loss 26.189629,Time used 0.005006s\n",
      "batch 10705, train_loss 29.062126,Time used 0.005003s\n",
      "batch 10706, train_loss 27.057976,Time used 0.007999s\n",
      "batch 10707, train_loss 27.596008,Time used 0.008033s\n",
      "batch 10708, train_loss 29.453547,Time used 0.008966s\n",
      "batch 10709, train_loss 26.070684,Time used 0.007997s\n",
      "batch 10710, train_loss 21.376104,Time used 0.008001s\n",
      "batch 10711, train_loss 25.748960,Time used 0.008000s\n",
      "batch 10712, train_loss 29.112020,Time used 0.006000s\n",
      "batch 10713, train_loss 28.024162,Time used 0.005000s\n",
      "batch 10714, train_loss 24.366518,Time used 0.006001s\n",
      "batch 10715, train_loss 24.400042,Time used 0.005998s\n",
      "batch 10716, train_loss 30.248341,Time used 0.005000s\n",
      "batch 10717, train_loss 26.461153,Time used 0.006002s\n",
      "batch 10718, train_loss 24.607897,Time used 0.004998s\n",
      "batch 10719, train_loss 24.501877,Time used 0.006001s\n",
      "batch 10720, train_loss 30.851440,Time used 0.007000s\n",
      "batch 10721, train_loss 33.694290,Time used 0.006999s\n",
      "batch 10722, train_loss 26.055286,Time used 0.009000s\n",
      "batch 10723, train_loss 23.970224,Time used 0.007001s\n",
      "batch 10724, train_loss 24.466991,Time used 0.006002s\n",
      "batch 10725, train_loss 22.942728,Time used 0.007999s\n",
      "batch 10726, train_loss 25.013006,Time used 0.007999s\n",
      "batch 10727, train_loss 25.105869,Time used 0.006003s\n",
      "batch 10728, train_loss 23.241491,Time used 0.006998s\n",
      "batch 10729, train_loss 24.312614,Time used 0.004999s\n",
      "batch 10730, train_loss 30.143845,Time used 0.006000s\n",
      "batch 10731, train_loss 21.810514,Time used 0.004997s\n",
      "batch 10732, train_loss 29.417923,Time used 0.005001s\n",
      "batch 10733, train_loss 27.791357,Time used 0.005999s\n",
      "batch 10734, train_loss 21.567690,Time used 0.005000s\n",
      "batch 10735, train_loss 22.679871,Time used 0.005000s\n",
      "batch 10736, train_loss 29.150454,Time used 0.006004s\n",
      "batch 10737, train_loss 28.977882,Time used 0.005998s\n",
      "batch 10738, train_loss 24.526203,Time used 0.005000s\n",
      "batch 10739, train_loss 26.135506,Time used 0.007000s\n",
      "batch 10740, train_loss 27.709797,Time used 0.004998s\n",
      "batch 10741, train_loss 26.252398,Time used 0.006004s\n",
      "batch 10742, train_loss 24.079819,Time used 0.010998s\n",
      "batch 10743, train_loss 28.135633,Time used 0.006000s\n",
      "batch 10744, train_loss 28.082277,Time used 0.006001s\n",
      "batch 10745, train_loss 28.261831,Time used 0.005999s\n",
      "batch 10746, train_loss 25.506516,Time used 0.006000s\n",
      "batch 10747, train_loss 27.916460,Time used 0.007000s\n",
      "batch 10748, train_loss 27.505278,Time used 0.007000s\n",
      "batch 10749, train_loss 24.375660,Time used 0.007001s\n",
      "batch 10750, train_loss 24.424959,Time used 0.006001s\n",
      "batch 10751, train_loss 25.698389,Time used 0.008000s\n",
      "batch 10752, train_loss 27.972479,Time used 0.006999s\n",
      "batch 10753, train_loss 26.473270,Time used 0.007003s\n",
      "batch 10754, train_loss 20.753263,Time used 0.004999s\n",
      "batch 10755, train_loss 28.545410,Time used 0.006000s\n",
      "batch 10756, train_loss 27.069046,Time used 0.005002s\n",
      "batch 10757, train_loss 26.944412,Time used 0.007999s\n",
      "batch 10758, train_loss 30.120974,Time used 0.007998s\n",
      "batch 10759, train_loss 26.406204,Time used 0.005001s\n",
      "batch 10760, train_loss 27.238459,Time used 0.005002s\n",
      "batch 10761, train_loss 19.899614,Time used 0.007999s\n",
      "batch 10762, train_loss 29.099327,Time used 0.007999s\n",
      "batch 10763, train_loss 26.930916,Time used 0.007996s\n",
      "batch 10764, train_loss 28.208805,Time used 0.005000s\n",
      "batch 10765, train_loss 27.203165,Time used 0.006002s\n",
      "batch 10766, train_loss 27.236177,Time used 0.004997s\n",
      "batch 10767, train_loss 29.192738,Time used 0.005000s\n",
      "batch 10768, train_loss 27.386574,Time used 0.006002s\n",
      "batch 10769, train_loss 27.478386,Time used 0.006000s\n",
      "batch 10770, train_loss 22.407524,Time used 0.005001s\n",
      "batch 10771, train_loss 26.678379,Time used 0.006998s\n",
      "batch 10772, train_loss 23.120289,Time used 0.005000s\n",
      "batch 10773, train_loss 26.355644,Time used 0.004999s\n",
      "batch 10774, train_loss 23.484495,Time used 0.006003s\n",
      "batch 10775, train_loss 30.509010,Time used 0.004999s\n",
      "batch 10776, train_loss 21.919161,Time used 0.005000s\n",
      "batch 10777, train_loss 25.181559,Time used 0.005001s\n",
      "batch 10778, train_loss 27.788620,Time used 0.006999s\n",
      "batch 10779, train_loss 26.915308,Time used 0.004998s\n",
      "batch 10780, train_loss 27.292831,Time used 0.005000s\n",
      "batch 10781, train_loss 23.422703,Time used 0.006003s\n",
      "batch 10782, train_loss 26.692461,Time used 0.006000s\n",
      "batch 10783, train_loss 23.622509,Time used 0.005000s\n",
      "batch 10784, train_loss 33.573963,Time used 0.006002s\n",
      "batch 10785, train_loss 25.121365,Time used 0.005001s\n",
      "batch 10786, train_loss 30.481638,Time used 0.006001s\n",
      "batch 10787, train_loss 27.386719,Time used 0.005999s\n",
      "batch 10788, train_loss 26.140467,Time used 0.005000s\n",
      "batch 10789, train_loss 27.448284,Time used 0.006003s\n",
      "batch 10790, train_loss 23.085331,Time used 0.005000s\n",
      "batch 10791, train_loss 24.383539,Time used 0.005000s\n",
      "batch 10792, train_loss 25.831627,Time used 0.006000s\n",
      "batch 10793, train_loss 26.118879,Time used 0.005996s\n",
      "batch 10794, train_loss 23.389771,Time used 0.005000s\n",
      "batch 10795, train_loss 24.571623,Time used 0.006000s\n",
      "batch 10796, train_loss 25.394878,Time used 0.007999s\n",
      "batch 10797, train_loss 24.985172,Time used 0.007009s\n",
      "batch 10798, train_loss 23.404100,Time used 0.006036s\n",
      "batch 10799, train_loss 27.766853,Time used 0.005967s\n",
      "batch 10800, train_loss 29.645357,Time used 0.005000s\n",
      "***************************test_batch 10800, test_rmse_loss 6.663662,test_mae_loss 2.998800,test_mape_loss 51.166363,Time used 0.018000s\n",
      "batch 10801, train_loss 29.050798,Time used 0.007994s\n",
      "batch 10802, train_loss 26.758005,Time used 0.006001s\n",
      "batch 10803, train_loss 27.526712,Time used 0.006999s\n",
      "batch 10804, train_loss 29.183092,Time used 0.007999s\n",
      "batch 10805, train_loss 26.304310,Time used 0.007004s\n",
      "batch 10806, train_loss 23.473782,Time used 0.005000s\n",
      "batch 10807, train_loss 23.649931,Time used 0.006998s\n",
      "batch 10808, train_loss 26.516361,Time used 0.005002s\n",
      "batch 10809, train_loss 24.126263,Time used 0.005999s\n",
      "batch 10810, train_loss 24.145494,Time used 0.005000s\n",
      "batch 10811, train_loss 24.727873,Time used 0.005001s\n",
      "batch 10812, train_loss 24.264458,Time used 0.005998s\n",
      "batch 10813, train_loss 24.561850,Time used 0.006000s\n",
      "batch 10814, train_loss 27.013903,Time used 0.003999s\n",
      "batch 10815, train_loss 25.916943,Time used 0.005002s\n",
      "batch 10816, train_loss 30.191885,Time used 0.006999s\n",
      "batch 10817, train_loss 23.478886,Time used 0.007998s\n",
      "batch 10818, train_loss 26.988935,Time used 0.007004s\n",
      "batch 10819, train_loss 24.054045,Time used 0.007001s\n",
      "batch 10820, train_loss 25.457342,Time used 0.005000s\n",
      "batch 10821, train_loss 30.354374,Time used 0.005998s\n",
      "batch 10822, train_loss 24.091721,Time used 0.007001s\n",
      "batch 10823, train_loss 27.976992,Time used 0.005968s\n",
      "batch 10824, train_loss 28.181091,Time used 0.007999s\n",
      "batch 10825, train_loss 26.771523,Time used 0.004998s\n",
      "batch 10826, train_loss 22.504036,Time used 0.005002s\n",
      "batch 10827, train_loss 27.131565,Time used 0.004999s\n",
      "batch 10828, train_loss 22.130953,Time used 0.005000s\n",
      "batch 10829, train_loss 24.150631,Time used 0.005000s\n",
      "batch 10830, train_loss 21.376345,Time used 0.007002s\n",
      "batch 10831, train_loss 28.042164,Time used 0.006000s\n",
      "batch 10832, train_loss 31.373806,Time used 0.004999s\n",
      "batch 10833, train_loss 24.932825,Time used 0.005000s\n",
      "batch 10834, train_loss 28.126429,Time used 0.004998s\n",
      "batch 10835, train_loss 22.390253,Time used 0.005999s\n",
      "batch 10836, train_loss 26.927362,Time used 0.004998s\n",
      "batch 10837, train_loss 26.323893,Time used 0.007004s\n",
      "batch 10838, train_loss 26.075022,Time used 0.006999s\n",
      "batch 10839, train_loss 23.661196,Time used 0.004999s\n",
      "batch 10840, train_loss 25.791367,Time used 0.005998s\n",
      "batch 10841, train_loss 28.852057,Time used 0.005008s\n",
      "batch 10842, train_loss 22.921129,Time used 0.004997s\n",
      "batch 10843, train_loss 25.362642,Time used 0.005000s\n",
      "batch 10844, train_loss 29.982725,Time used 0.007997s\n",
      "batch 10845, train_loss 32.045212,Time used 0.007998s\n",
      "batch 10846, train_loss 29.517248,Time used 0.006002s\n",
      "batch 10847, train_loss 24.948225,Time used 0.004999s\n",
      "batch 10848, train_loss 25.481020,Time used 0.004999s\n",
      "batch 10849, train_loss 24.629128,Time used 0.005998s\n",
      "batch 10850, train_loss 22.155224,Time used 0.006004s\n",
      "batch 10851, train_loss 26.854815,Time used 0.005000s\n",
      "batch 10852, train_loss 25.511734,Time used 0.006000s\n",
      "batch 10853, train_loss 25.576035,Time used 0.004997s\n",
      "batch 10854, train_loss 24.424744,Time used 0.006000s\n",
      "batch 10855, train_loss 23.257166,Time used 0.005002s\n",
      "batch 10856, train_loss 22.962782,Time used 0.005998s\n",
      "batch 10857, train_loss 26.041533,Time used 0.006000s\n",
      "batch 10858, train_loss 26.083395,Time used 0.007001s\n",
      "batch 10859, train_loss 26.780792,Time used 0.005000s\n",
      "batch 10860, train_loss 26.965906,Time used 0.005002s\n",
      "batch 10861, train_loss 28.710276,Time used 0.007998s\n",
      "batch 10862, train_loss 22.756018,Time used 0.006998s\n",
      "batch 10863, train_loss 23.903069,Time used 0.006006s\n",
      "batch 10864, train_loss 24.522203,Time used 0.004995s\n",
      "batch 10865, train_loss 26.216785,Time used 0.006038s\n",
      "batch 10866, train_loss 26.966867,Time used 0.007999s\n",
      "batch 10867, train_loss 30.378803,Time used 0.006004s\n",
      "batch 10868, train_loss 28.908342,Time used 0.005960s\n",
      "batch 10869, train_loss 26.561882,Time used 0.006000s\n",
      "batch 10870, train_loss 24.957624,Time used 0.006033s\n",
      "batch 10871, train_loss 26.778103,Time used 0.005002s\n",
      "batch 10872, train_loss 34.293449,Time used 0.004964s\n",
      "batch 10873, train_loss 25.232855,Time used 0.007001s\n",
      "batch 10874, train_loss 23.451597,Time used 0.007034s\n",
      "batch 10875, train_loss 24.385984,Time used 0.007969s\n",
      "batch 10876, train_loss 27.796181,Time used 0.005999s\n",
      "batch 10877, train_loss 26.986029,Time used 0.007999s\n",
      "batch 10878, train_loss 26.191746,Time used 0.006002s\n",
      "batch 10879, train_loss 25.562593,Time used 0.006000s\n",
      "batch 10880, train_loss 28.683374,Time used 0.005000s\n",
      "batch 10881, train_loss 27.002758,Time used 0.006995s\n",
      "batch 10882, train_loss 28.220118,Time used 0.006000s\n",
      "batch 10883, train_loss 24.343176,Time used 0.006016s\n",
      "batch 10884, train_loss 23.211494,Time used 0.004986s\n",
      "batch 10885, train_loss 27.184238,Time used 0.004997s\n",
      "batch 10886, train_loss 28.212769,Time used 0.005001s\n",
      "batch 10887, train_loss 33.813690,Time used 0.006039s\n",
      "batch 10888, train_loss 22.183113,Time used 0.008004s\n",
      "batch 10889, train_loss 23.965611,Time used 0.006997s\n",
      "batch 10890, train_loss 23.091532,Time used 0.007001s\n",
      "batch 10891, train_loss 26.861115,Time used 0.009998s\n",
      "batch 10892, train_loss 30.475325,Time used 0.008001s\n",
      "batch 10893, train_loss 22.811928,Time used 0.007999s\n",
      "batch 10894, train_loss 24.986675,Time used 0.005000s\n",
      "batch 10895, train_loss 26.999184,Time used 0.008000s\n",
      "batch 10896, train_loss 22.754372,Time used 0.007999s\n",
      "batch 10897, train_loss 25.162994,Time used 0.007999s\n",
      "batch 10898, train_loss 27.265787,Time used 0.004999s\n",
      "batch 10899, train_loss 24.808874,Time used 0.005000s\n",
      "batch 10900, train_loss 28.734903,Time used 0.005998s\n",
      "***************************test_batch 10900, test_rmse_loss 6.640242,test_mae_loss 2.989335,test_mape_loss 51.063634,Time used 0.018004s\n",
      "batch 10901, train_loss 24.501120,Time used 0.006001s\n",
      "batch 10902, train_loss 28.003130,Time used 0.004997s\n",
      "batch 10903, train_loss 23.154280,Time used 0.006000s\n",
      "batch 10904, train_loss 21.745804,Time used 0.005000s\n",
      "batch 10905, train_loss 23.121407,Time used 0.006999s\n",
      "batch 10906, train_loss 24.947113,Time used 0.006999s\n",
      "batch 10907, train_loss 31.126240,Time used 0.005002s\n",
      "batch 10908, train_loss 27.654036,Time used 0.005997s\n",
      "batch 10909, train_loss 23.149775,Time used 0.005000s\n",
      "batch 10910, train_loss 24.720381,Time used 0.006001s\n",
      "batch 10911, train_loss 27.637672,Time used 0.006000s\n",
      "batch 10912, train_loss 30.786726,Time used 0.005001s\n",
      "batch 10913, train_loss 27.346882,Time used 0.005999s\n",
      "batch 10914, train_loss 28.617819,Time used 0.005000s\n",
      "batch 10915, train_loss 26.857573,Time used 0.005000s\n",
      "batch 10916, train_loss 23.561802,Time used 0.006002s\n",
      "batch 10917, train_loss 26.460634,Time used 0.005001s\n",
      "batch 10918, train_loss 21.311211,Time used 0.006001s\n",
      "batch 10919, train_loss 25.384357,Time used 0.006998s\n",
      "batch 10920, train_loss 26.359886,Time used 0.004998s\n",
      "batch 10921, train_loss 29.649130,Time used 0.004999s\n",
      "batch 10922, train_loss 27.256914,Time used 0.005999s\n",
      "batch 10923, train_loss 26.481457,Time used 0.007002s\n",
      "batch 10924, train_loss 24.116055,Time used 0.004998s\n",
      "batch 10925, train_loss 23.867647,Time used 0.006999s\n",
      "batch 10926, train_loss 26.753119,Time used 0.008000s\n",
      "batch 10927, train_loss 26.461414,Time used 0.007001s\n",
      "batch 10928, train_loss 22.170382,Time used 0.004999s\n",
      "batch 10929, train_loss 24.445652,Time used 0.005000s\n",
      "batch 10930, train_loss 29.660208,Time used 0.005002s\n",
      "batch 10931, train_loss 28.939146,Time used 0.007005s\n",
      "batch 10932, train_loss 28.745377,Time used 0.005029s\n",
      "batch 10933, train_loss 27.588261,Time used 0.004966s\n",
      "batch 10934, train_loss 21.937553,Time used 0.005035s\n",
      "batch 10935, train_loss 27.450525,Time used 0.005000s\n",
      "batch 10936, train_loss 19.966347,Time used 0.004997s\n",
      "batch 10937, train_loss 22.045574,Time used 0.005001s\n",
      "batch 10938, train_loss 26.170853,Time used 0.004997s\n",
      "batch 10939, train_loss 27.984119,Time used 0.006001s\n",
      "batch 10940, train_loss 21.936846,Time used 0.006000s\n",
      "batch 10941, train_loss 24.309900,Time used 0.005999s\n",
      "batch 10942, train_loss 28.489735,Time used 0.005002s\n",
      "batch 10943, train_loss 27.796278,Time used 0.004998s\n",
      "batch 10944, train_loss 27.498802,Time used 0.005000s\n",
      "batch 10945, train_loss 25.984499,Time used 0.008001s\n",
      "batch 10946, train_loss 22.667555,Time used 0.005001s\n",
      "batch 10947, train_loss 24.822491,Time used 0.008003s\n",
      "batch 10948, train_loss 26.496748,Time used 0.006996s\n",
      "batch 10949, train_loss 25.836910,Time used 0.008002s\n",
      "batch 10950, train_loss 21.612389,Time used 0.008999s\n",
      "batch 10951, train_loss 26.543097,Time used 0.006001s\n",
      "batch 10952, train_loss 26.309963,Time used 0.007998s\n",
      "batch 10953, train_loss 28.642647,Time used 0.004999s\n",
      "batch 10954, train_loss 24.811165,Time used 0.006006s\n",
      "batch 10955, train_loss 26.458145,Time used 0.007994s\n",
      "batch 10956, train_loss 24.377913,Time used 0.006000s\n",
      "batch 10957, train_loss 29.146299,Time used 0.006999s\n",
      "batch 10958, train_loss 26.833044,Time used 0.006001s\n",
      "batch 10959, train_loss 26.453127,Time used 0.007000s\n",
      "batch 10960, train_loss 24.447044,Time used 0.005000s\n",
      "batch 10961, train_loss 31.680658,Time used 0.005000s\n",
      "batch 10962, train_loss 28.518963,Time used 0.005002s\n",
      "batch 10963, train_loss 23.732208,Time used 0.005000s\n",
      "batch 10964, train_loss 26.508184,Time used 0.004999s\n",
      "batch 10965, train_loss 24.300432,Time used 0.007003s\n",
      "batch 10966, train_loss 26.955370,Time used 0.007997s\n",
      "batch 10967, train_loss 23.443977,Time used 0.008001s\n",
      "batch 10968, train_loss 23.878576,Time used 0.006999s\n",
      "batch 10969, train_loss 26.098360,Time used 0.006001s\n",
      "batch 10970, train_loss 25.931860,Time used 0.004999s\n",
      "batch 10971, train_loss 25.039757,Time used 0.005000s\n",
      "batch 10972, train_loss 24.123894,Time used 0.005034s\n",
      "batch 10973, train_loss 24.954983,Time used 0.005038s\n",
      "batch 10974, train_loss 27.910028,Time used 0.006964s\n",
      "batch 10975, train_loss 30.889849,Time used 0.007036s\n",
      "batch 10976, train_loss 23.051743,Time used 0.004961s\n",
      "batch 10977, train_loss 23.604561,Time used 0.005000s\n",
      "batch 10978, train_loss 27.159122,Time used 0.006000s\n",
      "batch 10979, train_loss 27.051678,Time used 0.007037s\n",
      "batch 10980, train_loss 23.629637,Time used 0.004999s\n",
      "batch 10981, train_loss 26.868546,Time used 0.005966s\n",
      "batch 10982, train_loss 25.480904,Time used 0.006001s\n",
      "batch 10983, train_loss 26.478062,Time used 0.005000s\n",
      "batch 10984, train_loss 23.708464,Time used 0.006000s\n",
      "batch 10985, train_loss 25.901400,Time used 0.005000s\n",
      "batch 10986, train_loss 24.957275,Time used 0.005000s\n",
      "batch 10987, train_loss 27.703773,Time used 0.005995s\n",
      "batch 10988, train_loss 26.161469,Time used 0.005000s\n",
      "batch 10989, train_loss 22.129992,Time used 0.005004s\n",
      "batch 10990, train_loss 25.971609,Time used 0.007018s\n",
      "batch 10991, train_loss 29.570820,Time used 0.004979s\n",
      "batch 10992, train_loss 26.109312,Time used 0.005001s\n",
      "batch 10993, train_loss 25.958094,Time used 0.004999s\n",
      "batch 10994, train_loss 23.989624,Time used 0.005963s\n",
      "batch 10995, train_loss 25.253572,Time used 0.008001s\n",
      "batch 10996, train_loss 20.619949,Time used 0.007002s\n",
      "batch 10997, train_loss 28.452070,Time used 0.005000s\n",
      "batch 10998, train_loss 27.596495,Time used 0.005002s\n",
      "batch 10999, train_loss 23.515980,Time used 0.004999s\n",
      "batch 11000, train_loss 23.216108,Time used 0.006001s\n",
      "***************************test_batch 11000, test_rmse_loss 6.618644,test_mae_loss 2.983868,test_mape_loss 50.949995,Time used 0.018997s\n",
      "batch 11001, train_loss 28.314449,Time used 0.006006s\n",
      "batch 11002, train_loss 27.152536,Time used 0.005997s\n",
      "batch 11003, train_loss 23.297716,Time used 0.005000s\n",
      "batch 11004, train_loss 29.992546,Time used 0.005999s\n",
      "batch 11005, train_loss 26.050394,Time used 0.005001s\n",
      "batch 11006, train_loss 27.355429,Time used 0.005000s\n",
      "batch 11007, train_loss 27.789898,Time used 0.007000s\n",
      "batch 11008, train_loss 21.573584,Time used 0.006000s\n",
      "batch 11009, train_loss 23.092361,Time used 0.005001s\n",
      "batch 11010, train_loss 22.116158,Time used 0.004997s\n",
      "batch 11011, train_loss 32.048573,Time used 0.005001s\n",
      "batch 11012, train_loss 24.659279,Time used 0.004999s\n",
      "batch 11013, train_loss 26.126644,Time used 0.008002s\n",
      "batch 11014, train_loss 28.563644,Time used 0.007001s\n",
      "batch 11015, train_loss 24.603050,Time used 0.005998s\n",
      "batch 11016, train_loss 27.019428,Time used 0.006003s\n",
      "batch 11017, train_loss 24.606745,Time used 0.004995s\n",
      "batch 11018, train_loss 25.218309,Time used 0.005004s\n",
      "batch 11019, train_loss 23.372551,Time used 0.005000s\n",
      "batch 11020, train_loss 21.369652,Time used 0.006999s\n",
      "batch 11021, train_loss 27.497379,Time used 0.005000s\n",
      "batch 11022, train_loss 26.809767,Time used 0.005996s\n",
      "batch 11023, train_loss 27.220160,Time used 0.005005s\n",
      "batch 11024, train_loss 28.370600,Time used 0.004998s\n",
      "batch 11025, train_loss 23.105499,Time used 0.006000s\n",
      "batch 11026, train_loss 25.669779,Time used 0.006999s\n",
      "batch 11027, train_loss 31.930525,Time used 0.007002s\n",
      "batch 11028, train_loss 31.319967,Time used 0.005001s\n",
      "batch 11029, train_loss 23.141834,Time used 0.005000s\n",
      "batch 11030, train_loss 25.565449,Time used 0.004998s\n",
      "batch 11031, train_loss 26.661648,Time used 0.005998s\n",
      "batch 11032, train_loss 24.792995,Time used 0.005000s\n",
      "batch 11033, train_loss 24.088614,Time used 0.006003s\n",
      "batch 11034, train_loss 20.529152,Time used 0.005000s\n",
      "batch 11035, train_loss 30.277523,Time used 0.005002s\n",
      "batch 11036, train_loss 25.216022,Time used 0.007000s\n",
      "batch 11037, train_loss 27.202368,Time used 0.006999s\n",
      "batch 11038, train_loss 22.320724,Time used 0.008004s\n",
      "batch 11039, train_loss 26.060299,Time used 0.005002s\n",
      "batch 11040, train_loss 23.790787,Time used 0.006002s\n",
      "batch 11041, train_loss 26.091007,Time used 0.006990s\n",
      "batch 11042, train_loss 24.409458,Time used 0.006000s\n",
      "batch 11043, train_loss 24.959631,Time used 0.006000s\n",
      "batch 11044, train_loss 24.485905,Time used 0.006000s\n",
      "batch 11045, train_loss 22.265274,Time used 0.006001s\n",
      "batch 11046, train_loss 25.807386,Time used 0.007999s\n",
      "batch 11047, train_loss 24.038326,Time used 0.008003s\n",
      "batch 11048, train_loss 27.434374,Time used 0.007996s\n",
      "batch 11049, train_loss 29.495207,Time used 0.008001s\n",
      "batch 11050, train_loss 22.956087,Time used 0.009999s\n",
      "batch 11051, train_loss 25.528366,Time used 0.009002s\n",
      "batch 11052, train_loss 27.329464,Time used 0.006998s\n",
      "batch 11053, train_loss 26.712572,Time used 0.009004s\n",
      "batch 11054, train_loss 26.228737,Time used 0.005996s\n",
      "batch 11055, train_loss 28.489351,Time used 0.008999s\n",
      "batch 11056, train_loss 25.824619,Time used 0.008002s\n",
      "batch 11057, train_loss 25.352659,Time used 0.008999s\n",
      "batch 11058, train_loss 22.559517,Time used 0.007000s\n",
      "batch 11059, train_loss 26.023085,Time used 0.008001s\n",
      "batch 11060, train_loss 23.966524,Time used 0.007008s\n",
      "batch 11061, train_loss 26.224590,Time used 0.007993s\n",
      "batch 11062, train_loss 30.220196,Time used 0.008000s\n",
      "batch 11063, train_loss 22.781004,Time used 0.007000s\n",
      "batch 11064, train_loss 25.484131,Time used 0.008000s\n",
      "batch 11065, train_loss 24.897547,Time used 0.008996s\n",
      "batch 11066, train_loss 23.771563,Time used 0.009000s\n",
      "batch 11067, train_loss 25.976156,Time used 0.007000s\n",
      "batch 11068, train_loss 27.358049,Time used 0.004997s\n",
      "batch 11069, train_loss 23.115007,Time used 0.007999s\n",
      "batch 11070, train_loss 31.448925,Time used 0.007002s\n",
      "batch 11071, train_loss 24.157200,Time used 0.007999s\n",
      "batch 11072, train_loss 23.284538,Time used 0.007998s\n",
      "batch 11073, train_loss 23.879578,Time used 0.008002s\n",
      "batch 11074, train_loss 22.912554,Time used 0.006999s\n",
      "batch 11075, train_loss 26.852797,Time used 0.008000s\n",
      "batch 11076, train_loss 29.151865,Time used 0.009000s\n",
      "batch 11077, train_loss 25.377977,Time used 0.007999s\n",
      "batch 11078, train_loss 26.046022,Time used 0.007000s\n",
      "batch 11079, train_loss 23.102671,Time used 0.007999s\n",
      "batch 11080, train_loss 24.846931,Time used 0.007998s\n",
      "batch 11081, train_loss 27.164658,Time used 0.007999s\n",
      "batch 11082, train_loss 27.503113,Time used 0.008001s\n",
      "batch 11083, train_loss 24.686487,Time used 0.008999s\n",
      "batch 11084, train_loss 22.702023,Time used 0.009001s\n",
      "batch 11085, train_loss 27.588858,Time used 0.011999s\n",
      "batch 11086, train_loss 28.598291,Time used 0.011000s\n",
      "batch 11087, train_loss 22.946045,Time used 0.017001s\n",
      "batch 11088, train_loss 26.344364,Time used 0.007999s\n",
      "batch 11089, train_loss 26.581882,Time used 0.007001s\n",
      "batch 11090, train_loss 22.310604,Time used 0.007999s\n",
      "batch 11091, train_loss 26.754887,Time used 0.006000s\n",
      "batch 11092, train_loss 24.197817,Time used 0.006006s\n",
      "batch 11093, train_loss 26.698334,Time used 0.008001s\n",
      "batch 11094, train_loss 25.806608,Time used 0.009998s\n",
      "batch 11095, train_loss 26.543060,Time used 0.008002s\n",
      "batch 11096, train_loss 30.949564,Time used 0.008998s\n",
      "batch 11097, train_loss 25.675627,Time used 0.008999s\n",
      "batch 11098, train_loss 27.619261,Time used 0.009002s\n",
      "batch 11099, train_loss 22.561464,Time used 0.005998s\n",
      "batch 11100, train_loss 22.235455,Time used 0.007998s\n",
      "***************************test_batch 11100, test_rmse_loss 6.597854,test_mae_loss 2.975915,test_mape_loss 51.153145,Time used 0.023002s\n",
      "batch 11101, train_loss 26.740124,Time used 0.005999s\n",
      "batch 11102, train_loss 24.415321,Time used 0.006999s\n",
      "batch 11103, train_loss 26.762651,Time used 0.009007s\n",
      "batch 11104, train_loss 26.287451,Time used 0.008998s\n",
      "batch 11105, train_loss 23.440136,Time used 0.010000s\n",
      "batch 11106, train_loss 23.942648,Time used 0.009000s\n",
      "batch 11107, train_loss 23.899240,Time used 0.009001s\n",
      "batch 11108, train_loss 23.280704,Time used 0.010001s\n",
      "batch 11109, train_loss 26.715317,Time used 0.008998s\n",
      "batch 11110, train_loss 29.800455,Time used 0.004998s\n",
      "batch 11111, train_loss 26.845839,Time used 0.006003s\n",
      "batch 11112, train_loss 21.788374,Time used 0.005001s\n",
      "batch 11113, train_loss 24.939796,Time used 0.008002s\n",
      "batch 11114, train_loss 26.769918,Time used 0.007000s\n",
      "batch 11115, train_loss 27.328197,Time used 0.008003s\n",
      "batch 11116, train_loss 25.101498,Time used 0.006995s\n",
      "batch 11117, train_loss 23.188688,Time used 0.007002s\n",
      "batch 11118, train_loss 23.100317,Time used 0.007000s\n",
      "batch 11119, train_loss 23.182289,Time used 0.008000s\n",
      "batch 11120, train_loss 24.899502,Time used 0.007000s\n",
      "batch 11121, train_loss 26.314608,Time used 0.006998s\n",
      "batch 11122, train_loss 28.755783,Time used 0.009003s\n",
      "batch 11123, train_loss 27.860708,Time used 0.008000s\n",
      "batch 11124, train_loss 27.255011,Time used 0.005997s\n",
      "batch 11125, train_loss 24.566553,Time used 0.006000s\n",
      "batch 11126, train_loss 26.692205,Time used 0.007999s\n",
      "batch 11127, train_loss 23.045301,Time used 0.007999s\n",
      "batch 11128, train_loss 22.951742,Time used 0.009000s\n",
      "batch 11129, train_loss 23.720137,Time used 0.008999s\n",
      "batch 11130, train_loss 27.047403,Time used 0.007000s\n",
      "batch 11131, train_loss 24.430065,Time used 0.009000s\n",
      "batch 11132, train_loss 29.198950,Time used 0.005999s\n",
      "batch 11133, train_loss 22.826950,Time used 0.009002s\n",
      "batch 11134, train_loss 24.957348,Time used 0.008999s\n",
      "batch 11135, train_loss 27.836273,Time used 0.009001s\n",
      "batch 11136, train_loss 24.552599,Time used 0.008000s\n",
      "batch 11137, train_loss 25.295128,Time used 0.005997s\n",
      "batch 11138, train_loss 25.776386,Time used 0.008000s\n",
      "batch 11139, train_loss 24.485020,Time used 0.006002s\n",
      "batch 11140, train_loss 24.289658,Time used 0.007998s\n",
      "batch 11141, train_loss 26.297190,Time used 0.007003s\n",
      "batch 11142, train_loss 23.440996,Time used 0.007997s\n",
      "batch 11143, train_loss 26.309519,Time used 0.008001s\n",
      "batch 11144, train_loss 29.109428,Time used 0.008001s\n",
      "batch 11145, train_loss 28.119329,Time used 0.009001s\n",
      "batch 11146, train_loss 23.397520,Time used 0.007999s\n",
      "batch 11147, train_loss 22.652411,Time used 0.010001s\n",
      "batch 11148, train_loss 25.406107,Time used 0.007001s\n",
      "batch 11149, train_loss 22.736965,Time used 0.010000s\n",
      "batch 11150, train_loss 26.359695,Time used 0.009997s\n",
      "batch 11151, train_loss 25.442469,Time used 0.010002s\n",
      "batch 11152, train_loss 26.621588,Time used 0.017999s\n",
      "batch 11153, train_loss 34.682659,Time used 0.009004s\n",
      "batch 11154, train_loss 22.634623,Time used 0.014999s\n",
      "batch 11155, train_loss 21.888350,Time used 0.005001s\n",
      "batch 11156, train_loss 25.702225,Time used 0.007996s\n",
      "batch 11157, train_loss 24.247911,Time used 0.008000s\n",
      "batch 11158, train_loss 23.309967,Time used 0.007999s\n",
      "batch 11159, train_loss 27.422503,Time used 0.008999s\n",
      "batch 11160, train_loss 24.116455,Time used 0.008999s\n",
      "batch 11161, train_loss 27.757284,Time used 0.009000s\n",
      "batch 11162, train_loss 24.478472,Time used 0.007999s\n",
      "batch 11163, train_loss 27.945814,Time used 0.009000s\n",
      "batch 11164, train_loss 29.952084,Time used 0.007999s\n",
      "batch 11165, train_loss 23.881189,Time used 0.010000s\n",
      "batch 11166, train_loss 22.082447,Time used 0.008002s\n",
      "batch 11167, train_loss 22.720367,Time used 0.008999s\n",
      "batch 11168, train_loss 25.955873,Time used 0.010000s\n",
      "batch 11169, train_loss 28.217855,Time used 0.008999s\n",
      "batch 11170, train_loss 33.040684,Time used 0.009001s\n",
      "batch 11171, train_loss 22.661718,Time used 0.009001s\n",
      "batch 11172, train_loss 22.932600,Time used 0.005998s\n",
      "batch 11173, train_loss 23.071157,Time used 0.010004s\n",
      "batch 11174, train_loss 19.255440,Time used 0.007995s\n",
      "batch 11175, train_loss 25.077478,Time used 0.007004s\n",
      "batch 11176, train_loss 27.304285,Time used 0.007998s\n",
      "batch 11177, train_loss 24.297926,Time used 0.009000s\n",
      "batch 11178, train_loss 22.341160,Time used 0.006001s\n",
      "batch 11179, train_loss 27.141739,Time used 0.008000s\n",
      "batch 11180, train_loss 22.626568,Time used 0.004997s\n",
      "batch 11181, train_loss 24.865284,Time used 0.006002s\n",
      "batch 11182, train_loss 23.748451,Time used 0.006999s\n",
      "batch 11183, train_loss 29.965700,Time used 0.005001s\n",
      "batch 11184, train_loss 26.995695,Time used 0.006002s\n",
      "batch 11185, train_loss 25.398602,Time used 0.005999s\n",
      "batch 11186, train_loss 24.158182,Time used 0.005000s\n",
      "batch 11187, train_loss 28.671057,Time used 0.006997s\n",
      "batch 11188, train_loss 26.898085,Time used 0.008000s\n",
      "batch 11189, train_loss 28.064009,Time used 0.005007s\n",
      "batch 11190, train_loss 22.614691,Time used 0.005001s\n",
      "batch 11191, train_loss 22.050642,Time used 0.006998s\n",
      "batch 11192, train_loss 23.781895,Time used 0.004997s\n",
      "batch 11193, train_loss 25.222466,Time used 0.005999s\n",
      "batch 11194, train_loss 27.279358,Time used 0.006000s\n",
      "batch 11195, train_loss 25.454235,Time used 0.005002s\n",
      "batch 11196, train_loss 24.907970,Time used 0.005000s\n",
      "batch 11197, train_loss 26.710716,Time used 0.005001s\n",
      "batch 11198, train_loss 20.478512,Time used 0.004999s\n",
      "batch 11199, train_loss 27.333778,Time used 0.004998s\n",
      "batch 11200, train_loss 24.964890,Time used 0.006003s\n",
      "***************************test_batch 11200, test_rmse_loss 6.560228,test_mae_loss 2.962754,test_mape_loss 51.208033,Time used 0.017003s\n",
      "batch 11201, train_loss 23.759363,Time used 0.008995s\n",
      "batch 11202, train_loss 22.296375,Time used 0.006039s\n",
      "batch 11203, train_loss 25.378613,Time used 0.005998s\n",
      "batch 11204, train_loss 27.734529,Time used 0.005010s\n",
      "batch 11205, train_loss 31.842255,Time used 0.006953s\n",
      "batch 11206, train_loss 25.529072,Time used 0.005001s\n",
      "batch 11207, train_loss 24.280453,Time used 0.008000s\n",
      "batch 11208, train_loss 22.122099,Time used 0.005000s\n",
      "batch 11209, train_loss 23.227221,Time used 0.004999s\n",
      "batch 11210, train_loss 29.115835,Time used 0.004999s\n",
      "batch 11211, train_loss 31.015385,Time used 0.004999s\n",
      "batch 11212, train_loss 25.894602,Time used 0.005000s\n",
      "batch 11213, train_loss 23.952225,Time used 0.005000s\n",
      "batch 11214, train_loss 26.540455,Time used 0.005001s\n",
      "batch 11215, train_loss 22.891428,Time used 0.006035s\n",
      "batch 11216, train_loss 22.333305,Time used 0.005001s\n",
      "batch 11217, train_loss 24.634808,Time used 0.006969s\n",
      "batch 11218, train_loss 25.948927,Time used 0.008002s\n",
      "batch 11219, train_loss 23.020479,Time used 0.007997s\n",
      "batch 11220, train_loss 24.165634,Time used 0.005000s\n",
      "batch 11221, train_loss 23.167301,Time used 0.006002s\n",
      "batch 11222, train_loss 25.835810,Time used 0.005000s\n",
      "batch 11223, train_loss 22.591560,Time used 0.005001s\n",
      "batch 11224, train_loss 25.521177,Time used 0.005998s\n",
      "batch 11225, train_loss 27.666224,Time used 0.005003s\n",
      "batch 11226, train_loss 24.799204,Time used 0.004999s\n",
      "batch 11227, train_loss 24.087379,Time used 0.004999s\n",
      "batch 11228, train_loss 22.918524,Time used 0.008000s\n",
      "batch 11229, train_loss 26.858988,Time used 0.006000s\n",
      "batch 11230, train_loss 26.989374,Time used 0.005000s\n",
      "batch 11231, train_loss 23.624975,Time used 0.005002s\n",
      "batch 11232, train_loss 28.901476,Time used 0.005001s\n",
      "batch 11233, train_loss 28.203974,Time used 0.005000s\n",
      "batch 11234, train_loss 25.550550,Time used 0.007001s\n",
      "batch 11235, train_loss 25.099346,Time used 0.008000s\n",
      "batch 11236, train_loss 24.253864,Time used 0.007000s\n",
      "batch 11237, train_loss 23.136295,Time used 0.008003s\n",
      "batch 11238, train_loss 24.710796,Time used 0.009999s\n",
      "batch 11239, train_loss 27.984573,Time used 0.007999s\n",
      "batch 11240, train_loss 23.824772,Time used 0.004999s\n",
      "batch 11241, train_loss 31.926491,Time used 0.008000s\n",
      "batch 11242, train_loss 25.556543,Time used 0.006001s\n",
      "batch 11243, train_loss 23.185423,Time used 0.008000s\n",
      "batch 11244, train_loss 22.943579,Time used 0.007999s\n",
      "batch 11245, train_loss 25.408726,Time used 0.008001s\n",
      "batch 11246, train_loss 30.498280,Time used 0.009001s\n",
      "batch 11247, train_loss 22.477163,Time used 0.007000s\n",
      "batch 11248, train_loss 22.145201,Time used 0.005999s\n",
      "batch 11249, train_loss 27.060116,Time used 0.008997s\n",
      "batch 11250, train_loss 23.460472,Time used 0.009002s\n",
      "batch 11251, train_loss 23.804386,Time used 0.006999s\n",
      "batch 11252, train_loss 26.077991,Time used 0.008003s\n",
      "batch 11253, train_loss 26.034193,Time used 0.006000s\n",
      "batch 11254, train_loss 24.152988,Time used 0.010001s\n",
      "batch 11255, train_loss 24.382366,Time used 0.008998s\n",
      "batch 11256, train_loss 22.255724,Time used 0.005999s\n",
      "batch 11257, train_loss 28.569273,Time used 0.006998s\n",
      "batch 11258, train_loss 27.995472,Time used 0.008999s\n",
      "batch 11259, train_loss 24.900539,Time used 0.006002s\n",
      "batch 11260, train_loss 25.144613,Time used 0.007001s\n",
      "batch 11261, train_loss 24.932182,Time used 0.009000s\n",
      "batch 11262, train_loss 25.482607,Time used 0.008999s\n",
      "batch 11263, train_loss 25.105286,Time used 0.009006s\n",
      "batch 11264, train_loss 25.413042,Time used 0.007994s\n",
      "batch 11265, train_loss 25.406918,Time used 0.007999s\n",
      "batch 11266, train_loss 23.947367,Time used 0.008001s\n",
      "batch 11267, train_loss 24.786390,Time used 0.009000s\n",
      "batch 11268, train_loss 28.359743,Time used 0.008000s\n",
      "batch 11269, train_loss 24.420687,Time used 0.008000s\n",
      "batch 11270, train_loss 27.189703,Time used 0.010999s\n",
      "batch 11271, train_loss 30.070673,Time used 0.011002s\n",
      "batch 11272, train_loss 21.296791,Time used 0.011999s\n",
      "batch 11273, train_loss 26.414368,Time used 0.019000s\n",
      "batch 11274, train_loss 18.756548,Time used 0.009001s\n",
      "batch 11275, train_loss 22.284315,Time used 0.009002s\n",
      "batch 11276, train_loss 29.368382,Time used 0.007000s\n",
      "batch 11277, train_loss 21.187994,Time used 0.006001s\n",
      "batch 11278, train_loss 27.175821,Time used 0.009000s\n",
      "batch 11279, train_loss 24.125191,Time used 0.011999s\n",
      "batch 11280, train_loss 20.457458,Time used 0.016999s\n",
      "batch 11281, train_loss 21.293871,Time used 0.007997s\n",
      "batch 11282, train_loss 28.140738,Time used 0.009001s\n",
      "batch 11283, train_loss 25.690704,Time used 0.009000s\n",
      "batch 11284, train_loss 24.361208,Time used 0.009000s\n",
      "batch 11285, train_loss 25.770117,Time used 0.008000s\n",
      "batch 11286, train_loss 22.576473,Time used 0.009000s\n",
      "batch 11287, train_loss 25.869335,Time used 0.008001s\n",
      "batch 11288, train_loss 27.824856,Time used 0.007001s\n",
      "batch 11289, train_loss 28.189407,Time used 0.009000s\n",
      "batch 11290, train_loss 27.746677,Time used 0.008000s\n",
      "batch 11291, train_loss 26.415281,Time used 0.006999s\n",
      "batch 11292, train_loss 20.705994,Time used 0.008002s\n",
      "batch 11293, train_loss 26.802319,Time used 0.006998s\n",
      "batch 11294, train_loss 24.301779,Time used 0.007001s\n",
      "batch 11295, train_loss 22.991556,Time used 0.007999s\n",
      "batch 11296, train_loss 24.632662,Time used 0.005003s\n",
      "batch 11297, train_loss 26.770750,Time used 0.004998s\n",
      "batch 11298, train_loss 20.798313,Time used 0.006001s\n",
      "batch 11299, train_loss 25.030985,Time used 0.006004s\n",
      "batch 11300, train_loss 24.814833,Time used 0.005995s\n",
      "***************************test_batch 11300, test_rmse_loss 6.545712,test_mae_loss 2.958336,test_mape_loss 50.937999,Time used 0.020001s\n",
      "batch 11301, train_loss 24.577187,Time used 0.009000s\n",
      "batch 11302, train_loss 24.970751,Time used 0.008001s\n",
      "batch 11303, train_loss 21.378891,Time used 0.006999s\n",
      "batch 11304, train_loss 29.814569,Time used 0.007001s\n",
      "batch 11305, train_loss 22.326572,Time used 0.009002s\n",
      "batch 11306, train_loss 25.556662,Time used 0.008997s\n",
      "batch 11307, train_loss 24.578859,Time used 0.008004s\n",
      "batch 11308, train_loss 22.604683,Time used 0.009997s\n",
      "batch 11309, train_loss 22.910992,Time used 0.008006s\n",
      "batch 11310, train_loss 30.040140,Time used 0.008996s\n",
      "batch 11311, train_loss 22.689705,Time used 0.008001s\n",
      "batch 11312, train_loss 28.963099,Time used 0.008999s\n",
      "batch 11313, train_loss 24.164537,Time used 0.006000s\n",
      "batch 11314, train_loss 23.068449,Time used 0.009001s\n",
      "batch 11315, train_loss 26.559244,Time used 0.009002s\n",
      "batch 11316, train_loss 25.642950,Time used 0.008997s\n",
      "batch 11317, train_loss 24.947279,Time used 0.007999s\n",
      "batch 11318, train_loss 26.373638,Time used 0.008998s\n",
      "batch 11319, train_loss 26.593702,Time used 0.008012s\n",
      "batch 11320, train_loss 27.294640,Time used 0.006989s\n",
      "batch 11321, train_loss 24.792995,Time used 0.008000s\n",
      "batch 11322, train_loss 23.315266,Time used 0.007998s\n",
      "batch 11323, train_loss 24.008604,Time used 0.008002s\n",
      "batch 11324, train_loss 26.539547,Time used 0.007002s\n",
      "batch 11325, train_loss 22.851423,Time used 0.007997s\n",
      "batch 11326, train_loss 23.545576,Time used 0.008000s\n",
      "batch 11327, train_loss 25.599133,Time used 0.007999s\n",
      "batch 11328, train_loss 25.231827,Time used 0.008002s\n",
      "batch 11329, train_loss 24.425993,Time used 0.008999s\n",
      "batch 11330, train_loss 21.715265,Time used 0.008000s\n",
      "batch 11331, train_loss 26.763899,Time used 0.007000s\n",
      "batch 11332, train_loss 28.612427,Time used 0.011002s\n",
      "batch 11333, train_loss 26.403273,Time used 0.009008s\n",
      "batch 11334, train_loss 23.468239,Time used 0.009990s\n",
      "batch 11335, train_loss 25.876175,Time used 0.010001s\n",
      "batch 11336, train_loss 25.105560,Time used 0.012001s\n",
      "batch 11337, train_loss 23.124506,Time used 0.019000s\n",
      "batch 11338, train_loss 24.483366,Time used 0.010003s\n",
      "batch 11339, train_loss 26.128891,Time used 0.007998s\n",
      "batch 11340, train_loss 24.428152,Time used 0.008998s\n",
      "batch 11341, train_loss 25.709793,Time used 0.009001s\n",
      "batch 11342, train_loss 24.272135,Time used 0.008999s\n",
      "batch 11343, train_loss 26.760229,Time used 0.008003s\n",
      "batch 11344, train_loss 22.871956,Time used 0.007997s\n",
      "batch 11345, train_loss 27.956299,Time used 0.008001s\n",
      "batch 11346, train_loss 23.252182,Time used 0.007999s\n",
      "batch 11347, train_loss 26.320522,Time used 0.008001s\n",
      "batch 11348, train_loss 19.407717,Time used 0.008008s\n",
      "batch 11349, train_loss 23.565619,Time used 0.007999s\n",
      "batch 11350, train_loss 21.682798,Time used 0.007998s\n",
      "batch 11351, train_loss 31.042515,Time used 0.009002s\n",
      "batch 11352, train_loss 25.440969,Time used 0.008001s\n",
      "batch 11353, train_loss 24.042252,Time used 0.009000s\n",
      "batch 11354, train_loss 27.677691,Time used 0.008999s\n",
      "batch 11355, train_loss 22.028109,Time used 0.009001s\n",
      "batch 11356, train_loss 20.937471,Time used 0.008000s\n",
      "batch 11357, train_loss 27.346291,Time used 0.006999s\n",
      "batch 11358, train_loss 25.638268,Time used 0.008000s\n",
      "batch 11359, train_loss 26.636864,Time used 0.006997s\n",
      "batch 11360, train_loss 20.375418,Time used 0.005000s\n",
      "batch 11361, train_loss 21.020264,Time used 0.006999s\n",
      "batch 11362, train_loss 23.550804,Time used 0.008000s\n",
      "batch 11363, train_loss 23.724663,Time used 0.008000s\n",
      "batch 11364, train_loss 28.789351,Time used 0.011000s\n",
      "batch 11365, train_loss 22.353416,Time used 0.007000s\n",
      "batch 11366, train_loss 27.490458,Time used 0.006000s\n",
      "batch 11367, train_loss 27.725328,Time used 0.007001s\n",
      "batch 11368, train_loss 29.010826,Time used 0.007000s\n",
      "batch 11369, train_loss 27.998562,Time used 0.009000s\n",
      "batch 11370, train_loss 23.072145,Time used 0.008000s\n",
      "batch 11371, train_loss 30.968428,Time used 0.007999s\n",
      "batch 11372, train_loss 24.374292,Time used 0.007001s\n",
      "batch 11373, train_loss 20.644035,Time used 0.008000s\n",
      "batch 11374, train_loss 21.103498,Time used 0.008000s\n",
      "batch 11375, train_loss 29.607504,Time used 0.008004s\n",
      "batch 11376, train_loss 21.518343,Time used 0.006999s\n",
      "batch 11377, train_loss 26.082655,Time used 0.009001s\n",
      "batch 11378, train_loss 21.096870,Time used 0.007001s\n",
      "batch 11379, train_loss 22.983265,Time used 0.009000s\n",
      "batch 11380, train_loss 27.256758,Time used 0.008000s\n",
      "batch 11381, train_loss 27.248268,Time used 0.010001s\n",
      "batch 11382, train_loss 24.769163,Time used 0.007998s\n",
      "batch 11383, train_loss 26.364876,Time used 0.009001s\n",
      "batch 11384, train_loss 22.202856,Time used 0.007001s\n",
      "batch 11385, train_loss 28.812172,Time used 0.009000s\n",
      "batch 11386, train_loss 23.999924,Time used 0.008002s\n",
      "batch 11387, train_loss 26.120844,Time used 0.017000s\n",
      "batch 11388, train_loss 23.987808,Time used 0.008000s\n",
      "batch 11389, train_loss 25.621897,Time used 0.007997s\n",
      "batch 11390, train_loss 23.253117,Time used 0.008000s\n",
      "batch 11391, train_loss 26.189558,Time used 0.008000s\n",
      "batch 11392, train_loss 25.656839,Time used 0.009000s\n",
      "batch 11393, train_loss 23.936905,Time used 0.008004s\n",
      "batch 11394, train_loss 24.627607,Time used 0.008999s\n",
      "batch 11395, train_loss 23.272160,Time used 0.010000s\n",
      "batch 11396, train_loss 25.756752,Time used 0.012000s\n",
      "batch 11397, train_loss 24.712715,Time used 0.019000s\n",
      "batch 11398, train_loss 21.852655,Time used 0.013002s\n",
      "batch 11399, train_loss 24.834274,Time used 0.008999s\n",
      "batch 11400, train_loss 25.721117,Time used 0.007000s\n",
      "***************************test_batch 11400, test_rmse_loss 6.565335,test_mae_loss 2.964103,test_mape_loss 50.665803,Time used 0.028000s\n",
      "batch 11401, train_loss 21.217220,Time used 0.009996s\n",
      "batch 11402, train_loss 23.204723,Time used 0.008002s\n",
      "batch 11403, train_loss 26.862364,Time used 0.007999s\n",
      "batch 11404, train_loss 23.672421,Time used 0.008000s\n",
      "batch 11405, train_loss 26.759310,Time used 0.007998s\n",
      "batch 11406, train_loss 23.708677,Time used 0.008001s\n",
      "batch 11407, train_loss 25.891632,Time used 0.009001s\n",
      "batch 11408, train_loss 28.152826,Time used 0.009999s\n",
      "batch 11409, train_loss 24.693911,Time used 0.009000s\n",
      "batch 11410, train_loss 25.558411,Time used 0.007001s\n",
      "batch 11411, train_loss 22.964298,Time used 0.006000s\n",
      "batch 11412, train_loss 22.359003,Time used 0.008999s\n",
      "batch 11413, train_loss 23.729092,Time used 0.006999s\n",
      "batch 11414, train_loss 23.109528,Time used 0.009001s\n",
      "batch 11415, train_loss 21.794233,Time used 0.005999s\n",
      "batch 11416, train_loss 24.127569,Time used 0.007000s\n",
      "batch 11417, train_loss 25.982645,Time used 0.009000s\n",
      "batch 11418, train_loss 22.444233,Time used 0.010001s\n",
      "batch 11419, train_loss 27.842104,Time used 0.005997s\n",
      "batch 11420, train_loss 26.821676,Time used 0.006006s\n",
      "batch 11421, train_loss 28.156364,Time used 0.008995s\n",
      "batch 11422, train_loss 27.627495,Time used 0.007000s\n",
      "batch 11423, train_loss 24.292732,Time used 0.006002s\n",
      "batch 11424, train_loss 24.692511,Time used 0.006000s\n",
      "batch 11425, train_loss 24.328646,Time used 0.010999s\n",
      "batch 11426, train_loss 24.454702,Time used 0.008000s\n",
      "batch 11427, train_loss 24.025637,Time used 0.008001s\n",
      "batch 11428, train_loss 22.743931,Time used 0.008999s\n",
      "batch 11429, train_loss 22.668739,Time used 0.008001s\n",
      "batch 11430, train_loss 25.569838,Time used 0.009000s\n",
      "batch 11431, train_loss 23.904297,Time used 0.008999s\n",
      "batch 11432, train_loss 21.673292,Time used 0.008998s\n",
      "batch 11433, train_loss 24.233185,Time used 0.008001s\n",
      "batch 11434, train_loss 26.175924,Time used 0.008002s\n",
      "batch 11435, train_loss 26.264069,Time used 0.009000s\n",
      "batch 11436, train_loss 27.177954,Time used 0.008000s\n",
      "batch 11437, train_loss 21.886311,Time used 0.008000s\n",
      "batch 11438, train_loss 23.489082,Time used 0.007999s\n",
      "batch 11439, train_loss 25.382927,Time used 0.008999s\n",
      "batch 11440, train_loss 23.699934,Time used 0.009001s\n",
      "batch 11441, train_loss 31.474398,Time used 0.010000s\n",
      "batch 11442, train_loss 26.366743,Time used 0.009001s\n",
      "batch 11443, train_loss 26.213905,Time used 0.009000s\n",
      "batch 11444, train_loss 23.071785,Time used 0.008003s\n",
      "batch 11445, train_loss 23.130459,Time used 0.008998s\n",
      "batch 11446, train_loss 26.554771,Time used 0.008000s\n",
      "batch 11447, train_loss 23.509750,Time used 0.007999s\n",
      "batch 11448, train_loss 25.952747,Time used 0.007000s\n",
      "batch 11449, train_loss 25.228140,Time used 0.008998s\n",
      "batch 11450, train_loss 22.332291,Time used 0.008000s\n",
      "batch 11451, train_loss 26.233713,Time used 0.007003s\n",
      "batch 11452, train_loss 22.162672,Time used 0.007998s\n",
      "batch 11453, train_loss 26.642801,Time used 0.009000s\n",
      "batch 11454, train_loss 24.581724,Time used 0.009000s\n",
      "batch 11455, train_loss 24.573725,Time used 0.009000s\n",
      "batch 11456, train_loss 20.554716,Time used 0.009001s\n",
      "batch 11457, train_loss 24.209982,Time used 0.010002s\n",
      "batch 11458, train_loss 27.303677,Time used 0.010998s\n",
      "batch 11459, train_loss 25.223986,Time used 0.010999s\n",
      "batch 11460, train_loss 24.595026,Time used 0.019002s\n",
      "batch 11461, train_loss 31.119532,Time used 0.010998s\n",
      "batch 11462, train_loss 25.592812,Time used 0.009000s\n",
      "batch 11463, train_loss 22.772160,Time used 0.009002s\n",
      "batch 11464, train_loss 24.393188,Time used 0.008996s\n",
      "batch 11465, train_loss 24.536385,Time used 0.008000s\n",
      "batch 11466, train_loss 24.707422,Time used 0.008000s\n",
      "batch 11467, train_loss 24.002953,Time used 0.009001s\n",
      "batch 11468, train_loss 23.751202,Time used 0.009001s\n",
      "batch 11469, train_loss 25.459522,Time used 0.009000s\n",
      "batch 11470, train_loss 23.501593,Time used 0.008000s\n",
      "batch 11471, train_loss 23.644306,Time used 0.007999s\n",
      "batch 11472, train_loss 25.605419,Time used 0.008000s\n",
      "batch 11473, train_loss 25.741373,Time used 0.008000s\n",
      "batch 11474, train_loss 24.494650,Time used 0.008000s\n",
      "batch 11475, train_loss 24.536921,Time used 0.006999s\n",
      "batch 11476, train_loss 21.627018,Time used 0.008006s\n",
      "batch 11477, train_loss 23.370756,Time used 0.007995s\n",
      "batch 11478, train_loss 23.301775,Time used 0.008999s\n",
      "batch 11479, train_loss 23.967613,Time used 0.009001s\n",
      "batch 11480, train_loss 23.794455,Time used 0.007998s\n",
      "batch 11481, train_loss 24.542643,Time used 0.009001s\n",
      "batch 11482, train_loss 23.700571,Time used 0.007001s\n",
      "batch 11483, train_loss 23.346102,Time used 0.007000s\n",
      "batch 11484, train_loss 28.441679,Time used 0.007998s\n",
      "batch 11485, train_loss 21.692169,Time used 0.005999s\n",
      "batch 11486, train_loss 26.563520,Time used 0.005000s\n",
      "batch 11487, train_loss 24.714201,Time used 0.004997s\n",
      "batch 11488, train_loss 30.118429,Time used 0.007002s\n",
      "batch 11489, train_loss 21.928930,Time used 0.010998s\n",
      "batch 11490, train_loss 22.511564,Time used 0.009000s\n",
      "batch 11491, train_loss 21.882698,Time used 0.008001s\n",
      "batch 11492, train_loss 26.019022,Time used 0.015000s\n",
      "batch 11493, train_loss 26.325727,Time used 0.006000s\n",
      "batch 11494, train_loss 29.726641,Time used 0.006999s\n",
      "batch 11495, train_loss 23.780556,Time used 0.007999s\n",
      "batch 11496, train_loss 25.294466,Time used 0.007000s\n",
      "batch 11497, train_loss 24.040380,Time used 0.008000s\n",
      "batch 11498, train_loss 19.676088,Time used 0.008999s\n",
      "batch 11499, train_loss 24.720873,Time used 0.007002s\n",
      "batch 11500, train_loss 25.965096,Time used 0.008000s\n",
      "***************************test_batch 11500, test_rmse_loss 6.518444,test_mae_loss 2.947744,test_mape_loss 50.757168,Time used 0.031000s\n",
      "batch 11501, train_loss 29.709372,Time used 0.010000s\n",
      "batch 11502, train_loss 25.033005,Time used 0.009998s\n",
      "batch 11503, train_loss 23.327745,Time used 0.009003s\n",
      "batch 11504, train_loss 23.358660,Time used 0.008998s\n",
      "batch 11505, train_loss 26.582617,Time used 0.008001s\n",
      "batch 11506, train_loss 20.539450,Time used 0.009000s\n",
      "batch 11507, train_loss 21.409464,Time used 0.009000s\n",
      "batch 11508, train_loss 23.582832,Time used 0.008000s\n",
      "batch 11509, train_loss 27.593115,Time used 0.009000s\n",
      "batch 11510, train_loss 23.279249,Time used 0.009000s\n",
      "batch 11511, train_loss 30.337523,Time used 0.008000s\n",
      "batch 11512, train_loss 28.948780,Time used 0.008000s\n",
      "batch 11513, train_loss 21.900269,Time used 0.008000s\n",
      "batch 11514, train_loss 24.065514,Time used 0.006998s\n",
      "batch 11515, train_loss 22.783813,Time used 0.008001s\n",
      "batch 11516, train_loss 27.050747,Time used 0.007999s\n",
      "batch 11517, train_loss 25.617430,Time used 0.010002s\n",
      "batch 11518, train_loss 24.391039,Time used 0.010996s\n",
      "batch 11519, train_loss 23.037207,Time used 0.016002s\n",
      "batch 11520, train_loss 22.569870,Time used 0.020000s\n",
      "batch 11521, train_loss 26.319765,Time used 0.010002s\n",
      "batch 11522, train_loss 24.834265,Time used 0.006998s\n",
      "batch 11523, train_loss 20.262793,Time used 0.008000s\n",
      "batch 11524, train_loss 26.766592,Time used 0.007999s\n",
      "batch 11525, train_loss 23.801218,Time used 0.006000s\n",
      "batch 11526, train_loss 24.277052,Time used 0.004990s\n",
      "batch 11527, train_loss 23.522024,Time used 0.005000s\n",
      "batch 11528, train_loss 27.325703,Time used 0.008001s\n",
      "batch 11529, train_loss 22.311228,Time used 0.008004s\n",
      "batch 11530, train_loss 23.117409,Time used 0.008995s\n",
      "batch 11531, train_loss 19.273193,Time used 0.008998s\n",
      "batch 11532, train_loss 20.458279,Time used 0.007000s\n",
      "batch 11533, train_loss 25.529320,Time used 0.007000s\n",
      "batch 11534, train_loss 25.599899,Time used 0.007998s\n",
      "batch 11535, train_loss 23.600481,Time used 0.008001s\n",
      "batch 11536, train_loss 27.574286,Time used 0.008001s\n",
      "batch 11537, train_loss 26.219313,Time used 0.010000s\n",
      "batch 11538, train_loss 22.864321,Time used 0.009000s\n",
      "batch 11539, train_loss 26.040272,Time used 0.009999s\n",
      "batch 11540, train_loss 24.897322,Time used 0.009001s\n",
      "batch 11541, train_loss 24.404779,Time used 0.009998s\n",
      "batch 11542, train_loss 24.788248,Time used 0.010003s\n",
      "batch 11543, train_loss 25.064028,Time used 0.006999s\n",
      "batch 11544, train_loss 29.507339,Time used 0.008999s\n",
      "batch 11545, train_loss 22.870693,Time used 0.008999s\n",
      "batch 11546, train_loss 23.702793,Time used 0.004999s\n",
      "batch 11547, train_loss 21.649027,Time used 0.006000s\n",
      "batch 11548, train_loss 23.608753,Time used 0.006040s\n",
      "batch 11549, train_loss 21.872398,Time used 0.005997s\n",
      "batch 11550, train_loss 25.988522,Time used 0.004966s\n",
      "batch 11551, train_loss 21.216738,Time used 0.005002s\n",
      "batch 11552, train_loss 24.874619,Time used 0.005001s\n",
      "batch 11553, train_loss 25.370041,Time used 0.007997s\n",
      "batch 11554, train_loss 29.345785,Time used 0.007997s\n",
      "batch 11555, train_loss 21.515543,Time used 0.007001s\n",
      "batch 11556, train_loss 25.561769,Time used 0.004998s\n",
      "batch 11557, train_loss 24.799046,Time used 0.006003s\n",
      "batch 11558, train_loss 26.094429,Time used 0.005999s\n",
      "batch 11559, train_loss 28.127588,Time used 0.005997s\n",
      "batch 11560, train_loss 24.604313,Time used 0.005999s\n",
      "batch 11561, train_loss 23.210546,Time used 0.006001s\n",
      "batch 11562, train_loss 24.978210,Time used 0.005000s\n",
      "batch 11563, train_loss 22.361242,Time used 0.008001s\n",
      "batch 11564, train_loss 26.177214,Time used 0.006003s\n",
      "batch 11565, train_loss 22.537600,Time used 0.004996s\n",
      "batch 11566, train_loss 25.623562,Time used 0.006002s\n",
      "batch 11567, train_loss 25.931187,Time used 0.006000s\n",
      "batch 11568, train_loss 25.193630,Time used 0.005000s\n",
      "batch 11569, train_loss 27.462591,Time used 0.004995s\n",
      "batch 11570, train_loss 23.415066,Time used 0.004999s\n",
      "batch 11571, train_loss 24.324350,Time used 0.005000s\n",
      "batch 11572, train_loss 27.533257,Time used 0.005000s\n",
      "batch 11573, train_loss 26.466694,Time used 0.005000s\n",
      "batch 11574, train_loss 22.861334,Time used 0.005001s\n",
      "batch 11575, train_loss 22.301128,Time used 0.006002s\n",
      "batch 11576, train_loss 22.535666,Time used 0.004999s\n",
      "batch 11577, train_loss 22.076159,Time used 0.004999s\n",
      "batch 11578, train_loss 24.602745,Time used 0.005000s\n",
      "batch 11579, train_loss 23.298107,Time used 0.006003s\n",
      "batch 11580, train_loss 27.550072,Time used 0.005038s\n",
      "batch 11581, train_loss 23.311623,Time used 0.004958s\n",
      "batch 11582, train_loss 22.858454,Time used 0.005998s\n",
      "batch 11583, train_loss 25.407446,Time used 0.005000s\n",
      "batch 11584, train_loss 24.804794,Time used 0.005000s\n",
      "batch 11585, train_loss 23.500883,Time used 0.006000s\n",
      "batch 11586, train_loss 19.276569,Time used 0.005000s\n",
      "batch 11587, train_loss 25.524488,Time used 0.006001s\n",
      "batch 11588, train_loss 25.802208,Time used 0.008000s\n",
      "batch 11589, train_loss 24.789989,Time used 0.007002s\n",
      "batch 11590, train_loss 31.862181,Time used 0.004998s\n",
      "batch 11591, train_loss 21.001801,Time used 0.005040s\n",
      "batch 11592, train_loss 23.871456,Time used 0.007995s\n",
      "batch 11593, train_loss 27.491644,Time used 0.004999s\n",
      "batch 11594, train_loss 23.046015,Time used 0.005000s\n",
      "batch 11595, train_loss 23.831816,Time used 0.006004s\n",
      "batch 11596, train_loss 28.162819,Time used 0.005035s\n",
      "batch 11597, train_loss 24.478979,Time used 0.007964s\n",
      "batch 11598, train_loss 25.201773,Time used 0.005036s\n",
      "batch 11599, train_loss 22.864651,Time used 0.004998s\n",
      "batch 11600, train_loss 20.709755,Time used 0.005003s\n",
      "***************************test_batch 11600, test_rmse_loss 6.527390,test_mae_loss 2.949424,test_mape_loss 50.679264,Time used 0.026964s\n",
      "batch 11601, train_loss 22.130230,Time used 0.007040s\n",
      "batch 11602, train_loss 23.718634,Time used 0.004961s\n",
      "batch 11603, train_loss 26.952894,Time used 0.005036s\n",
      "batch 11604, train_loss 25.544641,Time used 0.004966s\n",
      "batch 11605, train_loss 26.854849,Time used 0.005039s\n",
      "batch 11606, train_loss 25.335886,Time used 0.004999s\n",
      "batch 11607, train_loss 25.650589,Time used 0.004968s\n",
      "batch 11608, train_loss 21.405783,Time used 0.007998s\n",
      "batch 11609, train_loss 22.171305,Time used 0.007002s\n",
      "batch 11610, train_loss 25.170149,Time used 0.005998s\n",
      "batch 11611, train_loss 23.008039,Time used 0.008000s\n",
      "batch 11612, train_loss 25.567415,Time used 0.005001s\n",
      "batch 11613, train_loss 24.955206,Time used 0.005002s\n",
      "batch 11614, train_loss 21.849258,Time used 0.004998s\n",
      "batch 11615, train_loss 23.073521,Time used 0.006999s\n",
      "batch 11616, train_loss 26.008945,Time used 0.009000s\n",
      "batch 11617, train_loss 21.322235,Time used 0.006998s\n",
      "batch 11618, train_loss 23.807476,Time used 0.005004s\n",
      "batch 11619, train_loss 25.872290,Time used 0.006002s\n",
      "batch 11620, train_loss 21.735825,Time used 0.006994s\n",
      "batch 11621, train_loss 28.380234,Time used 0.006002s\n",
      "batch 11622, train_loss 23.489700,Time used 0.005001s\n",
      "batch 11623, train_loss 26.582277,Time used 0.007997s\n",
      "batch 11624, train_loss 24.244223,Time used 0.007999s\n",
      "batch 11625, train_loss 26.251726,Time used 0.005001s\n",
      "batch 11626, train_loss 26.717356,Time used 0.005000s\n",
      "batch 11627, train_loss 23.032053,Time used 0.005002s\n",
      "batch 11628, train_loss 20.979736,Time used 0.004999s\n",
      "batch 11629, train_loss 23.181849,Time used 0.005000s\n",
      "batch 11630, train_loss 22.434746,Time used 0.005001s\n",
      "batch 11631, train_loss 23.530985,Time used 0.006035s\n",
      "batch 11632, train_loss 23.661726,Time used 0.005002s\n",
      "batch 11633, train_loss 23.178194,Time used 0.005998s\n",
      "batch 11634, train_loss 23.955894,Time used 0.005000s\n",
      "batch 11635, train_loss 26.621181,Time used 0.005001s\n",
      "batch 11636, train_loss 28.017860,Time used 0.004999s\n",
      "batch 11637, train_loss 27.425270,Time used 0.007962s\n",
      "batch 11638, train_loss 24.587189,Time used 0.006999s\n",
      "batch 11639, train_loss 21.594751,Time used 0.007002s\n",
      "batch 11640, train_loss 23.114862,Time used 0.003998s\n",
      "batch 11641, train_loss 22.864342,Time used 0.006998s\n",
      "batch 11642, train_loss 25.227169,Time used 0.005001s\n",
      "batch 11643, train_loss 25.699318,Time used 0.004998s\n",
      "batch 11644, train_loss 21.394920,Time used 0.005999s\n",
      "batch 11645, train_loss 19.928377,Time used 0.005037s\n",
      "batch 11646, train_loss 23.800638,Time used 0.007962s\n",
      "batch 11647, train_loss 22.318674,Time used 0.008001s\n",
      "batch 11648, train_loss 26.768671,Time used 0.008001s\n",
      "batch 11649, train_loss 18.893297,Time used 0.005000s\n",
      "batch 11650, train_loss 27.675409,Time used 0.006035s\n",
      "batch 11651, train_loss 27.711979,Time used 0.008002s\n",
      "batch 11652, train_loss 26.593180,Time used 0.004999s\n",
      "batch 11653, train_loss 24.772787,Time used 0.004966s\n",
      "batch 11654, train_loss 19.235353,Time used 0.004997s\n",
      "batch 11655, train_loss 22.691267,Time used 0.008000s\n",
      "batch 11656, train_loss 26.490177,Time used 0.005001s\n",
      "batch 11657, train_loss 26.344231,Time used 0.006001s\n",
      "batch 11658, train_loss 28.345156,Time used 0.004999s\n",
      "batch 11659, train_loss 26.426060,Time used 0.006000s\n",
      "batch 11660, train_loss 25.107786,Time used 0.004999s\n",
      "batch 11661, train_loss 22.263208,Time used 0.005998s\n",
      "batch 11662, train_loss 25.289818,Time used 0.005000s\n",
      "batch 11663, train_loss 24.464027,Time used 0.005000s\n",
      "batch 11664, train_loss 22.097609,Time used 0.007000s\n",
      "batch 11665, train_loss 21.681374,Time used 0.005997s\n",
      "batch 11666, train_loss 26.970186,Time used 0.005001s\n",
      "batch 11667, train_loss 23.378197,Time used 0.005001s\n",
      "batch 11668, train_loss 26.360308,Time used 0.005001s\n",
      "batch 11669, train_loss 22.155640,Time used 0.005036s\n",
      "batch 11670, train_loss 26.004002,Time used 0.005966s\n",
      "batch 11671, train_loss 24.375299,Time used 0.008035s\n",
      "batch 11672, train_loss 24.472183,Time used 0.007962s\n",
      "batch 11673, train_loss 29.103512,Time used 0.005002s\n",
      "batch 11674, train_loss 21.931517,Time used 0.006999s\n",
      "batch 11675, train_loss 21.112875,Time used 0.005999s\n",
      "batch 11676, train_loss 23.524498,Time used 0.005000s\n",
      "batch 11677, train_loss 24.033337,Time used 0.005033s\n",
      "batch 11678, train_loss 25.133369,Time used 0.008960s\n",
      "batch 11679, train_loss 23.301105,Time used 0.005001s\n",
      "batch 11680, train_loss 23.512564,Time used 0.006036s\n",
      "batch 11681, train_loss 26.893463,Time used 0.005002s\n",
      "batch 11682, train_loss 24.762058,Time used 0.004998s\n",
      "batch 11683, train_loss 23.182903,Time used 0.005000s\n",
      "batch 11684, train_loss 24.509579,Time used 0.004999s\n",
      "batch 11685, train_loss 25.343769,Time used 0.005001s\n",
      "batch 11686, train_loss 23.348089,Time used 0.005998s\n",
      "batch 11687, train_loss 23.374666,Time used 0.005000s\n",
      "batch 11688, train_loss 22.840187,Time used 0.005000s\n",
      "batch 11689, train_loss 24.658070,Time used 0.007000s\n",
      "batch 11690, train_loss 27.245909,Time used 0.005999s\n",
      "batch 11691, train_loss 25.166706,Time used 0.005001s\n",
      "batch 11692, train_loss 24.024998,Time used 0.006000s\n",
      "batch 11693, train_loss 25.040747,Time used 0.005000s\n",
      "batch 11694, train_loss 22.222183,Time used 0.004999s\n",
      "batch 11695, train_loss 23.444012,Time used 0.005003s\n",
      "batch 11696, train_loss 25.889763,Time used 0.005002s\n",
      "batch 11697, train_loss 25.909117,Time used 0.004999s\n",
      "batch 11698, train_loss 25.093824,Time used 0.006001s\n",
      "batch 11699, train_loss 22.665432,Time used 0.006003s\n",
      "batch 11700, train_loss 22.682795,Time used 0.006995s\n",
      "***************************test_batch 11700, test_rmse_loss 6.479835,test_mae_loss 2.936140,test_mape_loss 50.762252,Time used 0.030014s\n",
      "batch 11701, train_loss 21.888287,Time used 0.008987s\n",
      "batch 11702, train_loss 26.133371,Time used 0.008001s\n",
      "batch 11703, train_loss 21.363846,Time used 0.006000s\n",
      "batch 11704, train_loss 20.226410,Time used 0.005997s\n",
      "batch 11705, train_loss 26.063963,Time used 0.007003s\n",
      "batch 11706, train_loss 23.765686,Time used 0.008002s\n",
      "batch 11707, train_loss 29.173458,Time used 0.007998s\n",
      "batch 11708, train_loss 23.776890,Time used 0.007997s\n",
      "batch 11709, train_loss 23.485224,Time used 0.006999s\n",
      "batch 11710, train_loss 23.270782,Time used 0.005002s\n",
      "batch 11711, train_loss 23.030521,Time used 0.004998s\n",
      "batch 11712, train_loss 23.732786,Time used 0.005002s\n",
      "batch 11713, train_loss 25.045473,Time used 0.007997s\n",
      "batch 11714, train_loss 22.341208,Time used 0.005001s\n",
      "batch 11715, train_loss 23.408943,Time used 0.006997s\n",
      "batch 11716, train_loss 24.188574,Time used 0.005004s\n",
      "batch 11717, train_loss 26.509148,Time used 0.006999s\n",
      "batch 11718, train_loss 19.488810,Time used 0.004998s\n",
      "batch 11719, train_loss 24.247110,Time used 0.005999s\n",
      "batch 11720, train_loss 24.072994,Time used 0.006001s\n",
      "batch 11721, train_loss 27.946266,Time used 0.006000s\n",
      "batch 11722, train_loss 23.534771,Time used 0.007002s\n",
      "batch 11723, train_loss 24.500948,Time used 0.006996s\n",
      "batch 11724, train_loss 24.574053,Time used 0.007000s\n",
      "batch 11725, train_loss 25.195614,Time used 0.008001s\n",
      "batch 11726, train_loss 25.027203,Time used 0.006999s\n",
      "batch 11727, train_loss 28.751556,Time used 0.007001s\n",
      "batch 11728, train_loss 23.911699,Time used 0.006000s\n",
      "batch 11729, train_loss 22.654303,Time used 0.006002s\n",
      "batch 11730, train_loss 26.336306,Time used 0.006998s\n",
      "batch 11731, train_loss 20.861425,Time used 0.005000s\n",
      "batch 11732, train_loss 24.455465,Time used 0.006003s\n",
      "batch 11733, train_loss 28.073322,Time used 0.004999s\n",
      "batch 11734, train_loss 19.795296,Time used 0.006000s\n",
      "batch 11735, train_loss 20.848726,Time used 0.005001s\n",
      "batch 11736, train_loss 23.545277,Time used 0.004000s\n",
      "batch 11737, train_loss 24.190279,Time used 0.004997s\n",
      "batch 11738, train_loss 29.764215,Time used 0.006000s\n",
      "batch 11739, train_loss 24.991173,Time used 0.005002s\n",
      "batch 11740, train_loss 24.666769,Time used 0.003995s\n",
      "batch 11741, train_loss 24.287100,Time used 0.005999s\n",
      "batch 11742, train_loss 20.247448,Time used 0.007998s\n",
      "batch 11743, train_loss 25.805517,Time used 0.007000s\n",
      "batch 11744, train_loss 28.676506,Time used 0.005001s\n",
      "batch 11745, train_loss 25.122280,Time used 0.005001s\n",
      "batch 11746, train_loss 25.466286,Time used 0.005002s\n",
      "batch 11747, train_loss 25.119465,Time used 0.005000s\n",
      "batch 11748, train_loss 22.574211,Time used 0.004999s\n",
      "batch 11749, train_loss 21.357046,Time used 0.005997s\n",
      "batch 11750, train_loss 18.582644,Time used 0.005003s\n",
      "batch 11751, train_loss 23.466478,Time used 0.005033s\n",
      "batch 11752, train_loss 21.686710,Time used 0.006999s\n",
      "batch 11753, train_loss 24.612181,Time used 0.005000s\n",
      "batch 11754, train_loss 22.656462,Time used 0.005001s\n",
      "batch 11755, train_loss 25.273500,Time used 0.007036s\n",
      "batch 11756, train_loss 26.933823,Time used 0.005002s\n",
      "batch 11757, train_loss 22.582554,Time used 0.004997s\n",
      "batch 11758, train_loss 21.346067,Time used 0.005037s\n",
      "batch 11759, train_loss 24.295502,Time used 0.004998s\n",
      "batch 11760, train_loss 24.986177,Time used 0.004967s\n",
      "batch 11761, train_loss 25.799095,Time used 0.005001s\n",
      "batch 11762, train_loss 23.130100,Time used 0.005001s\n",
      "batch 11763, train_loss 22.225437,Time used 0.005995s\n",
      "batch 11764, train_loss 21.246204,Time used 0.005004s\n",
      "batch 11765, train_loss 22.803551,Time used 0.005001s\n",
      "batch 11766, train_loss 23.388824,Time used 0.008999s\n",
      "batch 11767, train_loss 22.000992,Time used 0.007001s\n",
      "batch 11768, train_loss 20.315544,Time used 0.005996s\n",
      "batch 11769, train_loss 21.571442,Time used 0.005000s\n",
      "batch 11770, train_loss 29.789398,Time used 0.005999s\n",
      "batch 11771, train_loss 20.671301,Time used 0.007998s\n",
      "batch 11772, train_loss 24.631054,Time used 0.008003s\n",
      "batch 11773, train_loss 24.322901,Time used 0.005035s\n",
      "batch 11774, train_loss 22.458832,Time used 0.005966s\n",
      "batch 11775, train_loss 23.679222,Time used 0.006000s\n",
      "batch 11776, train_loss 22.607193,Time used 0.005032s\n",
      "batch 11777, train_loss 22.981266,Time used 0.005000s\n",
      "batch 11778, train_loss 33.786552,Time used 0.006965s\n",
      "batch 11779, train_loss 26.014460,Time used 0.007999s\n",
      "batch 11780, train_loss 24.354239,Time used 0.007002s\n",
      "batch 11781, train_loss 24.328987,Time used 0.004998s\n",
      "batch 11782, train_loss 22.335674,Time used 0.006000s\n",
      "batch 11783, train_loss 22.903770,Time used 0.006000s\n",
      "batch 11784, train_loss 29.019909,Time used 0.005000s\n",
      "batch 11785, train_loss 26.092794,Time used 0.006999s\n",
      "batch 11786, train_loss 22.074854,Time used 0.006001s\n",
      "batch 11787, train_loss 20.229555,Time used 0.006000s\n",
      "batch 11788, train_loss 21.688635,Time used 0.005000s\n",
      "batch 11789, train_loss 24.025787,Time used 0.005999s\n",
      "batch 11790, train_loss 24.901377,Time used 0.006000s\n",
      "batch 11791, train_loss 29.587423,Time used 0.006000s\n",
      "batch 11792, train_loss 23.802927,Time used 0.006000s\n",
      "batch 11793, train_loss 25.149441,Time used 0.004998s\n",
      "batch 11794, train_loss 24.740126,Time used 0.005001s\n",
      "batch 11795, train_loss 23.488512,Time used 0.005002s\n",
      "batch 11796, train_loss 24.238638,Time used 0.004997s\n",
      "batch 11797, train_loss 25.701584,Time used 0.005002s\n",
      "batch 11798, train_loss 24.765207,Time used 0.005000s\n",
      "batch 11799, train_loss 20.471584,Time used 0.004000s\n",
      "batch 11800, train_loss 25.544609,Time used 0.005000s\n",
      "***************************test_batch 11800, test_rmse_loss 6.516212,test_mae_loss 2.946978,test_mape_loss 50.291732,Time used 0.027002s\n",
      "batch 11801, train_loss 19.679964,Time used 0.008036s\n",
      "batch 11802, train_loss 20.951948,Time used 0.004966s\n",
      "batch 11803, train_loss 21.608561,Time used 0.005033s\n",
      "batch 11804, train_loss 28.415932,Time used 0.005965s\n",
      "batch 11805, train_loss 24.425112,Time used 0.005035s\n",
      "batch 11806, train_loss 20.238155,Time used 0.004999s\n",
      "batch 11807, train_loss 29.176369,Time used 0.005962s\n",
      "batch 11808, train_loss 24.511517,Time used 0.007000s\n",
      "batch 11809, train_loss 22.947075,Time used 0.004963s\n",
      "batch 11810, train_loss 26.077061,Time used 0.006999s\n",
      "batch 11811, train_loss 24.746078,Time used 0.007037s\n",
      "batch 11812, train_loss 22.301420,Time used 0.007960s\n",
      "batch 11813, train_loss 24.770565,Time used 0.008037s\n",
      "batch 11814, train_loss 25.399050,Time used 0.006967s\n",
      "batch 11815, train_loss 25.124802,Time used 0.006003s\n",
      "batch 11816, train_loss 23.265144,Time used 0.005001s\n",
      "batch 11817, train_loss 21.703972,Time used 0.006002s\n",
      "batch 11818, train_loss 23.800552,Time used 0.006996s\n",
      "batch 11819, train_loss 21.393108,Time used 0.005000s\n",
      "batch 11820, train_loss 23.376955,Time used 0.004001s\n",
      "batch 11821, train_loss 25.687832,Time used 0.005038s\n",
      "batch 11822, train_loss 21.312393,Time used 0.005003s\n",
      "batch 11823, train_loss 25.196100,Time used 0.004999s\n",
      "batch 11824, train_loss 27.971010,Time used 0.004961s\n",
      "batch 11825, train_loss 22.652571,Time used 0.003999s\n",
      "batch 11826, train_loss 22.923668,Time used 0.005000s\n",
      "batch 11827, train_loss 21.600075,Time used 0.006043s\n",
      "batch 11828, train_loss 26.794634,Time used 0.004997s\n",
      "batch 11829, train_loss 26.886047,Time used 0.004967s\n",
      "batch 11830, train_loss 22.242031,Time used 0.004999s\n",
      "batch 11831, train_loss 23.178057,Time used 0.005000s\n",
      "batch 11832, train_loss 22.987080,Time used 0.005000s\n",
      "batch 11833, train_loss 25.709078,Time used 0.005000s\n",
      "batch 11834, train_loss 23.166634,Time used 0.006003s\n",
      "batch 11835, train_loss 24.734888,Time used 0.005017s\n",
      "batch 11836, train_loss 27.112034,Time used 0.005016s\n",
      "batch 11837, train_loss 24.423002,Time used 0.005965s\n",
      "batch 11838, train_loss 25.332432,Time used 0.005000s\n",
      "batch 11839, train_loss 29.690233,Time used 0.005001s\n",
      "batch 11840, train_loss 22.951000,Time used 0.005999s\n",
      "batch 11841, train_loss 22.597189,Time used 0.005000s\n",
      "batch 11842, train_loss 19.905575,Time used 0.005001s\n",
      "batch 11843, train_loss 26.337666,Time used 0.005004s\n",
      "batch 11844, train_loss 21.933676,Time used 0.004001s\n",
      "batch 11845, train_loss 20.088369,Time used 0.004999s\n",
      "batch 11846, train_loss 28.189877,Time used 0.005001s\n",
      "batch 11847, train_loss 20.565447,Time used 0.008035s\n",
      "batch 11848, train_loss 25.608826,Time used 0.007967s\n",
      "batch 11849, train_loss 22.493092,Time used 0.007997s\n",
      "batch 11850, train_loss 25.136040,Time used 0.008001s\n",
      "batch 11851, train_loss 23.177689,Time used 0.007001s\n",
      "batch 11852, train_loss 20.217344,Time used 0.004998s\n",
      "batch 11853, train_loss 25.617205,Time used 0.007000s\n",
      "batch 11854, train_loss 21.352240,Time used 0.006001s\n",
      "batch 11855, train_loss 22.483479,Time used 0.005001s\n",
      "batch 11856, train_loss 24.373213,Time used 0.005000s\n",
      "batch 11857, train_loss 27.210903,Time used 0.005000s\n",
      "batch 11858, train_loss 30.899021,Time used 0.005000s\n",
      "batch 11859, train_loss 23.898390,Time used 0.006000s\n",
      "batch 11860, train_loss 23.834187,Time used 0.004996s\n",
      "batch 11861, train_loss 20.974892,Time used 0.004999s\n",
      "batch 11862, train_loss 23.585661,Time used 0.005000s\n",
      "batch 11863, train_loss 26.417278,Time used 0.006005s\n",
      "batch 11864, train_loss 26.856895,Time used 0.005000s\n",
      "batch 11865, train_loss 24.161402,Time used 0.005001s\n",
      "batch 11866, train_loss 22.264618,Time used 0.007996s\n",
      "batch 11867, train_loss 22.523436,Time used 0.005003s\n",
      "batch 11868, train_loss 24.603045,Time used 0.006998s\n",
      "batch 11869, train_loss 21.708544,Time used 0.005001s\n",
      "batch 11870, train_loss 20.739126,Time used 0.005001s\n",
      "batch 11871, train_loss 23.161785,Time used 0.007998s\n",
      "batch 11872, train_loss 21.080763,Time used 0.007000s\n",
      "batch 11873, train_loss 22.230391,Time used 0.006003s\n",
      "batch 11874, train_loss 23.091665,Time used 0.007998s\n",
      "batch 11875, train_loss 22.400675,Time used 0.007002s\n",
      "batch 11876, train_loss 20.002003,Time used 0.005002s\n",
      "batch 11877, train_loss 23.036983,Time used 0.006000s\n",
      "batch 11878, train_loss 21.864849,Time used 0.005997s\n",
      "batch 11879, train_loss 29.511934,Time used 0.005000s\n",
      "batch 11880, train_loss 25.989634,Time used 0.004001s\n",
      "batch 11881, train_loss 22.118441,Time used 0.007998s\n",
      "batch 11882, train_loss 24.605185,Time used 0.007001s\n",
      "batch 11883, train_loss 22.821489,Time used 0.005000s\n",
      "batch 11884, train_loss 24.301556,Time used 0.006998s\n",
      "batch 11885, train_loss 23.968786,Time used 0.009003s\n",
      "batch 11886, train_loss 29.413803,Time used 0.007000s\n",
      "batch 11887, train_loss 23.288940,Time used 0.007001s\n",
      "batch 11888, train_loss 25.189875,Time used 0.006000s\n",
      "batch 11889, train_loss 23.160212,Time used 0.004997s\n",
      "batch 11890, train_loss 21.874031,Time used 0.006001s\n",
      "batch 11891, train_loss 21.631596,Time used 0.005003s\n",
      "batch 11892, train_loss 24.061230,Time used 0.005999s\n",
      "batch 11893, train_loss 23.947426,Time used 0.006033s\n",
      "batch 11894, train_loss 24.322170,Time used 0.007000s\n",
      "batch 11895, train_loss 24.803610,Time used 0.005002s\n",
      "batch 11896, train_loss 22.000505,Time used 0.006000s\n",
      "batch 11897, train_loss 22.078209,Time used 0.004969s\n",
      "batch 11898, train_loss 26.673113,Time used 0.004998s\n",
      "batch 11899, train_loss 20.615814,Time used 0.005034s\n",
      "batch 11900, train_loss 24.012669,Time used 0.007962s\n",
      "***************************test_batch 11900, test_rmse_loss 6.477820,test_mae_loss 2.932914,test_mape_loss 50.424114,Time used 0.018004s\n",
      "batch 11901, train_loss 22.781336,Time used 0.005997s\n",
      "batch 11902, train_loss 23.507671,Time used 0.004999s\n",
      "batch 11903, train_loss 22.759422,Time used 0.005000s\n",
      "batch 11904, train_loss 27.290764,Time used 0.005000s\n",
      "batch 11905, train_loss 19.387579,Time used 0.004997s\n",
      "batch 11906, train_loss 24.466806,Time used 0.005000s\n",
      "batch 11907, train_loss 24.807779,Time used 0.005002s\n",
      "batch 11908, train_loss 23.979088,Time used 0.005999s\n",
      "batch 11909, train_loss 23.285112,Time used 0.005000s\n",
      "batch 11910, train_loss 25.410482,Time used 0.006002s\n",
      "batch 11911, train_loss 23.409935,Time used 0.005999s\n",
      "batch 11912, train_loss 20.542307,Time used 0.008000s\n",
      "batch 11913, train_loss 23.659664,Time used 0.005997s\n",
      "batch 11914, train_loss 24.263191,Time used 0.006999s\n",
      "batch 11915, train_loss 25.556578,Time used 0.004000s\n",
      "batch 11916, train_loss 24.943832,Time used 0.005005s\n",
      "batch 11917, train_loss 24.078913,Time used 0.008002s\n",
      "batch 11918, train_loss 23.894636,Time used 0.005997s\n",
      "batch 11919, train_loss 26.926086,Time used 0.005000s\n",
      "batch 11920, train_loss 26.470976,Time used 0.005000s\n",
      "batch 11921, train_loss 22.395988,Time used 0.006001s\n",
      "batch 11922, train_loss 22.888321,Time used 0.006001s\n",
      "batch 11923, train_loss 25.143211,Time used 0.004999s\n",
      "batch 11924, train_loss 23.128130,Time used 0.009004s\n",
      "batch 11925, train_loss 20.556427,Time used 0.007994s\n",
      "batch 11926, train_loss 21.073950,Time used 0.006001s\n",
      "batch 11927, train_loss 23.116199,Time used 0.007998s\n",
      "batch 11928, train_loss 26.322533,Time used 0.006000s\n",
      "batch 11929, train_loss 29.044987,Time used 0.004999s\n",
      "batch 11930, train_loss 22.016867,Time used 0.006000s\n",
      "batch 11931, train_loss 24.147099,Time used 0.008000s\n",
      "batch 11932, train_loss 26.257187,Time used 0.005004s\n",
      "batch 11933, train_loss 25.753235,Time used 0.007999s\n",
      "batch 11934, train_loss 18.257484,Time used 0.007002s\n",
      "batch 11935, train_loss 24.496809,Time used 0.005004s\n",
      "batch 11936, train_loss 21.780470,Time used 0.004999s\n",
      "batch 11937, train_loss 26.632404,Time used 0.005995s\n",
      "batch 11938, train_loss 22.983082,Time used 0.005001s\n",
      "batch 11939, train_loss 23.129196,Time used 0.006000s\n",
      "batch 11940, train_loss 23.116686,Time used 0.005000s\n",
      "batch 11941, train_loss 24.933800,Time used 0.006999s\n",
      "batch 11942, train_loss 23.451897,Time used 0.005002s\n",
      "batch 11943, train_loss 25.727184,Time used 0.005002s\n",
      "batch 11944, train_loss 23.362869,Time used 0.005998s\n",
      "batch 11945, train_loss 22.957798,Time used 0.006001s\n",
      "batch 11946, train_loss 22.334839,Time used 0.005000s\n",
      "batch 11947, train_loss 21.188198,Time used 0.005002s\n",
      "batch 11948, train_loss 24.240650,Time used 0.005998s\n",
      "batch 11949, train_loss 26.722303,Time used 0.005999s\n",
      "batch 11950, train_loss 20.368958,Time used 0.007001s\n",
      "batch 11951, train_loss 25.541666,Time used 0.005003s\n",
      "batch 11952, train_loss 20.016239,Time used 0.004999s\n",
      "batch 11953, train_loss 23.902996,Time used 0.006999s\n",
      "batch 11954, train_loss 19.339567,Time used 0.007010s\n",
      "batch 11955, train_loss 23.173368,Time used 0.005000s\n",
      "batch 11956, train_loss 24.664803,Time used 0.005001s\n",
      "batch 11957, train_loss 22.949242,Time used 0.006001s\n",
      "batch 11958, train_loss 25.671219,Time used 0.004996s\n",
      "batch 11959, train_loss 27.353333,Time used 0.005001s\n",
      "batch 11960, train_loss 22.655548,Time used 0.006998s\n",
      "batch 11961, train_loss 28.296061,Time used 0.008000s\n",
      "batch 11962, train_loss 21.993876,Time used 0.008002s\n",
      "batch 11963, train_loss 22.458750,Time used 0.005001s\n",
      "batch 11964, train_loss 23.124830,Time used 0.005002s\n",
      "batch 11965, train_loss 25.231930,Time used 0.005997s\n",
      "batch 11966, train_loss 24.190208,Time used 0.004999s\n",
      "batch 11967, train_loss 24.460403,Time used 0.006001s\n",
      "batch 11968, train_loss 21.918411,Time used 0.006039s\n",
      "batch 11969, train_loss 22.432398,Time used 0.004962s\n",
      "batch 11970, train_loss 23.766045,Time used 0.006034s\n",
      "batch 11971, train_loss 23.441534,Time used 0.005004s\n",
      "batch 11972, train_loss 18.643717,Time used 0.004999s\n",
      "batch 11973, train_loss 24.787582,Time used 0.006000s\n",
      "batch 11974, train_loss 23.508005,Time used 0.005002s\n",
      "batch 11975, train_loss 25.925877,Time used 0.004998s\n",
      "batch 11976, train_loss 23.706879,Time used 0.005004s\n",
      "batch 11977, train_loss 26.176058,Time used 0.005033s\n",
      "batch 11978, train_loss 24.518499,Time used 0.008964s\n",
      "batch 11979, train_loss 23.778402,Time used 0.005000s\n",
      "batch 11980, train_loss 21.787012,Time used 0.005038s\n",
      "batch 11981, train_loss 27.340206,Time used 0.005968s\n",
      "batch 11982, train_loss 22.707615,Time used 0.005000s\n",
      "batch 11983, train_loss 27.030790,Time used 0.007997s\n",
      "batch 11984, train_loss 20.164591,Time used 0.005999s\n",
      "batch 11985, train_loss 23.664942,Time used 0.006998s\n",
      "batch 11986, train_loss 24.656000,Time used 0.008000s\n",
      "batch 11987, train_loss 22.942295,Time used 0.006007s\n",
      "batch 11988, train_loss 23.644009,Time used 0.004993s\n",
      "batch 11989, train_loss 24.503902,Time used 0.006001s\n",
      "batch 11990, train_loss 22.582283,Time used 0.005001s\n",
      "batch 11991, train_loss 23.541504,Time used 0.005000s\n",
      "batch 11992, train_loss 24.244774,Time used 0.005001s\n",
      "batch 11993, train_loss 23.599758,Time used 0.006001s\n",
      "batch 11994, train_loss 21.739973,Time used 0.005039s\n",
      "batch 11995, train_loss 24.514811,Time used 0.006960s\n",
      "batch 11996, train_loss 21.799250,Time used 0.005000s\n",
      "batch 11997, train_loss 23.093441,Time used 0.004999s\n",
      "batch 11998, train_loss 24.644741,Time used 0.006002s\n",
      "batch 11999, train_loss 23.155289,Time used 0.006000s\n",
      "batch 12000, train_loss 20.707838,Time used 0.004999s\n",
      "***************************test_batch 12000, test_rmse_loss 6.467447,test_mae_loss 2.929548,test_mape_loss 50.259422,Time used 0.022000s\n",
      "The total time is 79.883001s\n"
     ]
    }
   ],
   "source": [
    "train_log = []\n",
    "test_log = []\n",
    "#开始时间\n",
    "timestart = time.time()\n",
    "trained_batches = 0 #记录多少个batch\n",
    "for epoch in range(500):\n",
    "\n",
    "    total_1oss = 0 #记录Loss\n",
    "    for batch in next_batch(shuffle(train_set), batch_size=128):\n",
    "        #每一个batch的开始时间\n",
    "        batchstart = time.time()\n",
    "\n",
    "        batch = torch.from_numpy(batch).float().to(device)  # (batch, seq_len)\n",
    "        # 使用短序列的前12个值作为历史，最后一个值作为预测值。\n",
    "        x, label = batch[:, :6,:], batch[:, -1,:]\n",
    "        # print(x.unsqueeze(-1).shape)\n",
    "        out, hidden = torch_lstm(x)  # out: (batch_size, seq_len, hidden_size)\n",
    "        out = output_model(out[:, -1, :])\n",
    "        prediction = out  # (batch)\n",
    "#         print(prediction.shape,label.shape)\n",
    "        loss = loss_func(prediction, label)\n",
    "#         print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #correct += (prediction == label).sum().item()\n",
    "        #累加loss\n",
    "        #total_1oss += loss.item( )\n",
    "        trained_batches += 1\n",
    "         #计算平均loss与准确率\n",
    "        #train_loss = total_1oss / train_batch_num\n",
    "        #train_log.append(train_loss)\n",
    "        train_log.append(loss.detach().cpu().numpy().tolist())\n",
    "\n",
    "        train_batch_time = (time.time() - batchstart)\n",
    "        print('batch %d, train_loss %.6f,Time used %.6fs'%(trained_batches, loss,train_batch_time))\n",
    "        print('batch %d, train_loss %.6f,Time used %.6fs'%(trained_batches, loss,train_batch_time),file=f)\n",
    "\n",
    "        # 每训练一定数量的batch，就在测试集上测试模型效果。\n",
    "        if trained_batches % 100 == 0:\n",
    "            #每一个batch的开始时间\n",
    "            batch_test_start = time.time()\n",
    "            #在每个epoch上测试\n",
    "            all_prediction = []\n",
    "            for batch in next_batch(test_set, batch_size=128):\n",
    "                batch = torch.from_numpy(batch).float().to(device)  # (batch, seq_len)\n",
    "                x, label = batch[:, :6,:], batch[:, -1,:]\n",
    "                out, hidden = torch_lstm(x)  # out: (batch_size, seq_len, hidden_size)\n",
    "                out = output_model(out[:, -1, :])\n",
    "                prediction = out  # (batch)\n",
    "                all_prediction.append(prediction.detach().cpu().numpy())\n",
    "\n",
    "            all_prediction = np.concatenate(all_prediction)\n",
    "            all_label = test_set[:, -1]\n",
    "            # 没有进行反归一化操作。\n",
    "            #all_prediction = denormalize(all_prediction)\n",
    "            #all_label = denormalize(all_label)\n",
    "            # 计算测试指标。\n",
    "            rmse_score = math.sqrt(mse(all_label, all_prediction))\n",
    "            mae_score = mae(all_label, all_prediction)\n",
    "            mape_score = mape(all_label, all_prediction)\n",
    "            test_log.append([rmse_score, mae_score, mape_score])\n",
    "            test_batch_time = (time.time() - batch_test_start)\n",
    "            print('***************************test_batch %d, test_rmse_loss %.6f,test_mae_loss %.6f,test_mape_loss %.6f,Time used %.6fs'%(trained_batches, rmse_score,mae_score,mape_score,test_batch_time))\n",
    "            print('***************************test_batch %d, test_rmse_loss %.6f,test_mae_loss %.6f,test_mape_loss %.6f,Time used %.6fs'%(trained_batches, rmse_score,mae_score,mape_score,test_batch_time),file=f)\n",
    "\n",
    "#计算总时间\n",
    "timesum = (time.time() - timestart)\n",
    "print('The total time is %fs'%(timesum))\n",
    "print('The total time is %fs'%(timesum),file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_loss曲线\n",
    "x = np.linspace(0,len(train_log),len(train_log))\n",
    "plt.plot(x,train_log,label=\"train_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('./figure/1.4torchLSTMtrainloss1.jpg')\n",
    "plt.show()\n",
    "#plt.clf()\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,0],label=\"test_rmse_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('./figure/1.4torchLSTMtestrmseloss1.jpg')\n",
    "plt.show()\n",
    "#plt.clf()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,1],label=\"test_mae_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('./figure/1.4torchLSTMtestrmaeloss1.jpg')\n",
    "plt.show()\n",
    "#plt.clf()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,2],label=\"test_mape_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('./figure/1.4torchLSTMtestrmapeloss1.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_loss曲线\n",
    "x = np.linspace(0,len(train_log),len(train_log))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x,train_log,label=\"train_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(x_test,test_log[:,0],label=\"test_rmse_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(x_test,test_log[:,1],label=\"test_mae_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(x_test,test_log[:,2],label=\"test_mape_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig('./figure/LSTM-4-photo.jpg_32_64_128.jpg')\n",
    "plt.show()\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(Pytorch_RL)",
   "language": "python",
   "name": "pytorch_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}